# âœï¸ CoEdPilot

CoEdPilot is a Visual Studio Code extension that features automatic code edit recommendations, proposed by the paper "*CoEdPilot: Recommending Code Edits with Learned Prior Edit Relevance, Project-wise Awareness, and Interactive Nature*" by Chenyan Liu, Yufan Cai, Yun Lin, Yuhuan Huang, Yunrui Pei, Bo Jiang, Ping Yang, Jin Song Dong, and Hong Mei. Presented at ISSTA'24. 

If you are interested in the training and evaluation of the backend models, please refer to the [CoEdPilot](https://github.com/code-philia/CoEdPilot) repository.

## ğŸš€ Demo
> [!NOTE]
> Please click the image to watch the demo video on YouTube.

<div align="center">
   <a href="https://youtu.be/6G2-7Gf0Fhc">
   <img src="./media/demo_cover.png" width="600" />
   </a>
</div>

## âš™ï¸ Functionality

The extension introduces two major features: **Edit Locator** and **Edit Generator.** 

### Edit Locator

Combining a **ğŸ” file locator (discriminator) model** and a **ğŸ¯ line locator model.** It suggests edit locations according to *previous edits* and *current edit description.*

### Edit Generator

Based on a single **ğŸ“ generator model.** It generates replacements or insertions somewhere in the code, from suggested locations or manually selected. It also requires *previous edits* and *current edit description* and, in addition, the code to replace.

## âœ¨ UI

### Overview

![Overview](media/ui1.png)

+ Predicted locations will be displayed as a tree view in the left â¬…ï¸ and also highlighted in the active editor
+ Query status will be displayed in the status bar â†˜ï¸
+ Edit description is accepted in the input above â¬†ï¸

### Diff View

![Diff View](media/ui2.png)

Once performing a prediction on a line, a diff view is shown for switching â†”ï¸ or editing âœï¸ the prediction result.

## ğŸ§‘â€ğŸ’» Usage

1. Edit the code, as our extension will automatically record most previous edits.

2. Run `Predict Locations`: **right-click** anywhere in the editor and select it in the menu, or use the default keybinding `Ctrl` + `Alt` + `L` (in MacOS `Cmd` + `Alt` + `L`).

3. Run `Generate Edits`: select the code to be edited in the editor, then **right-click** and select it in the menu, or use the default keybinding `Ctrl` + `Alt` + `E` (in MacOS `Cmd` + `Alt` + `E`).

> [!NOTE]
> To select code for editing, you can:
>   * Click recommended locations in the left location list;
>   * Select part of the code for **replacing**;
>   * Select nothing to generate **insertion** code at the cursor position.
>
> And by default accepting an edit will trigger another location prediction immediately (you can change this in extension configuration).

4. Manually `Change Edit Description`: **right-click** and select it in the menu. By default the input box will automatically show at query **whenever the edit description is empty**.


5. After the model generates possible edits at that range, a difference tab with pop up for you to switch to different edits or edit the code. **There are buttons on the top right corner of the difference tab to accept, dismiss or switch among generated edits**.

## ğŸ› ï¸ Setup backend model

### Method 1: ğŸ³ Deploy via Docker (recommended ğŸ‘)
   > [!IMPORTANT]
   >   * This deployment method is not fully tested. Please feel free to raise issues if you encounter any problems;
   >   * MacOS is unable to use MPS acceleration via Docker, hence the following instructions are not applicable to MacOS.
   >   * If you need CUDA acceleration, your system **must have an NVIDIA GPU** with the **correct drivers installed**. Install the [NVIDIA Container Toolkit](https://learn.microsoft.com/en-us/windows/wsl/tutorials/gpu-compute).

   You can create a Docker image and start a Docker container according to the following steps to isolate the environment and simplify the backend model deployment.

   1. Navigate to the root directory of the CoEdPilot-extension project.

   2. Create the Docker image (For Linux / Windows with WSL):

      ```bash
      docker build -t coedpilot-extension --build-arg MIRROR_SOURCE=<MIRROR_SOURCE> --build-arg LANG=<LANG> .
      ```

      This command supports two `build-arg` parameters:

      - `MIRROR_SOURCE`: Specifies the mirror source for installing Python dependencies, e.g., `--build-arg MIRROR_SOURCE=https://pypi.tuna.tsinghua.edu.cn/simple`. If this argument is not provided, the mirror source will not be used for installing Python dependencies.
      - `LANG`: Specifies the model for different languages, e.g., `--build-arg LANG=javascript`. The supported languages are go, python, java, typescript, and javascript. If this argument is not provided, the default model language will be Python.

   3. Start the Docker container without GPU acceleration (Not recommended ğŸ‘):

      With the following command (with 5003 as default port):
      
      ```bash
      docker run -p 5003:5003 coedpilot-extension
      ```

   4. Start the Docker container with GPU acceleration (Recommended ğŸ‘):
      
      Start the Docker container with the following command (with 5003 as default port, please check the availability of this port):

      ```bash
      docker run --gpus all --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p 5003:5003 coedpilot-extension
      ```

   Now, the backend model is up and running. You can proceed to [setup the extension](#ï¸-extension-deployment) to use CoEdPilot-Extension.

   After the usage, you may follow the following command to stop and remove the Docker container and image.

   5. âš ï¸ Stop the Docker container:

      ```bash
      docker stop $(docker ps -a -q --filter ancestor=coedpilot-extension)
      ```

      This command stops all running containers based on the `coedpilot-extension` image.

   6. âš ï¸ Remove the Docker container:

      ```bash
      docker rm $(docker ps -a -q --filter ancestor=coedpilot-extension)
      ```

   7. âš ï¸ Remove the Docker image:

      ```bash
      docker rmi coedpilot-extension
      ```

### Method 2: Manual setup
   
   > [!IMPORTANT]
   > For *Windows* and *Linux using CUDA 11.8,* please follow [PyTorch official guide](https://pytorch.org/get-started/locally/) to install PyTorch with CUDA before the following steps.
   
   1. Install Python dependencies:
      Using `pip` (with Python 3.10):

      ```shell
      pip install -r requirements.txt
      ```

      Or using `conda` :

      ```shell
      conda create -n code-edit
      conda activate code-edit
      conda install python=3.10.13
      python -m pip install -r requirements.txt
      ```

   2. Download models into the project directory:

      As mentioned before, we respectively prepared 3 models (*file locator*(including embedding model, dependency analyzer and a regression model), *line locator*, and *generator*) for each language. Supported languages are `go`, `python`, `java`, `typescript` and `javascript`. You have 2 ways to download models.

      * **Method 2-1: Use init-server script (Recommended ğŸ‘)**

         Select <language> from `go`, `python`, `java`, `typescript` and `javascript` to download models for the language.

         ```bash
         python init-server.py <language>
         ```

      * **Method 2-2: Download manually**

         * Download and rename **models for different languages** and **dependency analyzer** from [Huggingface Collections](https://huggingface.co/collections/code-philia/coedpilot-65ee9df1b5e3b11755547205). 
            * `dependency-analyzer/`: dependency anaylzer model, available in [Huggingface](https://huggingface.co/code-philia/dependency-analyzer);
            * `embedding_model.bin`: embedding model for file locator, available in [Huggingface](https://huggingface.co/code-philia/CoEdPilot-file-locator);
            * `reg_model.pickle`: , linear regression model, available in [Huggingface](https://huggingface.co/code-philia/CoEdPilot-file-locator);
            * `locator_model.bin`: model for line locator, available in [Huggingface](https://huggingface.co/code-philia/CoEdPilot-line-locator), require renaming form `pytorch_model.bin` to `locator_model.bin`;
            * `generator_model.bin`: model for generator, available in [Huggingface](https://huggingface.co/code-philia/CoEdPilot-generator), require renaming from `pytorch_model.bin` to `generator_model.bin`.

         * To deploy models for one language, put its unzipped model folder **named with the language**.
            ```
            edit-pilot/
               models/
                     dependency-analyzer/
                     <language>/
                        embedding_model.bin
                        reg_model.pickle
                        locator_model.bin
                        generator_model.bin
            ```

   3. Start the backend:

      ```shell
      python src/model_server/server.py
      ```

      The backend will start listening on `http://localhost:5003` by default. If you want to change the host and port, please modify `src/model_server/server.ini`.

## ğŸ•¹ï¸ Extension deployment

> [!NOTE]
> Always remember to start up backend models before using the extension.

### Method 1: Install from VS Code extension store (Recommended ğŸ‘)

   1. Simply [donwload the extension](https://marketplace.visualstudio.com/items?itemName=CodePhilia.co-ed-pilot) from VS Code Extension Store.
   2. Open VS Code settings (press `Ctrl` + `,` / `Cmd` + `,`), search for `@ext:CodePhilia.co-ed-pilot`.
   3. Set `coEdPilot.queryUrl` to the server address, e.g., `http://localhost:5003` or `http://<SERVER_IP_ADDRESS>:<PORT>`.
   4. You are all set! Enjoy coding with CoEdPilot extension.

### Method 2: Run extension from VS Code development host (for temporary testing and development purposes)

   > [!NOTE] 
   > * Require Node.js (version >= 16). If Node.js not installed, please follow [Node.js official website](https://nodejs.org/en/download) to intall;
   > * Other extensions will be disabled in the development host.

   1. In the project root directory, install Node packages:

      ```shell
      npm install
      ```
   
   2. Open the project directory in VS Code. Press `F5`, then choose `Run Extension` if you are required to choose a configuration. A new VS Code window (the "development host") will open with CoEdPilot extension loaded. 

   3. You are all set! Enjoy coding with CoEdPilot extension.

### Method 3: Package extension as `.vsix` (for long-term usage)

   1. Make sure you have `yarn` installed.

      ```shell
      npm install -g yarn
      npm install -g vsce
      ```

   2. Execute the following command in the project root directory:

      ```shell
      yarn package
      ```

      This command will generate a `.vsix` file in the project root directory, based on the `package.json` file.

   3. Open the VS Code command palette (`Ctrl` + `Shift` + `P` / `Cmd` + `Shift` + `P`), then select `Extensions: Install from VSIX...` and choose the `.vsix` file generated in the previous step.

   4. Open VS Code settings (press `Ctrl` + `,` / `Cmd` + `,`), search for `@ext:CodePhilia.co-ed-pilot`.

   5. Set `coEdPilot.queryUrl` to the server address, e.g., `http://localhost:5003` or `http://<SERVER_IP_ADDRESS>:<PORT>`.

   6. You are all set! Enjoy coding with CoEdPilot extension.

## â“ Issues

The project is still in development, not fully tested on different platforms. 

Welcome to propose issues or contribute to the code.

**ğŸ˜„ Enjoy coding!**

æˆ‘ç°åœ¨å°±æ˜¯ä¸»è¦æŠŠå·¥ç¨‹æ–¹é¢å·®ä¸å¤šæå¥½äº†ï¼Œè¿˜å·®ä¸€äº›ï¼Œç”¨çš„å°±æ˜¯coedpiloté‡Œçš„æ¨¡å‹ã€‚ç°åœ¨å°±æ˜¯ä¸»è¦æƒ³æ‰¾ä¸€äº›åˆ›æ–°ç‚¹ï¼Œå·¥ç¨‹æ–¹é¢çš„è¯å¯ä»¥åšä¸€äº›ä¼˜åŒ–ï¼Œä¸è¿‡è¿˜æ˜¯æ¯”è¾ƒéº»çƒ¦ã€‚ç„¶åæˆ‘å¤šæ‰¾é‚“å¸ˆå…„æ²Ÿé€šä¸€ä¸‹ï¼Ÿ


è§¦å‘çš„æ¡ä»¶ï¼Ÿ
1. åˆ†æé”™è¯¯case
2. æ”¶é›†æ•°æ®ï¼Œ å¦‚ä½•çŸ¥é“ç”¨æˆ·å…ˆç¼–è¾‘äº†å“ªä¸ªhunk? èƒ½å¦å…ˆè®¾è®¡ä¸€äº›å¯å‘å¼ç®—æ³•æˆ– æ’åº  
æ˜¯å¦èƒ½å°†commit è§£è€¦æˆä¸€ä¸ªä¸ªçš„å°edit  edit sequence
å˜æˆå¯ä»¥è®­ç»ƒçš„editsæ•°æ®


å¾®è°ƒ1.3bçš„æ¨¡å‹ï¼Ÿ

generalçš„editå¹¶ä¸å…³å¿ƒ, ä»£ç è¡¥å…¨æˆ‘ä»¬å¹¶ä¸å…³å¿ƒ æ•°æ®ç­›é€‰æ—¶ ç¼–è¾‘è¡¥å…¨ä¸ä¸€æ ·

1æœˆ16æ—¥
åšä¸ªppt å±•ç¤ºæ’ä»¶

1: 'user_control_state = 1\r\n\r\ndef get_user_control_state():\r\n    global user_control_state\r\n    return user_control_state\r\n\r\ndef set_user_control_state(new_state):\r\n    global user_control_state\r\n    user_control_state = new_state\r\n    print("user_control_state set to ", user_control_state)'

1: 'ï»¿import asyncio\r\nimport logging\r\nimport uuid\r\nfrom datetime import datetime\r\nfrom typing import Callable\r\nimport time\r\n\r\nfrom data_types.account import Account\r\nfrom data_types.chat_messages import DetailMessage, TextMessage\r\nfrom routes.websocket_manager import websocket_manager, WebSocketManager\r\nfrom data_types.client_messages import Channel\r\nfrom senders.wechat_sender import WeChatSenderClient\r\nfrom senders.mp_sender import MiniProgramSenderClient\r\nfrom data_types.system_signals import Statâ€¦= None):\r\n    await sender.send_message(user_id, message)\r\n\r\n\r\nasync def check_received(user_id, fake_msg_id, msg_id, create_time, channel: Channel):\r\n    await sender.check_received(user_id, fake_msg_id, msg_id, create_time, channel)\r\n\r\n\r\nasync def update_last_online_time(user_id, channel: Channel):\r\n    await sender.update_last_online_time(user_id, channel)\r\n\r\nasync def send_system_status_signal(user_id: str, status: StatusSignal):\r\n    await sender.send_system_status_signal(user_id, status)'