{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep replace replace keep keep keep", "code_tokens": " <mask> \n <mask> Patterns for Flask\n <mask> ==================\n <mask> \n <mask> Certain things are common enough that the chances are high you will find\n <mask> them in most web applications.  For example quite a lot of applications\n <mask> are using relational databases and user authentication.  In that case,\n <mask> chances are they will open a database connection at the beginning of the\n <mask> request and get the information of the currently logged in user.  At the\n <mask> end of the request, the database connection is closed again.\n <mask> \n <mask> There are more user contributed snippets and patterns in the `Flask\n <mask> Snippet Archives <http://flask.pocoo.org/snippets/>`_.\n <mask> \n <mask> .. toctree::\n <mask>    :maxdepth: 2\n </s> update patterns, snippets, extensions docs </s> remove :ref:`signals`. You can provide custom classes for things like the request and\nresponse objects.  Dig deeper on the APIs you use, and look for the\ncustomizations which are available out of the box in a Flask release.  Look for\nways in which your project can be refactored into a collection of utilities and\nFlask extensions.  Explore the many `extensions\n<http://flask.pocoo.org/extensions/>`_ in the community, and look for patterns to\nbuild your own extensions if you do not find the tools you need.\n </s> add :ref:`signals`. You can provide custom classes for things like the\nrequest and response objects. Dig deeper on the APIs you use, and look\nfor the customizations which are available out of the box in a Flask\nrelease. Look for ways in which your project can be refactored into a\ncollection of utilities and Flask extensions. Explore the many\n:doc:`/extensions` in the community, and look for patterns to build your\nown extensions if you do not find the tools you need. </s> remove     extension author would like to move beyond the project, the project should\n    find a new maintainer including full source hosting transition and PyPI\n    access.  If no maintainer is available, give access to the Flask core team.\n1.  An approved Flask extension must provide exactly one package or module\n    named ``flask_extensionname``.\n2.  It must ship a testing suite that can either be invoked with ``make test``\n    or ``python setup.py test``.  For test suites invoked with ``make\n    test`` the extension has to ensure that all dependencies for the test\n    are installed automatically.  If tests are invoked with ``python setup.py\n    test``, test dependencies can be specified in the :file:`setup.py` file.  The\n    test suite also has to be part of the distribution.\n3.  APIs of approved extensions will be checked for the following\n    characteristics:\n\n   -   an approved extension has to support multiple applications\n       running in the same Python process.\n   -   it must be possible to use the factory pattern for creating\n       applications.\n\n4.  The license must be BSD/MIT/WTFPL licensed.\n5.  The naming scheme for official extensions is *Flask-ExtensionName* or\n    *ExtensionName-Flask*.\n6.  Approved extensions must define all their dependencies in the\n    :file:`setup.py` file unless a dependency cannot be met because it is not\n    available on PyPI.\n7.  The documentation must use the ``flask`` theme from the\n    `Official Pallets Themes`_.\n8.  The setup.py description (and thus the PyPI description) has to\n    link to the documentation, website (if there is one) and there\n    must be a link to automatically install the development version\n    (``PackageName==dev``).\n9. The ``zip_safe`` flag in the setup script must be set to ``False``,\n   even if the extension would be safe for zipping.\n10. An extension currently has to support Python 3.4 and newer and 2.7.\n </s> add     extension author would like to move beyond the project, the project\n    should find a new maintainer and transfer access to the repository,\n    documentation, PyPI, and any other services. If no maintainer\n    is available, give access to the Pallets core team.\n1.  The naming scheme is *Flask-ExtensionName* or *ExtensionName-Flask*.\n    It must provide exactly one package or module named\n    ``flask_extension_name``.\n2.  The extension must be BSD or MIT licensed. It must be open source\n    and publicly available.\n3.  The extension's API must have the following characteristics:\n\n    -   It must support multiple applications running in the same Python\n        process. Use ``current_app`` instead of ``self.app``, store\n        configuration and state per application instance.\n    -   It must be possible to use the factory pattern for creating\n        applications. Use the ``ext.init_app()`` pattern.\n\n4.  From a clone of the repository, an extension with its dependencies\n    must be installable with ``pip install -e .``.\n5.  It must ship a testing suite that can be invoked with ``tox -e py``\n    or ``pytest``. If not using ``tox``, the test dependencies should be\n    specified in a ``requirements.txt`` file. The tests must be part of\n    the sdist distribution.\n6.  The documentation must use the ``flask`` theme from the\n    `Official Pallets Themes`_. A link to the documentation or project\n    website must be in the PyPI metadata or the readme.\n7.  The active versions of Python should be supported. As of 2020 this\n    means Python 3.5 and newer. </s> remove     from werkzeug.contrib.fixers import LighttpdCGIRootFix\n    app.wsgi_app = LighttpdCGIRootFix(app.wsgi_app)\n </s> add .. code-block:: python\n\n    from werkzeug.middleware.proxy_fix import ProxyFix\n    app.wsgi_app = ProxyFix(app.wsgi_app)\n\nWrapping ``app.wsgi_app`` instead of ``app`` means that ``app`` still\npoints at your Flask application, not at the middleware, so you can\ncontinue to use and configure ``app`` directly. </s> remove Flask also has the concept of approved extensions.  Approved extensions\nare tested as part of Flask itself to ensure extensions do not break on\nnew releases.  If you want your own extension to be approved you have to\nfollow these guidelines:\n </s> add Flask previously had the concept of approved extensions. These came with\nsome vetting of support and compatibility. While this list became too\ndifficult to maintain over time, the guidelines are still relevant to\nall extensions maintained and developed today, as they help the Flask\necosystem remain consistent and compatible. </s> remove :doc:`extensiondev`.\n </s> add :doc:`/extensiondev`.", "html_url": "https://github.com/pallets/flask/commit/e01b68e7ee66f7c5ec221bcb9e0cd3526153664d", "file_name": "docs/patterns/index.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> loaded upfront.  The trick is to actually load the view function as needed.\n <mask> This can be accomplished with a helper class that behaves just like a\n <mask> function but internally imports the real function on first use::\n <mask> \n <mask>     from werkzeug import import_string, cached_property\n <mask> \n <mask>     class LazyView(object):\n <mask> \n <mask>         def __init__(self, import_name):\n <mask>             self.__module__, self.__name__ = import_name.rsplit('.', 1)\n </s> update patterns, snippets, extensions docs </s> remove     from werkzeug import SharedDataMiddleware\n </s> add     from werkzeug.middleware.shared_data import SharedDataMiddleware </s> remove :ref:`signals`. You can provide custom classes for things like the request and\nresponse objects.  Dig deeper on the APIs you use, and look for the\ncustomizations which are available out of the box in a Flask release.  Look for\nways in which your project can be refactored into a collection of utilities and\nFlask extensions.  Explore the many `extensions\n<http://flask.pocoo.org/extensions/>`_ in the community, and look for patterns to\nbuild your own extensions if you do not find the tools you need.\n </s> add :ref:`signals`. You can provide custom classes for things like the\nrequest and response objects. Dig deeper on the APIs you use, and look\nfor the customizations which are available out of the box in a Flask\nrelease. Look for ways in which your project can be refactored into a\ncollection of utilities and Flask extensions. Explore the many\n:doc:`/extensions` in the community, and look for patterns to build your\nown extensions if you do not find the tools you need. </s> remove     extension author would like to move beyond the project, the project should\n    find a new maintainer including full source hosting transition and PyPI\n    access.  If no maintainer is available, give access to the Flask core team.\n1.  An approved Flask extension must provide exactly one package or module\n    named ``flask_extensionname``.\n2.  It must ship a testing suite that can either be invoked with ``make test``\n    or ``python setup.py test``.  For test suites invoked with ``make\n    test`` the extension has to ensure that all dependencies for the test\n    are installed automatically.  If tests are invoked with ``python setup.py\n    test``, test dependencies can be specified in the :file:`setup.py` file.  The\n    test suite also has to be part of the distribution.\n3.  APIs of approved extensions will be checked for the following\n    characteristics:\n\n   -   an approved extension has to support multiple applications\n       running in the same Python process.\n   -   it must be possible to use the factory pattern for creating\n       applications.\n\n4.  The license must be BSD/MIT/WTFPL licensed.\n5.  The naming scheme for official extensions is *Flask-ExtensionName* or\n    *ExtensionName-Flask*.\n6.  Approved extensions must define all their dependencies in the\n    :file:`setup.py` file unless a dependency cannot be met because it is not\n    available on PyPI.\n7.  The documentation must use the ``flask`` theme from the\n    `Official Pallets Themes`_.\n8.  The setup.py description (and thus the PyPI description) has to\n    link to the documentation, website (if there is one) and there\n    must be a link to automatically install the development version\n    (``PackageName==dev``).\n9. The ``zip_safe`` flag in the setup script must be set to ``False``,\n   even if the extension would be safe for zipping.\n10. An extension currently has to support Python 3.4 and newer and 2.7.\n </s> add     extension author would like to move beyond the project, the project\n    should find a new maintainer and transfer access to the repository,\n    documentation, PyPI, and any other services. If no maintainer\n    is available, give access to the Pallets core team.\n1.  The naming scheme is *Flask-ExtensionName* or *ExtensionName-Flask*.\n    It must provide exactly one package or module named\n    ``flask_extension_name``.\n2.  The extension must be BSD or MIT licensed. It must be open source\n    and publicly available.\n3.  The extension's API must have the following characteristics:\n\n    -   It must support multiple applications running in the same Python\n        process. Use ``current_app`` instead of ``self.app``, store\n        configuration and state per application instance.\n    -   It must be possible to use the factory pattern for creating\n        applications. Use the ``ext.init_app()`` pattern.\n\n4.  From a clone of the repository, an extension with its dependencies\n    must be installable with ``pip install -e .``.\n5.  It must ship a testing suite that can be invoked with ``tox -e py``\n    or ``pytest``. If not using ``tox``, the test dependencies should be\n    specified in a ``requirements.txt`` file. The tests must be part of\n    the sdist distribution.\n6.  The documentation must use the ``flask`` theme from the\n    `Official Pallets Themes`_. A link to the documentation or project\n    website must be in the PyPI metadata or the readme.\n7.  The active versions of Python should be supported. As of 2020 this\n    means Python 3.5 and newer. </s> remove `IRC channel`_ to get some ideas for nice looking APIs.  Especially if you do\n </s> add `Discord server`_ to get some ideas for nice looking APIs.  Especially if you do </s> remove :doc:`extensiondev`.\n </s> add :doc:`/extensiondev`. </s> remove     from werkzeug.contrib.fixers import LighttpdCGIRootFix\n    app.wsgi_app = LighttpdCGIRootFix(app.wsgi_app)\n </s> add .. code-block:: python\n\n    from werkzeug.middleware.proxy_fix import ProxyFix\n    app.wsgi_app = ProxyFix(app.wsgi_app)\n\nWrapping ``app.wsgi_app`` instead of ``app`` means that ``app`` still\npoints at your Flask application, not at the middleware, so you can\ncontinue to use and configure ``app`` directly.", "html_url": "https://github.com/pallets/flask/commit/e01b68e7ee66f7c5ec221bcb9e0cd3526153664d", "file_name": "docs/patterns/lazyloading.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> docs for more information.\n <mask> \n <mask> Read more on :ref:`application-errors`.\n <mask> \n <mask> Hooking in WSGI Middlewares\n <mask> ---------------------------\n <mask> \n <mask> If you want to add a WSGI middleware to your application you can wrap the\n <mask> internal WSGI application.  For example if you want to use one of the\n <mask> middlewares from the Werkzeug package to work around bugs in lighttpd, you\n <mask> can do it like this::\n </s> update patterns, snippets, extensions docs </s> remove If you want to add a WSGI middleware to your application you can wrap the\ninternal WSGI application.  For example if you want to use one of the\nmiddlewares from the Werkzeug package to work around bugs in lighttpd, you\ncan do it like this::\n </s> add To add WSGI middleware to your Flask application, wrap the application's\n``wsgi_app`` attribute. For example, to apply Werkzeug's\n:class:`~werkzeug.middlware.proxy_fix.ProxyFix` middleware for running\nbehind Nginx: </s> remove     from werkzeug.contrib.fixers import LighttpdCGIRootFix\n    app.wsgi_app = LighttpdCGIRootFix(app.wsgi_app)\n </s> add .. code-block:: python\n\n    from werkzeug.middleware.proxy_fix import ProxyFix\n    app.wsgi_app = ProxyFix(app.wsgi_app)\n\nWrapping ``app.wsgi_app`` instead of ``app`` means that ``app`` still\npoints at your Flask application, not at the middleware, so you can\ncontinue to use and configure ``app`` directly. </s> remove `IRC channel`_ to get some ideas for nice looking APIs.  Especially if you do\n </s> add `Discord server`_ to get some ideas for nice looking APIs.  Especially if you do </s> remove :ref:`signals`. You can provide custom classes for things like the request and\nresponse objects.  Dig deeper on the APIs you use, and look for the\ncustomizations which are available out of the box in a Flask release.  Look for\nways in which your project can be refactored into a collection of utilities and\nFlask extensions.  Explore the many `extensions\n<http://flask.pocoo.org/extensions/>`_ in the community, and look for patterns to\nbuild your own extensions if you do not find the tools you need.\n </s> add :ref:`signals`. You can provide custom classes for things like the\nrequest and response objects. Dig deeper on the APIs you use, and look\nfor the customizations which are available out of the box in a Flask\nrelease. Look for ways in which your project can be refactored into a\ncollection of utilities and Flask extensions. Explore the many\n:doc:`/extensions` in the community, and look for patterns to build your\nown extensions if you do not find the tools you need. </s> remove create your own. Read :ref:`extension-dev` to develop your own Flask\n </s> add create your own. Read :doc:`/extensiondev` to develop your own Flask </s> remove     extension author would like to move beyond the project, the project should\n    find a new maintainer including full source hosting transition and PyPI\n    access.  If no maintainer is available, give access to the Flask core team.\n1.  An approved Flask extension must provide exactly one package or module\n    named ``flask_extensionname``.\n2.  It must ship a testing suite that can either be invoked with ``make test``\n    or ``python setup.py test``.  For test suites invoked with ``make\n    test`` the extension has to ensure that all dependencies for the test\n    are installed automatically.  If tests are invoked with ``python setup.py\n    test``, test dependencies can be specified in the :file:`setup.py` file.  The\n    test suite also has to be part of the distribution.\n3.  APIs of approved extensions will be checked for the following\n    characteristics:\n\n   -   an approved extension has to support multiple applications\n       running in the same Python process.\n   -   it must be possible to use the factory pattern for creating\n       applications.\n\n4.  The license must be BSD/MIT/WTFPL licensed.\n5.  The naming scheme for official extensions is *Flask-ExtensionName* or\n    *ExtensionName-Flask*.\n6.  Approved extensions must define all their dependencies in the\n    :file:`setup.py` file unless a dependency cannot be met because it is not\n    available on PyPI.\n7.  The documentation must use the ``flask`` theme from the\n    `Official Pallets Themes`_.\n8.  The setup.py description (and thus the PyPI description) has to\n    link to the documentation, website (if there is one) and there\n    must be a link to automatically install the development version\n    (``PackageName==dev``).\n9. The ``zip_safe`` flag in the setup script must be set to ``False``,\n   even if the extension would be safe for zipping.\n10. An extension currently has to support Python 3.4 and newer and 2.7.\n </s> add     extension author would like to move beyond the project, the project\n    should find a new maintainer and transfer access to the repository,\n    documentation, PyPI, and any other services. If no maintainer\n    is available, give access to the Pallets core team.\n1.  The naming scheme is *Flask-ExtensionName* or *ExtensionName-Flask*.\n    It must provide exactly one package or module named\n    ``flask_extension_name``.\n2.  The extension must be BSD or MIT licensed. It must be open source\n    and publicly available.\n3.  The extension's API must have the following characteristics:\n\n    -   It must support multiple applications running in the same Python\n        process. Use ``current_app`` instead of ``self.app``, store\n        configuration and state per application instance.\n    -   It must be possible to use the factory pattern for creating\n        applications. Use the ``ext.init_app()`` pattern.\n\n4.  From a clone of the repository, an extension with its dependencies\n    must be installable with ``pip install -e .``.\n5.  It must ship a testing suite that can be invoked with ``tox -e py``\n    or ``pytest``. If not using ``tox``, the test dependencies should be\n    specified in a ``requirements.txt`` file. The tests must be part of\n    the sdist distribution.\n6.  The documentation must use the ``flask`` theme from the\n    `Official Pallets Themes`_. A link to the documentation or project\n    website must be in the PyPI metadata or the readme.\n7.  The active versions of Python should be supported. As of 2020 this\n    means Python 3.5 and newer.", "html_url": "https://github.com/pallets/flask/commit/e01b68e7ee66f7c5ec221bcb9e0cd3526153664d", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep replace replace replace replace keep replace replace keep keep keep keep", "code_tokens": " <mask> Hooking in WSGI Middlewares\n <mask> ---------------------------\n <mask> \n <mask> If you want to add a WSGI middleware to your application you can wrap the\n <mask> internal WSGI application.  For example if you want to use one of the\n <mask> middlewares from the Werkzeug package to work around bugs in lighttpd, you\n <mask> can do it like this::\n <mask> \n <mask>     from werkzeug.contrib.fixers import LighttpdCGIRootFix\n <mask>     app.wsgi_app = LighttpdCGIRootFix(app.wsgi_app)\n <mask> \n <mask> Using Flask Extensions\n <mask> ----------------------\n <mask> \n </s> update patterns, snippets, extensions docs </s> remove Hooking in WSGI Middlewares\n---------------------------\n </s> add Hooking in WSGI Middleware\n-------------------------- </s> remove `IRC channel`_ to get some ideas for nice looking APIs.  Especially if you do\n </s> add `Discord server`_ to get some ideas for nice looking APIs.  Especially if you do </s> remove Flask also has the concept of approved extensions.  Approved extensions\nare tested as part of Flask itself to ensure extensions do not break on\nnew releases.  If you want your own extension to be approved you have to\nfollow these guidelines:\n </s> add Flask previously had the concept of approved extensions. These came with\nsome vetting of support and compatibility. While this list became too\ndifficult to maintain over time, the guidelines are still relevant to\nall extensions maintained and developed today, as they help the Flask\necosystem remain consistent and compatible. </s> remove     extension author would like to move beyond the project, the project should\n    find a new maintainer including full source hosting transition and PyPI\n    access.  If no maintainer is available, give access to the Flask core team.\n1.  An approved Flask extension must provide exactly one package or module\n    named ``flask_extensionname``.\n2.  It must ship a testing suite that can either be invoked with ``make test``\n    or ``python setup.py test``.  For test suites invoked with ``make\n    test`` the extension has to ensure that all dependencies for the test\n    are installed automatically.  If tests are invoked with ``python setup.py\n    test``, test dependencies can be specified in the :file:`setup.py` file.  The\n    test suite also has to be part of the distribution.\n3.  APIs of approved extensions will be checked for the following\n    characteristics:\n\n   -   an approved extension has to support multiple applications\n       running in the same Python process.\n   -   it must be possible to use the factory pattern for creating\n       applications.\n\n4.  The license must be BSD/MIT/WTFPL licensed.\n5.  The naming scheme for official extensions is *Flask-ExtensionName* or\n    *ExtensionName-Flask*.\n6.  Approved extensions must define all their dependencies in the\n    :file:`setup.py` file unless a dependency cannot be met because it is not\n    available on PyPI.\n7.  The documentation must use the ``flask`` theme from the\n    `Official Pallets Themes`_.\n8.  The setup.py description (and thus the PyPI description) has to\n    link to the documentation, website (if there is one) and there\n    must be a link to automatically install the development version\n    (``PackageName==dev``).\n9. The ``zip_safe`` flag in the setup script must be set to ``False``,\n   even if the extension would be safe for zipping.\n10. An extension currently has to support Python 3.4 and newer and 2.7.\n </s> add     extension author would like to move beyond the project, the project\n    should find a new maintainer and transfer access to the repository,\n    documentation, PyPI, and any other services. If no maintainer\n    is available, give access to the Pallets core team.\n1.  The naming scheme is *Flask-ExtensionName* or *ExtensionName-Flask*.\n    It must provide exactly one package or module named\n    ``flask_extension_name``.\n2.  The extension must be BSD or MIT licensed. It must be open source\n    and publicly available.\n3.  The extension's API must have the following characteristics:\n\n    -   It must support multiple applications running in the same Python\n        process. Use ``current_app`` instead of ``self.app``, store\n        configuration and state per application instance.\n    -   It must be possible to use the factory pattern for creating\n        applications. Use the ``ext.init_app()`` pattern.\n\n4.  From a clone of the repository, an extension with its dependencies\n    must be installable with ``pip install -e .``.\n5.  It must ship a testing suite that can be invoked with ``tox -e py``\n    or ``pytest``. If not using ``tox``, the test dependencies should be\n    specified in a ``requirements.txt`` file. The tests must be part of\n    the sdist distribution.\n6.  The documentation must use the ``flask`` theme from the\n    `Official Pallets Themes`_. A link to the documentation or project\n    website must be in the PyPI metadata or the readme.\n7.  The active versions of Python should be supported. As of 2020 this\n    means Python 3.5 and newer. </s> remove to contact the developers on the mailing list or IRC channel.  The best way for\n </s> add to contact the developers on the mailing list or Discord server.  The best way for", "html_url": "https://github.com/pallets/flask/commit/e01b68e7ee66f7c5ec221bcb9e0cd3526153664d", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         return \"Hello World\"\n <mask> \n <mask>     rv = client.get(\"/\", \"http://www.example.com:8080/test/\")\n <mask>     cookie = rv.headers[\"set-cookie\"].lower()\n <mask>     assert \"domain=.example.com\" in cookie\n <mask>     assert \"path=/\" in cookie\n <mask>     assert \"secure\" in cookie\n </s> avoid triggering setupmethod late in tests </s> remove     @app.route(\"/clear\")\n    def clear():\n        flask.session.pop(\"testing\", None)\n        return \"Goodbye World\"\n\n </s> add  </s> remove     app.debug = True\n    with pytest.raises(KeyError) as e:\n        client.get(\"/key\")\n    assert e.errisinstance(BadRequest)\n    assert \"missing_key\" in e.value.get_description()\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add         assert exc_info.errisinstance(BadRequest)\n        assert \"missing_key\" in exc_info.value.get_description() </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\") </s> remove     assert \"A setup function was called\" in str(e.value)\n\n    app.debug = False\n\n    @app.route(\"/foo\")\n    def working():\n        return \"Meh\"\n\n    assert client.get(\"/foo\").data == b\"Meh\"\n    assert app.got_first_request\n </s> add     assert \"setup method 'add_url_rule'\" in str(exc_info.value) </s> remove     app.debug = False\n    app.config[\"TRAP_BAD_REQUEST_ERRORS\"] = True\n    with pytest.raises(KeyError):\n        client.get(\"/key\")\n    with pytest.raises(BadRequest):\n        client.get(\"/abort\")\n </s> add     if expect_abort:\n        rv = client.get(\"/abort\")\n        assert rv.status_code == 400\n    else:\n        with pytest.raises(BadRequest):\n            client.get(\"/abort\") </s> remove     assert \"canonical URL 'http://localhost/foo/'\" in str(e.value)\n </s> add     assert \"canonical URL 'http://localhost/user/'\" in str(exc_info.value)", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     assert \"secure\" in cookie\n <mask>     assert \"httponly\" not in cookie\n <mask>     assert \"samesite\" in cookie\n <mask> \n <mask>     @app.route(\"/clear\")\n <mask>     def clear():\n <mask>         flask.session.pop(\"testing\", None)\n <mask>         return \"Goodbye World\"\n <mask> \n <mask>     rv = client.get(\"/clear\", \"http://www.example.com:8080/test/\")\n <mask>     cookie = rv.headers[\"set-cookie\"].lower()\n <mask>     assert \"session=;\" in cookie\n <mask>     assert \"domain=.example.com\" in cookie\n <mask>     assert \"path=/\" in cookie\n </s> avoid triggering setupmethod late in tests </s> add     @app.route(\"/clear\")\n    def clear():\n        flask.session.pop(\"testing\", None)\n        return \"Goodbye World\"\n </s> remove     app.debug = True\n    with pytest.raises(KeyError) as e:\n        client.get(\"/key\")\n    assert e.errisinstance(BadRequest)\n    assert \"missing_key\" in e.value.get_description()\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add         assert exc_info.errisinstance(BadRequest)\n        assert \"missing_key\" in exc_info.value.get_description() </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\") </s> remove     assert \"A setup function was called\" in str(e.value)\n\n    app.debug = False\n\n    @app.route(\"/foo\")\n    def working():\n        return \"Meh\"\n\n    assert client.get(\"/foo\").data == b\"Meh\"\n    assert app.got_first_request\n </s> add     assert \"setup method 'add_url_rule'\" in str(exc_info.value) </s> remove     assert \"canonical URL 'http://localhost/foo/'\" in str(e.value)\n </s> add     assert \"canonical URL 'http://localhost/user/'\" in str(exc_info.value) </s> remove     with pytest.raises(AssertionError) as e:\n </s> add     with pytest.raises(AssertionError) as exc_info:", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     rv = client.get(\"/E3\")\n <mask>     assert rv.data == b\"E2\"\n <mask> \n <mask> \n <mask> def test_trapping_of_bad_request_key_errors(app, client):\n <mask>     @app.route(\"/key\")\n <mask>     def fail():\n <mask>         flask.request.form[\"missing_key\"]\n <mask> \n <mask>     @app.route(\"/abort\")\n </s> avoid triggering setupmethod late in tests </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\") </s> remove     @app.route(\"/foo/\", methods=[\"GET\", \"POST\"])\n    def foo():\n        return \"success\"\n </s> add     app.config[\"DEBUG\"] = True </s> remove     app.debug = False\n    rv = client.post(\"/foo\", data={}, follow_redirects=True)\n    assert rv.data == b\"success\"\n </s> add     @app.route(\"/user/\", methods=[\"GET\", \"POST\"])\n    def user():\n        return flask.request.form[\"status\"] </s> remove     app.debug = False\n    app.config[\"TRAP_BAD_REQUEST_ERRORS\"] = True\n    with pytest.raises(KeyError):\n        client.get(\"/key\")\n    with pytest.raises(BadRequest):\n        client.get(\"/abort\")\n </s> add     if expect_abort:\n        rv = client.get(\"/abort\")\n        assert rv.status_code == 400\n    else:\n        with pytest.raises(BadRequest):\n            client.get(\"/abort\") </s> remove     app.debug = True\n\n    with client:\n        rv = client.post(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n        rv = client.get(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n </s> add     # default redirect code preserves form data\n    rv = client.post(\"/user\", data={\"status\": \"success\"}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> remove     assert \"A setup function was called\" in str(e.value)\n\n    app.debug = False\n\n    @app.route(\"/foo\")\n    def working():\n        return \"Meh\"\n\n    assert client.get(\"/foo\").data == b\"Meh\"\n    assert app.got_first_request\n </s> add     assert \"setup method 'add_url_rule'\" in str(exc_info.value)", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep replace replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>     @app.route(\"/abort\")\n <mask>     def allow_abort():\n <mask>         flask.abort(400)\n <mask> \n <mask>     rv = client.get(\"/key\")\n <mask>     assert rv.status_code == 400\n <mask>     assert b\"missing_key\" not in rv.data\n <mask>     rv = client.get(\"/abort\")\n <mask>     assert rv.status_code == 400\n <mask> \n <mask>     app.debug = True\n <mask>     with pytest.raises(KeyError) as e:\n <mask>         client.get(\"/key\")\n <mask>     assert e.errisinstance(BadRequest)\n <mask>     assert \"missing_key\" in e.value.get_description()\n <mask>     rv = client.get(\"/abort\")\n <mask>     assert rv.status_code == 400\n <mask> \n <mask>     app.debug = False\n <mask>     app.config[\"TRAP_BAD_REQUEST_ERRORS\"] = True\n </s> avoid triggering setupmethod late in tests </s> remove     app.debug = False\n    app.config[\"TRAP_BAD_REQUEST_ERRORS\"] = True\n    with pytest.raises(KeyError):\n        client.get(\"/key\")\n    with pytest.raises(BadRequest):\n        client.get(\"/abort\")\n </s> add     if expect_abort:\n        rv = client.get(\"/abort\")\n        assert rv.status_code == 400\n    else:\n        with pytest.raises(BadRequest):\n            client.get(\"/abort\") </s> remove     app.debug = True\n\n    with client:\n        rv = client.post(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n        rv = client.get(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n </s> add     # default redirect code preserves form data\n    rv = client.post(\"/user\", data={\"status\": \"success\"}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> remove     @app.route(\"/foo/\", methods=[\"GET\", \"POST\"])\n    def foo():\n        return \"success\"\n </s> add     app.config[\"DEBUG\"] = True </s> remove     app.debug = False\n    rv = client.post(\"/foo\", data={}, follow_redirects=True)\n    assert rv.data == b\"success\"\n </s> add     @app.route(\"/user/\", methods=[\"GET\", \"POST\"])\n    def user():\n        return flask.request.form[\"status\"] </s> remove     with pytest.raises(AssertionError) as e:\n </s> add     with pytest.raises(AssertionError) as exc_info:", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     assert \"missing_key\" in e.value.get_description()\n <mask>     rv = client.get(\"/abort\")\n <mask>     assert rv.status_code == 400\n <mask> \n <mask>     app.debug = False\n <mask>     app.config[\"TRAP_BAD_REQUEST_ERRORS\"] = True\n <mask>     with pytest.raises(KeyError):\n <mask>         client.get(\"/key\")\n <mask>     with pytest.raises(BadRequest):\n <mask>         client.get(\"/abort\")\n <mask> \n <mask> \n <mask> def test_trapping_of_all_http_exceptions(app, client):\n <mask>     app.config[\"TRAP_HTTP_EXCEPTIONS\"] = True\n <mask> \n </s> avoid triggering setupmethod late in tests </s> remove     app.debug = True\n    with pytest.raises(KeyError) as e:\n        client.get(\"/key\")\n    assert e.errisinstance(BadRequest)\n    assert \"missing_key\" in e.value.get_description()\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add         assert exc_info.errisinstance(BadRequest)\n        assert \"missing_key\" in exc_info.value.get_description() </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\") </s> remove     app.debug = True\n\n    with client:\n        rv = client.post(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n        rv = client.get(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n </s> add     # default redirect code preserves form data\n    rv = client.post(\"/user\", data={\"status\": \"success\"}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> remove     app.debug = False\n    rv = client.post(\"/foo\", data={}, follow_redirects=True)\n    assert rv.data == b\"success\"\n </s> add     @app.route(\"/user/\", methods=[\"GET\", \"POST\"])\n    def user():\n        return flask.request.form[\"status\"] </s> remove     assert \"A setup function was called\" in str(e.value)\n\n    app.debug = False\n\n    @app.route(\"/foo\")\n    def working():\n        return \"Meh\"\n\n    assert client.get(\"/foo\").data == b\"Meh\"\n    assert app.got_first_request\n </s> add     assert \"setup method 'add_url_rule'\" in str(exc_info.value) </s> remove     @app.route(\"/foo/\", methods=[\"GET\", \"POST\"])\n    def foo():\n        return \"success\"\n </s> add     app.config[\"DEBUG\"] = True", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     assert not app.got_first_request\n <mask>     assert client.get(\"/\").data == b\"Awesome\"\n <mask> \n <mask>     with pytest.raises(AssertionError) as e:\n <mask>         app.add_url_rule(\"/foo\", endpoint=\"late\")\n <mask> \n <mask>     assert \"A setup function was called\" in str(e.value)\n <mask> \n <mask>     app.debug = False\n </s> avoid triggering setupmethod late in tests </s> remove     assert \"A setup function was called\" in str(e.value)\n\n    app.debug = False\n\n    @app.route(\"/foo\")\n    def working():\n        return \"Meh\"\n\n    assert client.get(\"/foo\").data == b\"Meh\"\n    assert app.got_first_request\n </s> add     assert \"setup method 'add_url_rule'\" in str(exc_info.value) </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\") </s> remove     app.debug = True\n    with pytest.raises(KeyError) as e:\n        client.get(\"/key\")\n    assert e.errisinstance(BadRequest)\n    assert \"missing_key\" in e.value.get_description()\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add         assert exc_info.errisinstance(BadRequest)\n        assert \"missing_key\" in exc_info.value.get_description() </s> remove     assert \"canonical URL 'http://localhost/foo/'\" in str(e.value)\n </s> add     assert \"canonical URL 'http://localhost/user/'\" in str(exc_info.value) </s> remove     with client, pytest.raises(AssertionError) as e:\n        client.post(\"/foo\", data={})\n </s> add     with client, pytest.raises(AssertionError) as exc_info:\n        client.post(\"/user\", data={\"status\": \"error\"}, follow_redirects=True) </s> remove     @app.route(\"/foo/\", methods=[\"GET\", \"POST\"])\n    def foo():\n        return \"success\"\n </s> add     app.config[\"DEBUG\"] = True", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     with pytest.raises(AssertionError) as e:\n <mask>         app.add_url_rule(\"/foo\", endpoint=\"late\")\n <mask> \n <mask>     assert \"A setup function was called\" in str(e.value)\n <mask> \n <mask>     app.debug = False\n <mask> \n <mask>     @app.route(\"/foo\")\n <mask>     def working():\n <mask>         return \"Meh\"\n <mask> \n <mask>     assert client.get(\"/foo\").data == b\"Meh\"\n <mask>     assert app.got_first_request\n <mask> \n <mask> \n <mask> def test_before_first_request_functions(app, client):\n <mask>     got = []\n <mask> \n </s> avoid triggering setupmethod late in tests </s> remove     with pytest.raises(AssertionError) as e:\n </s> add     with pytest.raises(AssertionError) as exc_info: </s> remove     @app.route(\"/foo/\", methods=[\"GET\", \"POST\"])\n    def foo():\n        return \"success\"\n </s> add     app.config[\"DEBUG\"] = True </s> remove     assert \"canonical URL 'http://localhost/foo/'\" in str(e.value)\n </s> add     assert \"canonical URL 'http://localhost/user/'\" in str(exc_info.value) </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\") </s> remove     app.debug = False\n    app.config[\"TRAP_BAD_REQUEST_ERRORS\"] = True\n    with pytest.raises(KeyError):\n        client.get(\"/key\")\n    with pytest.raises(BadRequest):\n        client.get(\"/abort\")\n </s> add     if expect_abort:\n        rv = client.get(\"/abort\")\n        assert rv.status_code == 400\n    else:\n        with pytest.raises(BadRequest):\n            client.get(\"/abort\") </s> remove     app.debug = True\n    with pytest.raises(KeyError) as e:\n        client.get(\"/key\")\n    assert e.errisinstance(BadRequest)\n    assert \"missing_key\" in e.value.get_description()\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add         assert exc_info.errisinstance(BadRequest)\n        assert \"missing_key\" in exc_info.value.get_description()", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep replace replace replace keep", "code_tokens": " <mask>     assert app.got_first_request\n <mask> \n <mask> \n <mask> def test_routing_redirect_debugging(monkeypatch, app, client):\n <mask>     @app.route(\"/foo/\", methods=[\"GET\", \"POST\"])\n <mask>     def foo():\n <mask>         return \"success\"\n <mask> \n <mask>     app.debug = False\n <mask>     rv = client.post(\"/foo\", data={}, follow_redirects=True)\n <mask>     assert rv.data == b\"success\"\n <mask> \n </s> avoid triggering setupmethod late in tests </s> remove     app.debug = True\n\n    with client:\n        rv = client.post(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n        rv = client.get(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n </s> add     # default redirect code preserves form data\n    rv = client.post(\"/user\", data={\"status\": \"success\"}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> remove     assert \"A setup function was called\" in str(e.value)\n\n    app.debug = False\n\n    @app.route(\"/foo\")\n    def working():\n        return \"Meh\"\n\n    assert client.get(\"/foo\").data == b\"Meh\"\n    assert app.got_first_request\n </s> add     assert \"setup method 'add_url_rule'\" in str(exc_info.value) </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\") </s> remove     app.debug = False\n    app.config[\"TRAP_BAD_REQUEST_ERRORS\"] = True\n    with pytest.raises(KeyError):\n        client.get(\"/key\")\n    with pytest.raises(BadRequest):\n        client.get(\"/abort\")\n </s> add     if expect_abort:\n        rv = client.get(\"/abort\")\n        assert rv.status_code == 400\n    else:\n        with pytest.raises(BadRequest):\n            client.get(\"/abort\") </s> remove     with client, pytest.raises(AssertionError) as e:\n        client.post(\"/foo\", data={})\n </s> add     with client, pytest.raises(AssertionError) as exc_info:\n        client.post(\"/user\", data={\"status\": \"error\"}, follow_redirects=True)", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     app.debug = False\n <mask>     rv = client.post(\"/foo\", data={}, follow_redirects=True)\n <mask>     assert rv.data == b\"success\"\n <mask> \n <mask>     app.debug = True\n <mask> \n <mask>     with client:\n <mask>         rv = client.post(\"/foo\", data={}, follow_redirects=True)\n <mask>         assert rv.data == b\"success\"\n <mask>         rv = client.get(\"/foo\", data={}, follow_redirects=True)\n <mask>         assert rv.data == b\"success\"\n <mask> \n <mask>     monkeypatch.setattr(RequestRedirect, \"code\", 301)\n <mask> \n <mask>     with client, pytest.raises(AssertionError) as e:\n <mask>         client.post(\"/foo\", data={})\n </s> avoid triggering setupmethod late in tests </s> remove     app.debug = False\n    rv = client.post(\"/foo\", data={}, follow_redirects=True)\n    assert rv.data == b\"success\"\n </s> add     @app.route(\"/user/\", methods=[\"GET\", \"POST\"])\n    def user():\n        return flask.request.form[\"status\"] </s> remove     @app.route(\"/foo/\", methods=[\"GET\", \"POST\"])\n    def foo():\n        return \"success\"\n </s> add     app.config[\"DEBUG\"] = True </s> remove     with client, pytest.raises(AssertionError) as e:\n        client.post(\"/foo\", data={})\n </s> add     with client, pytest.raises(AssertionError) as exc_info:\n        client.post(\"/user\", data={\"status\": \"error\"}, follow_redirects=True) </s> add     # 301 and 302 raise error </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\") </s> remove     app.debug = True\n    with pytest.raises(KeyError) as e:\n        client.get(\"/key\")\n    assert e.errisinstance(BadRequest)\n    assert \"missing_key\" in e.value.get_description()\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add         assert exc_info.errisinstance(BadRequest)\n        assert \"missing_key\" in exc_info.value.get_description()", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     assert rv.data == b\"success\"\n <mask> \n <mask>     monkeypatch.setattr(RequestRedirect, \"code\", 301)\n <mask> \n <mask>     with client, pytest.raises(AssertionError) as exc_info:\n <mask>         client.post(\"/user\", data={\"status\": \"error\"}, follow_redirects=True)\n <mask> \n <mask>     assert \"canonical URL 'http://localhost/user/'\" in str(exc_info.value)\n </s> avoid triggering setupmethod late in tests </s> remove     with client, pytest.raises(AssertionError) as e:\n        client.post(\"/foo\", data={})\n </s> add     with client, pytest.raises(AssertionError) as exc_info:\n        client.post(\"/user\", data={\"status\": \"error\"}, follow_redirects=True) </s> remove     assert \"canonical URL 'http://localhost/foo/'\" in str(e.value)\n </s> add     assert \"canonical URL 'http://localhost/user/'\" in str(exc_info.value) </s> remove     app.debug = True\n\n    with client:\n        rv = client.post(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n        rv = client.get(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n </s> add     # default redirect code preserves form data\n    rv = client.post(\"/user\", data={\"status\": \"success\"}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> remove     with pytest.raises(AssertionError) as e:\n </s> add     with pytest.raises(AssertionError) as exc_info: </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\") </s> remove     assert \"A setup function was called\" in str(e.value)\n\n    app.debug = False\n\n    @app.route(\"/foo\")\n    def working():\n        return \"Meh\"\n\n    assert client.get(\"/foo\").data == b\"Meh\"\n    assert app.got_first_request\n </s> add     assert \"setup method 'add_url_rule'\" in str(exc_info.value)", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         assert rv.data == b\"success\"\n <mask> \n <mask>     monkeypatch.setattr(RequestRedirect, \"code\", 301)\n <mask> \n <mask>     with client, pytest.raises(AssertionError) as e:\n <mask>         client.post(\"/foo\", data={})\n <mask> \n <mask>     assert \"canonical URL 'http://localhost/foo/'\" in str(e.value)\n <mask> \n <mask> \n <mask> def test_route_decorator_custom_endpoint(app, client):\n </s> avoid triggering setupmethod late in tests </s> remove     assert \"canonical URL 'http://localhost/foo/'\" in str(e.value)\n </s> add     assert \"canonical URL 'http://localhost/user/'\" in str(exc_info.value) </s> add     # 301 and 302 raise error </s> remove     app.debug = True\n\n    with client:\n        rv = client.post(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n        rv = client.get(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n </s> add     # default redirect code preserves form data\n    rv = client.post(\"/user\", data={\"status\": \"success\"}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> remove     assert \"A setup function was called\" in str(e.value)\n\n    app.debug = False\n\n    @app.route(\"/foo\")\n    def working():\n        return \"Meh\"\n\n    assert client.get(\"/foo\").data == b\"Meh\"\n    assert app.got_first_request\n </s> add     assert \"setup method 'add_url_rule'\" in str(exc_info.value) </s> remove     with pytest.raises(AssertionError) as e:\n </s> add     with pytest.raises(AssertionError) as exc_info: </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\")", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     with client, pytest.raises(AssertionError) as e:\n <mask>         client.post(\"/foo\", data={})\n <mask> \n <mask>     assert \"canonical URL 'http://localhost/foo/'\" in str(e.value)\n <mask> \n <mask> \n <mask> def test_route_decorator_custom_endpoint(app, client):\n <mask>     app.debug = True\n <mask> \n </s> avoid triggering setupmethod late in tests </s> remove     with client, pytest.raises(AssertionError) as e:\n        client.post(\"/foo\", data={})\n </s> add     with client, pytest.raises(AssertionError) as exc_info:\n        client.post(\"/user\", data={\"status\": \"error\"}, follow_redirects=True) </s> add     # 301 and 302 raise error </s> remove     app.debug = True\n\n    with client:\n        rv = client.post(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n        rv = client.get(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n </s> add     # default redirect code preserves form data\n    rv = client.post(\"/user\", data={\"status\": \"success\"}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> remove     assert \"A setup function was called\" in str(e.value)\n\n    app.debug = False\n\n    @app.route(\"/foo\")\n    def working():\n        return \"Meh\"\n\n    assert client.get(\"/foo\").data == b\"Meh\"\n    assert app.got_first_request\n </s> add     assert \"setup method 'add_url_rule'\" in str(exc_info.value) </s> remove     with pytest.raises(AssertionError) as e:\n </s> add     with pytest.raises(AssertionError) as exc_info: </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400\n </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\")", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     necessary to interface with as it's used internally in the dispatching\n <mask>     to click.\n <mask>     \"\"\"\n <mask> \n <mask>     def __init__(self):\n <mask>         self.app_import_path = None\n <mask>         self.debug = None\n <mask>         self._loaded_app = None\n <mask> \n <mask>     def get_app_import_path(self):\n <mask>         \"\"\"Return the actual application import path or fails if it is\n <mask>         not yet set.\n </s> Improved support for composable cli </s> remove         name = 'flask'\n </s> add         name = None </s> remove cli = FlaskClickGroup(help='''\\\n </s> add cli = FlaskGroup(help='''\\ </s> remove class FlaskClickGroup(click.Group):\n </s> add class FlaskGroup(click.Group):", "html_url": "https://github.com/pallets/flask/commit/e059bf311c6a75150275b434c53544f7528749bc", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     f.__flask_without_appcontext__ = True\n <mask>     return f\n <mask> \n <mask> \n <mask> class FlaskClickGroup(click.Group):\n <mask>     \"\"\"Special subclass of the a regular click group that supports\n <mask>     loading more commands from the configured Flask app.\n <mask>     \"\"\"\n <mask> \n <mask>     def __init__(self, help=None):\n </s> Improved support for composable cli </s> remove cli = FlaskClickGroup(help='''\\\n </s> add cli = FlaskGroup(help='''\\ </s> remove         name = 'flask'\n </s> add         name = None </s> remove     def __init__(self):\n        self.app_import_path = None\n        self.debug = None\n </s> add     def __init__(self, app_import_path=None, debug=None):\n        self.app_import_path = app_import_path\n        self.debug = debug", "html_url": "https://github.com/pallets/flask/commit/e059bf311c6a75150275b434c53544f7528749bc", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return click.Group.invoke_subcommand(\n <mask>                 self, ctx, cmd, cmd_name, args)\n <mask> \n <mask> \n <mask> cli = FlaskClickGroup(help='''\\\n <mask> This shell command acts as general utility script for Flask applications.\n <mask> \n <mask> It loads the application configured (either through the FLASK_APP environment\n <mask> variable or the --app parameter) and then provides commands either provided\n <mask> by the application or Flask itself.\n </s> Improved support for composable cli </s> remove         name = 'flask'\n </s> add         name = None </s> remove class FlaskClickGroup(click.Group):\n </s> add class FlaskGroup(click.Group): </s> remove     def __init__(self):\n        self.app_import_path = None\n        self.debug = None\n </s> add     def __init__(self, app_import_path=None, debug=None):\n        self.app_import_path = app_import_path\n        self.debug = debug", "html_url": "https://github.com/pallets/flask/commit/e059bf311c6a75150275b434c53544f7528749bc", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # we need to ensure that we restore the actual command line so that\n <mask>         # the reloader can properly operate.\n <mask>         sys.argv = ['-m', this_module] + sys.argv[1:]\n <mask>     else:\n <mask>         name = 'flask'\n <mask> \n <mask>     cli.main(args=args, prog_name=name, obj=ScriptInfo(),\n <mask>              auto_envvar_prefix='FLASK')\n <mask> \n <mask> \n </s> Improved support for composable cli </s> remove     def __init__(self):\n        self.app_import_path = None\n        self.debug = None\n </s> add     def __init__(self, app_import_path=None, debug=None):\n        self.app_import_path = app_import_path\n        self.debug = debug </s> remove cli = FlaskClickGroup(help='''\\\n </s> add cli = FlaskGroup(help='''\\ </s> remove class FlaskClickGroup(click.Group):\n </s> add class FlaskGroup(click.Group):", "html_url": "https://github.com/pallets/flask/commit/e059bf311c6a75150275b434c53544f7528749bc", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Now, whenever you want to work on a project, you only have to activate the\n <mask> corresponding environment.  On OS X and Linux, do the following::\n <mask> \n <mask>     $ source venv/bin/activate\n <mask> \n <mask> If you are a Windows user, the following command is for you::\n <mask> \n <mask>     $ venv\\scripts\\activate\n <mask> \n </s> Use \".\" not \"source\" for shell sourcing.\n\nShell portability from mitsuhiko. </s> remove     $ source venv/bin/activate\n </s> add     $ . venv/bin/activate </s> remove     $ source venv/bin/activate\n </s> add     $ . venv/bin/activate", "html_url": "https://github.com/pallets/flask/commit/e070ede050fdb2ce155e13e29f5588c9831fa6b5", "file_name": "docs/installation.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     $ cd flask\n <mask>     $ virtualenv venv --distribute\n <mask>     New python executable in venv/bin/python\n <mask>     Installing distribute............done.\n <mask>     $ source venv/bin/activate\n <mask>     $ python setup.py develop\n <mask>     ...\n <mask>     Finished processing dependencies for Flask\n <mask> \n <mask> This will pull in the dependencies and activate the git head as the current\n </s> Use \".\" not \"source\" for shell sourcing.\n\nShell portability from mitsuhiko. </s> remove     $ source venv/bin/activate\n </s> add     $ . venv/bin/activate </s> remove     $ source venv/bin/activate\n </s> add     $ . venv/bin/activate", "html_url": "https://github.com/pallets/flask/commit/e070ede050fdb2ce155e13e29f5588c9831fa6b5", "file_name": "docs/installation.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     $ mkdir flask\n <mask>     $ cd flask\n <mask>     $ virtualenv venv --distribute\n <mask>     $ source venv/bin/activate\n <mask>     New python executable in venv/bin/python\n <mask>     Installing distribute............done.\n <mask>     $ pip install Flask==dev\n <mask>     ...\n <mask>     Finished processing dependencies for Flask==dev\n </s> Use \".\" not \"source\" for shell sourcing.\n\nShell portability from mitsuhiko. </s> remove     $ source venv/bin/activate\n </s> add     $ . venv/bin/activate </s> remove     $ source venv/bin/activate\n </s> add     $ . venv/bin/activate", "html_url": "https://github.com/pallets/flask/commit/e070ede050fdb2ce155e13e29f5588c9831fa6b5", "file_name": "docs/installation.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Unreleased\n <mask> \n <mask> \n <mask> Version 1.0.3\n <mask> -------------\n <mask> \n <mask> Unreleased\n </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> add                 assert flask.session.get('fizz') == 'buzz' </s> add             flask.session['fizz'] = 'buzz' </s> add                     assert flask.session.get('fizz') == 'buzz' </s> add             flask.session['fizz'] = 'buzz' </s> remove             request=self.request\n </s> add             request=self.request,\n            session=self.session </s> add         .. versionchanged:: 1.1\n           The current session object is used instead of reloading the original\n           data. This prevents `flask.session` pointing to an out-of-date object.", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> def copy_current_request_context(f):\n <mask>     \"\"\"A helper function that decorates a function to retain the current\n <mask>     request context.  This is useful when working with greenlets.  The moment\n <mask>     the function is decorated a copy of the request context is created and\n <mask>     then pushed when the function is called.\n <mask> \n <mask>     Example::\n <mask> \n <mask>         import gevent\n <mask>         from flask import copy_current_request_context\n </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> remove         self.session = None\n </s> add         self.session = session </s> add         .. versionchanged:: 1.1\n           The current session object is used instead of reloading the original\n           data. This prevents `flask.session` pointing to an out-of-date object. </s> remove     def __init__(self, app, environ, request=None):\n </s> add     def __init__(self, app, environ, request=None, session=None): </s> remove             request=self.request\n </s> add             request=self.request,\n            session=self.session </s> add -   :meth:`flask.RequestContext.copy` includes the current session\n    object in the request context copy. This prevents ``flask.session`` \n    pointing to an out-of-date object. (`#2935`)\n\n.. _#2935: https://github.com/pallets/flask/issues/2935\n </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function.\n </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function.", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         @app.route('/')\n <mask>         def index():\n <mask>             @copy_current_request_context\n <mask>             def do_some_work():\n <mask>                 # do some work here, it can access flask.request like you\n <mask>                 # would otherwise in the view function.\n <mask>                 ...\n <mask>             gevent.spawn(do_some_work)\n <mask>             return 'Regular response'\n <mask> \n <mask>     .. versionadded:: 0.10\n </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> remove         self.session = None\n </s> add         self.session = session </s> add             flask.session['fizz'] = 'buzz' </s> remove             request=self.request\n </s> add             request=self.request,\n            session=self.session </s> add             flask.session['fizz'] = 'buzz' </s> add         .. versionchanged:: 1.1\n           The current session object is used instead of reloading the original\n           data. This prevents `flask.session` pointing to an out-of-date object. </s> remove     def __init__(self, app, environ, request=None):\n </s> add     def __init__(self, app, environ, request=None, session=None):", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n <mask>     that situation, otherwise your unittests will leak memory.\n <mask>     \"\"\"\n <mask> \n <mask>     def __init__(self, app, environ, request=None):\n <mask>         self.app = app\n <mask>         if request is None:\n <mask>             request = app.request_class(environ)\n <mask>         self.request = request\n <mask>         self.url_adapter = app.create_url_adapter(self.request)\n </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> remove         self.session = None\n </s> add         self.session = session </s> remove     then pushed when the function is called.\n </s> add     then pushed when the function is called.  The current session is also\n    included in the copied request context. </s> add             flask.session['fizz'] = 'buzz' </s> add             flask.session['fizz'] = 'buzz' </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function.\n </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function. </s> add -   :meth:`flask.RequestContext.copy` includes the current session\n    object in the request context copy. This prevents ``flask.session`` \n    pointing to an out-of-date object. (`#2935`)\n\n.. _#2935: https://github.com/pallets/flask/issues/2935\n", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             request = app.request_class(environ)\n <mask>         self.request = request\n <mask>         self.url_adapter = app.create_url_adapter(self.request)\n <mask>         self.flashes = None\n <mask>         self.session = None\n <mask> \n <mask>         # Request contexts can be pushed multiple times and interleaved with\n <mask>         # other request contexts.  Now only if the last level is popped we\n <mask>         # get rid of them.  Additionally if an application context is missing\n <mask>         # one is created implicitly so for each level we add this information\n </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> remove     def __init__(self, app, environ, request=None):\n </s> add     def __init__(self, app, environ, request=None, session=None): </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function.\n </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function. </s> remove     then pushed when the function is called.\n </s> add     then pushed when the function is called.  The current session is also\n    included in the copied request context. </s> add             flask.session['fizz'] = 'buzz' </s> add             flask.session['fizz'] = 'buzz' </s> add -   :meth:`flask.RequestContext.copy` includes the current session\n    object in the request context copy. This prevents ``flask.session`` \n    pointing to an out-of-date object. (`#2935`)\n\n.. _#2935: https://github.com/pallets/flask/issues/2935\n", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         .. versionadded:: 0.10\n <mask>         \"\"\"\n <mask>         return self.__class__(self.app,\n <mask>             environ=self.request.environ,\n <mask>             request=self.request,\n <mask>             session=self.session\n </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> remove             request=self.request\n </s> add             request=self.request,\n            session=self.session </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function.\n </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function. </s> remove     def __init__(self, app, environ, request=None):\n </s> add     def __init__(self, app, environ, request=None, session=None): </s> add -   :meth:`flask.RequestContext.copy` includes the current session\n    object in the request context copy. This prevents ``flask.session`` \n    pointing to an out-of-date object. (`#2935`)\n\n.. _#2935: https://github.com/pallets/flask/issues/2935\n </s> add                 assert flask.session.get('fizz') == 'buzz' </s> add                     assert flask.session.get('fizz') == 'buzz'", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         .. versionadded:: 0.10\n <mask>         \"\"\"\n <mask>         return self.__class__(self.app,\n <mask>             environ=self.request.environ,\n <mask>             request=self.request\n <mask>         )\n <mask> \n <mask>     def match_request(self):\n <mask>         \"\"\"Can be overridden by a subclass to hook into the matching\n <mask>         of the request.\n </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> add         .. versionchanged:: 1.1\n           The current session object is used instead of reloading the original\n           data. This prevents `flask.session` pointing to an out-of-date object. </s> remove     then pushed when the function is called.\n </s> add     then pushed when the function is called.  The current session is also\n    included in the copied request context. </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function.\n </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function. </s> remove     def __init__(self, app, environ, request=None):\n </s> add     def __init__(self, app, environ, request=None, session=None): </s> add -   :meth:`flask.RequestContext.copy` includes the current session\n    object in the request context copy. This prevents ``flask.session`` \n    pointing to an out-of-date object. (`#2935`)\n\n.. _#2935: https://github.com/pallets/flask/issues/2935\n </s> remove         self.session = None\n </s> add         self.session = session", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         greenlets = []\n <mask> \n <mask>         @app.route('/')\n <mask>         def index():\n <mask>             reqctx = flask._request_ctx_stack.top.copy()\n <mask> \n <mask>             def g():\n <mask>                 assert not flask.request\n </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> add             flask.session['fizz'] = 'buzz' </s> add                     assert flask.session.get('fizz') == 'buzz' </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function.\n </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function. </s> remove     def __init__(self, app, environ, request=None):\n </s> add     def __init__(self, app, environ, request=None, session=None): </s> remove         self.session = None\n </s> add         self.session = session </s> add                 assert flask.session.get('fizz') == 'buzz'", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "tests/test_reqctx.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>                     assert flask.current_app == app\n <mask>                     assert flask.request.path == '/'\n <mask>                     assert flask.request.args['foo'] == 'bar'\n <mask>                 assert not flask.request\n <mask>                 return 42\n <mask> \n <mask>             greenlets.append(greenlet(g))\n </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> add                 assert flask.session.get('fizz') == 'buzz' </s> add             flask.session['fizz'] = 'buzz' </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function.\n </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function. </s> remove     def __init__(self, app, environ, request=None):\n </s> add     def __init__(self, app, environ, request=None, session=None): </s> remove             request=self.request\n </s> add             request=self.request,\n            session=self.session </s> add         .. versionchanged:: 1.1\n           The current session object is used instead of reloading the original\n           data. This prevents `flask.session` pointing to an out-of-date object.", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "tests/test_reqctx.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>         @app.route('/')\n <mask>         def index():\n <mask>             reqctx = flask._request_ctx_stack.top.copy()\n <mask> \n <mask>             @flask.copy_current_request_context\n <mask>             def g():\n </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> add             flask.session['fizz'] = 'buzz' </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function.\n </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function. </s> remove     def __init__(self, app, environ, request=None):\n </s> add     def __init__(self, app, environ, request=None, session=None): </s> remove             request=self.request\n </s> add             request=self.request,\n            session=self.session </s> remove         self.session = None\n </s> add         self.session = session </s> remove     then pushed when the function is called.\n </s> add     then pushed when the function is called.  The current session is also\n    included in the copied request context.", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "tests/test_reqctx.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>                 assert flask.current_app == app\n <mask>                 assert flask.request.path == '/'\n <mask>                 assert flask.request.args['foo'] == 'bar'\n <mask>                 return 42\n <mask> \n <mask>             greenlets.append(greenlet(g))\n <mask>             return 'Hello World!'\n </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> add                     assert flask.session.get('fizz') == 'buzz' </s> add             flask.session['fizz'] = 'buzz' </s> remove     def __init__(self, app, environ, request=None):\n </s> add     def __init__(self, app, environ, request=None, session=None): </s> remove             request=self.request\n </s> add             request=self.request,\n            session=self.session </s> add         .. versionchanged:: 1.1\n           The current session object is used instead of reloading the original\n           data. This prevents `flask.session` pointing to an out-of-date object. </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function.\n </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function.", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "tests/test_reqctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> import os\n <mask> from functools import update_wrapper\n <mask> \n <mask> from .helpers import _PackageBoundObject, _endpoint_from_view_func\n <mask> \n <mask> \n </s> Started work on testcases for blueprints </s> add         self.url_defaults = dict(self.blueprint.url_defaults)\n        self.url_defaults.update(self.options.get('url_defaults', ()))\n </s> add         \"\"\"A helper method to register a rule (and optionally a view function)\n        to the application.  The endpoint is automatically prefixed with the\n        blueprint's name.\n        \"\"\" </s> add         if url_defaults is None:\n            url_defaults = {}\n        self.url_defaults = url_defaults </s> remove                  url_prefix=None, subdomain=None):\n </s> add                  url_prefix=None, subdomain=None, url_defaults=None): </s> remove                               view_func, **options)\n </s> add                               view_func, defaults=defaults, **options) </s> add         defaults = self.url_defaults\n        if 'defaults' in options:\n            defaults = dict(defaults, **options.pop('defaults'))", "html_url": "https://github.com/pallets/flask/commit/e17e74d3a74b5d32a622587b2b9da9840bf3a7e0", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>         self.url_prefix = url_prefix\n <mask> \n <mask>     def add_url_rule(self, rule, endpoint=None, view_func=None, **options):\n <mask>         \"\"\"A helper method to register a rule (and optionally a view function)\n <mask>         to the application.  The endpoint is automatically prefixed with the\n <mask>         blueprint's name.\n <mask>         \"\"\"\n <mask>         if self.url_prefix:\n </s> Started work on testcases for blueprints </s> add         \"\"\"A helper method to register a rule (and optionally a view function)\n        to the application.  The endpoint is automatically prefixed with the\n        blueprint's name.\n        \"\"\" </s> add         if url_defaults is None:\n            url_defaults = {}\n        self.url_defaults = url_defaults </s> remove                               view_func, **options)\n </s> add                               view_func, defaults=defaults, **options) </s> remove                  url_prefix=None, subdomain=None):\n </s> add                  url_prefix=None, subdomain=None, url_defaults=None): </s> add         defaults = self.url_defaults\n        if 'defaults' in options:\n            defaults = dict(defaults, **options.pop('defaults')) </s> remove import os\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e17e74d3a74b5d32a622587b2b9da9840bf3a7e0", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>     def add_url_rule(self, rule, endpoint=None, view_func=None, **options):\n <mask>         if self.url_prefix:\n <mask>             rule = self.url_prefix + rule\n <mask>         options.setdefault('subdomain', self.subdomain)\n <mask>         if endpoint is None:\n </s> Started work on testcases for blueprints </s> add         self.url_defaults = dict(self.blueprint.url_defaults)\n        self.url_defaults.update(self.options.get('url_defaults', ()))\n </s> remove                               view_func, **options)\n </s> add                               view_func, defaults=defaults, **options) </s> add         defaults = self.url_defaults\n        if 'defaults' in options:\n            defaults = dict(defaults, **options.pop('defaults')) </s> add         if url_defaults is None:\n            url_defaults = {}\n        self.url_defaults = url_defaults </s> remove                  url_prefix=None, subdomain=None):\n </s> add                  url_prefix=None, subdomain=None, url_defaults=None): </s> remove import os\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e17e74d3a74b5d32a622587b2b9da9840bf3a7e0", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         if endpoint is None:\n <mask>             endpoint = _endpoint_from_view_func(view_func)\n <mask>         self.app.add_url_rule(rule, '%s.%s' % (self.blueprint.name, endpoint),\n <mask>                               view_func, defaults=defaults, **options)\n <mask> \n <mask> \n </s> Started work on testcases for blueprints </s> remove                               view_func, **options)\n </s> add                               view_func, defaults=defaults, **options) </s> add         \"\"\"A helper method to register a rule (and optionally a view function)\n        to the application.  The endpoint is automatically prefixed with the\n        blueprint's name.\n        \"\"\" </s> add         if url_defaults is None:\n            url_defaults = {}\n        self.url_defaults = url_defaults </s> add         self.url_defaults = dict(self.blueprint.url_defaults)\n        self.url_defaults.update(self.options.get('url_defaults', ()))\n </s> remove                  url_prefix=None, subdomain=None):\n </s> add                  url_prefix=None, subdomain=None, url_defaults=None): </s> remove import os\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e17e74d3a74b5d32a622587b2b9da9840bf3a7e0", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         options.setdefault('subdomain', self.subdomain)\n <mask>         if endpoint is None:\n <mask>             endpoint = _endpoint_from_view_func(view_func)\n <mask>         self.app.add_url_rule(rule, '%s.%s' % (self.blueprint.name, endpoint),\n <mask>                               view_func, **options)\n <mask> \n <mask> \n <mask> class Blueprint(_PackageBoundObject):\n <mask>     \"\"\"Represents a blueprint.\n <mask> \n </s> Started work on testcases for blueprints </s> add         defaults = self.url_defaults\n        if 'defaults' in options:\n            defaults = dict(defaults, **options.pop('defaults')) </s> add         \"\"\"A helper method to register a rule (and optionally a view function)\n        to the application.  The endpoint is automatically prefixed with the\n        blueprint's name.\n        \"\"\" </s> add         if url_defaults is None:\n            url_defaults = {}\n        self.url_defaults = url_defaults </s> add         self.url_defaults = dict(self.blueprint.url_defaults)\n        self.url_defaults.update(self.options.get('url_defaults', ()))\n </s> remove                  url_prefix=None, subdomain=None):\n </s> add                  url_prefix=None, subdomain=None, url_defaults=None): </s> remove import os\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e17e74d3a74b5d32a622587b2b9da9840bf3a7e0", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     _got_registered_once = False\n <mask> \n <mask>     def __init__(self, name, import_name, static_folder=None,\n <mask>                  static_url_path=None, template_folder=None,\n <mask>                  url_prefix=None, subdomain=None):\n <mask>         _PackageBoundObject.__init__(self, import_name, template_folder)\n <mask>         self.name = name\n <mask>         self.url_prefix = url_prefix\n <mask>         self.subdomain = subdomain\n <mask>         self.static_folder = static_folder\n </s> Started work on testcases for blueprints </s> add         self.url_defaults = dict(self.blueprint.url_defaults)\n        self.url_defaults.update(self.options.get('url_defaults', ()))\n </s> add         if url_defaults is None:\n            url_defaults = {}\n        self.url_defaults = url_defaults </s> add         defaults = self.url_defaults\n        if 'defaults' in options:\n            defaults = dict(defaults, **options.pop('defaults')) </s> add         \"\"\"A helper method to register a rule (and optionally a view function)\n        to the application.  The endpoint is automatically prefixed with the\n        blueprint's name.\n        \"\"\" </s> remove                               view_func, **options)\n </s> add                               view_func, defaults=defaults, **options) </s> remove import os\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e17e74d3a74b5d32a622587b2b9da9840bf3a7e0", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         self.deferred_functions = []\n <mask>         self.view_functions = {}\n <mask> \n <mask>     def record(self, func):\n <mask>         \"\"\"Registers a function that is called when the blueprint is\n <mask>         registered on the application.  This function is called with the\n </s> Started work on testcases for blueprints </s> add         \"\"\"A helper method to register a rule (and optionally a view function)\n        to the application.  The endpoint is automatically prefixed with the\n        blueprint's name.\n        \"\"\" </s> add         self.url_defaults = dict(self.blueprint.url_defaults)\n        self.url_defaults.update(self.options.get('url_defaults', ()))\n </s> add         defaults = self.url_defaults\n        if 'defaults' in options:\n            defaults = dict(defaults, **options.pop('defaults')) </s> remove                               view_func, **options)\n </s> add                               view_func, defaults=defaults, **options) </s> remove                  url_prefix=None, subdomain=None):\n </s> add                  url_prefix=None, subdomain=None, url_defaults=None): </s> remove import os\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e17e74d3a74b5d32a622587b2b9da9840bf3a7e0", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     with the documentation. It will return ``False`` if python-dotenv is\n <mask>     not installed, or if the given path isn't a file. :issue:`2937`\n <mask> -   Signaling support has a stub for the ``connect_via`` method when\n <mask>     the Blinker library is not installed. :pr:`3208`\n <mask> \n <mask> .. _#2935: https://github.com/pallets/flask/issues/2935\n <mask> .. _#2957: https://github.com/pallets/flask/issues/2957\n <mask> .. _#2994: https://github.com/pallets/flask/pull/2994\n </s> add SeparatedPathType to accept multiple paths\n\nMultiple paths for the reloader's `--extra-files` are accepted as one\noption, separated by ':'. </s> remove To define a list of files the reloader should watch additionally to the modules\nas in ``extra_files`` argument used in the ``app.run`` and ``werkzeug.serving.run_simple``\nyou can either use the ``--extra-files`` (or multiple ``-f``) option or define the\n``FLASK_RUN_EXTRA_FILES`` environment variable.\n\n.. code-block:: none\n\n    # on windows use ``;`` instead of ``:`` to separate paths\n    export FLASK_RUN_EXTRA_FILES=/path/to/file1:/path/to/file2\n    flask run\n     * Running on http://127.0.0.1:8000/\n     * Detected change in '/path/to/file1', reloading\n\nOn command line the same can be achieved with ``flask run -f /path/to/file1 -f /path/to/file2``.\n </s> add  </s> add class SeparatedPathType(click.Path):\n    \"\"\"Click option type that accepts a list of values separated by the\n    OS's path separator (``:``, ``;`` on Windows). Each value is\n    validated as a :class:`click.Path` type.\n    \"\"\"\n\n    def convert(self, value, param, ctx):\n        items = self.split_envvar_value(value)\n        super_convert = super(SeparatedPathType, self).convert\n        return [super_convert(item, param, ctx) for item in items]\n\n </s> remove -   Added support to ``extra_files`` argument in `flask run` CLI. (`#2898`_)\n\n.. _#2898: https://github.com/pallets/flask/pull/2898\n </s> add  </s> remove @click.option('--extra-files', '-f',\n              multiple=True, default=None, type=click.Path(),\n              help='Files reloader should watch additionally to the modules')\n </s> add @click.option(\n    \"--extra-files\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Extra files that trigger a reload on change. Multiple paths\"\n        \" are separated by '{}'.\".format(os.path.pathsep)\n    ),\n)", "html_url": "https://github.com/pallets/flask/commit/e18cc4d71d1c0ded4a2a7afb417c5ea03ebb0861", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> .. _#3059: https://github.com/pallets/flask/pull/3059\n <mask> .. _#3179: https://github.com/pallets/flask/pull/3179\n <mask> .. _#3125: https://github.com/pallets/flask/pull/3125\n <mask> \n <mask> -   Added support to ``extra_files`` argument in `flask run` CLI. (`#2898`_)\n <mask> \n <mask> .. _#2898: https://github.com/pallets/flask/pull/2898\n <mask> \n <mask> Version 1.0.3\n <mask> -------------\n <mask> \n <mask> Released 2019-05-17\n </s> add SeparatedPathType to accept multiple paths\n\nMultiple paths for the reloader's `--extra-files` are accepted as one\noption, separated by ':'. </s> add -   Add an ``--extra-files`` option to the ``flask run`` CLI command to\n    specify extra files that will trigger the reloader on change.\n    :issue:`2897` </s> remove To define a list of files the reloader should watch additionally to the modules\nas in ``extra_files`` argument used in the ``app.run`` and ``werkzeug.serving.run_simple``\nyou can either use the ``--extra-files`` (or multiple ``-f``) option or define the\n``FLASK_RUN_EXTRA_FILES`` environment variable.\n\n.. code-block:: none\n\n    # on windows use ``;`` instead of ``:`` to separate paths\n    export FLASK_RUN_EXTRA_FILES=/path/to/file1:/path/to/file2\n    flask run\n     * Running on http://127.0.0.1:8000/\n     * Detected change in '/path/to/file1', reloading\n\nOn command line the same can be achieved with ``flask run -f /path/to/file1 -f /path/to/file2``.\n </s> add  </s> add class SeparatedPathType(click.Path):\n    \"\"\"Click option type that accepts a list of values separated by the\n    OS's path separator (``:``, ``;`` on Windows). Each value is\n    validated as a :class:`click.Path` type.\n    \"\"\"\n\n    def convert(self, value, param, ctx):\n        items = self.split_envvar_value(value)\n        super_convert = super(SeparatedPathType, self).convert\n        return [super_convert(item, param, ctx) for item in items]\n\n </s> remove @click.option('--extra-files', '-f',\n              multiple=True, default=None, type=click.Path(),\n              help='Files reloader should watch additionally to the modules')\n </s> add @click.option(\n    \"--extra-files\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Extra files that trigger a reload on change. Multiple paths\"\n        \" are separated by '{}'.\".format(os.path.pathsep)\n    ),\n)", "html_url": "https://github.com/pallets/flask/commit/e18cc4d71d1c0ded4a2a7afb417c5ea03ebb0861", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> These can be added to the ``.flaskenv`` file just like ``FLASK_APP`` to\n <mask> control default command options.\n <mask> \n <mask> To define a list of files the reloader should watch additionally to the modules\n <mask> as in ``extra_files`` argument used in the ``app.run`` and ``werkzeug.serving.run_simple``\n <mask> you can either use the ``--extra-files`` (or multiple ``-f``) option or define the\n <mask> ``FLASK_RUN_EXTRA_FILES`` environment variable.\n <mask> \n <mask> .. code-block:: none\n <mask> \n <mask>     # on windows use ``;`` instead of ``:`` to separate paths\n <mask>     export FLASK_RUN_EXTRA_FILES=/path/to/file1:/path/to/file2\n <mask>     flask run\n <mask>      * Running on http://127.0.0.1:8000/\n <mask>      * Detected change in '/path/to/file1', reloading\n <mask> \n <mask> On command line the same can be achieved with ``flask run -f /path/to/file1 -f /path/to/file2``.\n <mask> \n <mask> Disable dotenv\n <mask> ~~~~~~~~~~~~~~\n <mask> \n <mask> The ``flask`` command will show a message if it detects dotenv files but\n </s> add SeparatedPathType to accept multiple paths\n\nMultiple paths for the reloader's `--extra-files` are accepted as one\noption, separated by ':'. </s> add -   Add an ``--extra-files`` option to the ``flask run`` CLI command to\n    specify extra files that will trigger the reloader on change.\n    :issue:`2897` </s> add class SeparatedPathType(click.Path):\n    \"\"\"Click option type that accepts a list of values separated by the\n    OS's path separator (``:``, ``;`` on Windows). Each value is\n    validated as a :class:`click.Path` type.\n    \"\"\"\n\n    def convert(self, value, param, ctx):\n        items = self.split_envvar_value(value)\n        super_convert = super(SeparatedPathType, self).convert\n        return [super_convert(item, param, ctx) for item in items]\n\n </s> remove @click.option('--extra-files', '-f',\n              multiple=True, default=None, type=click.Path(),\n              help='Files reloader should watch additionally to the modules')\n </s> add @click.option(\n    \"--extra-files\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Extra files that trigger a reload on change. Multiple paths\"\n        \" are separated by '{}'.\".format(os.path.pathsep)\n    ),\n) </s> remove -   Added support to ``extra_files`` argument in `flask run` CLI. (`#2898`_)\n\n.. _#2898: https://github.com/pallets/flask/pull/2898\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e18cc4d71d1c0ded4a2a7afb417c5ea03ebb0861", "file_name": "docs/cli.rst"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> @click.command(\"run\", short_help=\"Run a development server.\")\n <mask> @click.option(\"--host\", \"-h\", default=\"127.0.0.1\", help=\"The interface to bind to.\")\n <mask> @click.option(\"--port\", \"-p\", default=5000, help=\"The port to bind to.\")\n <mask> @click.option(\n <mask>     \"--cert\", type=CertParamType(), help=\"Specify a certificate file to use HTTPS.\"\n <mask> )\n </s> add SeparatedPathType to accept multiple paths\n\nMultiple paths for the reloader's `--extra-files` are accepted as one\noption, separated by ':'. </s> remove @click.option('--extra-files', '-f',\n              multiple=True, default=None, type=click.Path(),\n              help='Files reloader should watch additionally to the modules')\n </s> add @click.option(\n    \"--extra-files\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Extra files that trigger a reload on change. Multiple paths\"\n        \" are separated by '{}'.\".format(os.path.pathsep)\n    ),\n) </s> remove To define a list of files the reloader should watch additionally to the modules\nas in ``extra_files`` argument used in the ``app.run`` and ``werkzeug.serving.run_simple``\nyou can either use the ``--extra-files`` (or multiple ``-f``) option or define the\n``FLASK_RUN_EXTRA_FILES`` environment variable.\n\n.. code-block:: none\n\n    # on windows use ``;`` instead of ``:`` to separate paths\n    export FLASK_RUN_EXTRA_FILES=/path/to/file1:/path/to/file2\n    flask run\n     * Running on http://127.0.0.1:8000/\n     * Detected change in '/path/to/file1', reloading\n\nOn command line the same can be achieved with ``flask run -f /path/to/file1 -f /path/to/file2``.\n </s> add  </s> add -   Add an ``--extra-files`` option to the ``flask run`` CLI command to\n    specify extra files that will trigger the reloader on change.\n    :issue:`2897` </s> remove -   Added support to ``extra_files`` argument in `flask run` CLI. (`#2898`_)\n\n.. _#2898: https://github.com/pallets/flask/pull/2898\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e18cc4d71d1c0ded4a2a7afb417c5ea03ebb0861", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"--with-threads/--without-threads\",\n <mask>     default=True,\n <mask>     help=\"Enable or disable multithreading.\",\n <mask> )\n <mask> @click.option('--extra-files', '-f',\n <mask>               multiple=True, default=None, type=click.Path(),\n <mask>               help='Files reloader should watch additionally to the modules')\n <mask> @pass_script_info\n <mask> def run_command(info, host, port, reload, debugger, eager_loading,\n <mask>                 with_threads, cert, extra_files):\n <mask>     \"\"\"Run a local development server.\n <mask> \n </s> add SeparatedPathType to accept multiple paths\n\nMultiple paths for the reloader's `--extra-files` are accepted as one\noption, separated by ':'. </s> remove To define a list of files the reloader should watch additionally to the modules\nas in ``extra_files`` argument used in the ``app.run`` and ``werkzeug.serving.run_simple``\nyou can either use the ``--extra-files`` (or multiple ``-f``) option or define the\n``FLASK_RUN_EXTRA_FILES`` environment variable.\n\n.. code-block:: none\n\n    # on windows use ``;`` instead of ``:`` to separate paths\n    export FLASK_RUN_EXTRA_FILES=/path/to/file1:/path/to/file2\n    flask run\n     * Running on http://127.0.0.1:8000/\n     * Detected change in '/path/to/file1', reloading\n\nOn command line the same can be achieved with ``flask run -f /path/to/file1 -f /path/to/file2``.\n </s> add  </s> add class SeparatedPathType(click.Path):\n    \"\"\"Click option type that accepts a list of values separated by the\n    OS's path separator (``:``, ``;`` on Windows). Each value is\n    validated as a :class:`click.Path` type.\n    \"\"\"\n\n    def convert(self, value, param, ctx):\n        items = self.split_envvar_value(value)\n        super_convert = super(SeparatedPathType, self).convert\n        return [super_convert(item, param, ctx) for item in items]\n\n </s> add -   Add an ``--extra-files`` option to the ``flask run`` CLI command to\n    specify extra files that will trigger the reloader on change.\n    :issue:`2897` </s> remove -   Added support to ``extra_files`` argument in `flask run` CLI. (`#2898`_)\n\n.. _#2898: https://github.com/pallets/flask/pull/2898\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e18cc4d71d1c0ded4a2a7afb417c5ea03ebb0861", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>                          root path.\n <mask>         :param silent: set to ``True`` if you want silent failure for missing\n <mask>                        files.\n <mask> \n <mask>         .. versionadded:: 0.7\n <mask>            `silent` parameter.\n <mask>         \"\"\"\n <mask>         filename = os.path.join(self.root_path, filename)\n </s> document return value for config loading methods </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: Always returns ``True``.", "html_url": "https://github.com/pallets/flask/commit/e18ed45c8863ac645f3ce17a155034b8384e726f", "file_name": "src/flask/config.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             mapping of loaded data from the file.\n <mask>         :type load: ``Callable[[Reader], Mapping]`` where ``Reader``\n <mask>             implements a ``read`` method.\n <mask>         :param silent: Ignore the file if it doesn't exist.\n <mask> \n <mask>         .. versionadded:: 2.0\n <mask>         \"\"\"\n <mask>         filename = os.path.join(self.root_path, filename)\n <mask> \n </s> document return value for config loading methods </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: Always returns ``True``.", "html_url": "https://github.com/pallets/flask/commit/e18ed45c8863ac645f3ce17a155034b8384e726f", "file_name": "src/flask/config.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>             absolute path or relative to the config root path.\n <mask>         :param silent: Ignore the file if it doesn't exist.\n <mask> \n <mask>         .. deprecated:: 2.0.0\n <mask>             Will be removed in Flask 2.1. Use :meth:`from_file` instead.\n <mask>             This was removed early in 2.0.0, was added back in 2.0.1.\n <mask> \n <mask>         .. versionadded:: 0.11\n </s> document return value for config loading methods </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: Always returns ``True``.", "html_url": "https://github.com/pallets/flask/commit/e18ed45c8863ac645f3ce17a155034b8384e726f", "file_name": "src/flask/config.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         \"\"\"Updates the config like :meth:`update` ignoring items with non-upper\n <mask>         keys.\n <mask> \n <mask>         .. versionadded:: 0.11\n <mask>         \"\"\"\n <mask>         mappings: t.Dict[str, t.Any] = {}\n </s> document return value for config loading methods </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: ``True`` if the file was loaded successfully.", "html_url": "https://github.com/pallets/flask/commit/e18ed45c8863ac645f3ce17a155034b8384e726f", "file_name": "src/flask/config.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> -   :meth:`jsonify` supports :class:`dataclasses.dataclass` objects.\n <mask>     :pr:`3195`\n <mask> -   Allow customizing the :attr:`Flask.url_map_class` used for routing.\n <mask>     :pr:`3069`\n <mask> \n <mask> .. _#2935: https://github.com/pallets/flask/issues/2935\n <mask> .. _#2957: https://github.com/pallets/flask/issues/2957\n <mask> .. _#2994: https://github.com/pallets/flask/pull/2994\n <mask> .. _#3059: https://github.com/pallets/flask/pull/3059\n <mask> .. _#3179: https://github.com/pallets/flask/pull/3179\n </s> Fix 0 port value being overriden by default\n\nBy explicitly comparing port value with None,\ninstead of using its bool() value. </s> remove         port = int(port or sn_port or _port)\n </s> add         # pick the first value that's not None (0 is allowed)\n        port = int(next((p for p in (port, sn_port) if p is not None), _port)) </s> remove     app.config[\"SERVER_NAME\"] = \"pocoo.org:8080\"\n </s> add     app.config[\"SERVER_NAME\"] = server_name </s> remove def test_run_from_config(monkeypatch, host, port, expect_host, expect_port, app):\n </s> add def test_run_from_config(monkeypatch, host, port, server_name, expect_host, expect_port, app): </s> remove         (None, None, \"pocoo.org\", 8080),\n        (\"localhost\", None, \"localhost\", 8080),\n        (None, 80, \"pocoo.org\", 80),\n        (\"localhost\", 80, \"localhost\", 80),\n </s> add         (None, None, \"pocoo.org:8080\", \"pocoo.org\", 8080),\n        (\"localhost\", None, \"pocoo.org:8080\", \"localhost\", 8080),\n        (None, 80, \"pocoo.org:8080\", \"pocoo.org\", 80),\n        (\"localhost\", 80, \"pocoo.org:8080\", \"localhost\", 80),\n        (\"localhost\", 0, \"localhost:8080\", \"localhost\", 0),\n        (None, None, \"localhost:8080\", \"localhost\", 8080),\n        (None, None, \"localhost:0\", \"localhost\", 0), </s> remove     \"host,port,expect_host,expect_port\",\n </s> add     \"host,port,server_name,expect_host,expect_port\",", "html_url": "https://github.com/pallets/flask/commit/e1cc16f8bea15f11f63eacaa6089cd6e6b8b1965", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if server_name:\n <mask>             sn_host, _, sn_port = server_name.partition(\":\")\n <mask> \n <mask>         host = host or sn_host or _host\n <mask>         port = int(port or sn_port or _port)\n <mask> \n <mask>         options.setdefault(\"use_reloader\", self.debug)\n <mask>         options.setdefault(\"use_debugger\", self.debug)\n <mask>         options.setdefault(\"threaded\", True)\n <mask> \n </s> Fix 0 port value being overriden by default\n\nBy explicitly comparing port value with None,\ninstead of using its bool() value. </s> remove     app.config[\"SERVER_NAME\"] = \"pocoo.org:8080\"\n </s> add     app.config[\"SERVER_NAME\"] = server_name </s> remove def test_run_from_config(monkeypatch, host, port, expect_host, expect_port, app):\n </s> add def test_run_from_config(monkeypatch, host, port, server_name, expect_host, expect_port, app): </s> add -   The development server port can be set to 0, which tells the OS to\n    pick an available port. :issue:`2926` </s> remove         (None, None, \"pocoo.org\", 8080),\n        (\"localhost\", None, \"localhost\", 8080),\n        (None, 80, \"pocoo.org\", 80),\n        (\"localhost\", 80, \"localhost\", 80),\n </s> add         (None, None, \"pocoo.org:8080\", \"pocoo.org\", 8080),\n        (\"localhost\", None, \"pocoo.org:8080\", \"localhost\", 8080),\n        (None, 80, \"pocoo.org:8080\", \"pocoo.org\", 80),\n        (\"localhost\", 80, \"pocoo.org:8080\", \"localhost\", 80),\n        (\"localhost\", 0, \"localhost:8080\", \"localhost\", 0),\n        (None, None, \"localhost:8080\", \"localhost\", 8080),\n        (None, None, \"localhost:0\", \"localhost\", 0), </s> remove     \"host,port,expect_host,expect_port\",\n </s> add     \"host,port,server_name,expect_host,expect_port\",", "html_url": "https://github.com/pallets/flask/commit/e1cc16f8bea15f11f63eacaa6089cd6e6b8b1965", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace replace replace", "code_tokens": " <mask>     assert rv[\"result\"] == \"running on %s:%s ...\" % (hostname, port)\n <mask> \n <mask> \n <mask> @pytest.mark.parametrize(\n <mask>     \"host,port,expect_host,expect_port\",\n <mask>     (\n <mask>         (None, None, \"pocoo.org\", 8080),\n <mask>         (\"localhost\", None, \"localhost\", 8080),\n <mask>         (None, 80, \"pocoo.org\", 80),\n <mask>         (\"localhost\", 80, \"localhost\", 80),\n </s> Fix 0 port value being overriden by default\n\nBy explicitly comparing port value with None,\ninstead of using its bool() value. </s> remove     app.config[\"SERVER_NAME\"] = \"pocoo.org:8080\"\n </s> add     app.config[\"SERVER_NAME\"] = server_name </s> remove def test_run_from_config(monkeypatch, host, port, expect_host, expect_port, app):\n </s> add def test_run_from_config(monkeypatch, host, port, server_name, expect_host, expect_port, app): </s> remove         port = int(port or sn_port or _port)\n </s> add         # pick the first value that's not None (0 is allowed)\n        port = int(next((p for p in (port, sn_port) if p is not None), _port)) </s> add -   The development server port can be set to 0, which tells the OS to\n    pick an available port. :issue:`2926`", "html_url": "https://github.com/pallets/flask/commit/e1cc16f8bea15f11f63eacaa6089cd6e6b8b1965", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         (None, 80, \"pocoo.org\", 80),\n <mask>         (\"localhost\", 80, \"localhost\", 80),\n <mask>     ),\n <mask> )\n <mask> def test_run_from_config(monkeypatch, host, port, expect_host, expect_port, app):\n <mask>     def run_simple_mock(hostname, port, *args, **kwargs):\n <mask>         assert hostname == expect_host\n <mask>         assert port == expect_port\n <mask> \n <mask>     monkeypatch.setattr(werkzeug.serving, \"run_simple\", run_simple_mock)\n </s> Fix 0 port value being overriden by default\n\nBy explicitly comparing port value with None,\ninstead of using its bool() value. </s> remove         (None, None, \"pocoo.org\", 8080),\n        (\"localhost\", None, \"localhost\", 8080),\n        (None, 80, \"pocoo.org\", 80),\n        (\"localhost\", 80, \"localhost\", 80),\n </s> add         (None, None, \"pocoo.org:8080\", \"pocoo.org\", 8080),\n        (\"localhost\", None, \"pocoo.org:8080\", \"localhost\", 8080),\n        (None, 80, \"pocoo.org:8080\", \"pocoo.org\", 80),\n        (\"localhost\", 80, \"pocoo.org:8080\", \"localhost\", 80),\n        (\"localhost\", 0, \"localhost:8080\", \"localhost\", 0),\n        (None, None, \"localhost:8080\", \"localhost\", 8080),\n        (None, None, \"localhost:0\", \"localhost\", 0), </s> remove     app.config[\"SERVER_NAME\"] = \"pocoo.org:8080\"\n </s> add     app.config[\"SERVER_NAME\"] = server_name </s> remove     \"host,port,expect_host,expect_port\",\n </s> add     \"host,port,server_name,expect_host,expect_port\", </s> remove         port = int(port or sn_port or _port)\n </s> add         # pick the first value that's not None (0 is allowed)\n        port = int(next((p for p in (port, sn_port) if p is not None), _port)) </s> add -   The development server port can be set to 0, which tells the OS to\n    pick an available port. :issue:`2926`", "html_url": "https://github.com/pallets/flask/commit/e1cc16f8bea15f11f63eacaa6089cd6e6b8b1965", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         assert hostname == expect_host\n <mask>         assert port == expect_port\n <mask> \n <mask>     monkeypatch.setattr(werkzeug.serving, \"run_simple\", run_simple_mock)\n <mask>     app.config[\"SERVER_NAME\"] = \"pocoo.org:8080\"\n <mask>     app.run(host, port)\n <mask> \n <mask> \n <mask> def test_max_cookie_size(app, client, recwarn):\n <mask>     app.config[\"MAX_COOKIE_SIZE\"] = 100\n </s> Fix 0 port value being overriden by default\n\nBy explicitly comparing port value with None,\ninstead of using its bool() value. </s> remove def test_run_from_config(monkeypatch, host, port, expect_host, expect_port, app):\n </s> add def test_run_from_config(monkeypatch, host, port, server_name, expect_host, expect_port, app): </s> remove         port = int(port or sn_port or _port)\n </s> add         # pick the first value that's not None (0 is allowed)\n        port = int(next((p for p in (port, sn_port) if p is not None), _port)) </s> remove     \"host,port,expect_host,expect_port\",\n </s> add     \"host,port,server_name,expect_host,expect_port\", </s> remove         (None, None, \"pocoo.org\", 8080),\n        (\"localhost\", None, \"localhost\", 8080),\n        (None, 80, \"pocoo.org\", 80),\n        (\"localhost\", 80, \"localhost\", 80),\n </s> add         (None, None, \"pocoo.org:8080\", \"pocoo.org\", 8080),\n        (\"localhost\", None, \"pocoo.org:8080\", \"localhost\", 8080),\n        (None, 80, \"pocoo.org:8080\", \"pocoo.org\", 80),\n        (\"localhost\", 80, \"pocoo.org:8080\", \"localhost\", 80),\n        (\"localhost\", 0, \"localhost:8080\", \"localhost\", 0),\n        (None, None, \"localhost:8080\", \"localhost\", 8080),\n        (None, None, \"localhost:0\", \"localhost\", 0), </s> add -   The development server port can be set to 0, which tells the OS to\n    pick an available port. :issue:`2926`", "html_url": "https://github.com/pallets/flask/commit/e1cc16f8bea15f11f63eacaa6089cd6e6b8b1965", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> from __future__ import with_statement\n <mask> from sqlite3 import dbapi2 as sqlite3\n <mask> from flask import Flask, request, session, g, redirect, url_for, abort, \\\n <mask>      render_template, flash, _app_ctx_stack\n <mask> \n <mask> # configuration\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "examples/flaskr/flaskr.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> from __future__ import with_statement\n <mask> import time\n <mask> from sqlite3 import dbapi2 as sqlite3\n <mask> from hashlib import md5\n <mask> from datetime import datetime\n <mask> from flask import Flask, request, session, url_for, redirect, \\\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "examples/minitwit/minitwit.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     unichr = chr\n <mask>     range_type = range\n <mask>     text_type = str\n <mask>     string_types = (str,)\n <mask> \n <mask>     iterkeys = lambda d: iter(d.keys())\n <mask>     itervalues = lambda d: iter(d.values())\n <mask>     iteritems = lambda d: iter(d.items())\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add     integer_types = (int, long) </s> add     from urllib.parse import urlparse\n </s> remove     if isinstance(filename_or_fp, basestring):\n </s> add     if isinstance(filename_or_fp, string_types): </s> remove             if isinstance(status, basestring):\n </s> add             if isinstance(status, string_types): </s> remove \n    def test_init_jinja_globals(self):\n        class MyFlask(flask.Flask):\n            def init_jinja_globals(self):\n                self.jinja_env.globals['foo'] = '42'\n\n        with catch_warnings() as log:\n            app = MyFlask(__name__)\n            @app.route('/')\n            def foo():\n                return app.jinja_env.globals['foo']\n\n            c = app.test_client()\n            self.assert_equal(c.get('/').data, '42')\n            self.assert_equal(len(log), 1)\n            self.assert_('init_jinja_globals' in str(log[0]['message']))\n </s> add     \"\"\"not used currently\"\"\" </s> remove             if isinstance(rv, basestring):\n </s> add             if isinstance(rv, string_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/_compat.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     implements_to_string = _identity\n <mask>     encode_filename = _identity\n <mask>     get_next = lambda x: x.__next__\n <mask> \n <mask> else:\n <mask>     unichr = unichr\n <mask>     text_type = unicode\n <mask>     range_type = xrange\n <mask>     string_types = (str, unicode)\n <mask>     integer_types = (int, long)\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add     integer_types = (int, long) </s> add     integer_types = (int, ) </s> remove     if isinstance(filename_or_fp, basestring):\n </s> add     if isinstance(filename_or_fp, string_types): </s> remove             if isinstance(status, basestring):\n </s> add             if isinstance(status, string_types): </s> remove             if isinstance(rv, basestring):\n </s> add             if isinstance(rv, string_types): </s> remove         if isinstance(code_or_exception, (int, long)):\n </s> add         if isinstance(code_or_exception, integer_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/_compat.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     unichr = unichr\n <mask>     text_type = unicode\n <mask>     range_type = xrange\n <mask>     string_types = (str, unicode)\n <mask> \n <mask>     iterkeys = lambda d: d.iterkeys()\n <mask>     itervalues = lambda d: d.itervalues()\n <mask>     iteritems = lambda d: d.iteritems()\n <mask> \n <mask>     import cPickle as pickle\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add     integer_types = (int, ) </s> add     from urllib.parse import urlparse\n </s> remove \n    def test_init_jinja_globals(self):\n        class MyFlask(flask.Flask):\n            def init_jinja_globals(self):\n                self.jinja_env.globals['foo'] = '42'\n\n        with catch_warnings() as log:\n            app = MyFlask(__name__)\n            @app.route('/')\n            def foo():\n                return app.jinja_env.globals['foo']\n\n            c = app.test_client()\n            self.assert_equal(c.get('/').data, '42')\n            self.assert_equal(len(log), 1)\n            self.assert_('init_jinja_globals' in str(log[0]['message']))\n </s> add     \"\"\"not used currently\"\"\" </s> remove     if isinstance(filename_or_fp, basestring):\n </s> add     if isinstance(filename_or_fp, string_types): </s> remove             if isinstance(status, basestring):\n </s> add             if isinstance(status, string_types): </s> remove                 filename.encode('utf-8') if isinstance(filename, unicode)\n </s> add                 filename.encode('utf-8') if isinstance(filename, text_type)", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/_compat.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         return filename\n <mask> \n <mask> \n <mask> def with_metaclass(meta, *bases):\n <mask>     # This requires a bit of explanation: the basic idea is to make a\n <mask>     # dummy metaclass for one level of class instanciation that replaces\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove         for entry, value in sys.modules.items():\n </s> add         for entry, value in list(sys.modules.items()): </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv\n </s> add         return self.create_jinja_environment() </s> remove             raise exc_type, exc_value, tb\n </s> add             reraise(exc_type, exc_value, tb) </s> add from flask._compat import reraise </s> remove             raise exc_type, exc_value, tb\n </s> add             reraise(exc_type, exc_value, tb) </s> remove                     raise exc_type, exc_value, tb.tb_next\n </s> add                     reraise(exc_type, exc_value, tb.tb_next)", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/_compat.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import os\n <mask> import sys\n <mask> from threading import Lock\n <mask> from datetime import timedelta\n <mask> from itertools import chain\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     _default_template_ctx_processor\n <mask> from .signals import request_started, request_finished, got_request_exception, \\\n <mask>     request_tearing_down, appcontext_tearing_down\n <mask> \n <mask> # a lock used for logger initialization\n <mask> _logger_lock = Lock()\n <mask> \n <mask> \n <mask> def _make_timedelta(value):\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv\n </s> add         return self.create_jinja_environment() </s> add     from urlparse import urlparse\n </s> remove \n    def test_init_jinja_globals(self):\n        class MyFlask(flask.Flask):\n            def init_jinja_globals(self):\n                self.jinja_env.globals['foo'] = '42'\n\n        with catch_warnings() as log:\n            app = MyFlask(__name__)\n            @app.route('/')\n            def foo():\n                return app.jinja_env.globals['foo']\n\n            c = app.test_client()\n            self.assert_equal(c.get('/').data, '42')\n            self.assert_equal(len(log), 1)\n            self.assert_('init_jinja_globals' in str(log[0]['message']))\n </s> add     \"\"\"not used currently\"\"\" </s> remove                 for x in xrange(10):\n </s> add                 for x in range(10): </s> remove         if isinstance(code_or_exception, (int, long)):\n </s> add         if isinstance(code_or_exception, integer_types): </s> remove from urlparse import urlparse\n </s> add from flask._compat import urlparse", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     @locked_cached_property\n <mask>     def jinja_env(self):\n <mask>         \"\"\"The Jinja2 environment used to load templates.\"\"\"\n <mask>         rv = self.create_jinja_environment()\n <mask> \n <mask>         # Hack to support the init_jinja_globals method which is supported\n <mask>         # until 1.0 but has an API deficiency.\n <mask>         if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n <mask>            Flask.init_jinja_globals.__func__:\n <mask>             from warnings import warn\n <mask>             warn(DeprecationWarning('This flask class uses a customized '\n <mask>                 'init_jinja_globals() method which is deprecated. '\n <mask>                 'Move the code from that method into the '\n <mask>                 'create_jinja_environment() method instead.'))\n <mask>             self.__dict__['jinja_env'] = rv\n <mask>             self.init_jinja_globals()\n <mask> \n <mask>         return rv\n <mask> \n <mask>     @property\n <mask>     def got_first_request(self):\n <mask>         \"\"\"This attribute is set to `True` if the application started\n <mask>         handling the first request.\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove            and isinstance(filename, basestring):\n </s> add            and isinstance(filename, string_types): </s> add     from urlparse import urlparse\n </s> remove         if isinstance(code_or_exception, (int, long)):\n </s> add         if isinstance(code_or_exception, integer_types): </s> remove         for entry, value in sys.modules.items():\n </s> add         for entry, value in list(sys.modules.items()): </s> remove                     raise exc_type, exc_value, tb.tb_next\n </s> add                     reraise(exc_type, exc_value, tb.tb_next) </s> remove             if isinstance(rv, basestring):\n </s> add             if isinstance(rv, string_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @setupmethod\n <mask>     def _register_error_handler(self, key, code_or_exception, f):\n <mask>         if isinstance(code_or_exception, HTTPException):\n <mask>             code_or_exception = code_or_exception.code\n <mask>         if isinstance(code_or_exception, (int, long)):\n <mask>             assert code_or_exception != 500 or key is None, \\\n <mask>                 'It is currently not possible to register a 500 internal ' \\\n <mask>                 'server error on a per-blueprint level.'\n <mask>             self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n <mask>         else:\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv\n </s> add         return self.create_jinja_environment() </s> remove            and isinstance(filename, basestring):\n </s> add            and isinstance(filename, string_types): </s> remove             if isinstance(status, basestring):\n </s> add             if isinstance(status, string_types): </s> remove         for entry, value in sys.modules.items():\n </s> add         for entry, value in list(sys.modules.items()): </s> remove         if isinstance(obj, basestring):\n </s> add         if isinstance(obj, string_types): </s> add from flask._compat import reraise, string_types, integer_types", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>           @app.template_test()\n <mask>           def is_prime(n):\n <mask>               if n == 2:\n <mask>                   return True\n <mask>               for i in xrange(2, int(math.ceil(math.sqrt(n))) + 1):\n <mask>                   if n % i == 0:\n <mask>                       return False\n <mask>               return True\n <mask> \n <mask>         .. versionadded:: 0.10\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove             raise exc_type, exc_value, tb\n </s> add             reraise(exc_type, exc_value, tb) </s> remove         raise exc_type, exc_value, tb\n </s> add         reraise(exc_type, exc_value, tb) </s> remove         for entry, value in sys.modules.items():\n </s> add         for entry, value in list(sys.modules.items()): </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv\n </s> add         return self.create_jinja_environment() </s> remove \n    def test_init_jinja_globals(self):\n        class MyFlask(flask.Flask):\n            def init_jinja_globals(self):\n                self.jinja_env.globals['foo'] = '42'\n\n        with catch_warnings() as log:\n            app = MyFlask(__name__)\n            @app.route('/')\n            def foo():\n                return app.jinja_env.globals['foo']\n\n            c = app.test_client()\n            self.assert_equal(c.get('/').data, '42')\n            self.assert_equal(len(log), 1)\n            self.assert_('init_jinja_globals' in str(log[0]['message']))\n </s> add     \"\"\"not used currently\"\"\" </s> add     from urlparse import urlparse\n", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         for typecheck, handler in chain(blueprint_handlers, app_handlers):\n <mask>             if isinstance(e, typecheck):\n <mask>                 return handler(e)\n <mask> \n <mask>         raise exc_type, exc_value, tb\n <mask> \n <mask>     def handle_exception(self, e):\n <mask>         \"\"\"Default exception handling that kicks in when an exception\n <mask>         occurs that is not caught.  In debug mode the exception will\n <mask>         be re-raised immediately, otherwise it is logged and the handler\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove                 raise exc_type, exc_value, tb\n </s> add                 reraise(exc_type, exc_value, tb) </s> remove             raise exc_type, exc_value, tb\n </s> add             reraise(exc_type, exc_value, tb) </s> remove             raise exc_type, exc_value, tb\n </s> add             reraise(exc_type, exc_value, tb) </s> remove                     raise exc_type, exc_value, tb.tb_next\n </s> add                     reraise(exc_type, exc_value, tb.tb_next) </s> remove         for entry, value in sys.modules.items():\n </s> add         for entry, value in list(sys.modules.items()): </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv\n </s> add         return self.create_jinja_environment()", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             # raise it with the whole traceback in case we can do that\n <mask>             # (the function was actually called from the except part)\n <mask>             # otherwise, we just raise the error again\n <mask>             if exc_value is e:\n <mask>                 raise exc_type, exc_value, tb\n <mask>             else:\n <mask>                 raise e\n <mask> \n <mask>         self.log_exception((exc_type, exc_value, tb))\n <mask>         if handler is None:\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove             raise exc_type, exc_value, tb\n </s> add             reraise(exc_type, exc_value, tb) </s> remove                     raise exc_type, exc_value, tb.tb_next\n </s> add                     reraise(exc_type, exc_value, tb.tb_next) </s> remove         raise exc_type, exc_value, tb\n </s> add         reraise(exc_type, exc_value, tb) </s> remove             raise exc_type, exc_value, tb\n </s> add             reraise(exc_type, exc_value, tb) </s> remove             if isinstance(rv, basestring):\n </s> add             if isinstance(rv, string_types): </s> remove         for entry, value in sys.modules.items():\n </s> add         for entry, value in list(sys.modules.items()):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             # When we create a response object directly, we let the constructor\n <mask>             # set the headers and status.  We do this because there can be\n <mask>             # some extra logic involved when creating these objects with\n <mask>             # specific values (like defualt content type selection).\n <mask>             if isinstance(rv, basestring):\n <mask>                 rv = self.response_class(rv, headers=headers, status=status)\n <mask>                 headers = status = None\n <mask>             else:\n <mask>                 rv = self.response_class.force_type(rv, request.environ)\n <mask> \n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove             if isinstance(status, basestring):\n </s> add             if isinstance(status, string_types): </s> remove                 raise exc_type, exc_value, tb\n </s> add                 reraise(exc_type, exc_value, tb) </s> remove             raise exc_type, exc_value, tb\n </s> add             reraise(exc_type, exc_value, tb) </s> remove                     raise exc_type, exc_value, tb.tb_next\n </s> add                     reraise(exc_type, exc_value, tb.tb_next) </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv\n </s> add         return self.create_jinja_environment() </s> remove         for entry, value in sys.modules.items():\n </s> add         for entry, value in list(sys.modules.items()):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             else:\n <mask>                 rv = self.response_class.force_type(rv, request.environ)\n <mask> \n <mask>         if status is not None:\n <mask>             if isinstance(status, basestring):\n <mask>                 rv.status = status\n <mask>             else:\n <mask>                 rv.status_code = status\n <mask>         if headers:\n <mask>             rv.headers.extend(headers)\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove             if isinstance(rv, basestring):\n </s> add             if isinstance(rv, string_types): </s> remove     if isinstance(filename_or_fp, basestring):\n </s> add     if isinstance(filename_or_fp, string_types): </s> remove         if isinstance(code_or_exception, (int, long)):\n </s> add         if isinstance(code_or_exception, integer_types): </s> remove                 filename.encode('utf-8') if isinstance(filename, unicode)\n </s> add                 filename.encode('utf-8') if isinstance(filename, text_type) </s> add     from urllib.parse import urlparse\n </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv\n </s> add         return self.create_jinja_environment()", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # At this point we want to reraise the exception.  If the error is\n <mask>         # still the same one we can reraise it with the original traceback,\n <mask>         # otherwise we raise it from here.\n <mask>         if error is exc_value:\n <mask>             raise exc_type, exc_value, tb\n <mask>         raise error\n <mask> \n <mask>     def preprocess_request(self):\n <mask>         \"\"\"Called before the actual request dispatching and will\n <mask>         call every as :meth:`before_request` decorated function.\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove                 raise exc_type, exc_value, tb\n </s> add                 reraise(exc_type, exc_value, tb) </s> remove                     raise exc_type, exc_value, tb.tb_next\n </s> add                     reraise(exc_type, exc_value, tb.tb_next) </s> remove         raise exc_type, exc_value, tb\n </s> add         reraise(exc_type, exc_value, tb) </s> remove             if isinstance(rv, basestring):\n </s> add             if isinstance(rv, string_types): </s> remove         for entry, value in sys.modules.items():\n </s> add         for entry, value in list(sys.modules.items()): </s> remove             raise exc_type, exc_value, tb\n </s> add             reraise(exc_type, exc_value, tb)", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import imp\n <mask> import os\n <mask> import errno\n <mask> \n <mask> from werkzeug.utils import import_string\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add from flask._compat import string_types </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/config.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> import os\n <mask> import errno\n <mask> \n <mask> from werkzeug.utils import import_string\n <mask> \n <mask> \n <mask> class ConfigAttribute(object):\n <mask>     \"\"\"Makes an attribute forward to the config\"\"\"\n <mask> \n <mask>     def __init__(self, name, get_converter=None):\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n\n </s> add  </s> add from flask._compat import reraise, StringIO </s> add from flask._compat import reraise </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv\n </s> add         return self.create_jinja_environment() </s> add from flask._compat import StringIO </s> remove from StringIO import StringIO\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/config.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         package because the package might be installed system wide.\n <mask> \n <mask>         :param obj: an import name or object\n <mask>         \"\"\"\n <mask>         if isinstance(obj, basestring):\n <mask>             obj = import_string(obj)\n <mask>         for key in dir(obj):\n <mask>             if key.isupper():\n <mask>                 self[key] = getattr(obj, key)\n <mask> \n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove             if isinstance(rv, basestring):\n </s> add             if isinstance(rv, string_types): </s> remove            and isinstance(filename, basestring):\n </s> add            and isinstance(filename, string_types): </s> remove         for entry, value in sys.modules.items():\n </s> add         for entry, value in list(sys.modules.items()): </s> remove     if isinstance(filename_or_fp, basestring):\n </s> add     if isinstance(filename_or_fp, string_types): </s> remove         if isinstance(code_or_exception, (int, long)):\n </s> add         if isinstance(code_or_exception, integer_types): </s> remove             if isinstance(status, basestring):\n </s> add             if isinstance(status, string_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/config.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> import sys\n <mask> import os\n <mask> \n <mask> \n <mask> class ExtensionImporter(object):\n <mask>     \"\"\"This importer redirects imports from this submodule to other locations.\n <mask>     This makes it possible to transition from the old flaskext.name to the\n <mask>     newer flask_name without people having a hard time.\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add     from urlparse import urlparse\n </s> add from flask._compat import string_types </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv\n </s> add         return self.create_jinja_environment() </s> add from flask._compat import reraise, StringIO </s> remove             raise exc_type, exc_value, tb\n </s> add             reraise(exc_type, exc_value, tb) </s> remove from __future__ import with_statement\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/exthook.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 # If it's an important traceback we reraise it, otherwise\n <mask>                 # we swallow it and try the next choice.  The skipped frame\n <mask>                 # is the one from __import__ above which we don't care about\n <mask>                 if self.is_important_traceback(realname, tb):\n <mask>                     raise exc_type, exc_value, tb.tb_next\n <mask>                 continue\n <mask>             module = sys.modules[fullname] = sys.modules[realname]\n <mask>             if '.' not in modname:\n <mask>                 setattr(sys.modules[self.wrapper_module], modname, module)\n <mask>             return module\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove             raise exc_type, exc_value, tb\n </s> add             reraise(exc_type, exc_value, tb) </s> remove                 raise exc_type, exc_value, tb\n </s> add                 reraise(exc_type, exc_value, tb) </s> remove         for entry, value in sys.modules.items():\n </s> add         for entry, value in list(sys.modules.items()): </s> remove         raise exc_type, exc_value, tb\n </s> add         reraise(exc_type, exc_value, tb) </s> remove             if isinstance(rv, basestring):\n </s> add             if isinstance(rv, string_types): </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv\n </s> add         return self.create_jinja_environment()", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/exthook.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import os\n <mask> import sys\n <mask> import pkgutil\n <mask> import posixpath\n <mask> import mimetypes\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> from werkzeug.exceptions import NotFound\n <mask> import six\n <mask> \n <mask> # this was moved in 0.7\n <mask> try:\n <mask>     from werkzeug.wsgi import wrap_file\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add from flask._compat import StringIO </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from StringIO import StringIO\n </s> add  </s> remove         for x in xrange(2):\n </s> add         for x in range(2): </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                           :meth:`~Flask.get_send_file_max_age` of\n <mask>                           :data:`~flask.current_app`.\n <mask>     \"\"\"\n <mask>     mtime = None\n <mask>     if isinstance(filename_or_fp, basestring):\n <mask>         filename = filename_or_fp\n <mask>         file = None\n <mask>     else:\n <mask>         from warnings import warn\n <mask>         file = filename_or_fp\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove             if isinstance(rv, basestring):\n </s> add             if isinstance(rv, string_types): </s> remove             if isinstance(status, basestring):\n </s> add             if isinstance(status, string_types): </s> add     from urllib.parse import urlparse\n </s> remove         if isinstance(obj, basestring):\n </s> add         if isinstance(obj, string_types): </s> remove            and isinstance(filename, basestring):\n </s> add            and isinstance(filename, string_types): </s> add     integer_types = (int, long)", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         # XXX: this behavior is now deprecated because it was unreliable.\n <mask>         # removed in Flask 1.0\n <mask>         if not attachment_filename and not mimetype \\\n <mask>            and isinstance(filename, basestring):\n <mask>             warn(DeprecationWarning('The filename support for file objects '\n <mask>                 'passed to send_file is now deprecated.  Pass an '\n <mask>                 'attach_filename if you want mimetypes to be guessed.'),\n <mask>                 stacklevel=2)\n <mask>         if add_etags:\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv\n </s> add         return self.create_jinja_environment() </s> remove         for entry, value in sys.modules.items():\n </s> add         for entry, value in list(sys.modules.items()): </s> remove             raise exc_type, exc_value, tb\n </s> add             reraise(exc_type, exc_value, tb) </s> remove         if isinstance(code_or_exception, (int, long)):\n </s> add         if isinstance(code_or_exception, integer_types): </s> remove             if isinstance(rv, basestring):\n </s> add             if isinstance(rv, string_types): </s> remove         raise exc_type, exc_value, tb\n </s> add         reraise(exc_type, exc_value, tb)", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         rv.set_etag('flask-%s-%s-%s' % (\n <mask>             os.path.getmtime(filename),\n <mask>             os.path.getsize(filename),\n <mask>             adler32(\n <mask>                 filename.encode('utf-8') if isinstance(filename, unicode)\n <mask>                 else filename\n <mask>             ) & 0xffffffff\n <mask>         ))\n <mask>         if conditional:\n <mask>             rv = rv.make_conditional(request)\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove            and isinstance(filename, basestring):\n </s> add            and isinstance(filename, string_types): </s> remove             if isinstance(status, basestring):\n </s> add             if isinstance(status, string_types): </s> remove     if isinstance(filename_or_fp, basestring):\n </s> add     if isinstance(filename_or_fp, string_types): </s> remove             if isinstance(rv, basestring):\n </s> add             if isinstance(rv, string_types): </s> add     integer_types = (int, ) </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv\n </s> add         return self.create_jinja_environment()", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep replace replace keep keep keep keep keep keep keep keep replace keep", "code_tokens": " <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> from contextlib import contextmanager\n <mask> from werkzeug.test import Client, EnvironBuilder\n <mask> from flask import _request_ctx_stack\n <mask> from urlparse import urlparse\n <mask> \n <mask> from contextlib import contextmanager\n <mask> from werkzeug.test import Client, EnvironBuilder\n <mask> from flask import _request_ctx_stack\n <mask> from urlparse import urlparse\n <mask> \n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from StringIO import StringIO\n </s> add  </s> add from flask._compat import reraise, StringIO </s> remove from StringIO import StringIO\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import print_function\n <mask> from __future__ import with_statement\n <mask> \n <mask> import os\n <mask> import sys\n <mask> import flask\n <mask> import warnings\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import sys\n <mask> import flask\n <mask> import warnings\n <mask> import unittest\n <mask> from StringIO import StringIO\n <mask> from functools import update_wrapper\n <mask> from contextlib import contextmanager\n <mask> from werkzeug.utils import import_string, find_modules\n <mask> \n <mask> \n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add from flask._compat import reraise, StringIO </s> remove from StringIO import StringIO\n </s> add  </s> remove from StringIO import StringIO\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> from contextlib import contextmanager\n <mask> from werkzeug.utils import import_string, find_modules\n <mask> \n <mask> \n <mask> def add_to_path(path):\n <mask>     \"\"\"Adds an entry to sys.path if it's not already there.  This does\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from StringIO import StringIO\n </s> add  </s> add from flask._compat import string_types </s> remove from urlparse import urlparse\n </s> add from flask._compat import urlparse </s> remove from __future__ import with_statement\n\n </s> add  </s> add from flask._compat import reraise </s> remove                 for x in xrange(10):\n </s> add                 for x in range(10):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if exc_type is None:\n <mask>             self.test_case.fail('Expected exception of type %r' %\n <mask>                                 exception_name)\n <mask>         elif not issubclass(exc_type, self.exc_type):\n <mask>             raise exc_type, exc_value, tb\n <mask>         return True\n <mask> \n <mask> \n <mask> class BetterLoader(unittest.TestLoader):\n <mask>     \"\"\"A nicer loader that solves two problems.  First of all we are setting\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove         raise exc_type, exc_value, tb\n </s> add         reraise(exc_type, exc_value, tb) </s> remove                 raise exc_type, exc_value, tb\n </s> add                 reraise(exc_type, exc_value, tb) </s> add     from urlparse import urlparse\n </s> remove             raise exc_type, exc_value, tb\n </s> add             reraise(exc_type, exc_value, tb) </s> remove                     raise exc_type, exc_value, tb.tb_next\n </s> add                     reraise(exc_type, exc_value, tb.tb_next) </s> remove               for i in xrange(2, int(math.ceil(math.sqrt(n))) + 1):\n </s> add               for i in range(2, int(math.ceil(math.sqrt(n))) + 1):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2012 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import flask\n <mask> import unittest\n <mask> from flask.testsuite import FlaskTestCase\n <mask> \n <mask> \n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/appctx.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import re\n <mask> import uuid\n <mask> import flask\n <mask> import pickle\n <mask> import unittest\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def fail_func():\n <mask>             1/0\n <mask> \n <mask>         c = app.test_client()\n <mask>         for x in xrange(3):\n <mask>             with self.assert_raises(ZeroDivisionError):\n <mask>                 c.get('/fail')\n <mask> \n <mask>         self.assert_(flask._request_ctx_stack.top is not None)\n <mask>         self.assert_(flask._app_ctx_stack.top is not None)\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove                 for x in xrange(10):\n </s> add                 for x in range(10): </s> remove         for entry, value in sys.modules.items():\n </s> add         for entry, value in list(sys.modules.items()): </s> remove         for x in xrange(2):\n </s> add         for x in range(2): </s> remove \n    def test_init_jinja_globals(self):\n        class MyFlask(flask.Flask):\n            def init_jinja_globals(self):\n                self.jinja_env.globals['foo'] = '42'\n\n        with catch_warnings() as log:\n            app = MyFlask(__name__)\n            @app.route('/')\n            def foo():\n                return app.jinja_env.globals['foo']\n\n            c = app.test_client()\n            self.assert_equal(c.get('/').data, '42')\n            self.assert_equal(len(log), 1)\n            self.assert_('init_jinja_globals' in str(log[0]['message']))\n </s> add     \"\"\"not used currently\"\"\" </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv\n </s> add         return self.create_jinja_environment() </s> remove         raise exc_type, exc_value, tb\n </s> add         reraise(exc_type, exc_value, tb)", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import flask\n <mask> import unittest\n <mask> import warnings\n <mask> from flask.testsuite import FlaskTestCase, emits_module_deprecation_warning\n <mask> from werkzeug.exceptions import NotFound\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> from __future__ import with_statement\n <mask> \n <mask> import os\n <mask> import sys\n <mask> import flask\n <mask> import pkgutil\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import flask\n <mask> import unittest\n <mask> from flask.testsuite import FlaskTestCase, catch_warnings\n <mask> \n <mask> \n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/deprecations.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> from flask.testsuite import FlaskTestCase, catch_warnings\n <mask> \n <mask> \n <mask> class DeprecationsTestCase(FlaskTestCase):\n <mask> \n <mask>     def test_init_jinja_globals(self):\n <mask>         class MyFlask(flask.Flask):\n <mask>             def init_jinja_globals(self):\n <mask>                 self.jinja_env.globals['foo'] = '42'\n <mask> \n <mask>         with catch_warnings() as log:\n <mask>             app = MyFlask(__name__)\n <mask>             @app.route('/')\n <mask>             def foo():\n <mask>                 return app.jinja_env.globals['foo']\n <mask> \n <mask>             c = app.test_client()\n <mask>             self.assert_equal(c.get('/').data, '42')\n <mask>             self.assert_equal(len(log), 1)\n <mask>             self.assert_('init_jinja_globals' in str(log[0]['message']))\n <mask> \n <mask> \n <mask> def suite():\n <mask>     suite = unittest.TestSuite()\n <mask>     suite.addTest(unittest.makeSuite(DeprecationsTestCase))\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove         for x in xrange(3):\n </s> add         for x in range(3): </s> add from flask._compat import StringIO </s> remove         for x in xrange(2):\n </s> add         for x in range(2): </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv\n </s> add         return self.create_jinja_environment() </s> remove from urlparse import urlparse\n </s> add from flask._compat import urlparse </s> add     integer_types = (int, long)", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/deprecations.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> from __future__ import with_statement\n <mask> \n <mask> import sys\n <mask> import unittest\n <mask> from flask.testsuite import FlaskTestCase\n <mask> from six.moves import reload_module\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/ext.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # we clear this out for various reasons.  The most important one is\n <mask>         # that a real flaskext could be in there which would disable our\n <mask>         # fake package.  Secondly we want to make sure that the flaskext\n <mask>         # import hook does not break on reloading.\n <mask>         for entry, value in sys.modules.items():\n <mask>             if (entry.startswith('flask.ext.') or\n <mask>                 entry.startswith('flask_') or\n <mask>                 entry.startswith('flaskext.') or\n <mask>                 entry == 'flaskext') and value is not None:\n <mask>                 sys.modules.pop(entry, None)\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove                     raise exc_type, exc_value, tb.tb_next\n </s> add                     reraise(exc_type, exc_value, tb.tb_next) </s> add     from urlparse import urlparse\n </s> remove            and isinstance(filename, basestring):\n </s> add            and isinstance(filename, string_types): </s> remove             raise exc_type, exc_value, tb\n </s> add             reraise(exc_type, exc_value, tb) </s> remove                 raise exc_type, exc_value, tb\n </s> add                 reraise(exc_type, exc_value, tb) </s> remove             if isinstance(rv, basestring):\n </s> add             if isinstance(rv, string_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/ext.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         from flask.ext.oldext_package.submodule import test_function\n <mask>         self.assert_equal(test_function(), 42)\n <mask> \n <mask>     def test_flaskext_broken_package_no_module_caching(self):\n <mask>         for x in xrange(2):\n <mask>             with self.assert_raises(ImportError):\n <mask>                 import flask.ext.broken\n <mask> \n <mask>     def test_no_error_swallowing(self):\n <mask>         try:\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove                 for x in xrange(10):\n </s> add                 for x in range(10): </s> remove         for x in xrange(3):\n </s> add         for x in range(3): </s> add from flask._compat import StringIO </s> add from flask._compat import string_types, text_type </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from urlparse import urlparse\n </s> add from flask._compat import urlparse", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/ext.py"}
{"docstring_tokens": "keep keep keep replace replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import os\n <mask> import flask\n <mask> import unittest\n <mask> from logging import StreamHandler\n <mask> from StringIO import StringIO\n <mask> from flask.testsuite import FlaskTestCase, catch_warnings, catch_stderr\n <mask> from werkzeug.http import parse_cache_control_header, parse_options_header\n <mask> import six\n <mask> \n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add from flask._compat import StringIO </s> remove from StringIO import StringIO\n </s> add  </s> add from flask._compat import StringIO </s> remove from __future__ import with_statement\n </s> add  </s> remove from StringIO import StringIO\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> from werkzeug.http import parse_cache_control_header, parse_options_header\n <mask> import six\n <mask> \n <mask> \n <mask> def has_encoding(name):\n <mask>     try:\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from StringIO import StringIO\n </s> add  </s> add from flask._compat import string_types, text_type </s> remove         for x in xrange(2):\n </s> add         for x in range(2): </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import os\n <mask> import gc\n <mask> import sys\n <mask> import flask\n <mask> import threading\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/regression.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # This test only works on CPython 2.7.\n <mask>         if sys.version_info >= (2, 7) and \\\n <mask>                 not hasattr(sys, 'pypy_translation_info'):\n <mask>             with self.assert_no_leak():\n <mask>                 for x in xrange(10):\n <mask>                     fire()\n <mask> \n <mask>     def test_safe_join_toplevel_pardir(self):\n <mask>         from flask.helpers import safe_join\n <mask>         with self.assert_raises(NotFound):\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove         for x in xrange(2):\n </s> add         for x in range(2): </s> remove         for x in xrange(3):\n </s> add         for x in range(3): </s> remove         for entry, value in sys.modules.items():\n </s> add         for entry, value in list(sys.modules.items()): </s> remove            and isinstance(filename, basestring):\n </s> add            and isinstance(filename, string_types): </s> remove from urlparse import urlparse\n </s> add from flask._compat import urlparse </s> add from flask._compat import reraise, StringIO", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/regression.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2012 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import flask\n <mask> import unittest\n <mask> try:\n <mask>     from greenlet import greenlet\n <mask> except ImportError:\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/reqctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> from __future__ import with_statement\n <mask> \n <mask> import flask\n <mask> import unittest\n <mask> from flask.testsuite import FlaskTestCase\n <mask> \n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/signals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> import flask\n <mask> import unittest\n <mask> from StringIO import StringIO\n <mask> from logging import StreamHandler\n <mask> from flask.testsuite import FlaskTestCase\n <mask> \n <mask> \n <mask> class FlaskSubclassingTestCase(FlaskTestCase):\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add from flask._compat import StringIO </s> remove from StringIO import StringIO\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from StringIO import StringIO\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/subclassing.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> from logging import StreamHandler\n <mask> from flask.testsuite import FlaskTestCase\n <mask> \n <mask> \n <mask> class FlaskSubclassingTestCase(FlaskTestCase):\n <mask> \n <mask>     def test_suppressed_exception_logging(self):\n <mask>         class SuppressedFlask(flask.Flask):\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from StringIO import StringIO\n </s> add  </s> remove from StringIO import StringIO\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> add from flask._compat import string_types </s> remove \n    def test_init_jinja_globals(self):\n        class MyFlask(flask.Flask):\n            def init_jinja_globals(self):\n                self.jinja_env.globals['foo'] = '42'\n\n        with catch_warnings() as log:\n            app = MyFlask(__name__)\n            @app.route('/')\n            def foo():\n                return app.jinja_env.globals['foo']\n\n            c = app.test_client()\n            self.assert_equal(c.get('/').data, '42')\n            self.assert_equal(len(log), 1)\n            self.assert_('init_jinja_globals' in str(log[0]['message']))\n </s> add     \"\"\"not used currently\"\"\" </s> remove from __future__ import with_statement\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/subclassing.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import flask\n <mask> import unittest\n <mask> from flask.testsuite import FlaskTestCase\n <mask> \n <mask> \n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import flask\n <mask> import unittest\n <mask> from flask.testsuite import FlaskTestCase\n <mask> import six\n <mask> \n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/testing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> from __future__ import with_statement\n <mask> import flask\n <mask> import flask.views\n <mask> import unittest\n <mask> from flask.testsuite import FlaskTestCase\n <mask> from werkzeug.http import parse_set_header\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/views.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2010 by Ali Afshar.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import os\n <mask> import sys\n <mask> import shutil\n <mask> import urllib2\n <mask> import tempfile\n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n\n </s> add  </s> remove from __future__ import with_statement\n </s> add  </s> remove from __future__ import with_statement\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "scripts/flaskext_test.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     app = getattr(module, 'app', None)\n <mask>     if app is not None and callable(app):\n <mask>         return app\n <mask> \n <mask>     # Otherwise find the first object named Flask\n <mask>     matches = []\n <mask>     for key, value in iteritems(module.__dict__):\n <mask>         if isinstance(value, Flask):\n <mask>             matches.append(value)\n <mask> \n </s> Fix typos in docstrings and comments in run.py </s> remove     # Extra startup messages.  This depends a but on Werkzeug internals to\n </s> add     # Extra startup messages.  This depends a bit on Werkzeug internals to </s> remove     is known by it's import name.  By default the app ID can also be a\n </s> add     is known by its import name.  By default the app ID can also be a </s> remove     \"\"\"Special applicationt that dispatches to a flask application which\n </s> add     \"\"\"Special application that dispatches to a flask application which </s> remove     the application upfront because it means that we can forward all\n    errors for import problems into the browser as error.\n </s> add     the application up front because it means that we can forward all\n    errors for import problems into the browser as errors. </s> remove     # Chop off file extensions or package markers\n </s> add     # Chop off file extensions or package markers.", "html_url": "https://github.com/pallets/flask/commit/e21afed0bba82668c6e4f5f433d0ccfcf54b3577", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def prepare_exec_for_file(filename):\n <mask>     module = []\n <mask> \n <mask>     # Chop off file extensions or package markers\n <mask>     if filename.endswith('.py'):\n <mask>         filename = filename[:-3]\n <mask>     elif os.path.split(filename)[1] == '__init__.py':\n <mask>         filename = os.path.dirname(filename)\n <mask>     filename = os.path.realpath(filename)\n </s> Fix typos in docstrings and comments in run.py </s> remove     # Otherwise find the first object named Flask\n </s> add     # Otherwise find exactly one Flask instance, or fail. </s> remove     the application upfront because it means that we can forward all\n    errors for import problems into the browser as error.\n </s> add     the application up front because it means that we can forward all\n    errors for import problems into the browser as errors. </s> remove     # Extra startup messages.  This depends a but on Werkzeug internals to\n </s> add     # Extra startup messages.  This depends a bit on Werkzeug internals to </s> remove     is known by it's import name.  By default the app ID can also be a\n </s> add     is known by its import name.  By default the app ID can also be a </s> remove     \"\"\"Special applicationt that dispatches to a flask application which\n </s> add     \"\"\"Special application that dispatches to a flask application which", "html_url": "https://github.com/pallets/flask/commit/e21afed0bba82668c6e4f5f433d0ccfcf54b3577", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep keep keep keep keep replace replace keep keep", "code_tokens": " <mask> \n <mask> \n <mask> class DispatchingApp(object):\n <mask>     \"\"\"Special applicationt that dispatches to a flask application which\n <mask>     is imported by name on first request.  This is safer than importing\n <mask>     the application upfront because it means that we can forward all\n <mask>     errors for import problems into the browser as error.\n <mask>     \"\"\"\n <mask> \n <mask> class DispatchingApp(object):\n <mask>     \"\"\"Special applicationt that dispatches to a flask application which\n <mask>     is imported by name on first request.  This is safer than importing\n <mask>     the application upfront because it means that we can forward all\n <mask>     errors for import problems into the browser as error.\n <mask>     \"\"\"\n <mask> \n </s> Fix typos in docstrings and comments in run.py </s> remove     is known by it's import name.  By default the app ID can also be a\n </s> add     is known by its import name.  By default the app ID can also be a </s> remove     # Extra startup messages.  This depends a but on Werkzeug internals to\n </s> add     # Extra startup messages.  This depends a bit on Werkzeug internals to </s> remove     # Otherwise find the first object named Flask\n </s> add     # Otherwise find exactly one Flask instance, or fail. </s> remove     # Chop off file extensions or package markers\n </s> add     # Chop off file extensions or package markers.", "html_url": "https://github.com/pallets/flask/commit/e21afed0bba82668c6e4f5f433d0ccfcf54b3577", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     use_reloader=False, use_debugger=False,\n <mask>                     use_eager_loading=None, magic_app_id=True,\n <mask>                     **options):\n <mask>     \"\"\"Useful function to start a Werkzeug server for an application that\n <mask>     is known by it's import name.  By default the app ID can also be a\n <mask>     full file name in which case Flask attempts to reconstruct the import\n <mask>     name from it and do the right thing.\n <mask> \n <mask>     :param app_id: the import name of the application module.  If a colon\n <mask>                    is provided, everything afterwards is the application\n </s> Fix typos in docstrings and comments in run.py </s> remove     \"\"\"Special applicationt that dispatches to a flask application which\n </s> add     \"\"\"Special application that dispatches to a flask application which </s> remove     # Extra startup messages.  This depends a but on Werkzeug internals to\n </s> add     # Extra startup messages.  This depends a bit on Werkzeug internals to </s> remove     the application upfront because it means that we can forward all\n    errors for import problems into the browser as error.\n </s> add     the application up front because it means that we can forward all\n    errors for import problems into the browser as errors. </s> remove     # Otherwise find the first object named Flask\n </s> add     # Otherwise find exactly one Flask instance, or fail. </s> remove     # Chop off file extensions or package markers\n </s> add     # Chop off file extensions or package markers.", "html_url": "https://github.com/pallets/flask/commit/e21afed0bba82668c6e4f5f433d0ccfcf54b3577", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     if use_eager_loading is None:\n <mask>         use_eager_loading = not use_reloader\n <mask> \n <mask>     # Extra startup messages.  This depends a but on Werkzeug internals to\n <mask>     # not double execute when the reloader kicks in.\n <mask>     if os.environ.get('WERKZEUG_RUN_MAIN') != 'true':\n <mask>         print ' * Serving Flask app \"%s\"' % app_id\n <mask>         if debug is not None:\n <mask>             print ' * Forcing debug %s' % (debug and 'on' or 'off')\n </s> Fix typos in docstrings and comments in run.py </s> remove     # Otherwise find the first object named Flask\n </s> add     # Otherwise find exactly one Flask instance, or fail. </s> remove     is known by it's import name.  By default the app ID can also be a\n </s> add     is known by its import name.  By default the app ID can also be a </s> remove     the application upfront because it means that we can forward all\n    errors for import problems into the browser as error.\n </s> add     the application up front because it means that we can forward all\n    errors for import problems into the browser as errors. </s> remove     \"\"\"Special applicationt that dispatches to a flask application which\n </s> add     \"\"\"Special application that dispatches to a flask application which </s> remove     # Chop off file extensions or package markers\n </s> add     # Chop off file extensions or package markers.", "html_url": "https://github.com/pallets/flask/commit/e21afed0bba82668c6e4f5f433d0ccfcf54b3577", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> -------------\n <mask> \n <mask> Unreleased\n <mask> \n <mask> -   Update Click dependency to >= 8.0.\n <mask> \n <mask> \n <mask> Version 2.0.2\n <mask> -------------\n <mask> \n </s> remove deprecated script_info factory arg </s> remove     if int(click.__version__[0]) < 8:\n        warnings.warn(\n            \"Using the `flask` cli with Click 7 is deprecated and\"\n            \" will not be supported starting with Flask 2.1.\"\n            \" Please upgrade to Click 8 as soon as possible.\",\n            DeprecationWarning,\n        )\n    # TODO omit sys.argv once https://github.com/pallets/click/issues/536 is fixed\n    cli.main(args=sys.argv[1:])\n </s> add     cli.main() </s> remove def find_best_app(script_info, module):\n </s> add def find_best_app(module): </s> remove def find_app_by_string(script_info, module, app_name):\n </s> add def find_app_by_string(module, app_name): </s> remove             app = call_factory(script_info, attr, args, kwargs)\n </s> add             app = attr(*args, **kwargs) </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)\n\n\n </s> add  </s> remove     script_info = ScriptInfo()\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import platform\n <mask> import re\n <mask> import sys\n <mask> import traceback\n <mask> import warnings\n <mask> from functools import update_wrapper\n <mask> from operator import attrgetter\n <mask> from threading import Lock\n <mask> from threading import Thread\n <mask> \n </s> remove deprecated script_info factory arg </s> remove         locate_app(info, \"cliapp.importerrorapp\", None, raise_if_not_found=False)\n </s> add         locate_app(\"cliapp.importerrorapp\", None, raise_if_not_found=False) </s> remove def find_best_app(script_info, module):\n </s> add def find_best_app(module): </s> remove def find_app_by_string(script_info, module, app_name):\n </s> add def find_app_by_string(module, app_name): </s> remove     info = ScriptInfo()\n    app = locate_app(info, \"notanapp.py\", None, raise_if_not_found=False)\n </s> add     app = locate_app(\"notanapp.py\", None, raise_if_not_found=False) </s> remove         args = kwargs = None\n </s> add         args = []\n        kwargs = {} </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)\n\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> class NoAppException(click.UsageError):\n <mask>     \"\"\"Raised if an application cannot be found or loaded.\"\"\"\n <mask> \n <mask> \n <mask> def find_best_app(script_info, module):\n <mask>     \"\"\"Given a module instance this tries to find the best possible\n <mask>     application in the module or raises an exception.\n <mask>     \"\"\"\n <mask>     from . import Flask\n <mask> \n </s> remove deprecated script_info factory arg </s> remove def find_app_by_string(script_info, module, app_name):\n </s> add def find_app_by_string(module, app_name): </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)\n\n\n </s> add  </s> remove         args = kwargs = None\n </s> add         args = []\n        kwargs = {} </s> remove         return find_best_app(script_info, module)\n </s> add         return find_best_app(module) </s> remove     if int(click.__version__[0]) < 8:\n        warnings.warn(\n            \"Using the `flask` cli with Click 7 is deprecated and\"\n            \" will not be supported starting with Flask 2.1.\"\n            \" Please upgrade to Click 8 as soon as possible.\",\n            DeprecationWarning,\n        )\n    # TODO omit sys.argv once https://github.com/pallets/click/issues/536 is fixed\n    cli.main(args=sys.argv[1:])\n </s> add     cli.main() </s> remove             app = call_factory(script_info, attr, args, kwargs)\n </s> add             app = attr(*args, **kwargs)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app_factory = getattr(module, attr_name, None)\n <mask> \n <mask>         if inspect.isfunction(app_factory):\n <mask>             try:\n <mask>                 app = call_factory(script_info, app_factory)\n <mask> \n <mask>                 if isinstance(app, Flask):\n <mask>                     return app\n <mask>             except TypeError as e:\n <mask>                 if not _called_with_wrong_args(app_factory):\n </s> remove deprecated script_info factory arg </s> remove             app = call_factory(script_info, attr, args, kwargs)\n </s> add             app = attr(*args, **kwargs) </s> remove def locate_app(script_info, module_name, app_name, raise_if_not_found=True):\n </s> add def locate_app(module_name, app_name, raise_if_not_found=True): </s> remove             app = call_factory(self, self.create_app)\n </s> add             app = self.create_app() </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)\n\n\n </s> add  </s> remove                     app = locate_app(self, import_name, None, raise_if_not_found=False)\n </s> add                     app = locate_app(import_name, None, raise_if_not_found=False) </s> remove         args = kwargs = None\n </s> add         args = []\n        kwargs = {}", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         \" to specify one.\"\n <mask>     )\n <mask> \n <mask> \n <mask> def call_factory(script_info, app_factory, args=None, kwargs=None):\n <mask>     \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n <mask>     of arguments. Checks for the existence of a script_info argument and calls\n <mask>     the app_factory depending on that and the arguments provided.\n <mask>     \"\"\"\n <mask>     sig = inspect.signature(app_factory)\n <mask>     args = [] if args is None else args\n <mask>     kwargs = {} if kwargs is None else kwargs\n <mask> \n <mask>     if \"script_info\" in sig.parameters:\n <mask>         warnings.warn(\n <mask>             \"The 'script_info' argument is deprecated and will not be\"\n <mask>             \" passed to the app factory function in Flask 2.1.\",\n <mask>             DeprecationWarning,\n <mask>         )\n <mask>         kwargs[\"script_info\"] = script_info\n <mask> \n <mask>     if not args and len(sig.parameters) == 1:\n <mask>         first_parameter = next(iter(sig.parameters.values()))\n <mask> \n <mask>         if (\n <mask>             first_parameter.default is inspect.Parameter.empty\n <mask>             # **kwargs is reported as an empty default, ignore it\n <mask>             and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n <mask>         ):\n <mask>             warnings.warn(\n <mask>                 \"Script info is deprecated and will not be passed as the\"\n <mask>                 \" single argument to the app factory function in Flask\"\n <mask>                 \" 2.1.\",\n <mask>                 DeprecationWarning,\n <mask>             )\n <mask>             args.append(script_info)\n <mask> \n <mask>     return app_factory(*args, **kwargs)\n <mask> \n <mask> \n <mask> def _called_with_wrong_args(f):\n <mask>     \"\"\"Check whether calling a function raised a ``TypeError`` because\n <mask>     the call failed or because something in the factory raised the\n <mask>     error.\n <mask> \n </s> remove deprecated script_info factory arg </s> remove             app = call_factory(script_info, attr, args, kwargs)\n </s> add             app = attr(*args, **kwargs) </s> remove         args = kwargs = None\n </s> add         args = []\n        kwargs = {} </s> remove     if int(click.__version__[0]) < 8:\n        warnings.warn(\n            \"Using the `flask` cli with Click 7 is deprecated and\"\n            \" will not be supported starting with Flask 2.1.\"\n            \" Please upgrade to Click 8 as soon as possible.\",\n            DeprecationWarning,\n        )\n    # TODO omit sys.argv once https://github.com/pallets/click/issues/536 is fixed\n    cli.main(args=sys.argv[1:])\n </s> add     cli.main() </s> remove def find_app_by_string(script_info, module, app_name):\n </s> add def find_app_by_string(module, app_name): </s> remove def find_best_app(script_info, module):\n </s> add def find_best_app(module): </s> remove             app = call_factory(self, self.create_app)\n </s> add             app = self.create_app()", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # https://docs.python.org/2/library/sys.html#sys.exc_info\n <mask>         del tb\n <mask> \n <mask> \n <mask> def find_app_by_string(script_info, module, app_name):\n <mask>     \"\"\"Check if the given string is a variable name or a function. Call\n <mask>     a function to get the app instance, or return the variable directly.\n <mask>     \"\"\"\n <mask>     from . import Flask\n <mask> \n </s> remove deprecated script_info factory arg </s> remove def find_best_app(script_info, module):\n </s> add def find_best_app(module): </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)\n\n\n </s> add  </s> remove             app = call_factory(script_info, attr, args, kwargs)\n </s> add             app = attr(*args, **kwargs) </s> remove         args = kwargs = None\n </s> add         args = []\n        kwargs = {} </s> remove         return find_app_by_string(script_info, module, app_name)\n </s> add         return find_app_by_string(module, app_name) </s> remove     if int(click.__version__[0]) < 8:\n        warnings.warn(\n            \"Using the `flask` cli with Click 7 is deprecated and\"\n            \" will not be supported starting with Flask 2.1.\"\n            \" Please upgrade to Click 8 as soon as possible.\",\n            DeprecationWarning,\n        )\n    # TODO omit sys.argv once https://github.com/pallets/click/issues/536 is fixed\n    cli.main(args=sys.argv[1:])\n </s> add     cli.main()", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         ) from None\n <mask> \n <mask>     if isinstance(expr, ast.Name):\n <mask>         name = expr.id\n <mask>         args = kwargs = None\n <mask>     elif isinstance(expr, ast.Call):\n <mask>         # Ensure the function name is an attribute name only.\n <mask>         if not isinstance(expr.func, ast.Name):\n <mask>             raise NoAppException(\n <mask>                 f\"Function reference must be a simple name: {app_name!r}.\"\n </s> remove deprecated script_info factory arg </s> remove             app = call_factory(script_info, attr, args, kwargs)\n </s> add             app = attr(*args, **kwargs) </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)\n\n\n </s> add  </s> remove def find_app_by_string(script_info, module, app_name):\n </s> add def find_app_by_string(module, app_name): </s> remove             app = call_factory(self, self.create_app)\n </s> add             app = self.create_app() </s> remove def find_best_app(script_info, module):\n </s> add def find_best_app(module): </s> remove                 app = locate_app(self, import_name, name)\n </s> add                 app = locate_app(import_name, name)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     # If the attribute is a function, call it with any args and kwargs\n <mask>     # to get the real application.\n <mask>     if inspect.isfunction(attr):\n <mask>         try:\n <mask>             app = call_factory(script_info, attr, args, kwargs)\n <mask>         except TypeError as e:\n <mask>             if not _called_with_wrong_args(attr):\n <mask>                 raise\n <mask> \n <mask>             raise NoAppException(\n </s> remove deprecated script_info factory arg </s> remove         args = kwargs = None\n </s> add         args = []\n        kwargs = {} </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)\n\n\n </s> add  </s> remove                 app = call_factory(script_info, app_factory)\n </s> add                 app = app_factory() </s> remove def find_app_by_string(script_info, module, app_name):\n </s> add def find_app_by_string(module, app_name): </s> remove def locate_app(script_info, module_name, app_name, raise_if_not_found=True):\n </s> add def locate_app(module_name, app_name, raise_if_not_found=True): </s> remove     if int(click.__version__[0]) < 8:\n        warnings.warn(\n            \"Using the `flask` cli with Click 7 is deprecated and\"\n            \" will not be supported starting with Flask 2.1.\"\n            \" Please upgrade to Click 8 as soon as possible.\",\n            DeprecationWarning,\n        )\n    # TODO omit sys.argv once https://github.com/pallets/click/issues/536 is fixed\n    cli.main(args=sys.argv[1:])\n </s> add     cli.main()", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     return \".\".join(module_name[::-1])\n <mask> \n <mask> \n <mask> def locate_app(script_info, module_name, app_name, raise_if_not_found=True):\n <mask>     __traceback_hide__ = True  # noqa: F841\n <mask> \n <mask>     try:\n <mask>         __import__(module_name)\n <mask>     except ImportError as e:\n </s> remove deprecated script_info factory arg </s> remove                 app = call_factory(script_info, app_factory)\n </s> add                 app = app_factory() </s> remove             app = call_factory(script_info, attr, args, kwargs)\n </s> add             app = attr(*args, **kwargs) </s> remove         locate_app(info, \"cliapp.importerrorapp\", None, raise_if_not_found=False)\n </s> add         locate_app(\"cliapp.importerrorapp\", None, raise_if_not_found=False) </s> remove     if int(click.__version__[0]) < 8:\n        warnings.warn(\n            \"Using the `flask` cli with Click 7 is deprecated and\"\n            \" will not be supported starting with Flask 2.1.\"\n            \" Please upgrade to Click 8 as soon as possible.\",\n            DeprecationWarning,\n        )\n    # TODO omit sys.argv once https://github.com/pallets/click/issues/536 is fixed\n    cli.main(args=sys.argv[1:])\n </s> add     cli.main() </s> remove     info = ScriptInfo()\n    app = locate_app(info, \"notanapp.py\", None, raise_if_not_found=False)\n </s> add     app = locate_app(\"notanapp.py\", None, raise_if_not_found=False) </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)\n\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     module = sys.modules[module_name]\n <mask> \n <mask>     if app_name is None:\n <mask>         return find_best_app(script_info, module)\n <mask>     else:\n <mask>         return find_app_by_string(script_info, module, app_name)\n <mask> \n <mask> \n <mask> def get_version(ctx, param, value):\n </s> remove deprecated script_info factory arg </s> remove         return find_app_by_string(script_info, module, app_name)\n </s> add         return find_app_by_string(module, app_name) </s> remove             app = call_factory(self, self.create_app)\n </s> add             app = self.create_app() </s> remove def find_app_by_string(script_info, module, app_name):\n </s> add def find_app_by_string(module, app_name): </s> remove def find_best_app(script_info, module):\n </s> add def find_best_app(module): </s> remove                     app = locate_app(self, import_name, None, raise_if_not_found=False)\n </s> add                     app = locate_app(import_name, None, raise_if_not_found=False) </s> remove     if int(click.__version__[0]) < 8:\n        warnings.warn(\n            \"Using the `flask` cli with Click 7 is deprecated and\"\n            \" will not be supported starting with Flask 2.1.\"\n            \" Please upgrade to Click 8 as soon as possible.\",\n            DeprecationWarning,\n        )\n    # TODO omit sys.argv once https://github.com/pallets/click/issues/536 is fixed\n    cli.main(args=sys.argv[1:])\n </s> add     cli.main()", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     if app_name is None:\n <mask>         return find_best_app(script_info, module)\n <mask>     else:\n <mask>         return find_app_by_string(script_info, module, app_name)\n <mask> \n <mask> \n <mask> def get_version(ctx, param, value):\n <mask>     if not value or ctx.resilient_parsing:\n <mask>         return\n </s> remove deprecated script_info factory arg </s> remove         return find_best_app(script_info, module)\n </s> add         return find_best_app(module) </s> remove def find_app_by_string(script_info, module, app_name):\n </s> add def find_app_by_string(module, app_name): </s> remove             app = call_factory(self, self.create_app)\n </s> add             app = self.create_app() </s> remove     if int(click.__version__[0]) < 8:\n        warnings.warn(\n            \"Using the `flask` cli with Click 7 is deprecated and\"\n            \" will not be supported starting with Flask 2.1.\"\n            \" Please upgrade to Click 8 as soon as possible.\",\n            DeprecationWarning,\n        )\n    # TODO omit sys.argv once https://github.com/pallets/click/issues/536 is fixed\n    cli.main(args=sys.argv[1:])\n </s> add     cli.main() </s> remove def find_best_app(script_info, module):\n </s> add def find_best_app(module): </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)\n\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if self._loaded_app is not None:\n <mask>             return self._loaded_app\n <mask> \n <mask>         if self.create_app is not None:\n <mask>             app = call_factory(self, self.create_app)\n <mask>         else:\n <mask>             if self.app_import_path:\n <mask>                 path, name = (\n <mask>                     re.split(r\":(?![\\\\/])\", self.app_import_path, 1) + [None]\n <mask>                 )[:2]\n </s> remove deprecated script_info factory arg </s> remove                 app = locate_app(self, import_name, name)\n </s> add                 app = locate_app(import_name, name) </s> remove         return find_app_by_string(script_info, module, app_name)\n </s> add         return find_app_by_string(module, app_name) </s> remove         return find_best_app(script_info, module)\n </s> add         return find_best_app(module) </s> remove         args = kwargs = None\n </s> add         args = []\n        kwargs = {} </s> remove                     app = locate_app(self, import_name, None, raise_if_not_found=False)\n </s> add                     app = locate_app(import_name, None, raise_if_not_found=False) </s> remove     if int(click.__version__[0]) < 8:\n        warnings.warn(\n            \"Using the `flask` cli with Click 7 is deprecated and\"\n            \" will not be supported starting with Flask 2.1.\"\n            \" Please upgrade to Click 8 as soon as possible.\",\n            DeprecationWarning,\n        )\n    # TODO omit sys.argv once https://github.com/pallets/click/issues/536 is fixed\n    cli.main(args=sys.argv[1:])\n </s> add     cli.main()", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace keep keep keep", "code_tokens": " <mask>                     re.split(r\":(?![\\\\/])\", self.app_import_path, 1) + [None]\n <mask>                 )[:2]\n <mask>                 import_name = prepare_import(path)\n <mask>                 app = locate_app(self, import_name, name)\n <mask>             else:\n <mask>                 for path in (\"wsgi.py\", \"app.py\"):\n <mask>                     import_name = prepare_import(path)\n <mask>                     app = locate_app(self, import_name, None, raise_if_not_found=False)\n <mask> \n <mask>                     if app:\n <mask>                         break\n </s> remove deprecated script_info factory arg </s> remove             app = call_factory(self, self.create_app)\n </s> add             app = self.create_app() </s> remove     info = ScriptInfo()\n    app = locate_app(info, \"notanapp.py\", None, raise_if_not_found=False)\n </s> add     app = locate_app(\"notanapp.py\", None, raise_if_not_found=False) </s> remove         locate_app(info, iname, aname)\n </s> add         locate_app(iname, aname) </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)\n\n\n </s> add  </s> remove                 app = call_factory(script_info, app_factory)\n </s> add                 app = app_factory()", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask> )\n <mask> \n <mask> \n <mask> def main() -> None:\n <mask>     if int(click.__version__[0]) < 8:\n <mask>         warnings.warn(\n <mask>             \"Using the `flask` cli with Click 7 is deprecated and\"\n <mask>             \" will not be supported starting with Flask 2.1.\"\n <mask>             \" Please upgrade to Click 8 as soon as possible.\",\n <mask>             DeprecationWarning,\n <mask>         )\n <mask>     # TODO omit sys.argv once https://github.com/pallets/click/issues/536 is fixed\n <mask>     cli.main(args=sys.argv[1:])\n <mask> \n <mask> \n <mask> if __name__ == \"__main__\":\n <mask>     main()\n </s> remove deprecated script_info factory arg </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)\n\n\n </s> add  </s> remove             app = call_factory(script_info, attr, args, kwargs)\n </s> add             app = attr(*args, **kwargs) </s> remove -   Update Click dependency to >= 8.0.\n </s> add -   Drop support for Python 3.6. :pr:`4335`\n-   Update Click dependency to >= 8.0. :pr:`4008`\n-   Remove previously deprecated code. :pr:`4337`\n\n    -   The CLI does not pass ``script_info`` to app factory functions. </s> remove         locate_app(info, \"cliapp.importerrorapp\", None, raise_if_not_found=False)\n </s> add         locate_app(\"cliapp.importerrorapp\", None, raise_if_not_found=False) </s> remove         args = kwargs = None\n </s> add         args = []\n        kwargs = {} </s> remove def find_app_by_string(script_info, module, app_name):\n </s> add def find_app_by_string(module, app_name):", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep replace replace keep keep keep keep keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def test_find_best_app(test_apps):\n <mask>     script_info = ScriptInfo()\n <mask> \n <mask>     class Module:\n <mask>         app = Flask(\"appname\")\n <mask> \n <mask>     assert find_best_app(script_info, Module) == Module.app\n <mask> \n <mask>     class Module:\n <mask>         app = Flask(\"appname\")\n <mask> \n <mask>     assert find_best_app(script_info, Module) == Module.app\n <mask> \n <mask>     class Module:\n <mask>         application = Flask(\"appname\")\n <mask> \n </s> remove deprecated script_info factory arg </s> remove     assert find_best_app(script_info, Module) == Module.application\n </s> add     assert find_best_app(Module) == Module.application </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo=None, script_info=None):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module)\n </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module)\n </s> add     app = find_best_app(Module)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     class Module:\n <mask>         application = Flask(\"appname\")\n <mask> \n <mask>     assert find_best_app(script_info, Module) == Module.application\n <mask> \n <mask>     class Module:\n <mask>         myapp = Flask(\"appname\")\n <mask> \n <mask>     assert find_best_app(script_info, Module) == Module.myapp\n </s> remove deprecated script_info factory arg </s> remove     assert find_best_app(script_info, Module) == Module.app\n </s> add     assert find_best_app(Module) == Module.app </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     app = find_best_app(script_info, Module)\n </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo=None, script_info=None):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n </s> add     app = find_best_app(Module) </s> remove     script_info = ScriptInfo()\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     class Module:\n <mask>         myapp = Flask(\"appname\")\n <mask> \n <mask>     assert find_best_app(script_info, Module) == Module.myapp\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def create_app():\n <mask>             return Flask(\"appname\")\n </s> remove deprecated script_info factory arg </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.application\n </s> add     assert find_best_app(Module) == Module.application </s> remove     app = find_best_app(script_info, Module)\n </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module)\n </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo=None, script_info=None):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n </s> add     app = find_best_app(Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app():\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     app = find_best_app(script_info, Module)\n <mask>     assert isinstance(app, Flask)\n <mask>     assert app.name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n </s> remove deprecated script_info factory arg </s> remove     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo=None, script_info=None):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module)\n </s> add     app = find_best_app(Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.app\n </s> add     assert find_best_app(Module) == Module.app", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app(**kwargs):\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     app = find_best_app(script_info, Module)\n <mask>     assert isinstance(app, Flask)\n <mask>     assert app.name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def create_app(foo):\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     with pytest.deprecated_call(match=\"Script info\"):\n <mask>         app = find_best_app(script_info, Module)\n <mask> \n <mask>     assert isinstance(app, Flask)\n <mask>     assert app.name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def create_app(foo=None, script_info=None):\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     with pytest.deprecated_call(match=\"script_info\"):\n <mask>         app = find_best_app(script_info, Module)\n <mask> \n <mask>     assert isinstance(app, Flask)\n <mask>     assert app.name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n </s> remove deprecated script_info factory arg </s> remove     app = find_best_app(script_info, Module)\n </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module)\n </s> add     app = find_best_app(Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.app\n </s> add     assert find_best_app(Module) == Module.app </s> remove     assert find_best_app(script_info, Module) == Module.application\n </s> add     assert find_best_app(Module) == Module.application </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def make_app():\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     app = find_best_app(script_info, Module)\n <mask>     assert isinstance(app, Flask)\n <mask>     assert app.name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         myapp = Flask(\"appname1\")\n </s> remove deprecated script_info factory arg </s> remove     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo=None, script_info=None):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module)\n </s> add     app = find_best_app(Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.application\n </s> add     assert find_best_app(Module) == Module.application </s> remove     assert find_best_app(script_info, Module) == Module.app\n </s> add     assert find_best_app(Module) == Module.app", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app():\n <mask>             return Flask(\"appname2\")\n <mask> \n <mask>     assert find_best_app(script_info, Module) == Module.myapp\n <mask> \n <mask>     class Module:\n <mask>         myapp = Flask(\"appname1\")\n <mask> \n <mask>         @staticmethod\n </s> remove deprecated script_info factory arg </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     app = find_best_app(script_info, Module)\n </s> add     app = find_best_app(Module) </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module)\n </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     app = find_best_app(script_info, Module)\n </s> add     app = find_best_app(Module) </s> remove     assert find_best_app(script_info, Module) == Module.application\n </s> add     assert find_best_app(Module) == Module.application", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app():\n <mask>             return Flask(\"appname2\")\n <mask> \n <mask>     assert find_best_app(script_info, Module) == Module.myapp\n <mask> \n <mask>     class Module:\n <mask>         pass\n <mask> \n <mask>     pytest.raises(NoAppException, find_best_app, script_info, Module)\n </s> remove deprecated script_info factory arg </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module)\n </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module)\n </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module)\n </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     pytest.raises(TypeError, find_best_app, script_info, Module)\n </s> add     pytest.raises(TypeError, find_best_app, Module)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     class Module:\n <mask>         pass\n <mask> \n <mask>     pytest.raises(NoAppException, find_best_app, script_info, Module)\n <mask> \n <mask>     class Module:\n <mask>         myapp1 = Flask(\"appname1\")\n <mask>         myapp2 = Flask(\"appname2\")\n <mask> \n </s> remove deprecated script_info factory arg </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module)\n </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module)\n </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     app = find_best_app(script_info, Module)\n </s> add     app = find_best_app(Module) </s> remove     assert find_best_app(script_info, Module) == Module.application\n </s> add     assert find_best_app(Module) == Module.application", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     class Module:\n <mask>         myapp1 = Flask(\"appname1\")\n <mask>         myapp2 = Flask(\"appname2\")\n <mask> \n <mask>     pytest.raises(NoAppException, find_best_app, script_info, Module)\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def create_app(foo, bar):\n <mask>             return Flask(\"appname2\")\n </s> remove deprecated script_info factory arg </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module)\n </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module)\n </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     app = find_best_app(script_info, Module)\n </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo=None, script_info=None):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n </s> add     app = find_best_app(Module)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app(foo, bar):\n <mask>             return Flask(\"appname2\")\n <mask> \n <mask>     pytest.raises(NoAppException, find_best_app, script_info, Module)\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def create_app():\n <mask>             raise TypeError(\"bad bad factory!\")\n </s> remove deprecated script_info factory arg </s> remove     pytest.raises(TypeError, find_best_app, script_info, Module)\n </s> add     pytest.raises(TypeError, find_best_app, Module) </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module)\n </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module)\n </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     app = find_best_app(script_info, Module)\n </s> add     app = find_best_app(Module)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app():\n <mask>             raise TypeError(\"bad bad factory!\")\n <mask> \n <mask>     pytest.raises(TypeError, find_best_app, script_info, Module)\n <mask> \n <mask> \n <mask> @pytest.mark.parametrize(\n <mask>     \"value,path,result\",\n <mask>     (\n </s> remove deprecated script_info factory arg </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module)\n </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module)\n </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module)\n </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     info = ScriptInfo()\n    assert locate_app(info, iname, aname).name == result\n </s> add     assert locate_app(iname, aname).name == result </s> remove     assert find_best_app(script_info, Module) == Module.myapp\n </s> add     assert find_best_app(Module) == Module.myapp", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         (\"cliapp.factory\", \" create_app () \", \"app\"),\n <mask>     ),\n <mask> )\n <mask> def test_locate_app(test_apps, iname, aname, result):\n <mask>     info = ScriptInfo()\n <mask>     assert locate_app(info, iname, aname).name == result\n <mask> \n <mask> \n <mask> @pytest.mark.parametrize(\n <mask>     \"iname,aname\",\n <mask>     (\n </s> remove deprecated script_info factory arg </s> remove     info = ScriptInfo()\n\n </s> add  </s> remove         locate_app(info, iname, aname)\n </s> add         locate_app(iname, aname) </s> remove     info = ScriptInfo()\n    app = locate_app(info, \"notanapp.py\", None, raise_if_not_found=False)\n </s> add     app = locate_app(\"notanapp.py\", None, raise_if_not_found=False) </s> remove     pytest.raises(TypeError, find_best_app, script_info, Module)\n </s> add     pytest.raises(TypeError, find_best_app, Module) </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)\n\n\n </s> add  </s> remove     script_info = ScriptInfo()\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace", "code_tokens": " <mask>     ),\n <mask> )\n <mask> def test_locate_app_raises(test_apps, iname, aname):\n <mask>     info = ScriptInfo()\n <mask> \n <mask>     with pytest.raises(NoAppException):\n <mask>         locate_app(info, iname, aname)\n </s> remove deprecated script_info factory arg </s> remove     info = ScriptInfo()\n    assert locate_app(info, iname, aname).name == result\n </s> add     assert locate_app(iname, aname).name == result </s> remove     info = ScriptInfo()\n    app = locate_app(info, \"notanapp.py\", None, raise_if_not_found=False)\n </s> add     app = locate_app(\"notanapp.py\", None, raise_if_not_found=False) </s> remove         locate_app(info, \"cliapp.importerrorapp\", None, raise_if_not_found=False)\n </s> add         locate_app(\"cliapp.importerrorapp\", None, raise_if_not_found=False) </s> remove     script_info = ScriptInfo()\n\n </s> add  </s> remove     if int(click.__version__[0]) < 8:\n        warnings.warn(\n            \"Using the `flask` cli with Click 7 is deprecated and\"\n            \" will not be supported starting with Flask 2.1.\"\n            \" Please upgrade to Click 8 as soon as possible.\",\n            DeprecationWarning,\n        )\n    # TODO omit sys.argv once https://github.com/pallets/click/issues/536 is fixed\n    cli.main(args=sys.argv[1:])\n </s> add     cli.main()", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         locate_app(info, iname, aname)\n <mask> \n <mask> \n <mask> def test_locate_app_suppress_raise(test_apps):\n <mask>     info = ScriptInfo()\n <mask>     app = locate_app(info, \"notanapp.py\", None, raise_if_not_found=False)\n <mask>     assert app is None\n <mask> \n <mask>     # only direct import error is suppressed\n <mask>     with pytest.raises(NoAppException):\n <mask>         locate_app(info, \"cliapp.importerrorapp\", None, raise_if_not_found=False)\n <mask> \n <mask> \n <mask> def test_get_version(test_apps, capsys):\n <mask>     from flask import __version__ as flask_version\n </s> remove deprecated script_info factory arg </s> remove         locate_app(info, iname, aname)\n </s> add         locate_app(iname, aname) </s> remove     info = ScriptInfo()\n\n </s> add  </s> remove     info = ScriptInfo()\n    assert locate_app(info, iname, aname).name == result\n </s> add     assert locate_app(iname, aname).name == result </s> remove                     app = locate_app(self, import_name, None, raise_if_not_found=False)\n </s> add                     app = locate_app(import_name, None, raise_if_not_found=False) </s> remove import warnings\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     For more information, head over to the :ref:`Quickstart <url-building>`.\n <mask> \n <mask>     To integrate applications, :class:`Flask` has a hook to intercept URL build\n <mask>     errors through :attr:`Flask.build_error_handler`.  The `url_for` function\n <mask>     results in a :exc:`~werkzeug.routing.BuildError` when the current app does\n <mask>     not have a URL for the given endpoint and values.  When it does, the\n <mask>     :data:`~flask.current_app` calls its :attr:`~Flask.build_error_handler` if\n <mask>     it is not `None`, which can return a string to use as the result of\n <mask>     `url_for` (instead of `url_for`'s default to raise the\n <mask>     :exc:`~werkzeug.routing.BuildError` exception) or re-raise the exception.\n <mask>     An example::\n <mask> \n </s> Update url_for documentation\n\nPrevious documentation referenced a non-existent property on the Flask\nobject called \"build_error_handler\".\n\nThis should actually reference Flask.url_build_error_handlers. </s> remove         app.build_error_handler = external_url_handler\n </s> add         app.url_build_error_handlers.append(external_url_handler) </s> remove     `endpoint` and `**values` are the arguments passed into `url_for`.  Note\n </s> add     `endpoint` and `values` are the arguments passed into `url_for`.  Note </s> remove         def external_url_handler(error, endpoint, **values):\n </s> add         def external_url_handler(error, endpoint, values):", "html_url": "https://github.com/pallets/flask/commit/e31a2a80ec4254e8ac8127558bc29cfd23d05511", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     `url_for` (instead of `url_for`'s default to raise the\n <mask>     :exc:`~werkzeug.routing.BuildError` exception) or re-raise the exception.\n <mask>     An example::\n <mask> \n <mask>         def external_url_handler(error, endpoint, **values):\n <mask>             \"Looks up an external URL when `url_for` cannot build a URL.\"\n <mask>             # This is an example of hooking the build_error_handler.\n <mask>             # Here, lookup_url is some utility function you've built\n <mask>             # which looks up the endpoint in some external URL registry.\n <mask>             url = lookup_url(endpoint, **values)\n </s> Update url_for documentation\n\nPrevious documentation referenced a non-existent property on the Flask\nobject called \"build_error_handler\".\n\nThis should actually reference Flask.url_build_error_handlers. </s> remove         app.build_error_handler = external_url_handler\n </s> add         app.url_build_error_handlers.append(external_url_handler) </s> remove     `endpoint` and `**values` are the arguments passed into `url_for`.  Note\n </s> add     `endpoint` and `values` are the arguments passed into `url_for`.  Note </s> remove     errors through :attr:`Flask.build_error_handler`.  The `url_for` function\n    results in a :exc:`~werkzeug.routing.BuildError` when the current app does\n    not have a URL for the given endpoint and values.  When it does, the\n    :data:`~flask.current_app` calls its :attr:`~Flask.build_error_handler` if\n </s> add     errors through :attr:`Flask.url_build_error_handlers`.  The `url_for`\n    function results in a :exc:`~werkzeug.routing.BuildError` when the current\n    app does not have a URL for the given endpoint and values.  When it does, the\n    :data:`~flask.current_app` calls its :attr:`~Flask.url_build_error_handlers` if", "html_url": "https://github.com/pallets/flask/commit/e31a2a80ec4254e8ac8127558bc29cfd23d05511", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     raise error\n <mask>             # url_for will use this result, instead of raising BuildError.\n <mask>             return url\n <mask> \n <mask>         app.build_error_handler = external_url_handler\n <mask> \n <mask>     Here, `error` is the instance of :exc:`~werkzeug.routing.BuildError`, and\n <mask>     `endpoint` and `**values` are the arguments passed into `url_for`.  Note\n <mask>     that this is for building URLs outside the current application, and not for\n <mask>     handling 404 NotFound errors.\n </s> Update url_for documentation\n\nPrevious documentation referenced a non-existent property on the Flask\nobject called \"build_error_handler\".\n\nThis should actually reference Flask.url_build_error_handlers. </s> remove     `endpoint` and `**values` are the arguments passed into `url_for`.  Note\n </s> add     `endpoint` and `values` are the arguments passed into `url_for`.  Note </s> remove     errors through :attr:`Flask.build_error_handler`.  The `url_for` function\n    results in a :exc:`~werkzeug.routing.BuildError` when the current app does\n    not have a URL for the given endpoint and values.  When it does, the\n    :data:`~flask.current_app` calls its :attr:`~Flask.build_error_handler` if\n </s> add     errors through :attr:`Flask.url_build_error_handlers`.  The `url_for`\n    function results in a :exc:`~werkzeug.routing.BuildError` when the current\n    app does not have a URL for the given endpoint and values.  When it does, the\n    :data:`~flask.current_app` calls its :attr:`~Flask.url_build_error_handlers` if </s> remove         def external_url_handler(error, endpoint, **values):\n </s> add         def external_url_handler(error, endpoint, values):", "html_url": "https://github.com/pallets/flask/commit/e31a2a80ec4254e8ac8127558bc29cfd23d05511", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         app.build_error_handler = external_url_handler\n <mask> \n <mask>     Here, `error` is the instance of :exc:`~werkzeug.routing.BuildError`, and\n <mask>     `endpoint` and `**values` are the arguments passed into `url_for`.  Note\n <mask>     that this is for building URLs outside the current application, and not for\n <mask>     handling 404 NotFound errors.\n <mask> \n <mask>     .. versionadded:: 0.10\n <mask>        The `_scheme` parameter was added.\n </s> Update url_for documentation\n\nPrevious documentation referenced a non-existent property on the Flask\nobject called \"build_error_handler\".\n\nThis should actually reference Flask.url_build_error_handlers. </s> remove         app.build_error_handler = external_url_handler\n </s> add         app.url_build_error_handlers.append(external_url_handler) </s> remove     errors through :attr:`Flask.build_error_handler`.  The `url_for` function\n    results in a :exc:`~werkzeug.routing.BuildError` when the current app does\n    not have a URL for the given endpoint and values.  When it does, the\n    :data:`~flask.current_app` calls its :attr:`~Flask.build_error_handler` if\n </s> add     errors through :attr:`Flask.url_build_error_handlers`.  The `url_for`\n    function results in a :exc:`~werkzeug.routing.BuildError` when the current\n    app does not have a URL for the given endpoint and values.  When it does, the\n    :data:`~flask.current_app` calls its :attr:`~Flask.url_build_error_handlers` if </s> remove         def external_url_handler(error, endpoint, **values):\n </s> add         def external_url_handler(error, endpoint, values):", "html_url": "https://github.com/pallets/flask/commit/e31a2a80ec4254e8ac8127558bc29cfd23d05511", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> - Added support for explicit root paths when using Python 3.3's namespace\n <mask>   packages.\n <mask> \n <mask> Version 0.10.2\n <mask> --------------\n <mask> \n </s> Added thread flag to flask run </s> remove                     use_eager_loading=opts.with_eager_loading)\n </s> add                     use_eager_loading=opts.with_eager_loading,\n                    threaded=opts.with_threads) </s> add     parser.add_option('--with-threads', action='store_true',\n                      dest='with_threads',\n                      help='Enable multi-threading to handle multiple '\n                      'requests concurrently.')\n    parser.add_option('--without-threads', action='store_false',\n                      dest='with_threads',\n                      help='Disables multi-threading. (default)') </s> remove                use_debugger=use_debugger)\n </s> add                use_debugger=use_debugger, **options) </s> add     :param options: the options to be forwarded to the underlying\n                    Werkzeug server.  See\n                    :func:`werkzeug.serving.run_simple` for more\n                    information. </s> remove                     use_eager_loading=None, magic_app_id=True):\n </s> add                     use_eager_loading=None, magic_app_id=True,\n                    **options):", "html_url": "https://github.com/pallets/flask/commit/e46bca4051e51f3812d4a0b25f60f7b7959668c2", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def run_application(app_id, host='127.0.0.1', port=5000, debug=None,\n <mask>                     use_reloader=False, use_debugger=False,\n <mask>                     use_eager_loading=None, magic_app_id=True):\n <mask>     \"\"\"Useful function to start a Werkzeug server for an application that\n <mask>     is known by it's import name.  By default the app ID can also be a\n <mask>     full file name in which case Flask attempts to reconstruct the import\n <mask>     name from it and do the right thing.\n <mask> \n </s> Added thread flag to flask run </s> add     :param options: the options to be forwarded to the underlying\n                    Werkzeug server.  See\n                    :func:`werkzeug.serving.run_simple` for more\n                    information. </s> add - Added ``flask-run`` and the ``flask.run`` module to start the local\n  debug server.  This is recommended over the old ``flask.run()`` method\n  as it works faster and more reliable due to a different design. </s> add     parser.add_option('--with-threads', action='store_true',\n                      dest='with_threads',\n                      help='Enable multi-threading to handle multiple '\n                      'requests concurrently.')\n    parser.add_option('--without-threads', action='store_false',\n                      dest='with_threads',\n                      help='Disables multi-threading. (default)') </s> remove                use_debugger=use_debugger)\n </s> add                use_debugger=use_debugger, **options) </s> remove                     use_eager_loading=opts.with_eager_loading)\n </s> add                     use_eager_loading=opts.with_eager_loading,\n                    threaded=opts.with_threads)", "html_url": "https://github.com/pallets/flask/commit/e46bca4051e51f3812d4a0b25f60f7b7959668c2", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     :param magic_app_id: if this is enabled then the app id can also be a\n <mask>                          filename instead of an import module and Flask\n <mask>                          will attempt to reconstruct the import name.\n <mask>     \"\"\"\n <mask>     if magic_app_id:\n <mask>         if os.path.isfile(app_id) or os.sep in app_id or \\\n <mask>            os.altsep is not None and os.altsep in app_id:\n </s> Added thread flag to flask run </s> remove                     use_eager_loading=None, magic_app_id=True):\n </s> add                     use_eager_loading=None, magic_app_id=True,\n                    **options): </s> add - Added ``flask-run`` and the ``flask.run`` module to start the local\n  debug server.  This is recommended over the old ``flask.run()`` method\n  as it works faster and more reliable due to a different design. </s> add     parser.add_option('--with-threads', action='store_true',\n                      dest='with_threads',\n                      help='Enable multi-threading to handle multiple '\n                      'requests concurrently.')\n    parser.add_option('--without-threads', action='store_false',\n                      dest='with_threads',\n                      help='Disables multi-threading. (default)') </s> remove                use_debugger=use_debugger)\n </s> add                use_debugger=use_debugger, **options) </s> remove                     use_eager_loading=opts.with_eager_loading)\n </s> add                     use_eager_loading=opts.with_eager_loading,\n                    threaded=opts.with_threads)", "html_url": "https://github.com/pallets/flask/commit/e46bca4051e51f3812d4a0b25f60f7b7959668c2", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             print ' * Forcing debug %s' % (debug and 'on' or 'off')\n <mask> \n <mask>     app = DispatchingApp(app_id, debug, use_eager_loading)\n <mask>     run_simple(host, port, app, use_reloader=use_reloader,\n <mask>                use_debugger=use_debugger)\n <mask> \n <mask> \n <mask> def main(as_module=False):\n <mask>     this_module = __package__ + '.run'\n <mask> \n </s> Added thread flag to flask run </s> add     parser.add_option('--with-threads', action='store_true',\n                      dest='with_threads',\n                      help='Enable multi-threading to handle multiple '\n                      'requests concurrently.')\n    parser.add_option('--without-threads', action='store_false',\n                      dest='with_threads',\n                      help='Disables multi-threading. (default)') </s> add     :param options: the options to be forwarded to the underlying\n                    Werkzeug server.  See\n                    :func:`werkzeug.serving.run_simple` for more\n                    information. </s> add - Added ``flask-run`` and the ``flask.run`` module to start the local\n  debug server.  This is recommended over the old ``flask.run()`` method\n  as it works faster and more reliable due to a different design. </s> remove                     use_eager_loading=None, magic_app_id=True):\n </s> add                     use_eager_loading=None, magic_app_id=True,\n                    **options): </s> remove                     use_eager_loading=opts.with_eager_loading)\n </s> add                     use_eager_loading=opts.with_eager_loading,\n                    threaded=opts.with_threads)", "html_url": "https://github.com/pallets/flask/commit/e46bca4051e51f3812d4a0b25f60f7b7959668c2", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>                       'to unexpected crashes.')\n <mask>     parser.add_option('--without-eager-loading', action='store_false',\n <mask>                       dest='with_eager_loading',\n <mask>                       help='Disable the eager-loading.')\n <mask>     opts, args = parser.parse_args()\n <mask>     if len(args) != 1:\n <mask>         parser.error('Expected exactly one argument which is the import '\n <mask>                      'name of the application.')\n <mask> \n </s> Added thread flag to flask run </s> add     :param options: the options to be forwarded to the underlying\n                    Werkzeug server.  See\n                    :func:`werkzeug.serving.run_simple` for more\n                    information. </s> remove                     use_eager_loading=None, magic_app_id=True):\n </s> add                     use_eager_loading=None, magic_app_id=True,\n                    **options): </s> add - Added ``flask-run`` and the ``flask.run`` module to start the local\n  debug server.  This is recommended over the old ``flask.run()`` method\n  as it works faster and more reliable due to a different design. </s> remove                use_debugger=use_debugger)\n </s> add                use_debugger=use_debugger, **options) </s> remove                     use_eager_loading=opts.with_eager_loading)\n </s> add                     use_eager_loading=opts.with_eager_loading,\n                    threaded=opts.with_threads)", "html_url": "https://github.com/pallets/flask/commit/e46bca4051e51f3812d4a0b25f60f7b7959668c2", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask>     run_application(args[0], opts.host, opts.port, debug=opts.debug,\n <mask>                     use_reloader=opts.with_reloader,\n <mask>                     use_debugger=opts.with_debugger,\n <mask>                     use_eager_loading=opts.with_eager_loading)\n <mask> \n <mask> \n <mask> if __name__ == '__main__':\n <mask>     main(as_module=True)\n </s> Added thread flag to flask run </s> add     parser.add_option('--with-threads', action='store_true',\n                      dest='with_threads',\n                      help='Enable multi-threading to handle multiple '\n                      'requests concurrently.')\n    parser.add_option('--without-threads', action='store_false',\n                      dest='with_threads',\n                      help='Disables multi-threading. (default)') </s> remove                use_debugger=use_debugger)\n </s> add                use_debugger=use_debugger, **options) </s> add     :param options: the options to be forwarded to the underlying\n                    Werkzeug server.  See\n                    :func:`werkzeug.serving.run_simple` for more\n                    information. </s> remove                     use_eager_loading=None, magic_app_id=True):\n </s> add                     use_eager_loading=None, magic_app_id=True,\n                    **options): </s> add - Added ``flask-run`` and the ``flask.run`` module to start the local\n  debug server.  This is recommended over the old ``flask.run()`` method\n  as it works faster and more reliable due to a different design.", "html_url": "https://github.com/pallets/flask/commit/e46bca4051e51f3812d4a0b25f60f7b7959668c2", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     iteritems = lambda d: iter(d.items())\n <mask> \n <mask>     from inspect import getfullargspec as getargspec\n <mask>     from io import StringIO\n <mask> \n <mask>     def reraise(tp, value, tb=None):\n <mask>         if value.__traceback__ is not tb:\n <mask>             raise value.with_traceback(tb)\n </s> Fix DeprecationWarning on collections import </s> add     import collections as collections_abc </s> remove from collections import MutableMapping\n </s> add  </s> add from flask._compat import collections_abc </s> remove class SessionMixin(MutableMapping):\n </s> add class SessionMixin(collections_abc.MutableMapping):", "html_url": "https://github.com/pallets/flask/commit/e4ebbd3f5befca0f6891def3ebf292f756ec5f3b", "file_name": "flask/_compat.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     iteritems = lambda d: d.iteritems()\n <mask> \n <mask>     from inspect import getargspec\n <mask>     from cStringIO import StringIO\n <mask> \n <mask>     exec('def reraise(tp, value, tb=None):\\n raise tp, value, tb')\n <mask> \n <mask>     def implements_to_string(cls):\n </s> Fix DeprecationWarning on collections import </s> add     import collections.abc as collections_abc </s> remove from collections import MutableMapping\n </s> add  </s> add from flask._compat import collections_abc </s> remove class SessionMixin(MutableMapping):\n </s> add class SessionMixin(collections_abc.MutableMapping):", "html_url": "https://github.com/pallets/flask/commit/e4ebbd3f5befca0f6891def3ebf292f756ec5f3b", "file_name": "flask/_compat.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \"\"\"\n <mask> \n <mask> import hashlib\n <mask> import warnings\n <mask> from collections import MutableMapping\n <mask> from datetime import datetime\n <mask> \n <mask> from itsdangerous import BadSignature, URLSafeTimedSerializer\n <mask> from werkzeug.datastructures import CallbackDict\n <mask> \n </s> Fix DeprecationWarning on collections import </s> add from flask._compat import collections_abc </s> add     import collections as collections_abc </s> add     import collections.abc as collections_abc </s> remove class SessionMixin(MutableMapping):\n </s> add class SessionMixin(collections_abc.MutableMapping):", "html_url": "https://github.com/pallets/flask/commit/e4ebbd3f5befca0f6891def3ebf292f756ec5f3b", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> from werkzeug.datastructures import CallbackDict\n <mask> \n <mask> from flask.helpers import is_ip, total_seconds\n <mask> from flask.json.tag import TaggedJSONSerializer\n <mask> \n <mask> \n <mask> class SessionMixin(collections_abc.MutableMapping):\n <mask>     \"\"\"Expands a basic dictionary with session attributes.\"\"\"\n </s> Fix DeprecationWarning on collections import </s> remove class SessionMixin(MutableMapping):\n </s> add class SessionMixin(collections_abc.MutableMapping): </s> remove from collections import MutableMapping\n </s> add  </s> add     import collections as collections_abc </s> add     import collections.abc as collections_abc", "html_url": "https://github.com/pallets/flask/commit/e4ebbd3f5befca0f6891def3ebf292f756ec5f3b", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from flask.helpers import is_ip, total_seconds\n <mask> from flask.json.tag import TaggedJSONSerializer\n <mask> \n <mask> \n <mask> class SessionMixin(MutableMapping):\n <mask>     \"\"\"Expands a basic dictionary with session attributes.\"\"\"\n <mask> \n <mask>     @property\n <mask>     def permanent(self):\n <mask>         \"\"\"This reflects the ``'_permanent'`` key in the dict.\"\"\"\n </s> Fix DeprecationWarning on collections import </s> add from flask._compat import collections_abc </s> remove from collections import MutableMapping\n </s> add  </s> add     import collections as collections_abc </s> add     import collections.abc as collections_abc", "html_url": "https://github.com/pallets/flask/commit/e4ebbd3f5befca0f6891def3ebf292f756ec5f3b", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> def add_to_path(path):\n <mask>     def _samefile(x, y):\n <mask>         try:\n <mask>             return os.path.samefile(x, y)\n <mask>         except (IOError, OSError):\n </s> Some more cleanups in how the test runner is invoked </s> remove import unittest\nfrom flask.testsuite import BetterLoader\ntry:\n    unittest.main(testLoader=BetterLoader(), defaultTest='suite')\nexcept Exception, e:\n    print 'Error: %s' % e\n </s> add from flask.testsuite import main\nmain() </s> add     \"\"\"Yields all the tests and their names from a given suite.\"\"\" </s> add def setup_path():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps')))\n\n </s> remove def setup_paths():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps')))\n\n\n </s> add  </s> remove     setup_paths()\n </s> add     \"\"\"A testsuite that has all the Flask tests.  You can use this\n    function to integrate the Flask tests into your own testsuite\n    in case you want to test that monkeypatches to Flask do not\n    break it.\n    \"\"\"\n    setup_path() </s> add     \"\"\"Yields all testsuites.\"\"\"", "html_url": "https://github.com/pallets/flask/commit/e509d25d32965a8afd7ca98d67ee6f5a6af11cc8", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             pass\n <mask>     sys.path.append(path)\n <mask> \n <mask> \n <mask> def setup_paths():\n <mask>     add_to_path(os.path.abspath(os.path.join(\n <mask>         os.path.dirname(__file__), 'test_apps')))\n <mask> \n <mask> \n <mask> def iter_suites():\n <mask>     for module in find_modules(__name__):\n <mask>         mod = import_string(module)\n <mask>         if hasattr(mod, 'suite'):\n <mask>             yield mod.suite()\n </s> Some more cleanups in how the test runner is invoked </s> add     \"\"\"Yields all testsuites.\"\"\" </s> add def setup_path():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps')))\n\n </s> remove     setup_paths()\n </s> add     \"\"\"A testsuite that has all the Flask tests.  You can use this\n    function to integrate the Flask tests into your own testsuite\n    in case you want to test that monkeypatches to Flask do not\n    break it.\n    \"\"\"\n    setup_path() </s> add     \"\"\"Adds an entry to sys.path_info if it's not already there.\"\"\"\n    if not os.path.isdir(path):\n        raise RuntimeError('Tried to add nonexisting path')\n </s> add     \"\"\"Yields all the tests and their names from a given suite.\"\"\" </s> remove import unittest\nfrom flask.testsuite import BetterLoader\ntry:\n    unittest.main(testLoader=BetterLoader(), defaultTest='suite')\nexcept Exception, e:\n    print 'Error: %s' % e\n </s> add from flask.testsuite import main\nmain()", "html_url": "https://github.com/pallets/flask/commit/e509d25d32965a8afd7ca98d67ee6f5a6af11cc8", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> def iter_suites():\n <mask>     for module in find_modules(__name__):\n <mask>         mod = import_string(module)\n <mask>         if hasattr(mod, 'suite'):\n <mask>             yield mod.suite()\n </s> Some more cleanups in how the test runner is invoked </s> remove def setup_paths():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps')))\n\n\n </s> add  </s> remove     setup_paths()\n </s> add     \"\"\"A testsuite that has all the Flask tests.  You can use this\n    function to integrate the Flask tests into your own testsuite\n    in case you want to test that monkeypatches to Flask do not\n    break it.\n    \"\"\"\n    setup_path() </s> add     \"\"\"Adds an entry to sys.path_info if it's not already there.\"\"\"\n    if not os.path.isdir(path):\n        raise RuntimeError('Tried to add nonexisting path')\n </s> add     \"\"\"Yields all the tests and their names from a given suite.\"\"\" </s> add def setup_path():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps')))\n\n </s> remove import unittest\nfrom flask.testsuite import BetterLoader\ntry:\n    unittest.main(testLoader=BetterLoader(), defaultTest='suite')\nexcept Exception, e:\n    print 'Error: %s' % e\n </s> add from flask.testsuite import main\nmain()", "html_url": "https://github.com/pallets/flask/commit/e509d25d32965a8afd7ca98d67ee6f5a6af11cc8", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def find_all_tests(suite):\n <mask>     suites = [suite]\n <mask>     while suites:\n <mask>         s = suites.pop()\n <mask>         try:\n <mask>             suites.extend(s)\n </s> Some more cleanups in how the test runner is invoked </s> remove def setup_paths():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps')))\n\n\n </s> add  </s> add     \"\"\"Yields all testsuites.\"\"\" </s> add     \"\"\"Adds an entry to sys.path_info if it's not already there.\"\"\"\n    if not os.path.isdir(path):\n        raise RuntimeError('Tried to add nonexisting path')\n </s> remove     setup_paths()\n </s> add     \"\"\"A testsuite that has all the Flask tests.  You can use this\n    function to integrate the Flask tests into your own testsuite\n    in case you want to test that monkeypatches to Flask do not\n    break it.\n    \"\"\"\n    setup_path() </s> add def setup_path():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps')))\n\n </s> remove import unittest\nfrom flask.testsuite import BetterLoader\ntry:\n    unittest.main(testLoader=BetterLoader(), defaultTest='suite')\nexcept Exception, e:\n    print 'Error: %s' % e\n </s> add from flask.testsuite import main\nmain()", "html_url": "https://github.com/pallets/flask/commit/e509d25d32965a8afd7ca98d67ee6f5a6af11cc8", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>             rv.addTest(test)\n <mask>         return rv\n <mask> \n <mask> \n <mask> def suite():\n <mask>     \"\"\"A testsuite that has all the Flask tests.  You can use this\n <mask>     function to integrate the Flask tests into your own testsuite\n <mask>     in case you want to test that monkeypatches to Flask do not\n </s> Some more cleanups in how the test runner is invoked </s> remove     setup_paths()\n </s> add     \"\"\"A testsuite that has all the Flask tests.  You can use this\n    function to integrate the Flask tests into your own testsuite\n    in case you want to test that monkeypatches to Flask do not\n    break it.\n    \"\"\"\n    setup_path() </s> add     \"\"\"Adds an entry to sys.path_info if it's not already there.\"\"\"\n    if not os.path.isdir(path):\n        raise RuntimeError('Tried to add nonexisting path')\n </s> add     \"\"\"Yields all the tests and their names from a given suite.\"\"\" </s> add     \"\"\"Yields all testsuites.\"\"\" </s> remove def setup_paths():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps')))\n\n\n </s> add  </s> remove import unittest\nfrom flask.testsuite import BetterLoader\ntry:\n    unittest.main(testLoader=BetterLoader(), defaultTest='suite')\nexcept Exception, e:\n    print 'Error: %s' % e\n </s> add from flask.testsuite import main\nmain()", "html_url": "https://github.com/pallets/flask/commit/e509d25d32965a8afd7ca98d67ee6f5a6af11cc8", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         return rv\n <mask> \n <mask> \n <mask> def suite():\n <mask>     setup_paths()\n <mask>     suite = unittest.TestSuite()\n <mask>     for other_suite in iter_suites():\n <mask>         suite.addTest(other_suite)\n <mask>     return suite\n </s> Some more cleanups in how the test runner is invoked </s> add def setup_path():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps')))\n\n </s> remove def setup_paths():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps')))\n\n\n </s> add  </s> add     \"\"\"Yields all testsuites.\"\"\" </s> add     \"\"\"Adds an entry to sys.path_info if it's not already there.\"\"\"\n    if not os.path.isdir(path):\n        raise RuntimeError('Tried to add nonexisting path')\n </s> add     \"\"\"Yields all the tests and their names from a given suite.\"\"\" </s> remove import unittest\nfrom flask.testsuite import BetterLoader\ntry:\n    unittest.main(testLoader=BetterLoader(), defaultTest='suite')\nexcept Exception, e:\n    print 'Error: %s' % e\n </s> add from flask.testsuite import main\nmain()", "html_url": "https://github.com/pallets/flask/commit/e509d25d32965a8afd7ca98d67ee6f5a6af11cc8", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "replace replace replace replace replace replace", "code_tokens": " <mask> import unittest\n <mask> from flask.testsuite import BetterLoader\n <mask> try:\n <mask>     unittest.main(testLoader=BetterLoader(), defaultTest='suite')\n <mask> except Exception, e:\n <mask>     print 'Error: %s' % e\n </s> Some more cleanups in how the test runner is invoked </s> add     \"\"\"Yields all the tests and their names from a given suite.\"\"\" </s> add     \"\"\"Adds an entry to sys.path_info if it's not already there.\"\"\"\n    if not os.path.isdir(path):\n        raise RuntimeError('Tried to add nonexisting path')\n </s> remove     setup_paths()\n </s> add     \"\"\"A testsuite that has all the Flask tests.  You can use this\n    function to integrate the Flask tests into your own testsuite\n    in case you want to test that monkeypatches to Flask do not\n    break it.\n    \"\"\"\n    setup_path() </s> add def setup_path():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps')))\n\n </s> add     \"\"\"Yields all testsuites.\"\"\" </s> remove def setup_paths():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps')))\n\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e509d25d32965a8afd7ca98d67ee6f5a6af11cc8", "file_name": "run-tests.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     @app.route('/user/<username>')\n <mask>     def show_user_profile(username):\n <mask>         # show the user profile for that user\n <mask>         return 'User %s' % username\n <mask> \n <mask>     @app.route('/post/<int:post_id>')\n <mask>     def show_post(post_id):\n <mask>         # show the post with the given id, the id is an integer\n <mask>         return 'Post %d' % post_id\n </s> Fix some HTML injection paths in examples\n\nThese are unlikely to be copy-pasted by users but it's best practice to avoid it and other examples do. </s> remove         return '{}\\'s profile'.format(username)\n </s> add         return '{}\\'s profile'.format(escape(username)) </s> remove         return 'Subpath %s' % subpath\n </s> add         return 'Subpath %s' % escape(subpath) </s> remove     from flask import Flask, url_for\n </s> add     from flask import Flask, escape, url_for", "html_url": "https://github.com/pallets/flask/commit/e5b0fe68414cd3af9c1e91c82fa0c0ef4145c8c2", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     @app.route('/path/<path:subpath>')\n <mask>     def show_subpath(subpath):\n <mask>         # show the subpath after /path/\n <mask>         return 'Subpath %s' % subpath\n <mask> \n <mask> Converter types:\n <mask> \n <mask> ========== ==========================================\n <mask> ``string`` (default) accepts any text without a slash\n </s> Fix some HTML injection paths in examples\n\nThese are unlikely to be copy-pasted by users but it's best practice to avoid it and other examples do. </s> remove         return '{}\\'s profile'.format(username)\n </s> add         return '{}\\'s profile'.format(escape(username)) </s> remove         return 'User %s' % username\n </s> add         return 'User %s' % escape(username) </s> remove     from flask import Flask, url_for\n </s> add     from flask import Flask, escape, url_for", "html_url": "https://github.com/pallets/flask/commit/e5b0fe68414cd3af9c1e91c82fa0c0ef4145c8c2", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> to try out :func:`~flask.url_for`. :meth:`~flask.Flask.test_request_context`\n <mask> tells Flask to behave as though it's handling a request even while we use a\n <mask> Python shell. See :ref:`context-locals`. ::\n <mask> \n <mask>     from flask import Flask, url_for\n <mask> \n <mask>     app = Flask(__name__)\n <mask> \n <mask>     @app.route('/')\n <mask>     def index():\n </s> Fix some HTML injection paths in examples\n\nThese are unlikely to be copy-pasted by users but it's best practice to avoid it and other examples do. </s> remove         return 'User %s' % username\n </s> add         return 'User %s' % escape(username) </s> remove         return '{}\\'s profile'.format(username)\n </s> add         return '{}\\'s profile'.format(escape(username)) </s> remove         return 'Subpath %s' % subpath\n </s> add         return 'Subpath %s' % escape(subpath)", "html_url": "https://github.com/pallets/flask/commit/e5b0fe68414cd3af9c1e91c82fa0c0ef4145c8c2", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         return 'login'\n <mask> \n <mask>     @app.route('/user/<username>')\n <mask>     def profile(username):\n <mask>         return '{}\\'s profile'.format(username)\n <mask> \n <mask>     with app.test_request_context():\n <mask>         print(url_for('index'))\n <mask>         print(url_for('login'))\n <mask>         print(url_for('login', next='/'))\n </s> Fix some HTML injection paths in examples\n\nThese are unlikely to be copy-pasted by users but it's best practice to avoid it and other examples do. </s> remove         return 'User %s' % username\n </s> add         return 'User %s' % escape(username) </s> remove         return 'Subpath %s' % subpath\n </s> add         return 'Subpath %s' % escape(subpath) </s> remove     from flask import Flask, url_for\n </s> add     from flask import Flask, escape, url_for", "html_url": "https://github.com/pallets/flask/commit/e5b0fe68414cd3af9c1e91c82fa0c0ef4145c8c2", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>   refreshed each request and get their lifetime extended, if set to\n <mask>   `False` it will only be modified if the session actually modifies.\n <mask>   Non permanent sessions are not affected by this and will always\n <mask>   expire if the browser window closes.\n <mask> \n <mask> Version 0.10.2\n <mask> --------------\n <mask> \n <mask> (bugfix release, release date to be announced)\n <mask> \n </s> Added support for custom JSON mimetypes </s> add     @property\n    def is_json(self):\n        \"\"\"Indicates if this request is JSON or not.  By default a request\n        is considered to include JSON data if the mimetype is\n        ``application/json`` or ``application/*+json``.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        mt = self.mimetype\n        if mt == 'application/json':\n            return True\n        if mt.startswith('application/') and mt.endswith('+json'):\n            return True\n        return False\n </s> remove         if self.mimetype != 'application/json' and not force:\n </s> add         if not (force or self.is_json): </s> add     def test_json_custom_mimetypes(self):\n        app = flask.Flask(__name__)\n        @app.route('/json', methods=['POST'])\n        def return_json():\n            return flask.request.get_json()\n        c = app.test_client()\n        rv = c.post('/json', data='\"foo\"', content_type='application/x+json')\n        self.assert_equal(rv.data, b'foo')\n", "html_url": "https://github.com/pallets/flask/commit/e5bba9deb5c9ab9c66bea5c17e96741777fe46ab", "file_name": "CHANGES"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         self.assert_equal(rv.status_code, 400)\n <mask> \n <mask>     def test_json_body_encoding(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.testing = True\n <mask>         @app.route('/')\n </s> Added support for custom JSON mimetypes </s> remove         if self.mimetype != 'application/json' and not force:\n </s> add         if not (force or self.is_json): </s> add     @property\n    def is_json(self):\n        \"\"\"Indicates if this request is JSON or not.  By default a request\n        is considered to include JSON data if the mimetype is\n        ``application/json`` or ``application/*+json``.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        mt = self.mimetype\n        if mt == 'application/json':\n            return True\n        if mt.startswith('application/') and mt.endswith('+json'):\n            return True\n        return False\n </s> add - Made Flask support custom JSON mimetypes for incoming data.", "html_url": "https://github.com/pallets/flask/commit/e5bba9deb5c9ab9c66bea5c17e96741777fe46ab", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         # XXX: deprecate property\n <mask>         return self.get_json()\n <mask> \n <mask>     def get_json(self, force=False, silent=False, cache=True):\n <mask>         \"\"\"Parses the incoming JSON request data and returns it.  If\n <mask>         parsing fails the :meth:`on_json_loading_failed` method on the\n <mask>         request object will be invoked.  By default this function will\n <mask>         only load the json data if the mimetype is ``application/json``\n </s> Added support for custom JSON mimetypes </s> remove         if self.mimetype != 'application/json' and not force:\n </s> add         if not (force or self.is_json): </s> add - Made Flask support custom JSON mimetypes for incoming data. </s> add     def test_json_custom_mimetypes(self):\n        app = flask.Flask(__name__)\n        @app.route('/json', methods=['POST'])\n        def return_json():\n            return flask.request.get_json()\n        c = app.test_client()\n        rv = c.post('/json', data='\"foo\"', content_type='application/x+json')\n        self.assert_equal(rv.data, b'foo')\n", "html_url": "https://github.com/pallets/flask/commit/e5bba9deb5c9ab9c66bea5c17e96741777fe46ab", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         rv = getattr(self, '_cached_json', _missing)\n <mask>         if rv is not _missing:\n <mask>             return rv\n <mask> \n <mask>         if self.mimetype != 'application/json' and not force:\n <mask>             return None\n <mask> \n <mask>         # We accept a request charset against the specification as\n <mask>         # certain clients have been using this in the past.  This\n <mask>         # fits our general approach of being nice in what we accept\n </s> Added support for custom JSON mimetypes </s> add     @property\n    def is_json(self):\n        \"\"\"Indicates if this request is JSON or not.  By default a request\n        is considered to include JSON data if the mimetype is\n        ``application/json`` or ``application/*+json``.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        mt = self.mimetype\n        if mt == 'application/json':\n            return True\n        if mt.startswith('application/') and mt.endswith('+json'):\n            return True\n        return False\n </s> add - Made Flask support custom JSON mimetypes for incoming data. </s> add     def test_json_custom_mimetypes(self):\n        app = flask.Flask(__name__)\n        @app.route('/json', methods=['POST'])\n        def return_json():\n            return flask.request.get_json()\n        c = app.test_client()\n        rv = c.post('/json', data='\"foo\"', content_type='application/x+json')\n        self.assert_equal(rv.data, b'foo')\n", "html_url": "https://github.com/pallets/flask/commit/e5bba9deb5c9ab9c66bea5c17e96741777fe46ab", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep replace keep replace", "code_tokens": " <mask> ~~~~~~~~~~~~\n <mask> \n <mask> - Create a branch to identify the issue you would like to work on::\n <mask> \n <mask>         git branch your-branch-name\n </s> add instructions for bug and feature branches </s> add - Using your favorite editor, make your changes, `committing as you go`_. </s> remove         git checkout your-branch-name\n\n- Using your favorite editor, make your changes, `committing as you go`_ by using the following::\n\n        git add -A\n        git commit\n </s> add         git checkout -b your-branch-name origin/master </s> remove - Then switch to make sure that we are working on that branch by using::\n </s> add     If you're submitting a feature addition or change, branch off of the\n    \"master\" branch::", "html_url": "https://github.com/pallets/flask/commit/e61fd5f6cb1c7ebba86a9eef9c5e645d9c4032d1", "file_name": "CONTRIBUTING.rst"}
{"docstring_tokens": "keep keep replace keep replace replace replace replace replace replace keep", "code_tokens": " <mask>         git branch your-branch-name\n <mask> \n <mask> - Then switch to make sure that we are working on that branch by using::\n <mask> \n <mask>         git checkout your-branch-name\n <mask> \n <mask> - Using your favorite editor, make your changes, `committing as you go`_ by using the following::\n <mask> \n <mask>         git add -A\n <mask>         git commit\n <mask> \n </s> add instructions for bug and feature branches </s> add - Using your favorite editor, make your changes, `committing as you go`_. </s> remove - Create a branch to identify the issue you would like to work on::\n </s> add -   Create a branch to identify the issue you would like to work on. If\n    you're submitting a bug or documentation fix, branch off of the\n    latest \".x\" branch:: </s> remove         git branch your-branch-name\n </s> add         git checkout -b your-branch-name origin/1.0.x", "html_url": "https://github.com/pallets/flask/commit/e61fd5f6cb1c7ebba86a9eef9c5e645d9c4032d1", "file_name": "CONTRIBUTING.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>         git checkout -b your-branch-name origin/master\n <mask> \n <mask> - Try to follow `PEP8`_, but you may ignore the line length limit if following\n <mask>   it would make the code uglier.\n <mask> - Include tests that cover any code changes you make. Make sure the test fails\n <mask>   without your patch. `Run the tests. <contributing-testsuite_>`_.\n </s> add instructions for bug and feature branches </s> remove         git checkout your-branch-name\n\n- Using your favorite editor, make your changes, `committing as you go`_ by using the following::\n\n        git add -A\n        git commit\n </s> add         git checkout -b your-branch-name origin/master </s> remove - Create a branch to identify the issue you would like to work on::\n </s> add -   Create a branch to identify the issue you would like to work on. If\n    you're submitting a bug or documentation fix, branch off of the\n    latest \".x\" branch:: </s> remove         git branch your-branch-name\n </s> add         git checkout -b your-branch-name origin/1.0.x </s> remove - Then switch to make sure that we are working on that branch by using::\n </s> add     If you're submitting a feature addition or change, branch off of the\n    \"master\" branch::", "html_url": "https://github.com/pallets/flask/commit/e61fd5f6cb1c7ebba86a9eef9c5e645d9c4032d1", "file_name": "CONTRIBUTING.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     removed in Flask 2.1, while remaining compatible with both in\n <mask>     2.0.x. Use ``response.request.environ`` instead. :pr:`4341`\n <mask> -   Fix type annotation for ``errorhandler`` decorator. :issue:`4295`\n <mask> \n <mask> \n <mask> Version 2.0.2\n <mask> -------------\n </s> made ImportError verbose in cli.py </s> remove             raise NoAppException(f\"Could not import {module_name!r}.\") from e\n </s> add             raise NoAppException(f\"Could not import {module_name!r}.\") from None </s> remove                 f\"While importing {module_name!r}, an ImportError was raised.\"\n            ) from e\n </s> add                 f\"While importing {module_name!r}, an ImportError was\"\n                f\" raised:\\n\\n{traceback.format_exc()}\"\n            ) from None </s> remove     except ImportError as e:\n </s> add     except ImportError:", "html_url": "https://github.com/pallets/flask/commit/e679a85b80df354f8632f8ab3e40135f16f5e6d0", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep replace keep keep keep keep replace replace keep keep keep keep", "code_tokens": " <mask>         __import__(module_name)\n <mask>     except ImportError as e:\n <mask>         # Reraise the ImportError if it occurred within the imported module.\n <mask>         # Determine this by checking whether the trace has a depth > 1.\n <mask>         if sys.exc_info()[2].tb_next:\n <mask>             raise NoAppException(\n <mask>                 f\"While importing {module_name!r}, an ImportError was raised.\"\n <mask>             ) from e\n <mask>         elif raise_if_not_found:\n <mask>             raise NoAppException(f\"Could not import {module_name!r}.\") from e\n <mask>         else:\n <mask>             return\n </s> made ImportError verbose in cli.py </s> remove             raise NoAppException(f\"Could not import {module_name!r}.\") from e\n </s> add             raise NoAppException(f\"Could not import {module_name!r}.\") from None </s> add -   Revert a change to the CLI that caused it to hide ``ImportError``\n    tracebacks when importing the application. :issue:`4307`", "html_url": "https://github.com/pallets/flask/commit/e679a85b80df354f8632f8ab3e40135f16f5e6d0", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             raise NoAppException(\n <mask>                 f\"While importing {module_name!r}, an ImportError was raised.\"\n <mask>             ) from e\n <mask>         elif raise_if_not_found:\n <mask>             raise NoAppException(f\"Could not import {module_name!r}.\") from e\n <mask>         else:\n <mask>             return\n <mask> \n <mask>     module = sys.modules[module_name]\n <mask> \n </s> made ImportError verbose in cli.py </s> remove                 f\"While importing {module_name!r}, an ImportError was raised.\"\n            ) from e\n </s> add                 f\"While importing {module_name!r}, an ImportError was\"\n                f\" raised:\\n\\n{traceback.format_exc()}\"\n            ) from None </s> remove     except ImportError as e:\n </s> add     except ImportError: </s> add -   Revert a change to the CLI that caused it to hide ``ImportError``\n    tracebacks when importing the application. :issue:`4307`", "html_url": "https://github.com/pallets/flask/commit/e679a85b80df354f8632f8ab3e40135f16f5e6d0", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> In order to use jQuery, you have to download it first and place it in the\n <mask> static folder of your application and then ensure it's loaded.  Ideally\n <mask> you have a layout template that is used for all pages where you just have\n <mask> to add a script statement to your `head` to load jQuery:\n <mask> \n <mask> .. sourcecode:: html\n <mask> \n <mask>    <script type=text/javascript src=\"{{\n <mask>      url_for('static', filename='jquery.js') }}\"></script>\n </s> Improving documentation for loading jQuery. Now using Google CDN with fallback to local jQuery. </s> remove     <script type=text/javascript\n      src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js\"></script>\n </s> add     <script src=\"//ajax.googleapis.com/ajax/libs/jquery/1.6.1/jquery.js\"></script>\n    <script>window.jQuery || document.write('<script src=\"{{\n      url_for('static', filename='jquery.js') }}\">\\x3C/script>')</script> </s> remove will already be in the browser cache.  Downside is that if you don't have\nnetwork connectivity during development jQuery will not load.\n </s> add will already be in the browser cache. </s> remove In this case you don't have to put jQuery into your static folder, it will\ninstead be loaded from Google directly.  This has the advantage that your\n </s> add In this case you have to put jQuery into your static folder as a fallback, but it will\nfirst try to load it directly from Google. This has the advantage that your", "html_url": "https://github.com/pallets/flask/commit/e6b9f509ba3c47f748d5c6da5f6de5500248dbfd", "file_name": "docs/patterns/jquery.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> <http://code.google.com/apis/ajaxlibs/documentation/>`_ to load jQuery:\n <mask> \n <mask> .. sourcecode:: html\n <mask> \n <mask>     <script type=text/javascript\n <mask>       src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js\"></script>\n <mask> \n <mask> In this case you don't have to put jQuery into your static folder, it will\n <mask> instead be loaded from Google directly.  This has the advantage that your\n <mask> website will probably load faster for users if they went to at least one\n <mask> other website before using the same jQuery version from Google because it\n </s> Improving documentation for loading jQuery. Now using Google CDN with fallback to local jQuery. </s> remove to add a script statement to your `head` to load jQuery:\n </s> add to add a script statement to the bottom of your `<body>` to load jQuery: </s> remove will already be in the browser cache.  Downside is that if you don't have\nnetwork connectivity during development jQuery will not load.\n </s> add will already be in the browser cache. </s> remove In this case you don't have to put jQuery into your static folder, it will\ninstead be loaded from Google directly.  This has the advantage that your\n </s> add In this case you have to put jQuery into your static folder as a fallback, but it will\nfirst try to load it directly from Google. This has the advantage that your", "html_url": "https://github.com/pallets/flask/commit/e6b9f509ba3c47f748d5c6da5f6de5500248dbfd", "file_name": "docs/patterns/jquery.rst"}
{"docstring_tokens": "keep keep replace replace keep keep replace replace keep keep", "code_tokens": " <mask>       src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js\"></script>\n <mask> \n <mask> In this case you don't have to put jQuery into your static folder, it will\n <mask> instead be loaded from Google directly.  This has the advantage that your\n <mask> website will probably load faster for users if they went to at least one\n <mask> other website before using the same jQuery version from Google because it\n <mask> will already be in the browser cache.  Downside is that if you don't have\n <mask> network connectivity during development jQuery will not load.\n <mask> \n <mask> Where is My Site?\n </s> Improving documentation for loading jQuery. Now using Google CDN with fallback to local jQuery. </s> remove to add a script statement to your `head` to load jQuery:\n </s> add to add a script statement to the bottom of your `<body>` to load jQuery: </s> remove     <script type=text/javascript\n      src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js\"></script>\n </s> add     <script src=\"//ajax.googleapis.com/ajax/libs/jquery/1.6.1/jquery.js\"></script>\n    <script>window.jQuery || document.write('<script src=\"{{\n      url_for('static', filename='jquery.js') }}\">\\x3C/script>')</script>", "html_url": "https://github.com/pallets/flask/commit/e6b9f509ba3c47f748d5c6da5f6de5500248dbfd", "file_name": "docs/patterns/jquery.rst"}
{"docstring_tokens": "keep keep replace keep keep keep keep keep", "code_tokens": " <mask> .. _tutorial-css:\n <mask> \n <mask> Step 9: Adding Style\n <mask> ====================\n <mask> \n <mask> Now that everything else works, it's time to add some style to the\n <mask> application.  Just create a stylesheet called :file:`style.css` in the\n <mask> :file:`static` folder:\n </s> Clean up tutorial docs for installable app pattern with flaskr (#2002)\n\n* Clean up tutorial docs for installable app pattern\r\n\r\n- reading sequentially through the tutorial works.\r\n- fixes references to `export FLASK_APP=flaskr.flaskr`\r\n\r\n* Fixes titles for each section of flaskr tutorial\r\n\r\n* Revert grammar\r\n\r\n* Emphasize the Packaging Guide\r\n\r\n- adds more general packaging resource\r\n- removes the emphasis put on setuptools\r\n\r\n* rephrase and remove note admonitions\r\n\r\n- expanded on few points\r\n- removed note blocks, they are unneccessary\r\n\r\n* Remove note about reinstalling to update cli\r\n\r\n- I had mistakenly thought it was necessary to\r\n  re-install the app to update the cli.\r\n- the `--editable` flag detects the change and\r\n  the cli updates without issue. </s> remove Step 8: The Templates\n </s> add Step 7: The Templates </s> remove Adding Tests to flaskr\n======================\n </s> add Adding tests to flaskr\n---------------------- </s> remove     from flaskr import flaskr\n </s> add .. note:: Make sure that ``pytest`` is installed in the same virtualenv \n    as flaskr. Otherwise ``pytest`` test will not be able to import the \n    required components to test the application:: </s> remove Step 7: The View Functions\n </s> add Step 6: The View Functions </s> remove You now have a function for establishing a database connection with\n </s> add You currently have a function for establishing a database connection with </s> remove Continue with :ref:`tutorial-setuptools`.\n </s> add Continue with :ref:`tutorial-packaging`.", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/css.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Step 4: Database Connections\n <mask> ----------------------------\n <mask> \n <mask> You now have a function for establishing a database connection with\n <mask> `connect_db`, but by itself, it is not particularly useful.  Creating and\n <mask> closing database connections all the time is very inefficient, so you will\n <mask> need to keep it around for longer.  Because database connections\n <mask> encapsulate a transaction, you will need to make sure that only one\n <mask> request at a time uses the connection. An elegant way to do this is by\n </s> Clean up tutorial docs for installable app pattern with flaskr (#2002)\n\n* Clean up tutorial docs for installable app pattern\r\n\r\n- reading sequentially through the tutorial works.\r\n- fixes references to `export FLASK_APP=flaskr.flaskr`\r\n\r\n* Fixes titles for each section of flaskr tutorial\r\n\r\n* Revert grammar\r\n\r\n* Emphasize the Packaging Guide\r\n\r\n- adds more general packaging resource\r\n- removes the emphasis put on setuptools\r\n\r\n* rephrase and remove note admonitions\r\n\r\n- expanded on few points\r\n- removed note blocks, they are unneccessary\r\n\r\n* Remove note about reinstalling to update cli\r\n\r\n- I had mistakenly thought it was necessary to\r\n  re-install the app to update the cli.\r\n- the `--editable` flag detects the change and\r\n  the cli updates without issue. </s> remove Step 7: The View Functions\n </s> add Step 6: The View Functions </s> remove Step 8: The Templates\n </s> add Step 7: The Templates </s> remove One way to handle testing is to integrate it with ``setuptools``. All it\nrequires is adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. Go ahead and update the\n:file:`setup.py` to contain::\n </s> add Run and watch the tests pass, within the top-level :file:`flaskr/` \ndirectory as::\n\n    py.test\n\nTesting + setuptools\n--------------------\n\nOne way to handle testing is to integrate it with ``setuptools``. Here\nthat requires adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. One benefit of running the tests \nthis way is that you do not have to install ``pytest``. Go ahead and \nupdate the :file:`setup.py` file to contain:: </s> remove Adding Tests to flaskr\n======================\n </s> add Adding tests to flaskr\n---------------------- </s> remove     from flaskr import flaskr\n </s> add .. note:: Make sure that ``pytest`` is installed in the same virtualenv \n    as flaskr. Otherwise ``pytest`` test will not be able to import the \n    required components to test the application:: </s> remove download ``pytest`` or any other testing framework one might use. </s> add ", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/dbcon.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>    introduction\n <mask>    folders\n <mask>    schema\n <mask>    setup\n <mask>    setuptools\n <mask>    dbcon\n <mask>    dbinit\n <mask>    views\n <mask>    templates\n <mask>    css\n </s> Clean up tutorial docs for installable app pattern with flaskr (#2002)\n\n* Clean up tutorial docs for installable app pattern\r\n\r\n- reading sequentially through the tutorial works.\r\n- fixes references to `export FLASK_APP=flaskr.flaskr`\r\n\r\n* Fixes titles for each section of flaskr tutorial\r\n\r\n* Revert grammar\r\n\r\n* Emphasize the Packaging Guide\r\n\r\n- adds more general packaging resource\r\n- removes the emphasis put on setuptools\r\n\r\n* rephrase and remove note admonitions\r\n\r\n- expanded on few points\r\n- removed note blocks, they are unneccessary\r\n\r\n* Remove note about reinstalling to update cli\r\n\r\n- I had mistakenly thought it was necessary to\r\n  re-install the app to update the cli.\r\n- the `--editable` flag detects the change and\r\n  the cli updates without issue. </s> remove One way to handle testing is to integrate it with ``setuptools``. All it\nrequires is adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. Go ahead and update the\n:file:`setup.py` to contain::\n </s> add Run and watch the tests pass, within the top-level :file:`flaskr/` \ndirectory as::\n\n    py.test\n\nTesting + setuptools\n--------------------\n\nOne way to handle testing is to integrate it with ``setuptools``. Here\nthat requires adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. One benefit of running the tests \nthis way is that you do not have to install ``pytest``. Go ahead and \nupdate the :file:`setup.py` file to contain:: </s> remove Step 8: The Templates\n </s> add Step 7: The Templates </s> remove Step 7: The View Functions\n </s> add Step 6: The View Functions </s> remove             context.py\n </s> add  </s> remove You now have a function for establishing a database connection with\n </s> add You currently have a function for establishing a database connection with </s> remove Continue with :ref:`tutorial-setuptools`.\n </s> add Continue with :ref:`tutorial-packaging`.", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/index.rst"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask>         return rv\n <mask> \n <mask> In the next section you will see how to run the application.\n <mask> \n <mask> Continue with :ref:`tutorial-setuptools`.\n </s> Clean up tutorial docs for installable app pattern with flaskr (#2002)\n\n* Clean up tutorial docs for installable app pattern\r\n\r\n- reading sequentially through the tutorial works.\r\n- fixes references to `export FLASK_APP=flaskr.flaskr`\r\n\r\n* Fixes titles for each section of flaskr tutorial\r\n\r\n* Revert grammar\r\n\r\n* Emphasize the Packaging Guide\r\n\r\n- adds more general packaging resource\r\n- removes the emphasis put on setuptools\r\n\r\n* rephrase and remove note admonitions\r\n\r\n- expanded on few points\r\n- removed note blocks, they are unneccessary\r\n\r\n* Remove note about reinstalling to update cli\r\n\r\n- I had mistakenly thought it was necessary to\r\n  re-install the app to update the cli.\r\n- the `--editable` flag detects the change and\r\n  the cli updates without issue. </s> remove Adding Tests to flaskr\n======================\n </s> add Adding tests to flaskr\n---------------------- </s> remove Assuming you have seen the testing section above and have either written\n </s> add Assuming you have seen the :ref:`testing` section and have either written </s> remove Step 9: Adding Style\n </s> add Step 8: Adding Style </s> remove Step 8: The Templates\n </s> add Step 7: The Templates </s> remove     basedir = os.path.dirname(os.path.abspath(__file__))\n    sys.path.insert(0, basedir + '/../')\n </s> add At this point you can run the tests. Here ``pytest`` will be used.  </s> remove You now have a function for establishing a database connection with\n </s> add You currently have a function for establishing a database connection with", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/setup.rst"}
{"docstring_tokens": "keep keep replace keep keep keep keep keep", "code_tokens": " <mask> .. _tutorial-templates:\n <mask> \n <mask> Step 8: The Templates\n <mask> =====================\n <mask> \n <mask> Now it is time to start working on the templates.  As you may have\n <mask> noticed, if you make requests with the app running, you will get\n <mask> an exception that Flask cannot find the templates.  The templates\n </s> Clean up tutorial docs for installable app pattern with flaskr (#2002)\n\n* Clean up tutorial docs for installable app pattern\r\n\r\n- reading sequentially through the tutorial works.\r\n- fixes references to `export FLASK_APP=flaskr.flaskr`\r\n\r\n* Fixes titles for each section of flaskr tutorial\r\n\r\n* Revert grammar\r\n\r\n* Emphasize the Packaging Guide\r\n\r\n- adds more general packaging resource\r\n- removes the emphasis put on setuptools\r\n\r\n* rephrase and remove note admonitions\r\n\r\n- expanded on few points\r\n- removed note blocks, they are unneccessary\r\n\r\n* Remove note about reinstalling to update cli\r\n\r\n- I had mistakenly thought it was necessary to\r\n  re-install the app to update the cli.\r\n- the `--editable` flag detects the change and\r\n  the cli updates without issue. </s> remove Step 7: The View Functions\n </s> add Step 6: The View Functions </s> remove Step 9: Adding Style\n </s> add Step 8: Adding Style </s> remove You now have a function for establishing a database connection with\n </s> add You currently have a function for establishing a database connection with </s> remove Adding Tests to flaskr\n======================\n </s> add Adding tests to flaskr\n---------------------- </s> remove     import sys, os\n </s> add Running the tests\n----------------- </s> remove For now go ahead a create the :file:`tests/` directory as well as the\n:file:`context.py` and :file:`test_flaskr.py` files, if you haven't\nalready. The context file is used as an import helper. The contents\nof that file are::\n </s> add For now go ahead a create the :file:`tests/` directory as well as the \n:file:`test_flaskr.py` file.", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/templates.rst"}
{"docstring_tokens": "keep keep keep replace replace keep keep keep keep keep keep keep keep replace keep keep keep", "code_tokens": " <mask> example of how to perform unit testing in the :ref:`testing` section of the\n <mask> documentation.  Go there to see how easy it is to test Flask applications.\n <mask> \n <mask> Adding Tests to flaskr\n <mask> ======================\n <mask> \n <mask> Assuming you have seen the testing section above and have either written\n <mask> your own tests for ``flaskr`` or have followed along with the examples\n <mask> provided, you might be wondering about ways to organize the project.\n <mask> \n <mask> Adding Tests to flaskr\n <mask> ======================\n <mask> \n <mask> Assuming you have seen the testing section above and have either written\n <mask> your own tests for ``flaskr`` or have followed along with the examples\n <mask> provided, you might be wondering about ways to organize the project.\n <mask> \n </s> Clean up tutorial docs for installable app pattern with flaskr (#2002)\n\n* Clean up tutorial docs for installable app pattern\r\n\r\n- reading sequentially through the tutorial works.\r\n- fixes references to `export FLASK_APP=flaskr.flaskr`\r\n\r\n* Fixes titles for each section of flaskr tutorial\r\n\r\n* Revert grammar\r\n\r\n* Emphasize the Packaging Guide\r\n\r\n- adds more general packaging resource\r\n- removes the emphasis put on setuptools\r\n\r\n* rephrase and remove note admonitions\r\n\r\n- expanded on few points\r\n- removed note blocks, they are unneccessary\r\n\r\n* Remove note about reinstalling to update cli\r\n\r\n- I had mistakenly thought it was necessary to\r\n  re-install the app to update the cli.\r\n- the `--editable` flag detects the change and\r\n  the cli updates without issue. </s> remove Continue with :ref:`tutorial-setuptools`.\n </s> add Continue with :ref:`tutorial-packaging`. </s> remove One way to handle testing is to integrate it with ``setuptools``. All it\nrequires is adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. Go ahead and update the\n:file:`setup.py` to contain::\n </s> add Run and watch the tests pass, within the top-level :file:`flaskr/` \ndirectory as::\n\n    py.test\n\nTesting + setuptools\n--------------------\n\nOne way to handle testing is to integrate it with ``setuptools``. Here\nthat requires adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. One benefit of running the tests \nthis way is that you do not have to install ``pytest``. Go ahead and \nupdate the :file:`setup.py` file to contain:: </s> remove You now have a function for establishing a database connection with\n </s> add You currently have a function for establishing a database connection with </s> remove     from flaskr import flaskr\n </s> add .. note:: Make sure that ``pytest`` is installed in the same virtualenv \n    as flaskr. Otherwise ``pytest`` test will not be able to import the \n    required components to test the application:: </s> remove Step 8: The Templates\n </s> add Step 7: The Templates", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/testing.rst"}
{"docstring_tokens": "keep replace keep keep keep keep replace replace replace replace keep keep keep keep", "code_tokens": " <mask>         tests/\n <mask>             context.py\n <mask>             test_flaskr.py\n <mask>         setup.py\n <mask>         MANIFEST.in\n <mask> \n <mask> For now go ahead a create the :file:`tests/` directory as well as the\n <mask> :file:`context.py` and :file:`test_flaskr.py` files, if you haven't\n <mask> already. The context file is used as an import helper. The contents\n <mask> of that file are::\n <mask> \n <mask>     import sys, os\n <mask> \n <mask>     basedir = os.path.dirname(os.path.abspath(__file__))\n </s> Clean up tutorial docs for installable app pattern with flaskr (#2002)\n\n* Clean up tutorial docs for installable app pattern\r\n\r\n- reading sequentially through the tutorial works.\r\n- fixes references to `export FLASK_APP=flaskr.flaskr`\r\n\r\n* Fixes titles for each section of flaskr tutorial\r\n\r\n* Revert grammar\r\n\r\n* Emphasize the Packaging Guide\r\n\r\n- adds more general packaging resource\r\n- removes the emphasis put on setuptools\r\n\r\n* rephrase and remove note admonitions\r\n\r\n- expanded on few points\r\n- removed note blocks, they are unneccessary\r\n\r\n* Remove note about reinstalling to update cli\r\n\r\n- I had mistakenly thought it was necessary to\r\n  re-install the app to update the cli.\r\n- the `--editable` flag detects the change and\r\n  the cli updates without issue. </s> remove     import sys, os\n </s> add Running the tests\n----------------- </s> remove     basedir = os.path.dirname(os.path.abspath(__file__))\n    sys.path.insert(0, basedir + '/../')\n </s> add At this point you can run the tests. Here ``pytest`` will be used.  </s> remove One way to handle testing is to integrate it with ``setuptools``. All it\nrequires is adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. Go ahead and update the\n:file:`setup.py` to contain::\n </s> add Run and watch the tests pass, within the top-level :file:`flaskr/` \ndirectory as::\n\n    py.test\n\nTesting + setuptools\n--------------------\n\nOne way to handle testing is to integrate it with ``setuptools``. Here\nthat requires adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. One benefit of running the tests \nthis way is that you do not have to install ``pytest``. Go ahead and \nupdate the :file:`setup.py` file to contain:: </s> remove Step 8: The Templates\n </s> add Step 7: The Templates </s> remove Testing + Setuptools\n====================\n </s> add         pip install -e .\n        pip install pytest ", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/testing.rst"}
{"docstring_tokens": "keep keep keep replace keep replace replace keep keep keep", "code_tokens": " <mask> already. The context file is used as an import helper. The contents\n <mask> of that file are::\n <mask> \n <mask>     import sys, os\n <mask> \n <mask>     basedir = os.path.dirname(os.path.abspath(__file__))\n <mask>     sys.path.insert(0, basedir + '/../')\n <mask> \n <mask>     from flaskr import flaskr\n <mask> \n </s> Clean up tutorial docs for installable app pattern with flaskr (#2002)\n\n* Clean up tutorial docs for installable app pattern\r\n\r\n- reading sequentially through the tutorial works.\r\n- fixes references to `export FLASK_APP=flaskr.flaskr`\r\n\r\n* Fixes titles for each section of flaskr tutorial\r\n\r\n* Revert grammar\r\n\r\n* Emphasize the Packaging Guide\r\n\r\n- adds more general packaging resource\r\n- removes the emphasis put on setuptools\r\n\r\n* rephrase and remove note admonitions\r\n\r\n- expanded on few points\r\n- removed note blocks, they are unneccessary\r\n\r\n* Remove note about reinstalling to update cli\r\n\r\n- I had mistakenly thought it was necessary to\r\n  re-install the app to update the cli.\r\n- the `--editable` flag detects the change and\r\n  the cli updates without issue. </s> remove For now go ahead a create the :file:`tests/` directory as well as the\n:file:`context.py` and :file:`test_flaskr.py` files, if you haven't\nalready. The context file is used as an import helper. The contents\nof that file are::\n </s> add For now go ahead a create the :file:`tests/` directory as well as the \n:file:`test_flaskr.py` file. </s> remove     from flaskr import flaskr\n </s> add .. note:: Make sure that ``pytest`` is installed in the same virtualenv \n    as flaskr. Otherwise ``pytest`` test will not be able to import the \n    required components to test the application:: </s> remove Testing + Setuptools\n====================\n </s> add         pip install -e .\n        pip install pytest  </s> remove One way to handle testing is to integrate it with ``setuptools``. All it\nrequires is adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. Go ahead and update the\n:file:`setup.py` to contain::\n </s> add Run and watch the tests pass, within the top-level :file:`flaskr/` \ndirectory as::\n\n    py.test\n\nTesting + setuptools\n--------------------\n\nOne way to handle testing is to integrate it with ``setuptools``. Here\nthat requires adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. One benefit of running the tests \nthis way is that you do not have to install ``pytest``. Go ahead and \nupdate the :file:`setup.py` file to contain:: </s> remove Adding Tests to flaskr\n======================\n </s> add Adding tests to flaskr\n----------------------", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace keep keep", "code_tokens": " <mask> \n <mask>     basedir = os.path.dirname(os.path.abspath(__file__))\n <mask>     sys.path.insert(0, basedir + '/../')\n <mask> \n <mask>     from flaskr import flaskr\n <mask> \n <mask> Testing + Setuptools\n <mask> ====================\n <mask> \n <mask> One way to handle testing is to integrate it with ``setuptools``. All it\n </s> Clean up tutorial docs for installable app pattern with flaskr (#2002)\n\n* Clean up tutorial docs for installable app pattern\r\n\r\n- reading sequentially through the tutorial works.\r\n- fixes references to `export FLASK_APP=flaskr.flaskr`\r\n\r\n* Fixes titles for each section of flaskr tutorial\r\n\r\n* Revert grammar\r\n\r\n* Emphasize the Packaging Guide\r\n\r\n- adds more general packaging resource\r\n- removes the emphasis put on setuptools\r\n\r\n* rephrase and remove note admonitions\r\n\r\n- expanded on few points\r\n- removed note blocks, they are unneccessary\r\n\r\n* Remove note about reinstalling to update cli\r\n\r\n- I had mistakenly thought it was necessary to\r\n  re-install the app to update the cli.\r\n- the `--editable` flag detects the change and\r\n  the cli updates without issue. </s> remove     basedir = os.path.dirname(os.path.abspath(__file__))\n    sys.path.insert(0, basedir + '/../')\n </s> add At this point you can run the tests. Here ``pytest`` will be used.  </s> remove One way to handle testing is to integrate it with ``setuptools``. All it\nrequires is adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. Go ahead and update the\n:file:`setup.py` to contain::\n </s> add Run and watch the tests pass, within the top-level :file:`flaskr/` \ndirectory as::\n\n    py.test\n\nTesting + setuptools\n--------------------\n\nOne way to handle testing is to integrate it with ``setuptools``. Here\nthat requires adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. One benefit of running the tests \nthis way is that you do not have to install ``pytest``. Go ahead and \nupdate the :file:`setup.py` file to contain:: </s> remove     import sys, os\n </s> add Running the tests\n----------------- </s> remove For now go ahead a create the :file:`tests/` directory as well as the\n:file:`context.py` and :file:`test_flaskr.py` files, if you haven't\nalready. The context file is used as an import helper. The contents\nof that file are::\n </s> add For now go ahead a create the :file:`tests/` directory as well as the \n:file:`test_flaskr.py` file. </s> remove Adding Tests to flaskr\n======================\n </s> add Adding tests to flaskr\n----------------------", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Testing + Setuptools\n <mask> ====================\n <mask> \n <mask> One way to handle testing is to integrate it with ``setuptools``. All it\n <mask> requires is adding a couple of lines to the :file:`setup.py` file and\n <mask> creating a new file :file:`setup.cfg`. Go ahead and update the\n <mask> :file:`setup.py` to contain::\n <mask> \n <mask>     from setuptools import setup\n <mask> \n <mask>     setup(\n <mask>         name='flaskr',\n </s> Clean up tutorial docs for installable app pattern with flaskr (#2002)\n\n* Clean up tutorial docs for installable app pattern\r\n\r\n- reading sequentially through the tutorial works.\r\n- fixes references to `export FLASK_APP=flaskr.flaskr`\r\n\r\n* Fixes titles for each section of flaskr tutorial\r\n\r\n* Revert grammar\r\n\r\n* Emphasize the Packaging Guide\r\n\r\n- adds more general packaging resource\r\n- removes the emphasis put on setuptools\r\n\r\n* rephrase and remove note admonitions\r\n\r\n- expanded on few points\r\n- removed note blocks, they are unneccessary\r\n\r\n* Remove note about reinstalling to update cli\r\n\r\n- I had mistakenly thought it was necessary to\r\n  re-install the app to update the cli.\r\n- the `--editable` flag detects the change and\r\n  the cli updates without issue. </s> remove Testing + Setuptools\n====================\n </s> add         pip install -e .\n        pip install pytest  </s> remove     from flaskr import flaskr\n </s> add .. note:: Make sure that ``pytest`` is installed in the same virtualenv \n    as flaskr. Otherwise ``pytest`` test will not be able to import the \n    required components to test the application:: </s> remove     basedir = os.path.dirname(os.path.abspath(__file__))\n    sys.path.insert(0, basedir + '/../')\n </s> add At this point you can run the tests. Here ``pytest`` will be used.  </s> remove Adding Tests to flaskr\n======================\n </s> add Adding tests to flaskr\n---------------------- </s> remove For now go ahead a create the :file:`tests/` directory as well as the\n:file:`context.py` and :file:`test_flaskr.py` files, if you haven't\nalready. The context file is used as an import helper. The contents\nof that file are::\n </s> add For now go ahead a create the :file:`tests/` directory as well as the \n:file:`test_flaskr.py` file. </s> remove You now have a function for establishing a database connection with\n </s> add You currently have a function for establishing a database connection with", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         include_package_data=True,\n <mask>         install_requires=[\n <mask>             'flask',\n <mask>         ],\n <mask>     )\n <mask>         setup_requires=[\n <mask>             'pytest-runner',\n <mask>         ],\n <mask>         tests_require=[\n <mask>             'pytest',\n </s> Clean up tutorial docs for installable app pattern with flaskr (#2002)\n\n* Clean up tutorial docs for installable app pattern\r\n\r\n- reading sequentially through the tutorial works.\r\n- fixes references to `export FLASK_APP=flaskr.flaskr`\r\n\r\n* Fixes titles for each section of flaskr tutorial\r\n\r\n* Revert grammar\r\n\r\n* Emphasize the Packaging Guide\r\n\r\n- adds more general packaging resource\r\n- removes the emphasis put on setuptools\r\n\r\n* rephrase and remove note admonitions\r\n\r\n- expanded on few points\r\n- removed note blocks, they are unneccessary\r\n\r\n* Remove note about reinstalling to update cli\r\n\r\n- I had mistakenly thought it was necessary to\r\n  re-install the app to update the cli.\r\n- the `--editable` flag detects the change and\r\n  the cli updates without issue. </s> remove Step 7: The View Functions\n </s> add Step 6: The View Functions </s> remove             context.py\n </s> add  </s> remove You now have a function for establishing a database connection with\n </s> add You currently have a function for establishing a database connection with </s> remove    setuptools\n </s> add    packaging </s> remove Continue with :ref:`tutorial-setuptools`.\n </s> add Continue with :ref:`tutorial-packaging`. </s> remove Step 8: The Templates\n </s> add Step 7: The Templates", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask> \n <mask> This is one possible way to run and manage testing.  Here ``pytest`` is\n <mask> used, but there are other options such as ``nose``.  Integrating testing\n <mask> with ``setuptools`` is convenient because it is not necessary to actually\n <mask> download ``pytest`` or any other testing framework one might use. </s> Clean up tutorial docs for installable app pattern with flaskr (#2002)\n\n* Clean up tutorial docs for installable app pattern\r\n\r\n- reading sequentially through the tutorial works.\r\n- fixes references to `export FLASK_APP=flaskr.flaskr`\r\n\r\n* Fixes titles for each section of flaskr tutorial\r\n\r\n* Revert grammar\r\n\r\n* Emphasize the Packaging Guide\r\n\r\n- adds more general packaging resource\r\n- removes the emphasis put on setuptools\r\n\r\n* rephrase and remove note admonitions\r\n\r\n- expanded on few points\r\n- removed note blocks, they are unneccessary\r\n\r\n* Remove note about reinstalling to update cli\r\n\r\n- I had mistakenly thought it was necessary to\r\n  re-install the app to update the cli.\r\n- the `--editable` flag detects the change and\r\n  the cli updates without issue. </s> add download ``pytest`` or any other testing framework one might use. </s> remove     from flaskr import flaskr\n </s> add .. note:: Make sure that ``pytest`` is installed in the same virtualenv \n    as flaskr. Otherwise ``pytest`` test will not be able to import the \n    required components to test the application:: </s> remove You now have a function for establishing a database connection with\n </s> add You currently have a function for establishing a database connection with </s> remove Adding Tests to flaskr\n======================\n </s> add Adding tests to flaskr\n---------------------- </s> remove One way to handle testing is to integrate it with ``setuptools``. All it\nrequires is adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. Go ahead and update the\n:file:`setup.py` to contain::\n </s> add Run and watch the tests pass, within the top-level :file:`flaskr/` \ndirectory as::\n\n    py.test\n\nTesting + setuptools\n--------------------\n\nOne way to handle testing is to integrate it with ``setuptools``. Here\nthat requires adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. One benefit of running the tests \nthis way is that you do not have to install ``pytest``. Go ahead and \nupdate the :file:`setup.py` file to contain:: </s> remove Testing + Setuptools\n====================\n </s> add         pip install -e .\n        pip install pytest ", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/testing.rst"}
{"docstring_tokens": "keep keep keep add", "code_tokens": " <mask> This is one possible way to run and manage testing.  Here ``pytest`` is\n <mask> used, but there are other options such as ``nose``.  Integrating testing\n <mask> with ``setuptools`` is convenient because it is not necessary to actually\n <mask> download ``pytest`` or any other testing framework one might use.\n </s> Clean up tutorial docs for installable app pattern with flaskr (#2002)\n\n* Clean up tutorial docs for installable app pattern\r\n\r\n- reading sequentially through the tutorial works.\r\n- fixes references to `export FLASK_APP=flaskr.flaskr`\r\n\r\n* Fixes titles for each section of flaskr tutorial\r\n\r\n* Revert grammar\r\n\r\n* Emphasize the Packaging Guide\r\n\r\n- adds more general packaging resource\r\n- removes the emphasis put on setuptools\r\n\r\n* rephrase and remove note admonitions\r\n\r\n- expanded on few points\r\n- removed note blocks, they are unneccessary\r\n\r\n* Remove note about reinstalling to update cli\r\n\r\n- I had mistakenly thought it was necessary to\r\n  re-install the app to update the cli.\r\n- the `--editable` flag detects the change and\r\n  the cli updates without issue. </s> remove download ``pytest`` or any other testing framework one might use. </s> add  </s> remove     from flaskr import flaskr\n </s> add .. note:: Make sure that ``pytest`` is installed in the same virtualenv \n    as flaskr. Otherwise ``pytest`` test will not be able to import the \n    required components to test the application:: </s> remove You now have a function for establishing a database connection with\n </s> add You currently have a function for establishing a database connection with </s> remove Adding Tests to flaskr\n======================\n </s> add Adding tests to flaskr\n---------------------- </s> remove One way to handle testing is to integrate it with ``setuptools``. All it\nrequires is adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. Go ahead and update the\n:file:`setup.py` to contain::\n </s> add Run and watch the tests pass, within the top-level :file:`flaskr/` \ndirectory as::\n\n    py.test\n\nTesting + setuptools\n--------------------\n\nOne way to handle testing is to integrate it with ``setuptools``. Here\nthat requires adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. One benefit of running the tests \nthis way is that you do not have to install ``pytest``. Go ahead and \nupdate the :file:`setup.py` file to contain:: </s> remove Testing + Setuptools\n====================\n </s> add         pip install -e .\n        pip install pytest ", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/testing.rst"}
{"docstring_tokens": "keep keep replace keep keep keep keep keep", "code_tokens": " <mask> .. _tutorial-views:\n <mask> \n <mask> Step 7: The View Functions\n <mask> ==========================\n <mask> \n <mask> Now that the database connections are working, you can start writing the\n <mask> view functions.  You will need four of them:\n <mask> \n </s> Clean up tutorial docs for installable app pattern with flaskr (#2002)\n\n* Clean up tutorial docs for installable app pattern\r\n\r\n- reading sequentially through the tutorial works.\r\n- fixes references to `export FLASK_APP=flaskr.flaskr`\r\n\r\n* Fixes titles for each section of flaskr tutorial\r\n\r\n* Revert grammar\r\n\r\n* Emphasize the Packaging Guide\r\n\r\n- adds more general packaging resource\r\n- removes the emphasis put on setuptools\r\n\r\n* rephrase and remove note admonitions\r\n\r\n- expanded on few points\r\n- removed note blocks, they are unneccessary\r\n\r\n* Remove note about reinstalling to update cli\r\n\r\n- I had mistakenly thought it was necessary to\r\n  re-install the app to update the cli.\r\n- the `--editable` flag detects the change and\r\n  the cli updates without issue. </s> remove Step 8: The Templates\n </s> add Step 7: The Templates </s> remove You now have a function for establishing a database connection with\n </s> add You currently have a function for establishing a database connection with </s> remove Step 9: Adding Style\n </s> add Step 8: Adding Style </s> remove     basedir = os.path.dirname(os.path.abspath(__file__))\n    sys.path.insert(0, basedir + '/../')\n </s> add At this point you can run the tests. Here ``pytest`` will be used.  </s> remove For now go ahead a create the :file:`tests/` directory as well as the\n:file:`context.py` and :file:`test_flaskr.py` files, if you haven't\nalready. The context file is used as an import helper. The contents\nof that file are::\n </s> add For now go ahead a create the :file:`tests/` directory as well as the \n:file:`test_flaskr.py` file. </s> remove Adding Tests to flaskr\n======================\n </s> add Adding tests to flaskr\n----------------------", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/views.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> Useful Internals\n <mask> ----------------\n <mask> \n <mask> .. data:: _request_ctx_stack\n <mask> \n <mask>    The internal :class:`~werkzeug.local.LocalStack` that is used to implement\n <mask>    all the context local objects used in Flask.  This is a documented\n <mask>    instance and can be used by extensions and application code but the\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove \n.. _notes-on-proxies:\n\nNotes On Proxies\n----------------\n\nSome of the objects provided by Flask are proxies to other objects.  The\nreason behind this is that these proxies are shared between threads and\nthey have to dispatch to the actual object bound to a thread behind the\nscenes as necessary.\n\nMost of the time you don't have to care about that, but there are some\nexceptions where it is good to know that this object is an actual proxy:\n\n-   The proxy objects do not fake their inherited types, so if you want to\n    perform actual instance checks, you have to do that on the instance\n    that is being proxied (see `_get_current_object` below).\n-   if the object reference is important (so for example for sending\n    :ref:`signals`)\n\nIf you need to get access to the underlying object that is proxied, you\ncan use the :meth:`~werkzeug.local.LocalProxy._get_current_object` method::\n\n    app = current_app._get_current_object()\n    my_signal.send(app)\n </s> add  </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory.\n\n </s> add  </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods:\n </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand: </s> remove >>> ctx = app.test_request_context('/?next=http://example.com/')\n </s> add >>> ctx = app.test_request_context() </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block.\n </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block. </s> add .. data:: request_tearing_down\n\n   This signal is sent when the application is tearing down the request.\n   This is always called, even if an error happened.  No arguments are\n   provided.\n", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/api.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>           ctx = _request_ctx_stack.top\n <mask>           if ctx is not None:\n <mask>               return ctx.session\n <mask> \n <mask>    .. versionchanged:: 0.4\n <mask> \n <mask>    The request context is automatically popped at the end of the request\n <mask>    for you.  In debug mode the request context is kept around if\n <mask>    exceptions happen so that interactive debuggers have a chance to\n <mask>    introspect the data.  With 0.4 this can also be forced for requests\n <mask>    that did not fail and outside of `DEBUG` mode.  By setting\n <mask>    ``'flask._preserve_context'`` to `True` on the WSGI environment the\n <mask>    context will not pop itself at the end of the request.  This is used by\n <mask>    the :meth:`~flask.Flask.test_client` for example to implement the\n <mask>    deferred cleanup functionality.\n <mask> \n <mask>    You might find this helpful for unittests where you need the\n <mask>    information from the context local around for a little longer.  Make\n <mask>    sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n <mask>    that situation, otherwise your unittests will leak memory.\n <mask> \n <mask> Signals\n <mask> -------\n <mask> \n <mask> .. when modifying this list, also update the one in signals.rst\n <mask> \n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove =============================== =========================================\n``DEBUG``                       enable/disable debug mode\n``TESTING``                     enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``        explicitly enable or disable the\n                                propagation of exceptions.  If not set or\n                                explicitly set to `None` this is\n                                implicitly true if either `TESTING` or\n                                `DEBUG` is true.\n``SECRET_KEY``                  the secret key\n``SESSION_COOKIE_NAME``         the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``  the lifetime of a permanent session as\n                                :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``              enable/disable x-sendfile\n``LOGGER_NAME``                 the name of the logger\n``SERVER_NAME``                 the name of the server.  Required for\n                                subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``          If set to a value in bytes, Flask will\n                                reject incoming requests with a\n                                content length greater than this by\n                                returning a 413 status code.\n=============================== =========================================\n </s> add ================================= =========================================\n``DEBUG``                         enable/disable debug mode\n``TESTING``                       enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``          explicitly enable or disable the\n                                  propagation of exceptions.  If not set or\n                                  explicitly set to `None` this is\n                                  implicitly true if either `TESTING` or\n                                  `DEBUG` is true.\n``PRESERVE_CONTEXT_ON_EXCEPTION`` By default if the application is in\n                                  debug mode the request context is not\n                                  popped on exceptions to enable debuggers\n                                  to introspect the data.  This can be\n                                  disabled by this key.  You can also use\n                                  this setting to force-enable it for non\n                                  debug execution which might be useful to\n                                  debug production applications (but also\n                                  very risky).\n``SECRET_KEY``                    the secret key\n``SESSION_COOKIE_NAME``           the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``    the lifetime of a permanent session as\n                                  :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``                enable/disable x-sendfile\n``LOGGER_NAME``                   the name of the logger\n``SERVER_NAME``                   the name of the server.  Required for\n                                  subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``            If set to a value in bytes, Flask will\n                                  reject incoming requests with a\n                                  content length greater than this by\n                                  returning a 413 status code.\n================================= ========================================= </s> remove         .. versionchanged:: 0.4\n           The :meth:`after_request` functions are now called even if an\n           error handler took over request processing.  This ensures that\n           even if an exception happens database have the chance to\n           properly close the connection.\n\n </s> add  </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function.\n </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> remove class _RequestContext(object):\n </s> add class RequestContext(object): </s> remove \n.. _notes-on-proxies:\n\nNotes On Proxies\n----------------\n\nSome of the objects provided by Flask are proxies to other objects.  The\nreason behind this is that these proxies are shared between threads and\nthey have to dispatch to the actual object bound to a thread behind the\nscenes as necessary.\n\nMost of the time you don't have to care about that, but there are some\nexceptions where it is good to know that this object is an actual proxy:\n\n-   The proxy objects do not fake their inherited types, so if you want to\n    perform actual instance checks, you have to do that on the instance\n    that is being proxied (see `_get_current_object` below).\n-   if the object reference is important (so for example for sending\n    :ref:`signals`)\n\nIf you need to get access to the underlying object that is proxied, you\ncan use the :meth:`~werkzeug.local.LocalProxy._get_current_object` method::\n\n    app = current_app._get_current_object()\n    my_signal.send(app)\n </s> add  </s> remove         regardless of whether there was an exception or not.\n </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/api.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>    It is sent *before* the standard exception handling kicks in and even\n <mask>    in debug mode, where no exception handling happens.  The exception\n <mask>    itself is passed to the subscriber as `exception`.\n <mask> \n <mask> .. currentmodule:: None\n <mask> \n <mask> .. class:: flask.signals.Namespace\n <mask> \n <mask>    An alias for :class:`blinker.base.Namespace` if blinker is available,\n </s> Started work on new request dispatching.  Unittests not yet updated </s> add .. data:: flask.request_tearing_down\n   :noindex:\n\n   This signal is sent when the request is tearing down.  This is always\n   called, even if an exception is caused.  Currently functions listening\n   to this signal are called after the regular teardown handlers, but this\n   is not something you can rely on.\n\n   Example subscriber::\n\n        def close_db_connection(sender):\n            session.close()\n\n        from flask import request_tearing_down\n        request_tearing_down.connect(close_db_connection, app)\n </s> remove         .. versionchanged:: 0.4\n           The :meth:`after_request` functions are now called even if an\n           error handler took over request processing.  This ensures that\n           even if an exception happens database have the chance to\n           properly close the connection.\n\n </s> add  </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function.\n </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory.\n\n </s> add  </s> remove class _RequestContext(object):\n </s> add class RequestContext(object): </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/api.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace", "code_tokens": " <mask>       do nothing but will fail with a :exc:`RuntimeError` for all other\n <mask>       operations, including connecting.\n <mask> \n <mask> .. _blinker: http://pypi.python.org/pypi/blinker\n <mask> \n <mask> .. _notes-on-proxies:\n <mask> \n <mask> Notes On Proxies\n <mask> ----------------\n <mask> \n <mask> Some of the objects provided by Flask are proxies to other objects.  The\n <mask> reason behind this is that these proxies are shared between threads and\n <mask> they have to dispatch to the actual object bound to a thread behind the\n <mask> scenes as necessary.\n <mask> \n <mask> Most of the time you don't have to care about that, but there are some\n <mask> exceptions where it is good to know that this object is an actual proxy:\n <mask> \n <mask> -   The proxy objects do not fake their inherited types, so if you want to\n <mask>     perform actual instance checks, you have to do that on the instance\n <mask>     that is being proxied (see `_get_current_object` below).\n <mask> -   if the object reference is important (so for example for sending\n <mask>     :ref:`signals`)\n <mask> \n <mask> If you need to get access to the underlying object that is proxied, you\n <mask> can use the :meth:`~werkzeug.local.LocalProxy._get_current_object` method::\n <mask> \n <mask>     app = current_app._get_current_object()\n <mask>     my_signal.send(app)\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove         regardless of whether there was an exception or not.\n </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> add .. autoclass:: flask.ctx.RequestContext\n   :members:\n </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory.\n\n </s> add  </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see:\n </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove         .. versionchanged:: 0.4\n           The :meth:`after_request` functions are now called even if an\n           error handler took over request processing.  This ensures that\n           even if an exception happens database have the chance to\n           properly close the connection.\n\n </s> add  </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods:\n </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand:", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/api.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> The following configuration values are used internally by Flask:\n <mask> \n <mask> .. tabularcolumns:: |p{6.5cm}|p{8.5cm}|\n <mask> \n <mask> =============================== =========================================\n <mask> ``DEBUG``                       enable/disable debug mode\n <mask> ``TESTING``                     enable/disable testing mode\n <mask> ``PROPAGATE_EXCEPTIONS``        explicitly enable or disable the\n <mask>                                 propagation of exceptions.  If not set or\n <mask>                                 explicitly set to `None` this is\n <mask>                                 implicitly true if either `TESTING` or\n <mask>                                 `DEBUG` is true.\n <mask> ``SECRET_KEY``                  the secret key\n <mask> ``SESSION_COOKIE_NAME``         the name of the session cookie\n <mask> ``PERMANENT_SESSION_LIFETIME``  the lifetime of a permanent session as\n <mask>                                 :class:`datetime.timedelta` object.\n <mask> ``USE_X_SENDFILE``              enable/disable x-sendfile\n <mask> ``LOGGER_NAME``                 the name of the logger\n <mask> ``SERVER_NAME``                 the name of the server.  Required for\n <mask>                                 subdomain support (e.g.: ``'localhost'``)\n <mask> ``MAX_CONTENT_LENGTH``          If set to a value in bytes, Flask will\n <mask>                                 reject incoming requests with a\n <mask>                                 content length greater than this by\n <mask>                                 returning a 413 status code.\n <mask> =============================== =========================================\n <mask> \n <mask> .. admonition:: More on ``SERVER_NAME``\n <mask> \n <mask>    The ``SERVER_NAME`` key is used for the subdomain support.  Because\n <mask>    Flask cannot guess the subdomain part without the knowledge of the\n </s> Started work on new request dispatching.  Unittests not yet updated </s> add     #: If this is enabled and PROPAGATE_EXCEPTIONS is not changed from the\n    #: default it's implicitly enabled.\n    #: </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory.\n\n </s> add  </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug\n </s> remove \n.. _notes-on-proxies:\n\nNotes On Proxies\n----------------\n\nSome of the objects provided by Flask are proxies to other objects.  The\nreason behind this is that these proxies are shared between threads and\nthey have to dispatch to the actual object bound to a thread behind the\nscenes as necessary.\n\nMost of the time you don't have to care about that, but there are some\nexceptions where it is good to know that this object is an actual proxy:\n\n-   The proxy objects do not fake their inherited types, so if you want to\n    perform actual instance checks, you have to do that on the instance\n    that is being proxied (see `_get_current_object` below).\n-   if the object reference is important (so for example for sending\n    :ref:`signals`)\n\nIf you need to get access to the underlying object that is proxied, you\ncan use the :meth:`~werkzeug.local.LocalProxy._get_current_object` method::\n\n    app = current_app._get_current_object()\n    my_signal.send(app)\n </s> add  </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function.\n </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/config.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> .. versionadded:: 0.6\n <mask>    ``MAX_CONTENT_LENGTH``\n <mask> \n <mask> .. versionadded:: 0.7\n <mask>    ``PROPAGATE_EXCEPTIONS``\n <mask> \n <mask> Configuring from Files\n <mask> ----------------------\n <mask> \n <mask> Configuration becomes more useful if you can configure from a file, and\n </s> Started work on new request dispatching.  Unittests not yet updated </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug\n </s> remove =============================== =========================================\n``DEBUG``                       enable/disable debug mode\n``TESTING``                     enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``        explicitly enable or disable the\n                                propagation of exceptions.  If not set or\n                                explicitly set to `None` this is\n                                implicitly true if either `TESTING` or\n                                `DEBUG` is true.\n``SECRET_KEY``                  the secret key\n``SESSION_COOKIE_NAME``         the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``  the lifetime of a permanent session as\n                                :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``              enable/disable x-sendfile\n``LOGGER_NAME``                 the name of the logger\n``SERVER_NAME``                 the name of the server.  Required for\n                                subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``          If set to a value in bytes, Flask will\n                                reject incoming requests with a\n                                content length greater than this by\n                                returning a 413 status code.\n=============================== =========================================\n </s> add ================================= =========================================\n``DEBUG``                         enable/disable debug mode\n``TESTING``                       enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``          explicitly enable or disable the\n                                  propagation of exceptions.  If not set or\n                                  explicitly set to `None` this is\n                                  implicitly true if either `TESTING` or\n                                  `DEBUG` is true.\n``PRESERVE_CONTEXT_ON_EXCEPTION`` By default if the application is in\n                                  debug mode the request context is not\n                                  popped on exceptions to enable debuggers\n                                  to introspect the data.  This can be\n                                  disabled by this key.  You can also use\n                                  this setting to force-enable it for non\n                                  debug execution which might be useful to\n                                  debug production applications (but also\n                                  very risky).\n``SECRET_KEY``                    the secret key\n``SESSION_COOKIE_NAME``           the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``    the lifetime of a permanent session as\n                                  :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``                enable/disable x-sendfile\n``LOGGER_NAME``                   the name of the logger\n``SERVER_NAME``                   the name of the server.  Required for\n                                  subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``            If set to a value in bytes, Flask will\n                                  reject incoming requests with a\n                                  content length greater than this by\n                                  returning a 413 status code.\n================================= ========================================= </s> add .. data:: flask.request_tearing_down\n   :noindex:\n\n   This signal is sent when the request is tearing down.  This is always\n   called, even if an exception is caused.  Currently functions listening\n   to this signal are called after the regular teardown handlers, but this\n   is not something you can rely on.\n\n   Example subscriber::\n\n        def close_db_connection(sender):\n            session.close()\n\n        from flask import request_tearing_down\n        request_tearing_down.connect(close_db_connection, app)\n </s> remove         .. versionchanged:: 0.4\n           The :meth:`after_request` functions are now called even if an\n           error handler took over request processing.  This ensures that\n           even if an exception happens database have the chance to\n           properly close the connection.\n\n </s> add  </s> remove         return _RequestContext(self, environ)\n </s> add         return RequestContext(self, environ) </s> add .. autoclass:: flask.ctx.RequestContext\n   :members:\n", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/config.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>    testing\n <mask>    errorhandling\n <mask>    config\n <mask>    signals\n <mask>    shell\n <mask>    patterns/index\n <mask>    deploying/index\n <mask>    becomingbig\n </s> Started work on new request dispatching.  Unittests not yet updated </s> add     #: If this is enabled and PROPAGATE_EXCEPTIONS is not changed from the\n    #: default it's implicitly enabled.\n    #: </s> remove      request_finished, got_request_exception\n </s> add      request_finished, got_request_exception, request_tearing_down </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods:\n </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand: </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context:\n </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`: </s> remove         call every as :meth:`teardown_request` decorated function.\n </s> add         call every as :meth:`teardown_request` decorated function.  This is\n        not actually called by the :class:`Flask` object itself but is always\n        triggered when the request context is popped.  That way we have a\n        tighter control over certain resources under testing environments. </s> remove >>> ctx = app.test_request_context('/?next=http://example.com/')\n </s> add >>> ctx = app.test_request_context()", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/contents.rst.inc"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> that these functions are not only there for interactive shell usage, but\n <mask> also for unittesting and other situations that require a faked request\n <mask> context.\n <mask> \n <mask> Diving into Context Locals\n <mask> --------------------------\n <mask> \n <mask> Say you have a utility function that returns the URL the user should be\n <mask> redirected to.  Imagine it would always redirect to the URL's ``next``\n <mask> parameter or the HTTP referrer or the index page::\n <mask> \n <mask>     from flask import request, url_for\n <mask> \n <mask>     def redirect_url():\n <mask>         return request.args.get('next') or \\\n <mask>                request.referrer or \\\n <mask>                url_for('index')\n <mask> \n <mask> As you can see, it accesses the request object.  If you try to run this\n <mask> from a plain Python shell, this is the exception you will see:\n <mask> \n <mask> >>> redirect_url()\n <mask> Traceback (most recent call last):\n <mask>   File \"<stdin>\", line 1, in <module>\n <mask> AttributeError: 'NoneType' object has no attribute 'request'\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request'\n </s> add Creating a Request Context\n-------------------------- </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request'\n\n </s> add  </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context:\n </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`: </s> remove From that point onwards you can work with the request object:\n\n>>> redirect_url()\nu'http://example.com/'\n\nUntil you call `pop`:\n </s> add From that point onwards you can work with the request object until you\ncall `pop`: </s> remove         regardless of whether there was an exception or not.\n </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> remove \n.. _notes-on-proxies:\n\nNotes On Proxies\n----------------\n\nSome of the objects provided by Flask are proxies to other objects.  The\nreason behind this is that these proxies are shared between threads and\nthey have to dispatch to the actual object bound to a thread behind the\nscenes as necessary.\n\nMost of the time you don't have to care about that, but there are some\nexceptions where it is good to know that this object is an actual proxy:\n\n-   The proxy objects do not fake their inherited types, so if you want to\n    perform actual instance checks, you have to do that on the instance\n    that is being proxied (see `_get_current_object` below).\n-   if the object reference is important (so for example for sending\n    :ref:`signals`)\n\nIf you need to get access to the underlying object that is proxied, you\ncan use the :meth:`~werkzeug.local.LocalProxy._get_current_object` method::\n\n    app = current_app._get_current_object()\n    my_signal.send(app)\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep replace replace replace replace keep replace replace replace replace keep keep keep", "code_tokens": " <mask> \n <mask> >>> redirect_url()\n <mask> Traceback (most recent call last):\n <mask>   File \"<stdin>\", line 1, in <module>\n <mask> AttributeError: 'NoneType' object has no attribute 'request'\n <mask> \n <mask> That makes a lot of sense because we currently do not have a request we\n <mask> could access.  So we have to make a request and bind it to the current\n <mask> context.  The :attr:`~flask.Flask.test_request_context` method can create\n <mask> us a request context:\n <mask> \n <mask> >>> ctx = app.test_request_context('/?next=http://example.com/')\n <mask> \n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove >>> ctx = app.test_request_context('/?next=http://example.com/')\n </s> add >>> ctx = app.test_request_context() </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request'\n\n </s> add  </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see:\n </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove From that point onwards you can work with the request object:\n\n>>> redirect_url()\nu'http://example.com/'\n\nUntil you call `pop`:\n </s> add From that point onwards you can work with the request object until you\ncall `pop`: </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods:\n </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand:", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep replace keep replace replace replace keep", "code_tokens": " <mask> us a request context:\n <mask> \n <mask> >>> ctx = app.test_request_context('/?next=http://example.com/')\n <mask> \n <mask> This context can be used in two ways.  Either with the `with` statement\n <mask> (which unfortunately is not very handy for shell sessions).  The\n <mask> alternative way is to call the `push` and `pop` methods:\n <mask> \n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context:\n </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`: </s> remove From that point onwards you can work with the request object:\n\n>>> redirect_url()\nu'http://example.com/'\n\nUntil you call `pop`:\n </s> add From that point onwards you can work with the request object until you\ncall `pop`: </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block.\n </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block. </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request'\n </s> add Creating a Request Context\n-------------------------- </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory.\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> alternative way is to call the `push` and `pop` methods:\n <mask> \n <mask> >>> ctx.push()\n <mask> \n <mask> From that point onwards you can work with the request object:\n <mask> \n <mask> >>> redirect_url()\n <mask> u'http://example.com/'\n <mask> \n <mask> Until you call `pop`:\n <mask> \n <mask> >>> ctx.pop()\n <mask> >>> redirect_url()\n <mask> Traceback (most recent call last):\n <mask>   File \"<stdin>\", line 1, in <module>\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request'\n\n </s> add  </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods:\n </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand: </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request'\n </s> add Creating a Request Context\n-------------------------- </s> remove >>> ctx = app.test_request_context('/?next=http://example.com/')\n </s> add >>> ctx = app.test_request_context() </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see:\n </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context:\n </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`:", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Until you call `pop`:\n <mask> \n <mask> >>> ctx.pop()\n <mask> >>> redirect_url()\n <mask> Traceback (most recent call last):\n <mask>   File \"<stdin>\", line 1, in <module>\n <mask> AttributeError: 'NoneType' object has no attribute 'request'\n <mask> \n <mask> \n <mask> Firing Before/After Request\n <mask> ---------------------------\n <mask> \n <mask> By just creating a request context, you still don't have run the code that\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove From that point onwards you can work with the request object:\n\n>>> redirect_url()\nu'http://example.com/'\n\nUntil you call `pop`:\n </s> add From that point onwards you can work with the request object until you\ncall `pop`: </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request'\n </s> add Creating a Request Context\n-------------------------- </s> remove is normally run before a request.  This probably results in your database\nbeing unavailable, the current user not being stored on the\n </s> add is normally run before a request.  This might result in your database\nbeing unavailable if you are connecting to the database in a\nbefore-request callback or the current user not being stored on the </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see:\n </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context:\n </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`: </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods:\n </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand:", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> Firing Before/After Request\n <mask> ---------------------------\n <mask> \n <mask> By just creating a request context, you still don't have run the code that\n <mask> is normally run before a request.  This probably results in your database\n <mask> being unavailable, the current user not being stored on the\n <mask> :data:`~flask.g` object etc.\n <mask> \n <mask> This however can easily be done yourself.  Just call\n <mask> :meth:`~flask.Flask.preprocess_request`:\n <mask> \n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request'\n\n </s> add  </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request'\n </s> add Creating a Request Context\n-------------------------- </s> remove \n.. _notes-on-proxies:\n\nNotes On Proxies\n----------------\n\nSome of the objects provided by Flask are proxies to other objects.  The\nreason behind this is that these proxies are shared between threads and\nthey have to dispatch to the actual object bound to a thread behind the\nscenes as necessary.\n\nMost of the time you don't have to care about that, but there are some\nexceptions where it is good to know that this object is an actual proxy:\n\n-   The proxy objects do not fake their inherited types, so if you want to\n    perform actual instance checks, you have to do that on the instance\n    that is being proxied (see `_get_current_object` below).\n-   if the object reference is important (so for example for sending\n    :ref:`signals`)\n\nIf you need to get access to the underlying object that is proxied, you\ncan use the :meth:`~werkzeug.local.LocalProxy._get_current_object` method::\n\n    app = current_app._get_current_object()\n    my_signal.send(app)\n </s> add  </s> remove         .. versionchanged:: 0.4\n           The :meth:`after_request` functions are now called even if an\n           error handler took over request processing.  This ensures that\n           even if an exception happens database have the chance to\n           properly close the connection.\n\n </s> add  </s> remove         regardless of whether there was an exception or not.\n </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see:\n </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> >>> app.process_response(app.response_class())\n <mask> <Response 0 bytes [200 OK]>\n <mask> >>> ctx.pop()\n <mask> \n <mask> \n <mask> Further Improving the Shell Experience\n <mask> --------------------------------------\n <mask> \n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove From that point onwards you can work with the request object:\n\n>>> redirect_url()\nu'http://example.com/'\n\nUntil you call `pop`:\n </s> add From that point onwards you can work with the request object until you\ncall `pop`: </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request'\n\n </s> add  </s> remove >>> ctx = app.test_request_context('/?next=http://example.com/')\n </s> add >>> ctx = app.test_request_context() </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods:\n </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand: </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request'\n </s> add Creating a Request Context\n-------------------------- </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context:\n </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`:", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep add keep", "code_tokens": " <mask>         from flask import got_request_exception\n <mask>         got_request_exception.connect(log_exception, app)\n <mask> \n <mask> .. _blinker: http://pypi.python.org/pypi/blinker\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove from .signals import request_started, request_finished, got_request_exception\n </s> add from .signals import request_started, request_finished, got_request_exception, \\\n    request_tearing_down </s> remove      request_finished, got_request_exception\n </s> add      request_finished, got_request_exception, request_tearing_down </s> remove from .ctx import _RequestContext\n </s> add from .ctx import RequestContext </s> remove \n.. _notes-on-proxies:\n\nNotes On Proxies\n----------------\n\nSome of the objects provided by Flask are proxies to other objects.  The\nreason behind this is that these proxies are shared between threads and\nthey have to dispatch to the actual object bound to a thread behind the\nscenes as necessary.\n\nMost of the time you don't have to care about that, but there are some\nexceptions where it is good to know that this object is an actual proxy:\n\n-   The proxy objects do not fake their inherited types, so if you want to\n    perform actual instance checks, you have to do that on the instance\n    that is being proxied (see `_get_current_object` below).\n-   if the object reference is important (so for example for sending\n    :ref:`signals`)\n\nIf you need to get access to the underlying object that is proxied, you\ncan use the :meth:`~werkzeug.local.LocalProxy._get_current_object` method::\n\n    app = current_app._get_current_object()\n    my_signal.send(app)\n </s> add  </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see:\n </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove    ``PROPAGATE_EXCEPTIONS``\n </s> add    ``PROPAGATE_EXCEPTIONS``, ``PRESERVE_CONTEXT_ON_EXCEPTION``", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/signals.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> from .session import Session\n <mask> \n <mask> # the signals\n <mask> from .signals import signals_available, template_rendered, request_started, \\\n <mask>      request_finished, got_request_exception\n <mask> \n <mask> # only import json if it's available\n <mask> if json_available:\n <mask>     from .helpers import json\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove from .signals import request_started, request_finished, got_request_exception\n </s> add from .signals import request_started, request_finished, got_request_exception, \\\n    request_tearing_down </s> remove from .ctx import _RequestContext\n </s> add from .ctx import RequestContext </s> add .. data:: flask.request_tearing_down\n   :noindex:\n\n   This signal is sent when the request is tearing down.  This is always\n   called, even if an exception is caused.  Currently functions listening\n   to this signal are called after the regular teardown handlers, but this\n   is not something you can rely on.\n\n   Example subscriber::\n\n        def close_db_connection(sender):\n            session.close()\n\n        from flask import request_tearing_down\n        request_tearing_down.connect(close_db_connection, app)\n </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see:\n </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove            (tb is None or not self.app.debug):\n </s> add            (tb is None or not self.app.preserve_context_on_exception): </s> add request_tearing_down = _signals.signal('request-tearing-down')", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from .helpers import _PackageBoundObject, url_for, get_flashed_messages, \\\n <mask>     _tojson_filter, _endpoint_from_view_func\n <mask> from .wrappers import Request, Response\n <mask> from .config import ConfigAttribute, Config\n <mask> from .ctx import _RequestContext\n <mask> from .globals import _request_ctx_stack, request\n <mask> from .session import Session, _NullSession\n <mask> from .module import _ModuleSetupState\n <mask> from .templating import _DispatchingJinjaLoader, \\\n <mask>     _default_template_ctx_processor\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove from .signals import request_started, request_finished, got_request_exception\n </s> add from .signals import request_started, request_finished, got_request_exception, \\\n    request_tearing_down </s> remove      request_finished, got_request_exception\n </s> add      request_finished, got_request_exception, request_tearing_down </s> add .. data:: flask.request_tearing_down\n   :noindex:\n\n   This signal is sent when the request is tearing down.  This is always\n   called, even if an exception is caused.  Currently functions listening\n   to this signal are called after the regular teardown handlers, but this\n   is not something you can rely on.\n\n   Example subscriber::\n\n        def close_db_connection(sender):\n            session.close()\n\n        from flask import request_tearing_down\n        request_tearing_down.connect(close_db_connection, app)\n </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see:\n </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove    ``PROPAGATE_EXCEPTIONS``\n </s> add    ``PROPAGATE_EXCEPTIONS``, ``PRESERVE_CONTEXT_ON_EXCEPTION`` </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block.\n </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from .session import Session, _NullSession\n <mask> from .module import _ModuleSetupState\n <mask> from .templating import _DispatchingJinjaLoader, \\\n <mask>     _default_template_ctx_processor\n <mask> from .signals import request_started, request_finished, got_request_exception\n <mask> \n <mask> # a lock used for logger initialization\n <mask> _logger_lock = Lock()\n <mask> \n <mask> \n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove from .ctx import _RequestContext\n </s> add from .ctx import RequestContext </s> remove      request_finished, got_request_exception\n </s> add      request_finished, got_request_exception, request_tearing_down </s> add .. data:: flask.request_tearing_down\n   :noindex:\n\n   This signal is sent when the request is tearing down.  This is always\n   called, even if an exception is caused.  Currently functions listening\n   to this signal are called after the regular teardown handlers, but this\n   is not something you can rely on.\n\n   Example subscriber::\n\n        def close_db_connection(sender):\n            session.close()\n\n        from flask import request_tearing_down\n        request_tearing_down.connect(close_db_connection, app)\n </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see:\n </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block.\n </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block. </s> add         request_tearing_down.send(self)", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     #: additional runtime cost which should not be enabled by default.\n <mask>     #:\n <mask>     #: This attribute can also be configured from the config with the\n <mask>     #: `TESTING` configuration key.  Defaults to `False`.\n <mask>     testing = ConfigAttribute('TESTING')\n <mask> \n <mask>     #: If a secret key is set, cryptographic components can use this to\n <mask>     #: sign cookies and other things.  Set this to a complex random value\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove =============================== =========================================\n``DEBUG``                       enable/disable debug mode\n``TESTING``                     enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``        explicitly enable or disable the\n                                propagation of exceptions.  If not set or\n                                explicitly set to `None` this is\n                                implicitly true if either `TESTING` or\n                                `DEBUG` is true.\n``SECRET_KEY``                  the secret key\n``SESSION_COOKIE_NAME``         the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``  the lifetime of a permanent session as\n                                :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``              enable/disable x-sendfile\n``LOGGER_NAME``                 the name of the logger\n``SERVER_NAME``                 the name of the server.  Required for\n                                subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``          If set to a value in bytes, Flask will\n                                reject incoming requests with a\n                                content length greater than this by\n                                returning a 413 status code.\n=============================== =========================================\n </s> add ================================= =========================================\n``DEBUG``                         enable/disable debug mode\n``TESTING``                       enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``          explicitly enable or disable the\n                                  propagation of exceptions.  If not set or\n                                  explicitly set to `None` this is\n                                  implicitly true if either `TESTING` or\n                                  `DEBUG` is true.\n``PRESERVE_CONTEXT_ON_EXCEPTION`` By default if the application is in\n                                  debug mode the request context is not\n                                  popped on exceptions to enable debuggers\n                                  to introspect the data.  This can be\n                                  disabled by this key.  You can also use\n                                  this setting to force-enable it for non\n                                  debug execution which might be useful to\n                                  debug production applications (but also\n                                  very risky).\n``SECRET_KEY``                    the secret key\n``SESSION_COOKIE_NAME``           the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``    the lifetime of a permanent session as\n                                  :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``                enable/disable x-sendfile\n``LOGGER_NAME``                   the name of the logger\n``SERVER_NAME``                   the name of the server.  Required for\n                                  subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``            If set to a value in bytes, Flask will\n                                  reject incoming requests with a\n                                  content length greater than this by\n                                  returning a 413 status code.\n================================= ========================================= </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug\n </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see:\n </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods:\n </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand: </s> remove \n.. _notes-on-proxies:\n\nNotes On Proxies\n----------------\n\nSome of the objects provided by Flask are proxies to other objects.  The\nreason behind this is that these proxies are shared between threads and\nthey have to dispatch to the actual object bound to a thread behind the\nscenes as necessary.\n\nMost of the time you don't have to care about that, but there are some\nexceptions where it is good to know that this object is an actual proxy:\n\n-   The proxy objects do not fake their inherited types, so if you want to\n    perform actual instance checks, you have to do that on the instance\n    that is being proxied (see `_get_current_object` below).\n-   if the object reference is important (so for example for sending\n    :ref:`signals`)\n\nIf you need to get access to the underlying object that is proxied, you\ncan use the :meth:`~werkzeug.local.LocalProxy._get_current_object` method::\n\n    app = current_app._get_current_object()\n    my_signal.send(app)\n </s> add  </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context:\n </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`:", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         'DEBUG':                                False,\n <mask>         'TESTING':                              False,\n <mask>         'PROPAGATE_EXCEPTIONS':                 None,\n <mask>         'SECRET_KEY':                           None,\n <mask>         'SESSION_COOKIE_NAME':                  'session',\n <mask>         'PERMANENT_SESSION_LIFETIME':           timedelta(days=31),\n <mask>         'USE_X_SENDFILE':                       False,\n <mask>         'LOGGER_NAME':                          None,\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove         app.debug = True\n </s> add  </s> remove from .signals import request_started, request_finished, got_request_exception\n </s> add from .signals import request_started, request_finished, got_request_exception, \\\n    request_tearing_down </s> remove from .ctx import _RequestContext\n </s> add from .ctx import RequestContext </s> remove      request_finished, got_request_exception\n </s> add      request_finished, got_request_exception, request_tearing_down </s> add .. data:: flask.request_tearing_down\n   :noindex:\n\n   This signal is sent when the request is tearing down.  This is always\n   called, even if an exception is caused.  Currently functions listening\n   to this signal are called after the regular teardown handlers, but this\n   is not something you can rely on.\n\n   Example subscriber::\n\n        def close_db_connection(sender):\n            session.close()\n\n        from flask import request_tearing_down\n        request_tearing_down.connect(close_db_connection, app)\n </s> add The functions registered as :meth:`~flask.Flask.teardown_request` are\nautomatically called when the context is popped.  So this is the perfect\nplace to automatically tear down resources that were needed by the request\ncontext (such as database connections).\n", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>         if rv is not None:\n <mask>             return rv\n <mask>         return self.testing or self.debug\n <mask> \n <mask>     @property\n <mask>     def logger(self):\n <mask>         \"\"\"A :class:`logging.Logger` object for this application.  The\n <mask>         default configuration is to log to stderr if the application is\n <mask>         in debug mode.  This logger can be used to (surprise) log messages.\n </s> Started work on new request dispatching.  Unittests not yet updated </s> add         request_tearing_down.send(self) </s> remove             if req.routing_exception is not None:\n                raise req.routing_exception\n            rule = req.url_rule\n            # if we provide automatic options for this URL and the\n            # request came with the OPTIONS method, reply automatically\n            if getattr(rule, 'provide_automatic_options', False) \\\n               and req.method == 'OPTIONS':\n                return self.make_default_options_response()\n            # otherwise dispatch to the handler for that endpoint\n            return self.view_functions[rule.endpoint](**req.view_args)\n </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request() </s> remove =============================== =========================================\n``DEBUG``                       enable/disable debug mode\n``TESTING``                     enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``        explicitly enable or disable the\n                                propagation of exceptions.  If not set or\n                                explicitly set to `None` this is\n                                implicitly true if either `TESTING` or\n                                `DEBUG` is true.\n``SECRET_KEY``                  the secret key\n``SESSION_COOKIE_NAME``         the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``  the lifetime of a permanent session as\n                                :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``              enable/disable x-sendfile\n``LOGGER_NAME``                 the name of the logger\n``SERVER_NAME``                 the name of the server.  Required for\n                                subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``          If set to a value in bytes, Flask will\n                                reject incoming requests with a\n                                content length greater than this by\n                                returning a 413 status code.\n=============================== =========================================\n </s> add ================================= =========================================\n``DEBUG``                         enable/disable debug mode\n``TESTING``                       enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``          explicitly enable or disable the\n                                  propagation of exceptions.  If not set or\n                                  explicitly set to `None` this is\n                                  implicitly true if either `TESTING` or\n                                  `DEBUG` is true.\n``PRESERVE_CONTEXT_ON_EXCEPTION`` By default if the application is in\n                                  debug mode the request context is not\n                                  popped on exceptions to enable debuggers\n                                  to introspect the data.  This can be\n                                  disabled by this key.  You can also use\n                                  this setting to force-enable it for non\n                                  debug execution which might be useful to\n                                  debug production applications (but also\n                                  very risky).\n``SECRET_KEY``                    the secret key\n``SESSION_COOKIE_NAME``           the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``    the lifetime of a permanent session as\n                                  :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``                enable/disable x-sendfile\n``LOGGER_NAME``                   the name of the logger\n``SERVER_NAME``                   the name of the server.  Required for\n                                  subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``            If set to a value in bytes, Flask will\n                                  reject incoming requests with a\n                                  content length greater than this by\n                                  returning a 413 status code.\n================================= ========================================= </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block.\n </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block. </s> remove             return self.handle_http_exception(e)\n </s> add             rv = self.handle_http_exception(e)\n        response = self.make_response(rv)\n        response = self.process_response(response)\n        request_finished.send(self, response=response)\n        return response </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory.\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.before_request_funcs.setdefault(None, []).append(f)\n <mask>         return f\n <mask> \n <mask>     def after_request(self, f):\n <mask>         \"\"\"Register a function to be run after each request. Your function\n <mask>         must take one parameter, a :attr:`response_class` object and return\n <mask>         a new response object or the same (see :meth:`process_response`).\n <mask>         \"\"\"\n <mask>         self.after_request_funcs.setdefault(None, []).append(f)\n <mask>         return f\n </s> Started work on new request dispatching.  Unittests not yet updated </s> add         As of Flask 0.7 this function might not be executed at the end of the\n        request in case an unhandled exception ocurred. </s> remove         regardless of whether there was an exception or not.\n </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> remove         return _RequestContext(self, environ)\n </s> add         return RequestContext(self, environ) </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function.\n </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`. </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see:\n </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         \"\"\"Register a function to be run after each request.  Your function\n <mask>         must take one parameter, a :attr:`response_class` object and return\n <mask>         a new response object or the same (see :meth:`process_response`).\n <mask>         \"\"\"\n <mask>         self.after_request_funcs.setdefault(None, []).append(f)\n <mask>         return f\n <mask> \n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove         \"\"\"Register a function to be run after each request. Your function\n </s> add         \"\"\"Register a function to be run after each request.  Your function </s> remove         regardless of whether there was an exception or not.\n </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> remove         return _RequestContext(self, environ)\n </s> add         return RequestContext(self, environ) </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function.\n </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`. </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see:\n </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         return f\n <mask> \n <mask>     def teardown_request(self, f):\n <mask>         \"\"\"Register a function to be run at the end of each request,\n <mask>         regardless of whether there was an exception or not.\n <mask>         \"\"\"\n <mask>         self.teardown_request_funcs.setdefault(None, []).append(f)\n <mask>         return f\n <mask> \n <mask>     def context_processor(self, f):\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove         \"\"\"Register a function to be run after each request. Your function\n </s> add         \"\"\"Register a function to be run after each request.  Your function </s> add         As of Flask 0.7 this function might not be executed at the end of the\n        request in case an unhandled exception ocurred. </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function.\n </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> remove         .. versionchanged:: 0.4\n           The :meth:`after_request` functions are now called even if an\n           error handler took over request processing.  This ensures that\n           even if an exception happens database have the chance to\n           properly close the connection.\n\n </s> add  </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see:\n </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Does the request dispatching.  Matches the URL and returns the\n <mask>         return value of the view or error handler.  This does not have to\n <mask>         be a response object.  In order to convert the return value to a\n <mask>         proper response object, call :func:`make_response`.\n <mask>         \"\"\"\n <mask>         req = _request_ctx_stack.top.request\n <mask>         if req.routing_exception is not None:\n <mask>             raise req.routing_exception\n <mask>         rule = req.url_rule\n <mask>         # if we provide automatic options for this URL and the\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove             if req.routing_exception is not None:\n                raise req.routing_exception\n            rule = req.url_rule\n            # if we provide automatic options for this URL and the\n            # request came with the OPTIONS method, reply automatically\n            if getattr(rule, 'provide_automatic_options', False) \\\n               and req.method == 'OPTIONS':\n                return self.make_default_options_response()\n            # otherwise dispatch to the handler for that endpoint\n            return self.view_functions[rule.endpoint](**req.view_args)\n </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request() </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug\n </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see:\n </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove class _RequestContext(object):\n </s> add class RequestContext(object): </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function.\n </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> remove =============================== =========================================\n``DEBUG``                       enable/disable debug mode\n``TESTING``                     enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``        explicitly enable or disable the\n                                propagation of exceptions.  If not set or\n                                explicitly set to `None` this is\n                                implicitly true if either `TESTING` or\n                                `DEBUG` is true.\n``SECRET_KEY``                  the secret key\n``SESSION_COOKIE_NAME``         the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``  the lifetime of a permanent session as\n                                :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``              enable/disable x-sendfile\n``LOGGER_NAME``                 the name of the logger\n``SERVER_NAME``                 the name of the server.  Required for\n                                subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``          If set to a value in bytes, Flask will\n                                reject incoming requests with a\n                                content length greater than this by\n                                returning a 413 status code.\n=============================== =========================================\n </s> add ================================= =========================================\n``DEBUG``                         enable/disable debug mode\n``TESTING``                       enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``          explicitly enable or disable the\n                                  propagation of exceptions.  If not set or\n                                  explicitly set to `None` this is\n                                  implicitly true if either `TESTING` or\n                                  `DEBUG` is true.\n``PRESERVE_CONTEXT_ON_EXCEPTION`` By default if the application is in\n                                  debug mode the request context is not\n                                  popped on exceptions to enable debuggers\n                                  to introspect the data.  This can be\n                                  disabled by this key.  You can also use\n                                  this setting to force-enable it for non\n                                  debug execution which might be useful to\n                                  debug production applications (but also\n                                  very risky).\n``SECRET_KEY``                    the secret key\n``SESSION_COOKIE_NAME``           the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``    the lifetime of a permanent session as\n                                  :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``                enable/disable x-sendfile\n``LOGGER_NAME``                   the name of the logger\n``SERVER_NAME``                   the name of the server.  Required for\n                                  subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``            If set to a value in bytes, Flask will\n                                  reject incoming requests with a\n                                  content length greater than this by\n                                  returning a 413 status code.\n================================= =========================================", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace replace replace replace replace keep replace keep keep", "code_tokens": " <mask>         req = _request_ctx_stack.top.request\n <mask>         try:\n <mask>             if req.routing_exception is not None:\n <mask>                 raise req.routing_exception\n <mask>             rule = req.url_rule\n <mask>             # if we provide automatic options for this URL and the\n <mask>             # request came with the OPTIONS method, reply automatically\n <mask>             if getattr(rule, 'provide_automatic_options', False) \\\n <mask>                and req.method == 'OPTIONS':\n <mask>                 return self.make_default_options_response()\n <mask>             # otherwise dispatch to the handler for that endpoint\n <mask>             return self.view_functions[rule.endpoint](**req.view_args)\n <mask>         except HTTPException, e:\n <mask>             return self.handle_http_exception(e)\n <mask> \n <mask>     def make_default_options_response(self):\n </s> Started work on new request dispatching.  Unittests not yet updated </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`. </s> remove         \"\"\"Binds the request context.\"\"\"\n </s> add         \"\"\"Binds the request context to the current context.\"\"\" </s> remove            (tb is None or not self.app.debug):\n </s> add            (tb is None or not self.app.preserve_context_on_exception): </s> remove                 request_started.send(self)\n                rv = self.preprocess_request()\n                if rv is None:\n                    rv = self.dispatch_request()\n                response = self.make_response(rv)\n </s> add                 response = self.full_dispatch_request() </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory.\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         return response\n <mask> \n <mask>     def do_teardown_request(self):\n <mask>         \"\"\"Called after the actual request dispatching and will\n <mask>         call every as :meth:`teardown_request` decorated function.\n <mask>         \"\"\"\n <mask>         funcs = reversed(self.teardown_request_funcs.get(None, ()))\n <mask>         mod = request.module\n <mask>         if mod and mod in self.teardown_request_funcs:\n <mask>             funcs = chain(funcs, reversed(self.teardown_request_funcs[mod]))\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function.\n </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> remove         regardless of whether there was an exception or not.\n </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> remove         \"\"\"Register a function to be run after each request. Your function\n </s> add         \"\"\"Register a function to be run after each request.  Your function </s> add         As of Flask 0.7 this function might not be executed at the end of the\n        request in case an unhandled exception ocurred. </s> remove         \"\"\"Pops the request context.\"\"\"\n </s> add         \"\"\"Pops the request context and unbinds it by doing that.  This will\n        also trigger the execution of functions registered by the\n        :meth:`~flask.Flask.teardown_request` decorator.\n        \"\"\"\n        self.app.do_teardown_request() </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>             if rv is not None:\n <mask>                 return rv\n <mask> \n <mask>     def request_context(self, environ):\n <mask>         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n <mask>         environment and binds it to the current context.  This must be used in\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block.\n </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block. </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug\n </s> remove         return _RequestContext(self, environ)\n </s> add         return RequestContext(self, environ) </s> remove             if req.routing_exception is not None:\n                raise req.routing_exception\n            rule = req.url_rule\n            # if we provide automatic options for this URL and the\n            # request came with the OPTIONS method, reply automatically\n            if getattr(rule, 'provide_automatic_options', False) \\\n               and req.method == 'OPTIONS':\n                return self.make_default_options_response()\n            # otherwise dispatch to the handler for that endpoint\n            return self.view_functions[rule.endpoint](**req.view_args)\n </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request() </s> remove >>> ctx = app.test_request_context('/?next=http://example.com/')\n </s> add >>> ctx = app.test_request_context() </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context:\n </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`:", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             if rv is not None:\n <mask>                 return rv\n <mask> \n <mask>     def request_context(self, environ):\n <mask>         \"\"\"Creates a request context from the given environment and binds\n <mask>         it to the current context.  This must be used in combination with\n <mask>         the `with` statement because the request is only bound to the\n <mask>         current context for the duration of the `with` block.\n <mask> \n <mask>         Example usage::\n <mask> \n <mask>             with app.request_context(environ):\n <mask>                 do_something_with(request)\n </s> Started work on new request dispatching.  Unittests not yet updated </s> add         request_tearing_down.send(self) </s> remove >>> ctx = app.test_request_context('/?next=http://example.com/')\n </s> add >>> ctx = app.test_request_context() </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context:\n </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`: </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods:\n </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand: </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug\n </s> remove             if req.routing_exception is not None:\n                raise req.routing_exception\n            rule = req.url_rule\n            # if we provide automatic options for this URL and the\n            # request came with the OPTIONS method, reply automatically\n            if getattr(rule, 'provide_automatic_options', False) \\\n               and req.method == 'OPTIONS':\n                return self.make_default_options_response()\n            # otherwise dispatch to the handler for that endpoint\n            return self.view_functions[rule.endpoint](**req.view_args)\n </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request()", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>            is now passed the ctx object.\n <mask> \n <mask>         :param environ: a WSGI environment\n <mask>         \"\"\"\n <mask>         return _RequestContext(self, environ)\n <mask> \n <mask>     def test_request_context(self, *args, **kwargs):\n <mask>         \"\"\"Creates a WSGI environment from the given values (see\n <mask>         :func:`werkzeug.create_environ` for more information, this\n <mask>         function accepts the same arguments).\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block.\n </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block. </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function.\n </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> add         request_tearing_down.send(self) </s> add         As of Flask 0.7 this function might not be executed at the end of the\n        request in case an unhandled exception ocurred. </s> remove class _RequestContext(object):\n </s> add class RequestContext(object): </s> remove         \"\"\"Register a function to be run after each request. Your function\n </s> add         \"\"\"Register a function to be run after each request.  Your function", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace keep replace replace replace keep keep", "code_tokens": " <mask>         can continue to call methods on it.\n <mask> \n <mask>         .. versionchanged:: 0.4\n <mask>            The :meth:`after_request` functions are now called even if an\n <mask>            error handler took over request processing.  This ensures that\n <mask>            even if an exception happens database have the chance to\n <mask>            properly close the connection.\n <mask> \n <mask>         .. versionchanged:: 0.7\n <mask>            The :meth:`teardown_request` functions get called at the very end of\n <mask>            processing the request. If an exception was thrown, it gets passed to\n <mask>            each teardown_request function.\n <mask> \n <mask>         :param environ: a WSGI environment\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove         regardless of whether there was an exception or not.\n </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> add .. data:: request_tearing_down\n\n   This signal is sent when the application is tearing down the request.\n   This is always called, even if an error happened.  No arguments are\n   provided.\n </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory.\n\n </s> add  </s> add .. data:: flask.request_tearing_down\n   :noindex:\n\n   This signal is sent when the request is tearing down.  This is always\n   called, even if an exception is caused.  Currently functions listening\n   to this signal are called after the regular teardown handlers, but this\n   is not something you can rely on.\n\n   Example subscriber::\n\n        def close_db_connection(sender):\n            session.close()\n\n        from flask import request_tearing_down\n        request_tearing_down.connect(close_db_connection, app)\n </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep replace replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>                                exception context to start the response\n <mask>         \"\"\"\n <mask>         with self.request_context(environ):\n <mask>             try:\n <mask>                 request_started.send(self)\n <mask>                 rv = self.preprocess_request()\n <mask>                 if rv is None:\n <mask>                     rv = self.dispatch_request()\n <mask>                 response = self.make_response(rv)\n <mask>             except Exception, e:\n <mask>                 response = self.make_response(self.handle_exception(e))\n <mask>             try:\n <mask>                 response = self.process_response(response)\n <mask>             except Exception, e:\n <mask>                 response = self.make_response(self.handle_exception(e))\n <mask>             finally:\n <mask>                 self.do_teardown_request()\n <mask>             request_finished.send(self, response=response)\n <mask>             return response(environ, start_response)\n <mask> \n <mask>     def __call__(self, environ, start_response):\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove             return self.handle_http_exception(e)\n </s> add             rv = self.handle_http_exception(e)\n        response = self.make_response(rv)\n        response = self.process_response(response)\n        request_finished.send(self, response=response)\n        return response </s> remove             if req.routing_exception is not None:\n                raise req.routing_exception\n            rule = req.url_rule\n            # if we provide automatic options for this URL and the\n            # request came with the OPTIONS method, reply automatically\n            if getattr(rule, 'provide_automatic_options', False) \\\n               and req.method == 'OPTIONS':\n                return self.make_default_options_response()\n            # otherwise dispatch to the handler for that endpoint\n            return self.view_functions[rule.endpoint](**req.view_args)\n </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request() </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug\n </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`. </s> remove         \"\"\"Binds the request context.\"\"\"\n </s> add         \"\"\"Binds the request context to the current context.\"\"\"", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     return _request_ctx_stack.top is not None\n <mask> \n <mask> \n <mask> class _RequestContext(object):\n <mask>     \"\"\"The request context contains all request relevant information.  It is\n <mask>     created at the beginning of the request and pushed to the\n <mask>     `_request_ctx_stack` and removed at the end of it.  It will create the\n <mask>     URL adapter and request object for the WSGI environment provided.\n <mask>     \"\"\"\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory.\n\n </s> add  </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function.\n </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> remove         regardless of whether there was an exception or not.\n </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block.\n </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block. </s> add         As of Flask 0.7 this function might not be executed at the end of the\n        request in case an unhandled exception ocurred. </s> add .. data:: request_tearing_down\n\n   This signal is sent when the application is tearing down the request.\n   This is always called, even if an error happened.  No arguments are\n   provided.\n", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         except HTTPException, e:\n <mask>             self.request.routing_exception = e\n <mask> \n <mask>     def push(self):\n <mask>         \"\"\"Binds the request context.\"\"\"\n <mask>         _request_ctx_stack.push(self)\n <mask> \n <mask>         # Open the session at the moment that the request context is\n <mask>         # available. This allows a custom open_session method to use the\n <mask>         # request context (e.g. flask-sqlalchemy).\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove             if req.routing_exception is not None:\n                raise req.routing_exception\n            rule = req.url_rule\n            # if we provide automatic options for this URL and the\n            # request came with the OPTIONS method, reply automatically\n            if getattr(rule, 'provide_automatic_options', False) \\\n               and req.method == 'OPTIONS':\n                return self.make_default_options_response()\n            # otherwise dispatch to the handler for that endpoint\n            return self.view_functions[rule.endpoint](**req.view_args)\n </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request() </s> remove             return self.handle_http_exception(e)\n </s> add             rv = self.handle_http_exception(e)\n        response = self.make_response(rv)\n        response = self.process_response(response)\n        request_finished.send(self, response=response)\n        return response </s> remove            (tb is None or not self.app.debug):\n </s> add            (tb is None or not self.app.preserve_context_on_exception): </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods:\n </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand: </s> remove         \"\"\"Pops the request context.\"\"\"\n </s> add         \"\"\"Pops the request context and unbinds it by doing that.  This will\n        also trigger the execution of functions registered by the\n        :meth:`~flask.Flask.teardown_request` decorator.\n        \"\"\"\n        self.app.do_teardown_request() </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory.\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if self.session is None:\n <mask>             self.session = _NullSession()\n <mask> \n <mask>     def pop(self):\n <mask>         \"\"\"Pops the request context.\"\"\"\n <mask>         _request_ctx_stack.pop()\n <mask> \n <mask>     def __enter__(self):\n <mask>         self.push()\n <mask>         return self\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove         \"\"\"Binds the request context.\"\"\"\n </s> add         \"\"\"Binds the request context to the current context.\"\"\" </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug\n </s> remove             if req.routing_exception is not None:\n                raise req.routing_exception\n            rule = req.url_rule\n            # if we provide automatic options for this URL and the\n            # request came with the OPTIONS method, reply automatically\n            if getattr(rule, 'provide_automatic_options', False) \\\n               and req.method == 'OPTIONS':\n                return self.make_default_options_response()\n            # otherwise dispatch to the handler for that endpoint\n            return self.view_functions[rule.endpoint](**req.view_args)\n </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request() </s> add         request_tearing_down.send(self) </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block.\n </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block. </s> remove         call every as :meth:`teardown_request` decorated function.\n </s> add         call every as :meth:`teardown_request` decorated function.  This is\n        not actually called by the :class:`Flask` object itself but is always\n        triggered when the request context is popped.  That way we have a\n        tighter control over certain resources under testing environments.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep", "code_tokens": " <mask>         # access the request object in the interactive shell.  Furthermore\n <mask>         # the context can be force kept alive for the test client.\n <mask>         # See flask.testing for how this works.\n <mask>         if not self.request.environ.get('flask._preserve_context') and \\\n <mask>            (tb is None or not self.app.debug):\n <mask>             self.pop()\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove             if req.routing_exception is not None:\n                raise req.routing_exception\n            rule = req.url_rule\n            # if we provide automatic options for this URL and the\n            # request came with the OPTIONS method, reply automatically\n            if getattr(rule, 'provide_automatic_options', False) \\\n               and req.method == 'OPTIONS':\n                return self.make_default_options_response()\n            # otherwise dispatch to the handler for that endpoint\n            return self.view_functions[rule.endpoint](**req.view_args)\n </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request() </s> remove         \"\"\"Binds the request context.\"\"\"\n </s> add         \"\"\"Binds the request context to the current context.\"\"\" </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory.\n\n </s> add  </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`. </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see:\n </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove class _RequestContext(object):\n </s> add class RequestContext(object):", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep add keep", "code_tokens": " <mask> # the API documentation in docs/api.rst as well as docs/signals.rst\n <mask> template_rendered = _signals.signal('template-rendered')\n <mask> request_started = _signals.signal('request-started')\n <mask> request_finished = _signals.signal('request-finished')\n <mask> got_request_exception = _signals.signal('got-request-exception')\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove         call every as :meth:`teardown_request` decorated function.\n </s> add         call every as :meth:`teardown_request` decorated function.  This is\n        not actually called by the :class:`Flask` object itself but is always\n        triggered when the request context is popped.  That way we have a\n        tighter control over certain resources under testing environments. </s> add The functions registered as :meth:`~flask.Flask.teardown_request` are\nautomatically called when the context is popped.  So this is the perfect\nplace to automatically tear down resources that were needed by the request\ncontext (such as database connections).\n </s> remove      request_finished, got_request_exception\n </s> add      request_finished, got_request_exception, request_tearing_down </s> remove from .signals import request_started, request_finished, got_request_exception\n </s> add from .signals import request_started, request_finished, got_request_exception, \\\n    request_tearing_down </s> add .. data:: request_tearing_down\n\n   This signal is sent when the application is tearing down the request.\n   This is always called, even if an error happened.  No arguments are\n   provided.\n </s> remove         \"\"\"Binds the request context.\"\"\"\n </s> add         \"\"\"Binds the request context to the current context.\"\"\"", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/signals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             t.join()\n <mask> \n <mask>     def test_max_content_length(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.debug = True\n <mask>         app.config['MAX_CONTENT_LENGTH'] = 64\n <mask>         @app.route('/accept', methods=['POST'])\n <mask>         def accept_file():\n <mask>             flask.request.form['myfile']\n <mask>             assert False\n </s> Started work on new request dispatching.  Unittests not yet updated </s> add         @app.before_request\n        def always_first():\n            flask.request.form['myfile']\n            assert False </s> remove             try:\n                response = self.process_response(response)\n            except Exception, e:\n                response = self.make_response(self.handle_exception(e))\n            finally:\n                self.do_teardown_request()\n            request_finished.send(self, response=response)\n </s> add  </s> remove         \"\"\"Pops the request context.\"\"\"\n </s> add         \"\"\"Pops the request context and unbinds it by doing that.  This will\n        also trigger the execution of functions registered by the\n        :meth:`~flask.Flask.teardown_request` decorator.\n        \"\"\"\n        self.app.do_teardown_request() </s> remove             return self.handle_http_exception(e)\n </s> add             rv = self.handle_http_exception(e)\n        response = self.make_response(rv)\n        response = self.process_response(response)\n        request_finished.send(self, response=response)\n        return response </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug\n </s> remove         call every as :meth:`teardown_request` decorated function.\n </s> add         call every as :meth:`teardown_request` decorated function.  This is\n        not actually called by the :class:`Flask` object itself but is always\n        triggered when the request context is popped.  That way we have a\n        tighter control over certain resources under testing environments.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     def test_max_content_length(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.config['MAX_CONTENT_LENGTH'] = 64\n <mask>         @app.route('/accept', methods=['POST'])\n <mask>         def accept_file():\n <mask>             flask.request.form['myfile']\n <mask>             assert False\n <mask>         @app.errorhandler(413)\n <mask>         def catcher(error):\n </s> Started work on new request dispatching.  Unittests not yet updated </s> remove         app.debug = True\n </s> add  </s> remove         \"\"\"Pops the request context.\"\"\"\n </s> add         \"\"\"Pops the request context and unbinds it by doing that.  This will\n        also trigger the execution of functions registered by the\n        :meth:`~flask.Flask.teardown_request` decorator.\n        \"\"\"\n        self.app.do_teardown_request() </s> remove             try:\n                response = self.process_response(response)\n            except Exception, e:\n                response = self.make_response(self.handle_exception(e))\n            finally:\n                self.do_teardown_request()\n            request_finished.send(self, response=response)\n </s> add  </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug\n </s> remove             return self.handle_http_exception(e)\n </s> add             rv = self.handle_http_exception(e)\n        response = self.make_response(rv)\n        response = self.process_response(response)\n        request_finished.send(self, response=response)\n        return response </s> remove         \"\"\"Binds the request context.\"\"\"\n </s> add         \"\"\"Binds the request context to the current context.\"\"\"", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> FastCGI\n <mask> =======\n <mask> \n <mask> FastCGI is a deployment option on servers like `nginx`_, `lighttpd`_, and\n <mask> `cherokee`_; see :ref:`deploying-uwsgi` and :ref:`deploying-wsgi-standalone`\n <mask> for other options.  To use your WSGI application with any of them you will need\n <mask> a FastCGI server first.  The most popular one is `flup`_ which we will use for\n <mask> this guide.  Make sure to have it installed to follow along.\n <mask> \n <mask> .. admonition:: Watch Out\n <mask> \n <mask>    Please make sure in advance that any ``app.run()`` calls you might\n <mask>    have in your application file are inside an ``if __name__ ==\n </s> Fix broken cross-references; use :doc: tags where necessary </s> remove guide.  Make sure to have it installed to follow along.\n </s> add guide. Make sure to have it installed to follow along. </s> remove `cherokee`_; see :ref:`deploying-fastcgi` and :ref:`deploying-wsgi-standalone`\nfor other options.  To use your WSGI application with uWSGI protocol you will\nneed a uWSGI server first. uWSGI is both a protocol and an application server;\nthe application server can serve uWSGI, FastCGI, and HTTP protocols.\n </s> add `cherokee`_; see :doc:`fastcgi` and :doc:`wsgi-standalone` for other options.\nTo use your WSGI application with uWSGI protocol you will need a uWSGI server\nfirst. uWSGI is both a protocol and an application server; the application\nserver can serve uWSGI, FastCGI, and HTTP protocols. </s> remove since its smarter about that. It is used together with the ``--mount`` directive\nwhich will make requests to ``/yourapplication`` be directed to ``myapp:app``.\nIf your application is accessible at root level, you can use a single ``/``\ninstead of ``/yourapplication``. ``myapp`` refers to the name of the file of\nyour flask application (without extension) or the module which provides ``app``.\n``app`` is the callable inside of your application (usually the line reads\n``app = Flask(__name__)``.\n </s> add since it is smarter about that. It is used together with the ``--mount``\ndirective which will make requests to ``/yourapplication`` be directed to\n``myapp:app``. If your application is accessible at root level, you can use a\nsingle ``/`` instead of ``/yourapplication``. ``myapp`` refers to the name of\nthe file of your flask application (without extension) or the module which\nprovides ``app``. ``app`` is the callable inside of your application (usually\nthe line reads ``app = Flask(__name__)``. </s> remove For a more optimized setup, see :ref:`configuring uWSGI and NGINX <deploying-uwsgi>`.\n </s> add For a more optimized setup, see :doc:`configuring uWSGI and NGINX <uwsgi>`.", "html_url": "https://github.com/pallets/flask/commit/e771016a5bac3c08987907a2ec63385d58b81be0", "file_name": "docs/deploying/fastcgi.rst"}
{"docstring_tokens": "keep keep keep replace replace replace replace keep keep replace", "code_tokens": " <mask> =====\n <mask> \n <mask> uWSGI is a deployment option on servers like `nginx`_, `lighttpd`_, and\n <mask> `cherokee`_; see :ref:`deploying-fastcgi` and :ref:`deploying-wsgi-standalone`\n <mask> for other options.  To use your WSGI application with uWSGI protocol you will\n <mask> need a uWSGI server first. uWSGI is both a protocol and an application server;\n <mask> the application server can serve uWSGI, FastCGI, and HTTP protocols.\n <mask> \n <mask> The most popular uWSGI server is `uwsgi`_, which we will use for this\n <mask> guide.  Make sure to have it installed to follow along.\n </s> Fix broken cross-references; use :doc: tags where necessary </s> remove `cherokee`_; see :ref:`deploying-uwsgi` and :ref:`deploying-wsgi-standalone`\nfor other options.  To use your WSGI application with any of them you will need\na FastCGI server first.  The most popular one is `flup`_ which we will use for\nthis guide.  Make sure to have it installed to follow along.\n </s> add `cherokee`_; see :doc:`uwsgi` and :doc:`wsgi-standalone` for other options. To\nuse your WSGI application with any of them you will need a FastCGI server first.\nThe most popular one is `flup`_ which we will use for this guide. Make sure to\nhave it installed to follow along. </s> remove since its smarter about that. It is used together with the ``--mount`` directive\nwhich will make requests to ``/yourapplication`` be directed to ``myapp:app``.\nIf your application is accessible at root level, you can use a single ``/``\ninstead of ``/yourapplication``. ``myapp`` refers to the name of the file of\nyour flask application (without extension) or the module which provides ``app``.\n``app`` is the callable inside of your application (usually the line reads\n``app = Flask(__name__)``.\n </s> add since it is smarter about that. It is used together with the ``--mount``\ndirective which will make requests to ``/yourapplication`` be directed to\n``myapp:app``. If your application is accessible at root level, you can use a\nsingle ``/`` instead of ``/yourapplication``. ``myapp`` refers to the name of\nthe file of your flask application (without extension) or the module which\nprovides ``app``. ``app`` is the callable inside of your application (usually\nthe line reads ``app = Flask(__name__)``. </s> remove For a more optimized setup, see :ref:`configuring uWSGI and NGINX <deploying-uwsgi>`.\n </s> add For a more optimized setup, see :doc:`configuring uWSGI and NGINX <uwsgi>`.", "html_url": "https://github.com/pallets/flask/commit/e771016a5bac3c08987907a2ec63385d58b81be0", "file_name": "docs/deploying/uwsgi.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     $ uwsgi -s /tmp/yourapplication.sock --manage-script-name --mount /yourapplication=myapp:app\n <mask> \n <mask> The ``--manage-script-name`` will move the handling of ``SCRIPT_NAME`` to uwsgi,\n <mask> since its smarter about that. It is used together with the ``--mount`` directive\n <mask> which will make requests to ``/yourapplication`` be directed to ``myapp:app``.\n <mask> If your application is accessible at root level, you can use a single ``/``\n <mask> instead of ``/yourapplication``. ``myapp`` refers to the name of the file of\n <mask> your flask application (without extension) or the module which provides ``app``.\n <mask> ``app`` is the callable inside of your application (usually the line reads\n <mask> ``app = Flask(__name__)``.\n <mask> \n <mask> If you want to deploy your flask application inside of a virtual environment,\n <mask> you need to also add ``--virtualenv /path/to/virtual/environment``. You might\n <mask> also need to add ``--plugin python`` or ``--plugin python3`` depending on which\n <mask> python version you use for your project.\n </s> Fix broken cross-references; use :doc: tags where necessary </s> remove `cherokee`_; see :ref:`deploying-uwsgi` and :ref:`deploying-wsgi-standalone`\nfor other options.  To use your WSGI application with any of them you will need\na FastCGI server first.  The most popular one is `flup`_ which we will use for\nthis guide.  Make sure to have it installed to follow along.\n </s> add `cherokee`_; see :doc:`uwsgi` and :doc:`wsgi-standalone` for other options. To\nuse your WSGI application with any of them you will need a FastCGI server first.\nThe most popular one is `flup`_ which we will use for this guide. Make sure to\nhave it installed to follow along. </s> remove `cherokee`_; see :ref:`deploying-fastcgi` and :ref:`deploying-wsgi-standalone`\nfor other options.  To use your WSGI application with uWSGI protocol you will\nneed a uWSGI server first. uWSGI is both a protocol and an application server;\nthe application server can serve uWSGI, FastCGI, and HTTP protocols.\n </s> add `cherokee`_; see :doc:`fastcgi` and :doc:`wsgi-standalone` for other options.\nTo use your WSGI application with uWSGI protocol you will need a uWSGI server\nfirst. uWSGI is both a protocol and an application server; the application\nserver can serve uWSGI, FastCGI, and HTTP protocols. </s> remove guide.  Make sure to have it installed to follow along.\n </s> add guide. Make sure to have it installed to follow along. </s> remove For a more optimized setup, see :ref:`configuring uWSGI and NGINX <deploying-uwsgi>`.\n </s> add For a more optimized setup, see :doc:`configuring uWSGI and NGINX <uwsgi>`.", "html_url": "https://github.com/pallets/flask/commit/e771016a5bac3c08987907a2ec63385d58b81be0", "file_name": "docs/deploying/uwsgi.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Running `uWSGI HTTP Router`_::\n <mask> \n <mask>     uwsgi --http 127.0.0.1:5000 --module myproject:app\n <mask> \n <mask> For a more optimized setup, see :ref:`configuring uWSGI and NGINX <deploying-uwsgi>`.\n <mask> \n <mask> .. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n <mask> .. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router\n <mask> \n <mask> Gevent\n </s> Fix broken cross-references; use :doc: tags where necessary </s> remove `cherokee`_; see :ref:`deploying-fastcgi` and :ref:`deploying-wsgi-standalone`\nfor other options.  To use your WSGI application with uWSGI protocol you will\nneed a uWSGI server first. uWSGI is both a protocol and an application server;\nthe application server can serve uWSGI, FastCGI, and HTTP protocols.\n </s> add `cherokee`_; see :doc:`fastcgi` and :doc:`wsgi-standalone` for other options.\nTo use your WSGI application with uWSGI protocol you will need a uWSGI server\nfirst. uWSGI is both a protocol and an application server; the application\nserver can serve uWSGI, FastCGI, and HTTP protocols. </s> remove guide.  Make sure to have it installed to follow along.\n </s> add guide. Make sure to have it installed to follow along. </s> remove `cherokee`_; see :ref:`deploying-uwsgi` and :ref:`deploying-wsgi-standalone`\nfor other options.  To use your WSGI application with any of them you will need\na FastCGI server first.  The most popular one is `flup`_ which we will use for\nthis guide.  Make sure to have it installed to follow along.\n </s> add `cherokee`_; see :doc:`uwsgi` and :doc:`wsgi-standalone` for other options. To\nuse your WSGI application with any of them you will need a FastCGI server first.\nThe most popular one is `flup`_ which we will use for this guide. Make sure to\nhave it installed to follow along. </s> remove since its smarter about that. It is used together with the ``--mount`` directive\nwhich will make requests to ``/yourapplication`` be directed to ``myapp:app``.\nIf your application is accessible at root level, you can use a single ``/``\ninstead of ``/yourapplication``. ``myapp`` refers to the name of the file of\nyour flask application (without extension) or the module which provides ``app``.\n``app`` is the callable inside of your application (usually the line reads\n``app = Flask(__name__)``.\n </s> add since it is smarter about that. It is used together with the ``--mount``\ndirective which will make requests to ``/yourapplication`` be directed to\n``myapp:app``. If your application is accessible at root level, you can use a\nsingle ``/`` instead of ``/yourapplication``. ``myapp`` refers to the name of\nthe file of your flask application (without extension) or the module which\nprovides ``app``. ``app`` is the callable inside of your application (usually\nthe line reads ``app = Flask(__name__)``.", "html_url": "https://github.com/pallets/flask/commit/e771016a5bac3c08987907a2ec63385d58b81be0", "file_name": "docs/deploying/wsgi-standalone.rst"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> - Fixed an issue causing exceptions raised before entering a request or app\n <mask>   context to be passed to teardown handlers.\n <mask> \n <mask> Version 0.10.1\n <mask> --------------\n <mask> \n <mask> (bugfix release, released on June 14th 2013)\n <mask> \n </s> Fixe a bug in the test client causing url parameters to be removed.  This fixes #968 </s> add             if url.query:\n                path += '?' + url.query </s> add     def test_full_url_request(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n\n        @app.route('/action', methods=['POST'])\n        def action():\n            return 'x'\n\n        with app.test_client() as c:\n            rv = c.post('http://domain.com/action?vodka=42', data={'gin': 43})\n            self.assert_equal(rv.status_code, 200)\n            self.assert_('gin' in flask.request.form)\n            self.ssert_('vodka' in flask.request.args)\n", "html_url": "https://github.com/pallets/flask/commit/e7c587789ae22a626196cea26340253dd9b70bf1", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         if app_root:\n <mask>             base_url += app_root.lstrip('/')\n <mask>         if url.netloc:\n <mask>             path = url.path\n <mask>     return EnvironBuilder(path, base_url, *args, **kwargs)\n <mask> \n <mask> \n <mask> class FlaskClient(Client):\n <mask>     \"\"\"Works like a regular Werkzeug test client but has some knowledge about\n <mask>     how Flask works to defer the cleanup of the request context stack to the\n </s> Fixe a bug in the test client causing url parameters to be removed.  This fixes #968 </s> add - Fixed an issue with query parameters getting removed from requests in\n  the test client when absolute URLs were requested. </s> add     def test_full_url_request(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n\n        @app.route('/action', methods=['POST'])\n        def action():\n            return 'x'\n\n        with app.test_client() as c:\n            rv = c.post('http://domain.com/action?vodka=42', data={'gin': 43})\n            self.assert_equal(rv.status_code, 200)\n            self.assert_('gin' in flask.request.form)\n            self.ssert_('vodka' in flask.request.args)\n", "html_url": "https://github.com/pallets/flask/commit/e7c587789ae22a626196cea26340253dd9b70bf1", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>         self.assert_equal(called, [None, None])\n <mask> \n <mask> \n <mask> class SubdomainTestCase(FlaskTestCase):\n <mask> \n <mask>     def setUp(self):\n <mask>         self.app = flask.Flask(__name__)\n <mask>         self.app.config['SERVER_NAME'] = 'example.com'\n </s> Fixe a bug in the test client causing url parameters to be removed.  This fixes #968 </s> add             if url.query:\n                path += '?' + url.query </s> add - Fixed an issue with query parameters getting removed from requests in\n  the test client when absolute URLs were requested.", "html_url": "https://github.com/pallets/flask/commit/e7c587789ae22a626196cea26340253dd9b70bf1", "file_name": "flask/testsuite/testing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return\n <mask> \n <mask>         # Add a \"Vary: Cookie\" header if the session was accessed at all.\n <mask>         if session.accessed:\n <mask>             response.headers.add('Vary', 'Cookie')\n <mask> \n <mask>         if not self.should_set_cookie(app, session):\n <mask>             return\n <mask> \n <mask>         httponly = self.get_cookie_httponly(app)\n </s> Don't overwrite Vary header when setting for cookie access #2317 </s> remove         if header:\n            assert rv.headers['Vary'] == 'Cookie'\n </s> add         if header_value:\n            # The 'Vary' key should exist in the headers only once.\n            assert len(rv.headers.get_all('Vary')) == 1\n            assert rv.headers['Vary'] == header_value </s> remove     def expect(path, header=True):\n </s> add     def expect(path, header_value='Cookie'): </s> add     @app.route('/vary-cookie-header-set')\n    def vary_cookie_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Cookie'\n        flask.session['test'] = 'test'\n        return response\n\n    @app.route('/vary-header-set')\n    def vary_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Accept-Encoding, Accept-Language'\n        flask.session['test'] = 'test'\n        return response\n </s> remove     expect('/no-vary-header', False)\n </s> add     expect('/vary-cookie-header-set')\n    expect('/vary-header-set', 'Accept-Encoding, Accept-Language, Cookie')\n    expect('/no-vary-header', None)", "html_url": "https://github.com/pallets/flask/commit/e7cd68ba58b78309a342fbce68f6ef1edef3e5e5", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     def setdefault():\n <mask>         return flask.session.setdefault('test', 'default')\n <mask> \n <mask>     @app.route('/no-vary-header')\n <mask>     def no_vary_header():\n <mask>         return ''\n <mask> \n <mask>     def expect(path, header_value='Cookie'):\n </s> Don't overwrite Vary header when setting for cookie access #2317 </s> remove     def expect(path, header=True):\n </s> add     def expect(path, header_value='Cookie'): </s> remove     expect('/no-vary-header', False)\n </s> add     expect('/vary-cookie-header-set')\n    expect('/vary-header-set', 'Accept-Encoding, Accept-Language, Cookie')\n    expect('/no-vary-header', None) </s> remove         if header:\n            assert rv.headers['Vary'] == 'Cookie'\n </s> add         if header_value:\n            # The 'Vary' key should exist in the headers only once.\n            assert len(rv.headers.get_all('Vary')) == 1\n            assert rv.headers['Vary'] == header_value </s> remove             response.headers.add('Vary', 'Cookie')\n </s> add             self._patch_vary_cookie_header(response)", "html_url": "https://github.com/pallets/flask/commit/e7cd68ba58b78309a342fbce68f6ef1edef3e5e5", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @app.route('/no-vary-header')\n <mask>     def no_vary_header():\n <mask>         return ''\n <mask> \n <mask>     def expect(path, header=True):\n <mask>         rv = client.get(path)\n <mask> \n <mask>         if header:\n <mask>             assert rv.headers['Vary'] == 'Cookie'\n <mask>         else:\n </s> Don't overwrite Vary header when setting for cookie access #2317 </s> remove         if header:\n            assert rv.headers['Vary'] == 'Cookie'\n </s> add         if header_value:\n            # The 'Vary' key should exist in the headers only once.\n            assert len(rv.headers.get_all('Vary')) == 1\n            assert rv.headers['Vary'] == header_value </s> add     @app.route('/vary-cookie-header-set')\n    def vary_cookie_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Cookie'\n        flask.session['test'] = 'test'\n        return response\n\n    @app.route('/vary-header-set')\n    def vary_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Accept-Encoding, Accept-Language'\n        flask.session['test'] = 'test'\n        return response\n </s> remove             response.headers.add('Vary', 'Cookie')\n </s> add             self._patch_vary_cookie_header(response) </s> remove     expect('/no-vary-header', False)\n </s> add     expect('/vary-cookie-header-set')\n    expect('/vary-header-set', 'Accept-Encoding, Accept-Language, Cookie')\n    expect('/no-vary-header', None)", "html_url": "https://github.com/pallets/flask/commit/e7cd68ba58b78309a342fbce68f6ef1edef3e5e5", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def expect(path, header=True):\n <mask>         rv = client.get(path)\n <mask> \n <mask>         if header:\n <mask>             assert rv.headers['Vary'] == 'Cookie'\n <mask>         else:\n <mask>             assert 'Vary' not in rv.headers\n <mask> \n <mask>     expect('/set')\n <mask>     expect('/get')\n </s> Don't overwrite Vary header when setting for cookie access #2317 </s> remove     def expect(path, header=True):\n </s> add     def expect(path, header_value='Cookie'): </s> remove     expect('/no-vary-header', False)\n </s> add     expect('/vary-cookie-header-set')\n    expect('/vary-header-set', 'Accept-Encoding, Accept-Language, Cookie')\n    expect('/no-vary-header', None) </s> add     @app.route('/vary-cookie-header-set')\n    def vary_cookie_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Cookie'\n        flask.session['test'] = 'test'\n        return response\n\n    @app.route('/vary-header-set')\n    def vary_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Accept-Encoding, Accept-Language'\n        flask.session['test'] = 'test'\n        return response\n </s> remove             response.headers.add('Vary', 'Cookie')\n </s> add             self._patch_vary_cookie_header(response)", "html_url": "https://github.com/pallets/flask/commit/e7cd68ba58b78309a342fbce68f6ef1edef3e5e5", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     expect('/set')\n <mask>     expect('/get')\n <mask>     expect('/getitem')\n <mask>     expect('/setdefault')\n <mask>     expect('/no-vary-header', False)\n <mask> \n <mask> \n <mask> def test_flashes(app, req_ctx):\n <mask>     app.secret_key = 'testkey'\n <mask> \n </s> Don't overwrite Vary header when setting for cookie access #2317 </s> remove         if header:\n            assert rv.headers['Vary'] == 'Cookie'\n </s> add         if header_value:\n            # The 'Vary' key should exist in the headers only once.\n            assert len(rv.headers.get_all('Vary')) == 1\n            assert rv.headers['Vary'] == header_value </s> add     @app.route('/vary-cookie-header-set')\n    def vary_cookie_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Cookie'\n        flask.session['test'] = 'test'\n        return response\n\n    @app.route('/vary-header-set')\n    def vary_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Accept-Encoding, Accept-Language'\n        flask.session['test'] = 'test'\n        return response\n </s> remove     def expect(path, header=True):\n </s> add     def expect(path, header_value='Cookie'): </s> remove             response.headers.add('Vary', 'Cookie')\n </s> add             self._patch_vary_cookie_header(response)", "html_url": "https://github.com/pallets/flask/commit/e7cd68ba58b78309a342fbce68f6ef1edef3e5e5", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     def _record(self, func):\n <mask>         self._register_events.append(func)\n <mask> \n <mask> \n <mask> class Flask(_PackageBoundObject):\n <mask>     \"\"\"The flask object implements a WSGI application and acts as the central\n <mask>     object.  It is passed the name of the module or package of the\n <mask>     application.  Once it is created it will act as a central registry for\n </s> Started working on config support </s> remove     session_cookie_name = 'session'\n </s> add     session_cookie_name = ConfigAttribute('session.cookie_name') </s> remove     secret_key = None\n </s> add     secret_key = ConfigAttribute('secret_key') </s> add     #: the debug flag.  Set this to `True` to enable debugging of the\n    #: application.  In debug mode the debugger will kick in when an unhandled\n    #: exception ocurrs and the integrated server will automatically reload\n    #: the application if changes in the code are detected.\n    debug = ConfigAttribute('debug')\n </s> remove     permanent_session_lifetime = timedelta(days=31)\n </s> add     permanent_session_lifetime = ConfigAttribute('session.permanent_lifetime') </s> remove         #: the debug flag.  Set this to `True` to enable debugging of\n        #: the application.  In debug mode the debugger will kick in\n        #: when an unhandled exception ocurrs and the integrated server\n        #: will automatically reload the application if changes in the\n        #: code are detected.\n        self.debug = False\n </s> add         #: the configuration dictionary\n        self.config = self.default_config.copy()\n        if config:\n            self.config.update(config) </s> remove     def __init__(self, import_name):\n </s> add     #: default configuration parameters\n    default_config = ImmutableDict({\n        'debug':                                False,\n        'secret_key':                           None,\n        'session.cookie_name':                  'session',\n        'session.permanent_lifetime':           timedelta(days=31),\n        'use_x_sendfile':                       False\n    })\n\n    def __init__(self, import_name, config=None):", "html_url": "https://github.com/pallets/flask/commit/e84140aba2786655bbddcedb363d16de1e285441", "file_name": "flask.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     static_path = '/static'\n <mask> \n <mask>     #: if a secret key is set, cryptographic components can use this to\n <mask>     #: sign cookies and other things.  Set this to a complex random value\n <mask>     #: when you want to use the secure cookie for instance.\n <mask>     secret_key = ConfigAttribute('secret_key')\n <mask> \n </s> Started working on config support </s> remove     secret_key = None\n </s> add     secret_key = ConfigAttribute('secret_key') </s> remove     session_cookie_name = 'session'\n </s> add     session_cookie_name = ConfigAttribute('session.cookie_name') </s> remove     permanent_session_lifetime = timedelta(days=31)\n </s> add     permanent_session_lifetime = ConfigAttribute('session.permanent_lifetime') </s> remove         #: the debug flag.  Set this to `True` to enable debugging of\n        #: the application.  In debug mode the debugger will kick in\n        #: when an unhandled exception ocurrs and the integrated server\n        #: will automatically reload the application if changes in the\n        #: code are detected.\n        self.debug = False\n </s> add         #: the configuration dictionary\n        self.config = self.default_config.copy()\n        if config:\n            self.config.update(config) </s> remove     use_x_sendfile = False\n </s> add     use_x_sendfile = ConfigAttribute('use_x_sendfile') </s> remove     def __init__(self, import_name):\n </s> add     #: default configuration parameters\n    default_config = ImmutableDict({\n        'debug':                                False,\n        'secret_key':                           None,\n        'session.cookie_name':                  'session',\n        'session.permanent_lifetime':           timedelta(days=31),\n        'use_x_sendfile':                       False\n    })\n\n    def __init__(self, import_name, config=None):", "html_url": "https://github.com/pallets/flask/commit/e84140aba2786655bbddcedb363d16de1e285441", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace keep keep", "code_tokens": " <mask>     #: if a secret key is set, cryptographic components can use this to\n <mask>     #: sign cookies and other things.  Set this to a complex random value\n <mask>     #: when you want to use the secure cookie for instance.\n <mask>     secret_key = None\n <mask> \n <mask>     #: The secure cookie uses this for the name of the session cookie\n <mask>     session_cookie_name = 'session'\n <mask> \n <mask>     #: A :class:`~datetime.timedelta` which is used to set the expiration\n </s> Started working on config support </s> add     #: the debug flag.  Set this to `True` to enable debugging of the\n    #: application.  In debug mode the debugger will kick in when an unhandled\n    #: exception ocurrs and the integrated server will automatically reload\n    #: the application if changes in the code are detected.\n    debug = ConfigAttribute('debug')\n </s> remove     permanent_session_lifetime = timedelta(days=31)\n </s> add     permanent_session_lifetime = ConfigAttribute('session.permanent_lifetime') </s> remove         #: the debug flag.  Set this to `True` to enable debugging of\n        #: the application.  In debug mode the debugger will kick in\n        #: when an unhandled exception ocurrs and the integrated server\n        #: will automatically reload the application if changes in the\n        #: code are detected.\n        self.debug = False\n </s> add         #: the configuration dictionary\n        self.config = self.default_config.copy()\n        if config:\n            self.config.update(config) </s> remove     use_x_sendfile = False\n </s> add     use_x_sendfile = ConfigAttribute('use_x_sendfile') </s> remove     def __init__(self, import_name):\n </s> add     #: default configuration parameters\n    default_config = ImmutableDict({\n        'debug':                                False,\n        'secret_key':                           None,\n        'session.cookie_name':                  'session',\n        'session.permanent_lifetime':           timedelta(days=31),\n        'use_x_sendfile':                       False\n    })\n\n    def __init__(self, import_name, config=None):", "html_url": "https://github.com/pallets/flask/commit/e84140aba2786655bbddcedb363d16de1e285441", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     #: A :class:`~datetime.timedelta` which is used to set the expiration\n <mask>     #: date of a permanent session.  The default is 31 days which makes a\n <mask>     #: permanent session survive for roughly one month.\n <mask>     permanent_session_lifetime = timedelta(days=31)\n <mask> \n <mask>     #: Enable this if you want to use the X-Sendfile feature.  Keep in\n <mask>     #: mind that the server has to support this.  This only affects files\n <mask>     #: sent with the :func:`send_file` method.\n <mask>     #:\n </s> Started working on config support </s> remove     session_cookie_name = 'session'\n </s> add     session_cookie_name = ConfigAttribute('session.cookie_name') </s> remove     use_x_sendfile = False\n </s> add     use_x_sendfile = ConfigAttribute('use_x_sendfile') </s> remove     secret_key = None\n </s> add     secret_key = ConfigAttribute('secret_key') </s> add     #: the debug flag.  Set this to `True` to enable debugging of the\n    #: application.  In debug mode the debugger will kick in when an unhandled\n    #: exception ocurrs and the integrated server will automatically reload\n    #: the application if changes in the code are detected.\n    debug = ConfigAttribute('debug')\n </s> remove         #: the debug flag.  Set this to `True` to enable debugging of\n        #: the application.  In debug mode the debugger will kick in\n        #: when an unhandled exception ocurrs and the integrated server\n        #: will automatically reload the application if changes in the\n        #: code are detected.\n        self.debug = False\n </s> add         #: the configuration dictionary\n        self.config = self.default_config.copy()\n        if config:\n            self.config.update(config) </s> remove     def __init__(self, import_name):\n </s> add     #: default configuration parameters\n    default_config = ImmutableDict({\n        'debug':                                False,\n        'secret_key':                           None,\n        'session.cookie_name':                  'session',\n        'session.permanent_lifetime':           timedelta(days=31),\n        'use_x_sendfile':                       False\n    })\n\n    def __init__(self, import_name, config=None):", "html_url": "https://github.com/pallets/flask/commit/e84140aba2786655bbddcedb363d16de1e285441", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     #: mind that the server has to support this.  This only affects files\n <mask>     #: sent with the :func:`send_file` method.\n <mask>     #:\n <mask>     #: .. versionadded:: 0.2\n <mask>     use_x_sendfile = False\n <mask> \n <mask>     #: the logging format used for the debug logger.  This is only used when\n <mask>     #: the application is in debug mode, otherwise the attached logging\n <mask>     #: handler does the formatting.\n <mask>     #:\n </s> Started working on config support </s> remove     permanent_session_lifetime = timedelta(days=31)\n </s> add     permanent_session_lifetime = ConfigAttribute('session.permanent_lifetime') </s> remove         #: the debug flag.  Set this to `True` to enable debugging of\n        #: the application.  In debug mode the debugger will kick in\n        #: when an unhandled exception ocurrs and the integrated server\n        #: will automatically reload the application if changes in the\n        #: code are detected.\n        self.debug = False\n </s> add         #: the configuration dictionary\n        self.config = self.default_config.copy()\n        if config:\n            self.config.update(config) </s> remove     session_cookie_name = 'session'\n </s> add     session_cookie_name = ConfigAttribute('session.cookie_name') </s> add     #: the debug flag.  Set this to `True` to enable debugging of the\n    #: application.  In debug mode the debugger will kick in when an unhandled\n    #: exception ocurrs and the integrated server will automatically reload\n    #: the application if changes in the code are detected.\n    debug = ConfigAttribute('debug')\n </s> remove     secret_key = None\n </s> add     secret_key = ConfigAttribute('secret_key') </s> remove     def __init__(self, import_name):\n </s> add     #: default configuration parameters\n    default_config = ImmutableDict({\n        'debug':                                False,\n        'secret_key':                           None,\n        'session.cookie_name':                  'session',\n        'session.permanent_lifetime':           timedelta(days=31),\n        'use_x_sendfile':                       False\n    })\n\n    def __init__(self, import_name, config=None):", "html_url": "https://github.com/pallets/flask/commit/e84140aba2786655bbddcedb363d16de1e285441", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         autoescape=True,\n <mask>         extensions=['jinja2.ext.autoescape', 'jinja2.ext.with_']\n <mask>     )\n <mask> \n <mask>     def __init__(self, import_name):\n <mask>         _PackageBoundObject.__init__(self, import_name)\n <mask> \n <mask>         #: the debug flag.  Set this to `True` to enable debugging of\n <mask>         #: the application.  In debug mode the debugger will kick in\n <mask>         #: when an unhandled exception ocurrs and the integrated server\n </s> Started working on config support </s> remove         #: the debug flag.  Set this to `True` to enable debugging of\n        #: the application.  In debug mode the debugger will kick in\n        #: when an unhandled exception ocurrs and the integrated server\n        #: will automatically reload the application if changes in the\n        #: code are detected.\n        self.debug = False\n </s> add         #: the configuration dictionary\n        self.config = self.default_config.copy()\n        if config:\n            self.config.update(config) </s> add     #: the debug flag.  Set this to `True` to enable debugging of the\n    #: application.  In debug mode the debugger will kick in when an unhandled\n    #: exception ocurrs and the integrated server will automatically reload\n    #: the application if changes in the code are detected.\n    debug = ConfigAttribute('debug')\n </s> remove     secret_key = None\n </s> add     secret_key = ConfigAttribute('secret_key') </s> remove     permanent_session_lifetime = timedelta(days=31)\n </s> add     permanent_session_lifetime = ConfigAttribute('session.permanent_lifetime') </s> remove     use_x_sendfile = False\n </s> add     use_x_sendfile = ConfigAttribute('use_x_sendfile') </s> remove     session_cookie_name = 'session'\n </s> add     session_cookie_name = ConfigAttribute('session.cookie_name')", "html_url": "https://github.com/pallets/flask/commit/e84140aba2786655bbddcedb363d16de1e285441", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def __init__(self, import_name):\n <mask>         _PackageBoundObject.__init__(self, import_name)\n <mask> \n <mask>         #: the debug flag.  Set this to `True` to enable debugging of\n <mask>         #: the application.  In debug mode the debugger will kick in\n <mask>         #: when an unhandled exception ocurrs and the integrated server\n <mask>         #: will automatically reload the application if changes in the\n <mask>         #: code are detected.\n <mask>         self.debug = False\n <mask> \n <mask>         #: a dictionary of all view functions registered.  The keys will\n <mask>         #: be function names which are also used to generate URLs and\n <mask>         #: the values are the function objects themselves.\n <mask>         #: to register a view function, use the :meth:`route` decorator.\n </s> Started working on config support </s> add     #: the debug flag.  Set this to `True` to enable debugging of the\n    #: application.  In debug mode the debugger will kick in when an unhandled\n    #: exception ocurrs and the integrated server will automatically reload\n    #: the application if changes in the code are detected.\n    debug = ConfigAttribute('debug')\n </s> remove     def __init__(self, import_name):\n </s> add     #: default configuration parameters\n    default_config = ImmutableDict({\n        'debug':                                False,\n        'secret_key':                           None,\n        'session.cookie_name':                  'session',\n        'session.permanent_lifetime':           timedelta(days=31),\n        'use_x_sendfile':                       False\n    })\n\n    def __init__(self, import_name, config=None): </s> remove     secret_key = None\n </s> add     secret_key = ConfigAttribute('secret_key') </s> remove     permanent_session_lifetime = timedelta(days=31)\n </s> add     permanent_session_lifetime = ConfigAttribute('session.permanent_lifetime') </s> remove     session_cookie_name = 'session'\n </s> add     session_cookie_name = ConfigAttribute('session.cookie_name') </s> remove     use_x_sendfile = False\n </s> add     use_x_sendfile = ConfigAttribute('use_x_sendfile')", "html_url": "https://github.com/pallets/flask/commit/e84140aba2786655bbddcedb363d16de1e285441", "file_name": "flask.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> - Implemented :meth:`~flask.testing.TestClient.session_transaction` to\n <mask>   easily modify sessions from the test environment.\n <mask> \n <mask> Version 0.7.3\n <mask> -------------\n <mask> \n <mask> Bugfix release, release date to be decided\n </s> The test client and test_request_context are now both using the same logic internally for creating the environ.  Also they use APPLICATION_ROOT now. </s> add def make_test_environ_builder(app, path='/', base_url=None, *args, **kwargs):\n    \"\"\"Creates a new test builder with some application defaults thrown in.\"\"\"\n    http_host = app.config.get('SERVER_NAME')\n    app_root = app.config.get('APPLICATION_ROOT')\n    if base_url is None:\n        base_url = 'http://%s/' % (http_host or 'localhost')\n        if app_root:\n            base_url += app_root.lstrip('/')\n    return EnvironBuilder(path, base_url, *args, **kwargs)\n\n </s> remove         from werkzeug.test import create_environ\n        environ_overrides = kwargs.setdefault('environ_overrides', {})\n        if self.config.get('SERVER_NAME'):\n            server_name = self.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, '80'\n            else:\n                http_host, http_port = server_name.split(':', 1)\n\n            environ_overrides.setdefault('SERVER_NAME', server_name)\n            environ_overrides.setdefault('HTTP_HOST', server_name)\n            environ_overrides.setdefault('SERVER_PORT', http_port)\n        return self.request_context(create_environ(*args, **kwargs))\n </s> add         from flask.testing import make_test_environ_builder\n        builder = make_test_environ_builder(self, *args, **kwargs)\n        try:\n            return self.request_context(builder.get_environ())\n        finally:\n            builder.close() </s> add     def test_environ_defaults_from_config(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n        app.config['SERVER_NAME'] = 'example.com:1234'\n        app.config['APPLICATION_ROOT'] = '/foo'\n        @app.route('/')\n        def index():\n            return flask.request.url\n\n        ctx = app.test_request_context()\n        self.assertEqual(ctx.request.url, 'http://example.com:1234/foo/')\n        with app.test_client() as c:\n            rv = c.get('/')\n            self.assertEqual(rv.data, 'http://example.com:1234/foo/')\n </s> remove         builder = EnvironBuilder(*args, **kwargs)\n\n        if self.application.config.get('SERVER_NAME'):\n            server_name = self.application.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, None\n            else:\n                http_host, http_port = server_name.split(':', 1)\n            if builder.base_url == 'http://localhost/':\n                # Default Generated Base URL\n                if http_port != None:\n                    builder.host = http_host + ':' + http_port\n                else:\n                    builder.host = http_host\n </s> add  </s> add         builder = make_test_environ_builder(self.application, *args, **kwargs) </s> remove         See :class:`~flask.testing.TestClient` for more information.\n </s> add         See :class:`~flask.testing.FlaskClient` for more information.", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> -----------\n <mask> \n <mask> .. currentmodule:: flask.testing\n <mask> \n <mask> .. autoclass:: TestClient\n <mask>    :members:\n <mask> \n <mask> \n <mask> Application Globals\n <mask> -------------------\n </s> The test client and test_request_context are now both using the same logic internally for creating the environ.  Also they use APPLICATION_ROOT now. </s> remove         See :class:`~flask.testing.TestClient` for more information.\n </s> add         See :class:`~flask.testing.FlaskClient` for more information. </s> remove         from werkzeug.test import create_environ\n        environ_overrides = kwargs.setdefault('environ_overrides', {})\n        if self.config.get('SERVER_NAME'):\n            server_name = self.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, '80'\n            else:\n                http_host, http_port = server_name.split(':', 1)\n\n            environ_overrides.setdefault('SERVER_NAME', server_name)\n            environ_overrides.setdefault('HTTP_HOST', server_name)\n            environ_overrides.setdefault('SERVER_PORT', http_port)\n        return self.request_context(create_environ(*args, **kwargs))\n </s> add         from flask.testing import make_test_environ_builder\n        builder = make_test_environ_builder(self, *args, **kwargs)\n        try:\n            return self.request_context(builder.get_environ())\n        finally:\n            builder.close() </s> add     def test_environ_defaults_from_config(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n        app.config['SERVER_NAME'] = 'example.com:1234'\n        app.config['APPLICATION_ROOT'] = '/foo'\n        @app.route('/')\n        def index():\n            return flask.request.url\n\n        ctx = app.test_request_context()\n        self.assertEqual(ctx.request.url, 'http://example.com:1234/foo/')\n        with app.test_client() as c:\n            rv = c.get('/')\n            self.assertEqual(rv.data, 'http://example.com:1234/foo/')\n </s> remove         builder = EnvironBuilder(*args, **kwargs)\n\n        if self.application.config.get('SERVER_NAME'):\n            server_name = self.application.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, None\n            else:\n                http_host, http_port = server_name.split(':', 1)\n            if builder.base_url == 'http://localhost/':\n                # Default Generated Base URL\n                if http_port != None:\n                    builder.host = http_host + ':' + http_port\n                else:\n                    builder.host = http_host\n </s> add  </s> add         builder = make_test_environ_builder(self.application, *args, **kwargs) </s> add def make_test_environ_builder(app, path='/', base_url=None, *args, **kwargs):\n    \"\"\"Creates a new test builder with some application defaults thrown in.\"\"\"\n    http_host = app.config.get('SERVER_NAME')\n    app_root = app.config.get('APPLICATION_ROOT')\n    if base_url is None:\n        base_url = 'http://%s/' % (http_host or 'localhost')\n        if app_root:\n            base_url += app_root.lstrip('/')\n    return EnvironBuilder(path, base_url, *args, **kwargs)\n\n", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "docs/api.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             with app.test_client() as c:\n <mask>                 rv = c.get('/?vodka=42')\n <mask>                 assert request.args['vodka'] == '42'\n <mask> \n <mask>         See :class:`~flask.testing.TestClient` for more information.\n <mask> \n <mask>         .. versionchanged:: 0.4\n <mask>            added support for `with` block usage for the client.\n <mask> \n <mask>         .. versionadded:: 0.7\n </s> The test client and test_request_context are now both using the same logic internally for creating the environ.  Also they use APPLICATION_ROOT now. </s> add     def test_environ_defaults_from_config(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n        app.config['SERVER_NAME'] = 'example.com:1234'\n        app.config['APPLICATION_ROOT'] = '/foo'\n        @app.route('/')\n        def index():\n            return flask.request.url\n\n        ctx = app.test_request_context()\n        self.assertEqual(ctx.request.url, 'http://example.com:1234/foo/')\n        with app.test_client() as c:\n            rv = c.get('/')\n            self.assertEqual(rv.data, 'http://example.com:1234/foo/')\n </s> remove .. autoclass:: TestClient\n </s> add .. autoclass:: FlaskClient </s> remove         from werkzeug.test import create_environ\n        environ_overrides = kwargs.setdefault('environ_overrides', {})\n        if self.config.get('SERVER_NAME'):\n            server_name = self.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, '80'\n            else:\n                http_host, http_port = server_name.split(':', 1)\n\n            environ_overrides.setdefault('SERVER_NAME', server_name)\n            environ_overrides.setdefault('HTTP_HOST', server_name)\n            environ_overrides.setdefault('SERVER_PORT', http_port)\n        return self.request_context(create_environ(*args, **kwargs))\n </s> add         from flask.testing import make_test_environ_builder\n        builder = make_test_environ_builder(self, *args, **kwargs)\n        try:\n            return self.request_context(builder.get_environ())\n        finally:\n            builder.close() </s> remove         builder = EnvironBuilder(*args, **kwargs)\n\n        if self.application.config.get('SERVER_NAME'):\n            server_name = self.application.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, None\n            else:\n                http_host, http_port = server_name.split(':', 1)\n            if builder.base_url == 'http://localhost/':\n                # Default Generated Base URL\n                if http_port != None:\n                    builder.host = http_host + ':' + http_port\n                else:\n                    builder.host = http_host\n </s> add  </s> add def make_test_environ_builder(app, path='/', base_url=None, *args, **kwargs):\n    \"\"\"Creates a new test builder with some application defaults thrown in.\"\"\"\n    http_host = app.config.get('SERVER_NAME')\n    app_root = app.config.get('APPLICATION_ROOT')\n    if base_url is None:\n        base_url = 'http://%s/' % (http_host or 'localhost')\n        if app_root:\n            base_url += app_root.lstrip('/')\n    return EnvironBuilder(path, base_url, *args, **kwargs)\n\n </s> add - Refactored test client internally.  The ``APPLICATION_ROOT`` configuration\n  variable as well as ``SERVER_NAME`` are now properly used by the test client\n  as defaults.", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Creates a WSGI environment from the given values (see\n <mask>         :func:`werkzeug.test.EnvironBuilder` for more information, this\n <mask>         function accepts the same arguments).\n <mask>         \"\"\"\n <mask>         from werkzeug.test import create_environ\n <mask>         environ_overrides = kwargs.setdefault('environ_overrides', {})\n <mask>         if self.config.get('SERVER_NAME'):\n <mask>             server_name = self.config.get('SERVER_NAME')\n <mask>             if ':' not in server_name:\n <mask>                 http_host, http_port = server_name, '80'\n <mask>             else:\n <mask>                 http_host, http_port = server_name.split(':', 1)\n <mask> \n <mask>             environ_overrides.setdefault('SERVER_NAME', server_name)\n <mask>             environ_overrides.setdefault('HTTP_HOST', server_name)\n <mask>             environ_overrides.setdefault('SERVER_PORT', http_port)\n <mask>         return self.request_context(create_environ(*args, **kwargs))\n <mask> \n <mask>     def wsgi_app(self, environ, start_response):\n <mask>         \"\"\"The actual WSGI application.  This is not implemented in\n <mask>         `__call__` so that middlewares can be applied without losing a\n <mask>         reference to the class.  So instead of doing this::\n </s> The test client and test_request_context are now both using the same logic internally for creating the environ.  Also they use APPLICATION_ROOT now. </s> remove         builder = EnvironBuilder(*args, **kwargs)\n\n        if self.application.config.get('SERVER_NAME'):\n            server_name = self.application.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, None\n            else:\n                http_host, http_port = server_name.split(':', 1)\n            if builder.base_url == 'http://localhost/':\n                # Default Generated Base URL\n                if http_port != None:\n                    builder.host = http_host + ':' + http_port\n                else:\n                    builder.host = http_host\n </s> add  </s> add def make_test_environ_builder(app, path='/', base_url=None, *args, **kwargs):\n    \"\"\"Creates a new test builder with some application defaults thrown in.\"\"\"\n    http_host = app.config.get('SERVER_NAME')\n    app_root = app.config.get('APPLICATION_ROOT')\n    if base_url is None:\n        base_url = 'http://%s/' % (http_host or 'localhost')\n        if app_root:\n            base_url += app_root.lstrip('/')\n    return EnvironBuilder(path, base_url, *args, **kwargs)\n\n </s> remove         See :class:`~flask.testing.TestClient` for more information.\n </s> add         See :class:`~flask.testing.FlaskClient` for more information. </s> add     def test_environ_defaults_from_config(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n        app.config['SERVER_NAME'] = 'example.com:1234'\n        app.config['APPLICATION_ROOT'] = '/foo'\n        @app.route('/')\n        def index():\n            return flask.request.url\n\n        ctx = app.test_request_context()\n        self.assertEqual(ctx.request.url, 'http://example.com:1234/foo/')\n        with app.test_client() as c:\n            rv = c.get('/')\n            self.assertEqual(rv.data, 'http://example.com:1234/foo/')\n </s> add         builder = make_test_environ_builder(self.application, *args, **kwargs) </s> add - Refactored test client internally.  The ``APPLICATION_ROOT`` configuration\n  variable as well as ``SERVER_NAME`` are now properly used by the test client\n  as defaults.", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> from werkzeug.test import Client, EnvironBuilder\n <mask> from flask import _request_ctx_stack\n <mask> \n <mask> \n <mask> class FlaskClient(Client):\n <mask>     \"\"\"Works like a regular Werkzeug test client but has some knowledge about\n <mask>     how Flask works to defer the cleanup of the request context stack to the\n <mask>     end of a with body when used in a with statement.  For general information\n <mask>     about how to use this class refer to :class:`werkzeug.test.Client`.\n <mask> \n </s> The test client and test_request_context are now both using the same logic internally for creating the environ.  Also they use APPLICATION_ROOT now. </s> remove         from werkzeug.test import create_environ\n        environ_overrides = kwargs.setdefault('environ_overrides', {})\n        if self.config.get('SERVER_NAME'):\n            server_name = self.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, '80'\n            else:\n                http_host, http_port = server_name.split(':', 1)\n\n            environ_overrides.setdefault('SERVER_NAME', server_name)\n            environ_overrides.setdefault('HTTP_HOST', server_name)\n            environ_overrides.setdefault('SERVER_PORT', http_port)\n        return self.request_context(create_environ(*args, **kwargs))\n </s> add         from flask.testing import make_test_environ_builder\n        builder = make_test_environ_builder(self, *args, **kwargs)\n        try:\n            return self.request_context(builder.get_environ())\n        finally:\n            builder.close() </s> add - Refactored test client internally.  The ``APPLICATION_ROOT`` configuration\n  variable as well as ``SERVER_NAME`` are now properly used by the test client\n  as defaults. </s> add     def test_environ_defaults_from_config(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n        app.config['SERVER_NAME'] = 'example.com:1234'\n        app.config['APPLICATION_ROOT'] = '/foo'\n        @app.route('/')\n        def index():\n            return flask.request.url\n\n        ctx = app.test_request_context()\n        self.assertEqual(ctx.request.url, 'http://example.com:1234/foo/')\n        with app.test_client() as c:\n            rv = c.get('/')\n            self.assertEqual(rv.data, 'http://example.com:1234/foo/')\n </s> remove         See :class:`~flask.testing.TestClient` for more information.\n </s> add         See :class:`~flask.testing.FlaskClient` for more information. </s> remove         builder = EnvironBuilder(*args, **kwargs)\n\n        if self.application.config.get('SERVER_NAME'):\n            server_name = self.application.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, None\n            else:\n                http_host, http_port = server_name.split(':', 1)\n            if builder.base_url == 'http://localhost/':\n                # Default Generated Base URL\n                if http_port != None:\n                    builder.host = http_host + ':' + http_port\n                else:\n                    builder.host = http_host\n </s> add  </s> add         builder = make_test_environ_builder(self.application, *args, **kwargs)", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         as_tuple = kwargs.pop('as_tuple', False)\n <mask>         buffered = kwargs.pop('buffered', False)\n <mask>         follow_redirects = kwargs.pop('follow_redirects', False)\n <mask> \n <mask>         old = _request_ctx_stack.top\n <mask>         try:\n <mask>             return Client.open(self, builder,\n <mask>                                as_tuple=as_tuple,\n </s> The test client and test_request_context are now both using the same logic internally for creating the environ.  Also they use APPLICATION_ROOT now. </s> remove         builder = EnvironBuilder(*args, **kwargs)\n\n        if self.application.config.get('SERVER_NAME'):\n            server_name = self.application.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, None\n            else:\n                http_host, http_port = server_name.split(':', 1)\n            if builder.base_url == 'http://localhost/':\n                # Default Generated Base URL\n                if http_port != None:\n                    builder.host = http_host + ':' + http_port\n                else:\n                    builder.host = http_host\n </s> add  </s> add     def test_environ_defaults_from_config(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n        app.config['SERVER_NAME'] = 'example.com:1234'\n        app.config['APPLICATION_ROOT'] = '/foo'\n        @app.route('/')\n        def index():\n            return flask.request.url\n\n        ctx = app.test_request_context()\n        self.assertEqual(ctx.request.url, 'http://example.com:1234/foo/')\n        with app.test_client() as c:\n            rv = c.get('/')\n            self.assertEqual(rv.data, 'http://example.com:1234/foo/')\n </s> remove         from werkzeug.test import create_environ\n        environ_overrides = kwargs.setdefault('environ_overrides', {})\n        if self.config.get('SERVER_NAME'):\n            server_name = self.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, '80'\n            else:\n                http_host, http_port = server_name.split(':', 1)\n\n            environ_overrides.setdefault('SERVER_NAME', server_name)\n            environ_overrides.setdefault('HTTP_HOST', server_name)\n            environ_overrides.setdefault('SERVER_PORT', http_port)\n        return self.request_context(create_environ(*args, **kwargs))\n </s> add         from flask.testing import make_test_environ_builder\n        builder = make_test_environ_builder(self, *args, **kwargs)\n        try:\n            return self.request_context(builder.get_environ())\n        finally:\n            builder.close() </s> add def make_test_environ_builder(app, path='/', base_url=None, *args, **kwargs):\n    \"\"\"Creates a new test builder with some application defaults thrown in.\"\"\"\n    http_host = app.config.get('SERVER_NAME')\n    app_root = app.config.get('APPLICATION_ROOT')\n    if base_url is None:\n        base_url = 'http://%s/' % (http_host or 'localhost')\n        if app_root:\n            base_url += app_root.lstrip('/')\n    return EnvironBuilder(path, base_url, *args, **kwargs)\n\n </s> remove         See :class:`~flask.testing.TestClient` for more information.\n </s> add         See :class:`~flask.testing.FlaskClient` for more information. </s> remove .. autoclass:: TestClient\n </s> add .. autoclass:: FlaskClient", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         as_tuple = kwargs.pop('as_tuple', False)\n <mask>         buffered = kwargs.pop('buffered', False)\n <mask>         follow_redirects = kwargs.pop('follow_redirects', False)\n <mask> \n <mask>         builder = EnvironBuilder(*args, **kwargs)\n <mask> \n <mask>         if self.application.config.get('SERVER_NAME'):\n <mask>             server_name = self.application.config.get('SERVER_NAME')\n <mask>             if ':' not in server_name:\n <mask>                 http_host, http_port = server_name, None\n <mask>             else:\n <mask>                 http_host, http_port = server_name.split(':', 1)\n <mask>             if builder.base_url == 'http://localhost/':\n <mask>                 # Default Generated Base URL\n <mask>                 if http_port != None:\n <mask>                     builder.host = http_host + ':' + http_port\n <mask>                 else:\n <mask>                     builder.host = http_host\n <mask>         old = _request_ctx_stack.top\n <mask>         try:\n <mask>             return Client.open(self, builder,\n <mask>                                as_tuple=as_tuple,\n <mask>                                buffered=buffered,\n </s> The test client and test_request_context are now both using the same logic internally for creating the environ.  Also they use APPLICATION_ROOT now. </s> add         builder = make_test_environ_builder(self.application, *args, **kwargs) </s> remove         from werkzeug.test import create_environ\n        environ_overrides = kwargs.setdefault('environ_overrides', {})\n        if self.config.get('SERVER_NAME'):\n            server_name = self.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, '80'\n            else:\n                http_host, http_port = server_name.split(':', 1)\n\n            environ_overrides.setdefault('SERVER_NAME', server_name)\n            environ_overrides.setdefault('HTTP_HOST', server_name)\n            environ_overrides.setdefault('SERVER_PORT', http_port)\n        return self.request_context(create_environ(*args, **kwargs))\n </s> add         from flask.testing import make_test_environ_builder\n        builder = make_test_environ_builder(self, *args, **kwargs)\n        try:\n            return self.request_context(builder.get_environ())\n        finally:\n            builder.close() </s> add def make_test_environ_builder(app, path='/', base_url=None, *args, **kwargs):\n    \"\"\"Creates a new test builder with some application defaults thrown in.\"\"\"\n    http_host = app.config.get('SERVER_NAME')\n    app_root = app.config.get('APPLICATION_ROOT')\n    if base_url is None:\n        base_url = 'http://%s/' % (http_host or 'localhost')\n        if app_root:\n            base_url += app_root.lstrip('/')\n    return EnvironBuilder(path, base_url, *args, **kwargs)\n\n </s> add     def test_environ_defaults_from_config(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n        app.config['SERVER_NAME'] = 'example.com:1234'\n        app.config['APPLICATION_ROOT'] = '/foo'\n        @app.route('/')\n        def index():\n            return flask.request.url\n\n        ctx = app.test_request_context()\n        self.assertEqual(ctx.request.url, 'http://example.com:1234/foo/')\n        with app.test_client() as c:\n            rv = c.get('/')\n            self.assertEqual(rv.data, 'http://example.com:1234/foo/')\n </s> remove         See :class:`~flask.testing.TestClient` for more information.\n </s> add         See :class:`~flask.testing.FlaskClient` for more information. </s> remove .. autoclass:: TestClient\n </s> add .. autoclass:: FlaskClient", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> class TestToolsTestCase(FlaskTestCase):\n <mask> \n <mask>     def test_session_transactions(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.testing = True\n <mask>         app.secret_key = 'testing'\n <mask> \n </s> The test client and test_request_context are now both using the same logic internally for creating the environ.  Also they use APPLICATION_ROOT now. </s> add def make_test_environ_builder(app, path='/', base_url=None, *args, **kwargs):\n    \"\"\"Creates a new test builder with some application defaults thrown in.\"\"\"\n    http_host = app.config.get('SERVER_NAME')\n    app_root = app.config.get('APPLICATION_ROOT')\n    if base_url is None:\n        base_url = 'http://%s/' % (http_host or 'localhost')\n        if app_root:\n            base_url += app_root.lstrip('/')\n    return EnvironBuilder(path, base_url, *args, **kwargs)\n\n </s> add         builder = make_test_environ_builder(self.application, *args, **kwargs) </s> remove         builder = EnvironBuilder(*args, **kwargs)\n\n        if self.application.config.get('SERVER_NAME'):\n            server_name = self.application.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, None\n            else:\n                http_host, http_port = server_name.split(':', 1)\n            if builder.base_url == 'http://localhost/':\n                # Default Generated Base URL\n                if http_port != None:\n                    builder.host = http_host + ':' + http_port\n                else:\n                    builder.host = http_host\n </s> add  </s> remove         from werkzeug.test import create_environ\n        environ_overrides = kwargs.setdefault('environ_overrides', {})\n        if self.config.get('SERVER_NAME'):\n            server_name = self.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, '80'\n            else:\n                http_host, http_port = server_name.split(':', 1)\n\n            environ_overrides.setdefault('SERVER_NAME', server_name)\n            environ_overrides.setdefault('HTTP_HOST', server_name)\n            environ_overrides.setdefault('SERVER_PORT', http_port)\n        return self.request_context(create_environ(*args, **kwargs))\n </s> add         from flask.testing import make_test_environ_builder\n        builder = make_test_environ_builder(self, *args, **kwargs)\n        try:\n            return self.request_context(builder.get_environ())\n        finally:\n            builder.close() </s> remove         See :class:`~flask.testing.TestClient` for more information.\n </s> add         See :class:`~flask.testing.FlaskClient` for more information. </s> remove .. autoclass:: TestClient\n </s> add .. autoclass:: FlaskClient", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> -   Show an error when a blueprint name contains a dot. The ``.`` has\n <mask>     special meaning, it is used to separate (nested) blueprint names and\n <mask>     the endpoint name. :issue:`4041`\n <mask> \n <mask> \n <mask> Version 2.0.0\n <mask> -------------\n </s> fix url_prefix argument when nesting blueprints </s> remove             url_prefix = options.get(\"url_prefix\", \"\")\n            if \"url_prefix\" in bp_options:\n                url_prefix = (\n                    url_prefix.rstrip(\"/\") + \"/\" + bp_options[\"url_prefix\"].lstrip(\"/\")\n </s> add             bp_options = bp_options.copy()\n            bp_url_prefix = bp_options.get(\"url_prefix\")\n\n            if bp_url_prefix is None:\n                bp_url_prefix = blueprint.url_prefix\n\n            if state.url_prefix is not None and bp_url_prefix is not None:\n                bp_options[\"url_prefix\"] = (\n                    state.url_prefix.rstrip(\"/\") + \"/\" + bp_url_prefix.lstrip(\"/\") </s> remove         each :meth:`record` callbackwith it.\n </s> add         each :meth:`record` callback with it. </s> remove             bp_options[\"url_prefix\"] = url_prefix\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e93704fbfd5f40e48f8fe9034b6b0fe420d28fb3", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def register(self, app: \"Flask\", options: dict) -> None:\n <mask>         \"\"\"Called by :meth:`Flask.register_blueprint` to register all\n <mask>         views and callbacks registered on the blueprint with the\n <mask>         application. Creates a :class:`.BlueprintSetupState` and calls\n <mask>         each :meth:`record` callbackwith it.\n <mask> \n <mask>         :param app: The application this blueprint is being registered\n <mask>             with.\n <mask>         :param options: Keyword arguments forwarded from\n <mask>             :meth:`~Flask.register_blueprint`.\n </s> fix url_prefix argument when nesting blueprints </s> remove             url_prefix = options.get(\"url_prefix\", \"\")\n            if \"url_prefix\" in bp_options:\n                url_prefix = (\n                    url_prefix.rstrip(\"/\") + \"/\" + bp_options[\"url_prefix\"].lstrip(\"/\")\n </s> add             bp_options = bp_options.copy()\n            bp_url_prefix = bp_options.get(\"url_prefix\")\n\n            if bp_url_prefix is None:\n                bp_url_prefix = blueprint.url_prefix\n\n            if state.url_prefix is not None and bp_url_prefix is not None:\n                bp_options[\"url_prefix\"] = (\n                    state.url_prefix.rstrip(\"/\") + \"/\" + bp_url_prefix.lstrip(\"/\") </s> add -   Combine URL prefixes when nesting blueprints that were created with\n    a ``url_prefix`` value. :issue:`4037` </s> remove             bp_options[\"url_prefix\"] = url_prefix\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e93704fbfd5f40e48f8fe9034b6b0fe420d28fb3", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep replace replace replace replace keep keep replace keep", "code_tokens": " <mask> \n <mask>         for blueprint, bp_options in self._blueprints:\n <mask>             url_prefix = options.get(\"url_prefix\", \"\")\n <mask>             if \"url_prefix\" in bp_options:\n <mask>                 url_prefix = (\n <mask>                     url_prefix.rstrip(\"/\") + \"/\" + bp_options[\"url_prefix\"].lstrip(\"/\")\n <mask>                 )\n <mask> \n <mask>             bp_options[\"url_prefix\"] = url_prefix\n <mask>             bp_options[\"name_prefix\"] = options.get(\"name_prefix\", \"\") + self.name + \".\"\n </s> fix url_prefix argument when nesting blueprints </s> remove         each :meth:`record` callbackwith it.\n </s> add         each :meth:`record` callback with it. </s> add -   Combine URL prefixes when nesting blueprints that were created with\n    a ``url_prefix`` value. :issue:`4037`", "html_url": "https://github.com/pallets/flask/commit/e93704fbfd5f40e48f8fe9034b6b0fe420d28fb3", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>   stack yet. This allows ``stream_with_context`` generators to access the same\n <mask>   session that the containing view uses. (`#2354`_)\n <mask> \n <mask> .. _#1489: https://github.com/pallets/flask/pull/1489\n <mask> .. _#1621: https://github.com/pallets/flask/pull/1621\n <mask> .. _#1898: https://github.com/pallets/flask/pull/1898\n </s> clean up JSON code and docs </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None:\n            return ctx.app.config['MAX_CONTENT_LENGTH']\n </s> add         if current_app:\n            return current_app.config['MAX_CONTENT_LENGTH'] </s> add     .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON. </s> remove         .. versionadded:: 1.0\n </s> add         .. versionadded:: 0.11 </s> remove         \"\"\"Indicates if this request/response is in JSON format or not.  By\n        default it is considered to include JSON data if the mimetype is\n </s> add         \"\"\"Check if the mimetype indicates JSON data, either </s> remove Note that if the ``json`` argument is provided then the test client will put\nJSON-serialized data in the request body, and also set the\n``Content-Type: application/json`` HTTP header.\n </s> add Passing the ``json`` argument in the test client methods sets the request data\nto the JSON-serialized object and sets the content type to\n``application/json``. You can get the JSON data from the request or response\nwith ``get_json``. </s> add     _cached_json = Ellipsis\n", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> .. _#2326: https://github.com/pallets/flask/pull/2326\n <mask> .. _#2348: https://github.com/pallets/flask/pull/2348\n <mask> .. _#2352: https://github.com/pallets/flask/pull/2352\n <mask> .. _#2354: https://github.com/pallets/flask/pull/2354\n <mask> \n <mask> Version 0.12.2\n <mask> --------------\n <mask> \n </s> clean up JSON code and docs </s> remove     .. versionadded:: 0.12\n </s> add     .. versionadded:: 1.0 </s> remove         .. versionadded:: 1.0\n </s> add         .. versionadded:: 0.11 </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_) </s> add     _cached_json = Ellipsis\n </s> remove            Removed buggy previous behavior of generating a random JSON\n           response.  If you want that behavior back you can trivially\n           add it by subclassing.\n </s> add            Raise a :exc:`BadRequest` error instead of returning an error\n           message as JSON. If you want that behavior you can add it by\n           subclassing. </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug:\n </s> add         if current_app is not None and current_app.debug:", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> - Mimetype guessing in ``send_file`` now fails loudly and doesn't fall back to\n <mask>   ``application/octet-stream``. See pull request ``#1988``.\n <mask> - Make ``flask.safe_join`` able to join multiple paths like ``os.path.join``\n <mask>   (pull request ``#1730``).\n <mask> - Added `json` keyword argument to :meth:`flask.testing.FlaskClient.open`\n <mask>   (and related ``get``, ``post``, etc.), which makes it more convenient to\n <mask>   send JSON requests from the test client.\n <mask> - Added ``is_json`` and ``get_json`` to :class:``flask.wrappers.Response``\n <mask>   in order to make it easier to build assertions when testing JSON responses.\n <mask> - Revert a behavior change that made the dev server crash instead of returning\n <mask>   a Internal Server Error (pull request ``#2006``).\n <mask> - Correctly invoke response handlers for both regular request dispatching as\n <mask>   well as error handlers.\n <mask> - Disable logger propagation by default for the app logger.\n </s> clean up JSON code and docs </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_) </s> remove Note that if the ``json`` argument is provided then the test client will put\nJSON-serialized data in the request body, and also set the\n``Content-Type: application/json`` HTTP header.\n </s> add Passing the ``json`` argument in the test client methods sets the request data\nto the JSON-serialized object and sets the content type to\n``application/json``. You can get the JSON data from the request or response\nwith ``get_json``. </s> add     .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON. </s> remove            Removed buggy previous behavior of generating a random JSON\n           response.  If you want that behavior back you can trivially\n           add it by subclassing.\n </s> add            Raise a :exc:`BadRequest` error instead of returning an error\n           message as JSON. If you want that behavior you can add it by\n           subclassing. </s> remove         \"\"\"Called if decoding of the JSON data failed.  The return value of\n        this method is used by :meth:`get_json` when an error occurred.  The\n        default implementation just raises a :class:`BadRequest` exception.\n </s> add         \"\"\"Called if :meth:`get_json` parsing fails and isn't silenced. If\n        this method returns a value, it is used as the return value for\n        :meth:`get_json`. The default implementation raises a\n        :class:`BadRequest` exception. </s> remove         \"\"\"Parses the JSON request/response data and returns it.  By default\n        this function will return ``None`` if the mimetype is not\n        :mimetype:`application/json` but this can be overridden by the\n        ``force`` parameter. If parsing fails the\n        :meth:`on_json_loading_failed` method on the request object will be\n        invoked.\n\n        :param force: if set to ``True`` the mimetype is ignored.\n        :param silent: if set to ``True`` this method will fail silently\n                       and return ``None``.\n        :param cache: if set to ``True`` the parsed JSON data is remembered\n                      on the object.\n </s> add         \"\"\"Parse and return the data as JSON. If the mimetype does not indicate\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), this returns\n        ``None`` unless ``force`` is true. If parsing fails,\n        :meth:`on_json_loading_failed` is called and its return value is used\n        as the return value.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence parsing errors and return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent calls.", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep replace keep", "code_tokens": " <mask> -----------------\n <mask> \n <mask> .. versionadded:: 1.0\n <mask> \n <mask> Flask has great support for JSON, and is a popular choice for building REST\n <mask> APIs. Testing both JSON requests and responses using the test client is very\n <mask> convenient::\n <mask> \n <mask>     from flask import jsonify\n <mask> \n </s> clean up JSON code and docs </s> add     .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON. </s> remove     .. versionadded:: 0.12\n </s> add     .. versionadded:: 1.0 </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_) </s> remove         .. versionadded:: 1.0\n </s> add         .. versionadded:: 0.11 </s> remove from . import json\nfrom .globals import _app_ctx_stack\n </s> add from flask import json\nfrom flask.globals import current_app", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         return jsonify(token=generate_token(email, password))\n <mask> \n <mask>     with app.test_client() as c:\n <mask>         email = 'john@example.com'\n <mask>         password = 'secret'\n <mask>         resp = c.post('/api/auth', json={'login': email, 'password': password})\n <mask> \n <mask>         json_data = resp.get_json()\n <mask>         assert verify_token(email, json_data['token'])\n <mask> \n <mask> Note that if the ``json`` argument is provided then the test client will put\n <mask> JSON-serialized data in the request body, and also set the\n <mask> ``Content-Type: application/json`` HTTP header.\n </s> clean up JSON code and docs </s> remove Note that if the ``json`` argument is provided then the test client will put\nJSON-serialized data in the request body, and also set the\n``Content-Type: application/json`` HTTP header.\n </s> add Passing the ``json`` argument in the test client methods sets the request data\nto the JSON-serialized object and sets the content type to\n``application/json``. You can get the JSON data from the request or response\nwith ``get_json``. </s> remove     from flask import jsonify\n </s> add     from flask import request, jsonify </s> remove         # We accept MIME charset header against the specification as certain\n        # clients have been using this in the past.  For responses, we assume\n        # that if the response charset was set explicitly then the data had\n        # been encoded correctly as well.\n </s> add         # We accept MIME charset against the specification as certain clients\n        # have used this in the past. For responses, we assume that if the\n        # charset is set then the data has been encoded correctly as well. </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_) </s> remove             data = self._get_data_for_json(cache)\n            if charset is not None:\n                rv = json.loads(data, encoding=charset)\n            else:\n                rv = json.loads(data)\n </s> add             data = self._get_data_for_json(cache=cache)\n            rv = json.loads(data, encoding=charset) </s> add     .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON.", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace", "code_tokens": " <mask> \n <mask>         json_data = resp.get_json()\n <mask>         assert verify_token(email, json_data['token'])\n <mask> \n <mask> Note that if the ``json`` argument is provided then the test client will put\n <mask> JSON-serialized data in the request body, and also set the\n <mask> ``Content-Type: application/json`` HTTP header.\n </s> clean up JSON code and docs </s> remove         email = 'john@example.com'\n        password = 'secret'\n        resp = c.post('/api/auth', json={'login': email, 'password': password})\n\n        json_data = resp.get_json()\n </s> add         rv = c.post('/api/auth', json={\n            'username': 'flask', 'password': 'secret'\n        })\n        json_data = rv.get_json() </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_) </s> add     .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON. </s> remove         # We accept MIME charset header against the specification as certain\n        # clients have been using this in the past.  For responses, we assume\n        # that if the response charset was set explicitly then the data had\n        # been encoded correctly as well.\n </s> add         # We accept MIME charset against the specification as certain clients\n        # have used this in the past. For responses, we assume that if the\n        # charset is set then the data has been encoded correctly as well. </s> remove         \"\"\"Parses the JSON request/response data and returns it.  By default\n        this function will return ``None`` if the mimetype is not\n        :mimetype:`application/json` but this can be overridden by the\n        ``force`` parameter. If parsing fails the\n        :meth:`on_json_loading_failed` method on the request object will be\n        invoked.\n\n        :param force: if set to ``True`` the mimetype is ignored.\n        :param silent: if set to ``True`` this method will fail silently\n                       and return ``None``.\n        :param cache: if set to ``True`` the parsed JSON data is remembered\n                      on the object.\n </s> add         \"\"\"Parse and return the data as JSON. If the mimetype does not indicate\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), this returns\n        ``None`` unless ``force`` is true. If parsing fails,\n        :meth:`on_json_loading_failed` is called and its return value is used\n        as the return value.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence parsing errors and return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent calls. </s> remove     from flask import jsonify\n </s> add     from flask import request, jsonify", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     from urlparse import urlsplit as url_parse\n <mask> \n <mask> \n <mask> def make_test_environ_builder(\n <mask>     app, path='/', base_url=None, subdomain=None, url_scheme=None, json=None,\n <mask>     *args, **kwargs\n <mask> ):\n <mask>     \"\"\"Creates a new test builder with some application defaults thrown in.\"\"\"\n <mask> \n <mask>     assert (\n </s> clean up JSON code and docs </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files:\n </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ): </s> remove Note that if the ``json`` argument is provided then the test client will put\nJSON-serialized data in the request body, and also set the\n``Content-Type: application/json`` HTTP header.\n </s> add Passing the ``json`` argument in the test client methods sets the request data\nto the JSON-serialized object and sets the content type to\n``application/json``. You can get the JSON data from the request or response\nwith ``get_json``. </s> remove Flask has great support for JSON, and is a popular choice for building REST\nAPIs. Testing both JSON requests and responses using the test client is very\nconvenient::\n </s> add Flask has great support for JSON, and is a popular choice for building JSON\nAPIs. Making requests with JSON data and examining JSON data in responses is\nvery convenient:: </s> remove         email = 'john@example.com'\n        password = 'secret'\n        resp = c.post('/api/auth', json={'login': email, 'password': password})\n\n        json_data = resp.get_json()\n </s> add         rv = c.post('/api/auth', json={\n            'username': 'flask', 'password': 'secret'\n        })\n        json_data = rv.get_json() </s> remove     from flask import jsonify\n </s> add     from flask import request, jsonify </s> remove         if 'data' in kwargs:\n            raise ValueError('Client cannot provide both `json` and `data`')\n </s> add         assert 'data' not in kwargs, (\n            \"Client cannot provide both 'json' and 'data'.\"\n        )", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep replace replace keep replace keep keep keep", "code_tokens": " <mask>     if 'json' in kwargs:\n <mask>         if 'data' in kwargs:\n <mask>             raise ValueError('Client cannot provide both `json` and `data`')\n <mask> \n <mask>         kwargs['data'] = json_dumps(kwargs.pop('json'))\n <mask> \n <mask>         # Only set Content-Type when not explicitly provided\n <mask>         if 'content_type' not in kwargs:\n </s> clean up JSON code and docs </s> remove         # Only set Content-Type when not explicitly provided\n </s> add  </s> remove         # We accept MIME charset header against the specification as certain\n        # clients have been using this in the past.  For responses, we assume\n        # that if the response charset was set explicitly then the data had\n        # been encoded correctly as well.\n </s> add         # We accept MIME charset against the specification as certain clients\n        # have used this in the past. For responses, we assume that if the\n        # charset is set then the data has been encoded correctly as well. </s> remove             data = self._get_data_for_json(cache)\n            if charset is not None:\n                rv = json.loads(data, encoding=charset)\n            else:\n                rv = json.loads(data)\n </s> add             data = self._get_data_for_json(cache=cache)\n            rv = json.loads(data, encoding=charset) </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug:\n </s> add         if current_app is not None and current_app.debug: </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files:\n </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ):", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             raise ValueError('Client cannot provide both `json` and `data`')\n <mask> \n <mask>         kwargs['data'] = json_dumps(kwargs.pop('json'))\n <mask> \n <mask>         # Only set Content-Type when not explicitly provided\n <mask>         if 'content_type' not in kwargs:\n <mask>             kwargs['content_type'] = 'application/json'\n <mask> \n <mask>     return EnvironBuilder(path, base_url, *args, **kwargs)\n <mask> \n </s> clean up JSON code and docs </s> remove         kwargs['data'] = json_dumps(kwargs.pop('json'))\n </s> add         # push a context so flask.json can use app's json attributes\n        with app.app_context():\n            kwargs['data'] = json_dumps(kwargs.pop('json')) </s> remove         if 'data' in kwargs:\n            raise ValueError('Client cannot provide both `json` and `data`')\n </s> add         assert 'data' not in kwargs, (\n            \"Client cannot provide both 'json' and 'data'.\"\n        ) </s> remove         # We accept MIME charset header against the specification as certain\n        # clients have been using this in the past.  For responses, we assume\n        # that if the response charset was set explicitly then the data had\n        # been encoded correctly as well.\n </s> add         # We accept MIME charset against the specification as certain clients\n        # have used this in the past. For responses, we assume that if the\n        # charset is set then the data has been encoded correctly as well. </s> remove             data = self._get_data_for_json(cache)\n            if charset is not None:\n                rv = json.loads(data, encoding=charset)\n            else:\n                rv = json.loads(data)\n </s> add             data = self._get_data_for_json(cache=cache)\n            rv = json.loads(data, encoding=charset) </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug:\n </s> add         if current_app is not None and current_app.debug: </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files:\n </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ):", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from werkzeug.exceptions import BadRequest\n <mask> from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase\n <mask> \n <mask> from flask import json\n <mask> from flask.globals import current_app\n </s> clean up JSON code and docs </s> remove from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase\n </s> add  </s> add from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase </s> remove from . import json\nfrom .globals import _app_ctx_stack\n </s> add from flask import json\nfrom flask.globals import current_app </s> remove     from flask import jsonify\n </s> add     from flask import request, jsonify </s> remove Flask has great support for JSON, and is a popular choice for building REST\nAPIs. Testing both JSON requests and responses using the test client is very\nconvenient::\n </s> add Flask has great support for JSON, and is a popular choice for building JSON\nAPIs. Making requests with JSON data and examining JSON data in responses is\nvery convenient:: </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files:\n </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ):", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2015 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase\n <mask> from werkzeug.exceptions import BadRequest\n <mask> \n <mask> from . import json\n <mask> from .globals import _app_ctx_stack\n <mask> \n </s> clean up JSON code and docs </s> add from warnings import warn </s> remove from . import json\nfrom .globals import _app_ctx_stack\n </s> add from flask import json\nfrom flask.globals import current_app </s> add from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase </s> remove     from flask import jsonify\n </s> add     from flask import request, jsonify </s> remove         \"\"\"If this request/response is in JSON format then this property will\n        contain the parsed JSON data.  Otherwise it will be ``None``.\n </s> add         \"\"\"This will contain the parsed JSON data if the mimetype indicates\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), otherwise it\n        will be ``None``. </s> remove     app, path='/', base_url=None, subdomain=None, url_scheme=None, json=None,\n </s> add     app, path='/', base_url=None, subdomain=None, url_scheme=None,", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from werkzeug.exceptions import BadRequest\n <mask> \n <mask> from flask import json\n <mask> from flask.globals import current_app\n <mask> \n <mask> \n <mask> class JSONMixin(object):\n </s> clean up JSON code and docs </s> remove from . import json\nfrom .globals import _app_ctx_stack\n </s> add from flask import json\nfrom flask.globals import current_app </s> add from warnings import warn </s> remove from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase\n </s> add  </s> remove     from flask import jsonify\n </s> add     from flask import request, jsonify </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files:\n </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ): </s> remove     .. versionadded:: 0.12\n </s> add     .. versionadded:: 1.0", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase\n <mask> from werkzeug.exceptions import BadRequest\n <mask> \n <mask> from . import json\n <mask> from .globals import _app_ctx_stack\n <mask> \n <mask> \n <mask> class JSONMixin(object):\n <mask>     \"\"\"Common mixin for both request and response objects to provide JSON\n <mask>     parsing capabilities.\n </s> clean up JSON code and docs </s> remove from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase\n </s> add  </s> add from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase </s> add from warnings import warn </s> remove     .. versionadded:: 0.12\n </s> add     .. versionadded:: 1.0 </s> remove     from flask import jsonify\n </s> add     from flask import request, jsonify </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_)", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> class JSONMixin(object):\n <mask>     \"\"\"Common mixin for both request and response objects to provide JSON\n <mask>     parsing capabilities.\n <mask> \n <mask>     .. versionadded:: 0.12\n <mask>     \"\"\"\n <mask> \n <mask>     @property\n <mask>     def is_json(self):\n <mask>         \"\"\"Indicates if this request/response is in JSON format or not.  By\n </s> clean up JSON code and docs </s> remove from . import json\nfrom .globals import _app_ctx_stack\n </s> add from flask import json\nfrom flask.globals import current_app </s> remove         \"\"\"Indicates if this request/response is in JSON format or not.  By\n        default it is considered to include JSON data if the mimetype is\n </s> add         \"\"\"Check if the mimetype indicates JSON data, either </s> remove         .. versionadded:: 1.0\n </s> add         .. versionadded:: 0.11 </s> remove         if mt == 'application/json':\n            return True\n        if mt.startswith('application/') and mt.endswith('+json'):\n            return True\n        return False\n </s> add         return (\n            mt == 'application/json'\n            or (mt.startswith('application/')) and mt.endswith('+json')\n        ) </s> add     _cached_json = Ellipsis\n </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_)", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask> \n <mask>     @property\n <mask>     def is_json(self):\n <mask>         \"\"\"Check if the mimetype indicates JSON data, either\n <mask>         :mimetype:`application/json` or :mimetype:`application/*+json`.\n <mask> \n <mask>         .. versionadded:: 0.11\n </s> clean up JSON code and docs </s> remove         \"\"\"Indicates if this request/response is in JSON format or not.  By\n        default it is considered to include JSON data if the mimetype is\n </s> add         \"\"\"Check if the mimetype indicates JSON data, either </s> remove         .. versionadded:: 1.0\n </s> add         .. versionadded:: 0.11 </s> remove     .. versionadded:: 0.12\n </s> add     .. versionadded:: 1.0 </s> remove         \"\"\"If this request/response is in JSON format then this property will\n        contain the parsed JSON data.  Otherwise it will be ``None``.\n </s> add         \"\"\"This will contain the parsed JSON data if the mimetype indicates\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), otherwise it\n        will be ``None``. </s> remove         if mt == 'application/json':\n            return True\n        if mt.startswith('application/') and mt.endswith('+json'):\n            return True\n        return False\n </s> add         return (\n            mt == 'application/json'\n            or (mt.startswith('application/')) and mt.endswith('+json')\n        ) </s> remove         \"\"\"Parses the JSON request/response data and returns it.  By default\n        this function will return ``None`` if the mimetype is not\n        :mimetype:`application/json` but this can be overridden by the\n        ``force`` parameter. If parsing fails the\n        :meth:`on_json_loading_failed` method on the request object will be\n        invoked.\n\n        :param force: if set to ``True`` the mimetype is ignored.\n        :param silent: if set to ``True`` this method will fail silently\n                       and return ``None``.\n        :param cache: if set to ``True`` the parsed JSON data is remembered\n                      on the object.\n </s> add         \"\"\"Parse and return the data as JSON. If the mimetype does not indicate\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), this returns\n        ``None`` unless ``force`` is true. If parsing fails,\n        :meth:`on_json_loading_failed` is called and its return value is used\n        as the return value.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence parsing errors and return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent calls.", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep replace replace keep keep replace keep keep", "code_tokens": " <mask> \n <mask>     @property\n <mask>     def is_json(self):\n <mask>         \"\"\"Indicates if this request/response is in JSON format or not.  By\n <mask>         default it is considered to include JSON data if the mimetype is\n <mask>         :mimetype:`application/json` or :mimetype:`application/*+json`.\n <mask> \n <mask>         .. versionadded:: 1.0\n <mask>         \"\"\"\n <mask>         mt = self.mimetype\n </s> clean up JSON code and docs </s> remove     .. versionadded:: 0.12\n </s> add     .. versionadded:: 1.0 </s> remove         if mt == 'application/json':\n            return True\n        if mt.startswith('application/') and mt.endswith('+json'):\n            return True\n        return False\n </s> add         return (\n            mt == 'application/json'\n            or (mt.startswith('application/')) and mt.endswith('+json')\n        ) </s> add     _cached_json = Ellipsis\n </s> remove         getter = getattr(self, 'get_data', None)\n        if getter is not None:\n            return getter(cache=cache)\n        return self.data\n </s> add         return self.get_data(cache=cache) </s> remove         \"\"\"If this request/response is in JSON format then this property will\n        contain the parsed JSON data.  Otherwise it will be ``None``.\n </s> add         \"\"\"This will contain the parsed JSON data if the mimetype indicates\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), otherwise it\n        will be ``None``.", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep replace replace keep keep keep keep", "code_tokens": " <mask> \n <mask>         .. versionadded:: 1.0\n <mask>         \"\"\"\n <mask>         mt = self.mimetype\n <mask>         if mt == 'application/json':\n <mask>             return True\n <mask>         if mt.startswith('application/') and mt.endswith('+json'):\n <mask>             return True\n <mask>         return False\n <mask> \n <mask>     @property\n <mask>     def json(self):\n <mask>         \"\"\"If this request/response is in JSON format then this property will\n <mask>         contain the parsed JSON data.  Otherwise it will be ``None``.\n <mask> \n <mask>         The :meth:`get_json` method should be used instead.\n <mask>         \"\"\"\n <mask>         from warnings import warn\n </s> clean up JSON code and docs </s> remove         The :meth:`get_json` method should be used instead.\n </s> add         .. deprecated:: 1.0\n            Use :meth:`get_json` instead. </s> remove         .. versionadded:: 1.0\n </s> add         .. versionadded:: 0.11 </s> remove         from warnings import warn\n </s> add  </s> remove         \"\"\"Indicates if this request/response is in JSON format or not.  By\n        default it is considered to include JSON data if the mimetype is\n </s> add         \"\"\"Check if the mimetype indicates JSON data, either </s> remove             'json is deprecated.  Use get_json() instead.'), stacklevel=2)\n </s> add             \"'json' is deprecated. Use 'get_json()' instead.\"\n        ), stacklevel=2)", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep replace keep replace keep keep keep", "code_tokens": " <mask> \n <mask>         The :meth:`get_json` method should be used instead.\n <mask>         \"\"\"\n <mask>         from warnings import warn\n <mask>         warn(DeprecationWarning(\n <mask>             'json is deprecated.  Use get_json() instead.'), stacklevel=2)\n <mask>         return self.get_json()\n </s> clean up JSON code and docs </s> remove             'json is deprecated.  Use get_json() instead.'), stacklevel=2)\n </s> add             \"'json' is deprecated. Use 'get_json()' instead.\"\n        ), stacklevel=2) </s> remove         \"\"\"If this request/response is in JSON format then this property will\n        contain the parsed JSON data.  Otherwise it will be ``None``.\n </s> add         \"\"\"This will contain the parsed JSON data if the mimetype indicates\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), otherwise it\n        will be ``None``. </s> remove         getter = getattr(self, 'get_data', None)\n        if getter is not None:\n            return getter(cache=cache)\n        return self.data\n </s> add         return self.get_data(cache=cache) </s> remove         \"\"\"Called if decoding of the JSON data failed.  The return value of\n        this method is used by :meth:`get_json` when an error occurred.  The\n        default implementation just raises a :class:`BadRequest` exception.\n </s> add         \"\"\"Called if :meth:`get_json` parsing fails and isn't silenced. If\n        this method returns a value, it is used as the return value for\n        :meth:`get_json`. The default implementation raises a\n        :class:`BadRequest` exception. </s> add from warnings import warn", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep replace keep keep keep replace replace replace replace keep keep", "code_tokens": " <mask>         from warnings import warn\n <mask>         warn(DeprecationWarning(\n <mask>             'json is deprecated.  Use get_json() instead.'), stacklevel=2)\n <mask>         return self.get_json()\n <mask> \n <mask>     def _get_data_for_json(self, cache):\n <mask>         getter = getattr(self, 'get_data', None)\n <mask>         if getter is not None:\n <mask>             return getter(cache=cache)\n <mask>         return self.data\n <mask> \n <mask>     def get_json(self, force=False, silent=False, cache=True):\n </s> clean up JSON code and docs </s> remove         from warnings import warn\n </s> add  </s> remove         The :meth:`get_json` method should be used instead.\n </s> add         .. deprecated:: 1.0\n            Use :meth:`get_json` instead. </s> remove         \"\"\"Parses the JSON request/response data and returns it.  By default\n        this function will return ``None`` if the mimetype is not\n        :mimetype:`application/json` but this can be overridden by the\n        ``force`` parameter. If parsing fails the\n        :meth:`on_json_loading_failed` method on the request object will be\n        invoked.\n\n        :param force: if set to ``True`` the mimetype is ignored.\n        :param silent: if set to ``True`` this method will fail silently\n                       and return ``None``.\n        :param cache: if set to ``True`` the parsed JSON data is remembered\n                      on the object.\n </s> add         \"\"\"Parse and return the data as JSON. If the mimetype does not indicate\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), this returns\n        ``None`` unless ``force`` is true. If parsing fails,\n        :meth:`on_json_loading_failed` is called and its return value is used\n        as the return value.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence parsing errors and return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent calls. </s> remove         \"\"\"If this request/response is in JSON format then this property will\n        contain the parsed JSON data.  Otherwise it will be ``None``.\n </s> add         \"\"\"This will contain the parsed JSON data if the mimetype indicates\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), otherwise it\n        will be ``None``. </s> remove         try:\n            return getattr(self, '_cached_json')\n        except AttributeError:\n            pass\n </s> add         if cache and self._cached_json is not Ellipsis:\n            return self._cached_json", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace replace replace replace replace replace keep replace replace replace replace keep", "code_tokens": " <mask>     def get_json(self, force=False, silent=False, cache=True):\n <mask>         \"\"\"Parses the JSON request/response data and returns it.  By default\n <mask>         this function will return ``None`` if the mimetype is not\n <mask>         :mimetype:`application/json` but this can be overridden by the\n <mask>         ``force`` parameter. If parsing fails the\n <mask>         :meth:`on_json_loading_failed` method on the request object will be\n <mask>         invoked.\n <mask> \n <mask>         :param force: if set to ``True`` the mimetype is ignored.\n <mask>         :param silent: if set to ``True`` this method will fail silently\n <mask>                        and return ``None``.\n <mask>         :param cache: if set to ``True`` the parsed JSON data is remembered\n <mask>                       on the object.\n <mask>         \"\"\"\n <mask>         try:\n <mask>             return getattr(self, '_cached_json')\n <mask>         except AttributeError:\n <mask>             pass\n <mask> \n </s> clean up JSON code and docs </s> remove         getter = getattr(self, 'get_data', None)\n        if getter is not None:\n            return getter(cache=cache)\n        return self.data\n </s> add         return self.get_data(cache=cache) </s> remove         \"\"\"If this request/response is in JSON format then this property will\n        contain the parsed JSON data.  Otherwise it will be ``None``.\n </s> add         \"\"\"This will contain the parsed JSON data if the mimetype indicates\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), otherwise it\n        will be ``None``. </s> remove         \"\"\"Indicates if this request/response is in JSON format or not.  By\n        default it is considered to include JSON data if the mimetype is\n </s> add         \"\"\"Check if the mimetype indicates JSON data, either </s> remove         .. versionadded:: 1.0\n </s> add         .. versionadded:: 0.11 </s> remove         \"\"\"Called if decoding of the JSON data failed.  The return value of\n        this method is used by :meth:`get_json` when an error occurred.  The\n        default implementation just raises a :class:`BadRequest` exception.\n </s> add         \"\"\"Called if :meth:`get_json` parsing fails and isn't silenced. If\n        this method returns a value, it is used as the return value for\n        :meth:`get_json`. The default implementation raises a\n        :class:`BadRequest` exception.", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep replace replace replace replace keep keep replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask> \n <mask>         # We accept MIME charset header against the specification as certain\n <mask>         # clients have been using this in the past.  For responses, we assume\n <mask>         # that if the response charset was set explicitly then the data had\n <mask>         # been encoded correctly as well.\n <mask>         charset = self.mimetype_params.get('charset')\n <mask>         try:\n <mask>             data = self._get_data_for_json(cache)\n <mask>             if charset is not None:\n <mask>                 rv = json.loads(data, encoding=charset)\n <mask>             else:\n <mask>                 rv = json.loads(data)\n <mask>         except ValueError as e:\n <mask>             if silent:\n <mask>                 rv = None\n <mask>             else:\n </s> clean up JSON code and docs </s> remove         try:\n            return getattr(self, '_cached_json')\n        except AttributeError:\n            pass\n </s> add         if cache and self._cached_json is not Ellipsis:\n            return self._cached_json </s> remove         email = 'john@example.com'\n        password = 'secret'\n        resp = c.post('/api/auth', json={'login': email, 'password': password})\n\n        json_data = resp.get_json()\n </s> add         rv = c.post('/api/auth', json={\n            'username': 'flask', 'password': 'secret'\n        })\n        json_data = rv.get_json() </s> remove         kwargs['data'] = json_dumps(kwargs.pop('json'))\n </s> add         # push a context so flask.json can use app's json attributes\n        with app.app_context():\n            kwargs['data'] = json_dumps(kwargs.pop('json')) </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files:\n </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ): </s> remove         # Only set Content-Type when not explicitly provided\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep replace replace replace keep keep replace replace replace keep keep keep", "code_tokens": " <mask> \n <mask>     def on_json_loading_failed(self, e):\n <mask>         \"\"\"Called if decoding of the JSON data failed.  The return value of\n <mask>         this method is used by :meth:`get_json` when an error occurred.  The\n <mask>         default implementation just raises a :class:`BadRequest` exception.\n <mask> \n <mask>         .. versionchanged:: 0.10\n <mask>            Removed buggy previous behavior of generating a random JSON\n <mask>            response.  If you want that behavior back you can trivially\n <mask>            add it by subclassing.\n <mask> \n <mask>         .. versionadded:: 0.8\n <mask>         \"\"\"\n </s> clean up JSON code and docs </s> add     .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON. </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug:\n </s> add         if current_app is not None and current_app.debug: </s> remove - Added `json` keyword argument to :meth:`flask.testing.FlaskClient.open`\n  (and related ``get``, ``post``, etc.), which makes it more convenient to\n  send JSON requests from the test client.\n- Added ``is_json`` and ``get_json`` to :class:``flask.wrappers.Response``\n  in order to make it easier to build assertions when testing JSON responses.\n </s> add  </s> remove         The :meth:`get_json` method should be used instead.\n </s> add         .. deprecated:: 1.0\n            Use :meth:`get_json` instead. </s> remove         \"\"\"Parses the JSON request/response data and returns it.  By default\n        this function will return ``None`` if the mimetype is not\n        :mimetype:`application/json` but this can be overridden by the\n        ``force`` parameter. If parsing fails the\n        :meth:`on_json_loading_failed` method on the request object will be\n        invoked.\n\n        :param force: if set to ``True`` the mimetype is ignored.\n        :param silent: if set to ``True`` this method will fail silently\n                       and return ``None``.\n        :param cache: if set to ``True`` the parsed JSON data is remembered\n                      on the object.\n </s> add         \"\"\"Parse and return the data as JSON. If the mimetype does not indicate\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), this returns\n        ``None`` unless ``force`` is true. If parsing fails,\n        :meth:`on_json_loading_failed` is called and its return value is used\n        as the return value.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence parsing errors and return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent calls.", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>            add it by subclassing.\n <mask> \n <mask>         .. versionadded:: 0.8\n <mask>         \"\"\"\n <mask>         ctx = _app_ctx_stack.top\n <mask>         if ctx is not None and ctx.app.debug:\n <mask>             raise BadRequest('Failed to decode JSON object: {0}'.format(e))\n <mask>         raise BadRequest()\n <mask> \n <mask> \n <mask> class Request(RequestBase, JSONMixin):\n </s> clean up JSON code and docs </s> remove            Removed buggy previous behavior of generating a random JSON\n           response.  If you want that behavior back you can trivially\n           add it by subclassing.\n </s> add            Raise a :exc:`BadRequest` error instead of returning an error\n           message as JSON. If you want that behavior you can add it by\n           subclassing. </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files:\n </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ): </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None:\n            return ctx.app.config['MAX_CONTENT_LENGTH']\n </s> add         if current_app:\n            return current_app.config['MAX_CONTENT_LENGTH'] </s> remove         \"\"\"Called if decoding of the JSON data failed.  The return value of\n        this method is used by :meth:`get_json` when an error occurred.  The\n        default implementation just raises a :class:`BadRequest` exception.\n </s> add         \"\"\"Called if :meth:`get_json` parsing fails and isn't silenced. If\n        this method returns a value, it is used as the return value for\n        :meth:`get_json`. The default implementation raises a\n        :class:`BadRequest` exception. </s> remove         .. versionadded:: 1.0\n </s> add         .. versionadded:: 0.11 </s> remove     .. versionadded:: 0.12\n </s> add     .. versionadded:: 1.0", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     @property\n <mask>     def max_content_length(self):\n <mask>         \"\"\"Read-only view of the ``MAX_CONTENT_LENGTH`` config key.\"\"\"\n <mask>         ctx = _app_ctx_stack.top\n <mask>         if ctx is not None:\n <mask>             return ctx.app.config['MAX_CONTENT_LENGTH']\n <mask> \n <mask>     @property\n <mask>     def endpoint(self):\n <mask>         \"\"\"The endpoint that matched the request.  This in combination with\n <mask>         :attr:`view_args` can be used to reconstruct the same or a\n </s> clean up JSON code and docs </s> remove            Removed buggy previous behavior of generating a random JSON\n           response.  If you want that behavior back you can trivially\n           add it by subclassing.\n </s> add            Raise a :exc:`BadRequest` error instead of returning an error\n           message as JSON. If you want that behavior you can add it by\n           subclassing. </s> add     .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON. </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files:\n </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ): </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_) </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug:\n </s> add         if current_app is not None and current_app.debug: </s> remove         \"\"\"Indicates if this request/response is in JSON format or not.  By\n        default it is considered to include JSON data if the mimetype is\n </s> add         \"\"\"Check if the mimetype indicates JSON data, either", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         RequestBase._load_form_data(self)\n <mask> \n <mask>         # In debug mode we're replacing the files multidict with an ad-hoc\n <mask>         # subclass that raises a different error for key errors.\n <mask>         ctx = _app_ctx_stack.top\n <mask>         if ctx is not None and ctx.app.debug and \\\n <mask>            self.mimetype != 'multipart/form-data' and not self.files:\n <mask>             from .debughelpers import attach_enctype_error_multidict\n <mask>             attach_enctype_error_multidict(self)\n <mask> \n <mask> \n <mask> class Response(ResponseBase, JSONMixin):\n </s> clean up JSON code and docs </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug:\n </s> add         if current_app is not None and current_app.debug: </s> remove            Removed buggy previous behavior of generating a random JSON\n           response.  If you want that behavior back you can trivially\n           add it by subclassing.\n </s> add            Raise a :exc:`BadRequest` error instead of returning an error\n           message as JSON. If you want that behavior you can add it by\n           subclassing. </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None:\n            return ctx.app.config['MAX_CONTENT_LENGTH']\n </s> add         if current_app:\n            return current_app.config['MAX_CONTENT_LENGTH'] </s> remove         \"\"\"Called if decoding of the JSON data failed.  The return value of\n        this method is used by :meth:`get_json` when an error occurred.  The\n        default implementation just raises a :class:`BadRequest` exception.\n </s> add         \"\"\"Called if :meth:`get_json` parsing fails and isn't silenced. If\n        this method returns a value, it is used as the return value for\n        :meth:`get_json`. The default implementation raises a\n        :class:`BadRequest` exception. </s> remove         # We accept MIME charset header against the specification as certain\n        # clients have been using this in the past.  For responses, we assume\n        # that if the response charset was set explicitly then the data had\n        # been encoded correctly as well.\n </s> add         # We accept MIME charset against the specification as certain clients\n        # have used this in the past. For responses, we assume that if the\n        # charset is set then the data has been encoded correctly as well. </s> remove         kwargs['data'] = json_dumps(kwargs.pop('json'))\n </s> add         # push a context so flask.json can use app's json attributes\n        with app.app_context():\n            kwargs['data'] = json_dumps(kwargs.pop('json'))", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>     :meth:`~flask.Flask.make_response` will take care of that for you.\n <mask> \n <mask>     If you want to replace the response object used you can subclass this and\n <mask>     set :attr:`~flask.Flask.response_class` to your subclass.\n <mask>     \"\"\"\n <mask> \n <mask>     default_mimetype = 'text/html'\n <mask> \n <mask>     def _get_data_for_json(self, cache):\n </s> clean up JSON code and docs </s> remove            Removed buggy previous behavior of generating a random JSON\n           response.  If you want that behavior back you can trivially\n           add it by subclassing.\n </s> add            Raise a :exc:`BadRequest` error instead of returning an error\n           message as JSON. If you want that behavior you can add it by\n           subclassing. </s> remove         \"\"\"Called if decoding of the JSON data failed.  The return value of\n        this method is used by :meth:`get_json` when an error occurred.  The\n        default implementation just raises a :class:`BadRequest` exception.\n </s> add         \"\"\"Called if :meth:`get_json` parsing fails and isn't silenced. If\n        this method returns a value, it is used as the return value for\n        :meth:`get_json`. The default implementation raises a\n        :class:`BadRequest` exception. </s> remove         \"\"\"Parses the JSON request/response data and returns it.  By default\n        this function will return ``None`` if the mimetype is not\n        :mimetype:`application/json` but this can be overridden by the\n        ``force`` parameter. If parsing fails the\n        :meth:`on_json_loading_failed` method on the request object will be\n        invoked.\n\n        :param force: if set to ``True`` the mimetype is ignored.\n        :param silent: if set to ``True`` this method will fail silently\n                       and return ``None``.\n        :param cache: if set to ``True`` the parsed JSON data is remembered\n                      on the object.\n </s> add         \"\"\"Parse and return the data as JSON. If the mimetype does not indicate\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), this returns\n        ``None`` unless ``force`` is true. If parsing fails,\n        :meth:`on_json_loading_failed` is called and its return value is used\n        as the return value.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence parsing errors and return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent calls. </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_) </s> remove Note that if the ``json`` argument is provided then the test client will put\nJSON-serialized data in the request body, and also set the\n``Content-Type: application/json`` HTTP header.\n </s> add Passing the ``json`` argument in the test client methods sets the request data\nto the JSON-serialized object and sets the content type to\n``application/json``. You can get the JSON data from the request or response\nwith ``get_json``. </s> remove         getter = getattr(self, 'get_data', None)\n        if getter is not None:\n            return getter(cache=cache)\n        return self.data\n </s> add         return self.get_data(cache=cache)", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def test_json_request_and_response(app, client):\n <mask>     @app.route('/echo', methods=['POST'])\n <mask>     def echo():\n <mask>         return jsonify(flask.request.json)\n <mask> \n <mask>     with client:\n <mask>         json_data = {'drink': {'gin': 1, 'tonic': True}, 'price': 10}\n <mask>         rv = client.post('/echo', json=json_data)\n <mask> \n </s> clean up JSON code and docs </s> remove         email = 'john@example.com'\n        password = 'secret'\n        resp = c.post('/api/auth', json={'login': email, 'password': password})\n\n        json_data = resp.get_json()\n </s> add         rv = c.post('/api/auth', json={\n            'username': 'flask', 'password': 'secret'\n        })\n        json_data = rv.get_json() </s> remove             data = self._get_data_for_json(cache)\n            if charset is not None:\n                rv = json.loads(data, encoding=charset)\n            else:\n                rv = json.loads(data)\n </s> add             data = self._get_data_for_json(cache=cache)\n            rv = json.loads(data, encoding=charset) </s> remove     from flask import jsonify\n </s> add     from flask import request, jsonify </s> remove Note that if the ``json`` argument is provided then the test client will put\nJSON-serialized data in the request body, and also set the\n``Content-Type: application/json`` HTTP header.\n </s> add Passing the ``json`` argument in the test client methods sets the request data\nto the JSON-serialized object and sets the content type to\n``application/json``. You can get the JSON data from the request or response\nwith ``get_json``. </s> remove         \"\"\"Called if decoding of the JSON data failed.  The return value of\n        this method is used by :meth:`get_json` when an error occurred.  The\n        default implementation just raises a :class:`BadRequest` exception.\n </s> add         \"\"\"Called if :meth:`get_json` parsing fails and isn't silenced. If\n        this method returns a value, it is used as the return value for\n        :meth:`get_json`. The default implementation raises a\n        :class:`BadRequest` exception. </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None:\n            return ctx.app.config['MAX_CONTENT_LENGTH']\n </s> add         if current_app:\n            return current_app.config['MAX_CONTENT_LENGTH']", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "tests/test_testing.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>    reqcontext\n <mask>    blueprints\n <mask>    extensions\n <mask>    shell\n <mask>    patterns/index\n <mask>    deploying/index\n <mask>    becomingbig\n <mask> \n </s> Updated docs for click support </s> add Command Line Interface\n----------------------\n\nStarting with Flask 1.0 the recommended way to work with the shell is the\n``flask shell`` command which does a lot of this automatically for you.\nFor instance the shell is automatically initialized with a loaded\napplication context.\n\nFor more information see :ref:`cli`.\n </s> remove Why would you want to build URLs using the URL reversing function :func:`~flask.url_for` \ninstead of hard-coding them into your templates?  There are three good reasons \nfor this:\n </s> add Why would you want to build URLs using the URL reversing function\n:func:`~flask.url_for` instead of hard-coding them into your templates?\nThere are three good reasons for this: </s> remove Both methods have the exact same effect.\n </s> add There are more parameters that are explained in the :ref:`server` docs. </s> remove     app.run(debug=True)\n </s> add 1.  it activates the debugger\n2.  it activates the automatic reloader\n3.  it enables the debug mode on the Flask application. </s> remove Or pass it as a parameter to run::\n </s> add This does the following things: </s> remove     app.debug = True\n    app.run()\n </s> add     flask --debug -a hello run", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/contents.rst.inc"}
{"docstring_tokens": "keep keep keep replace replace replace keep keep keep keep replace keep keep", "code_tokens": " <mask>     def hello_world():\n <mask>         return 'Hello World!'\n <mask> \n <mask>     if __name__ == '__main__':\n <mask>         app.run()\n <mask> \n <mask> Just save it as `hello.py` (or something similar) and run it with your Python\n <mask> interpreter.  Make sure to not call your application `flask.py` because this\n <mask> would conflict with Flask itself.\n <mask> \n <mask> ::\n <mask> \n <mask>     $ python hello.py\n </s> Updated docs for click support </s> remove     $ python hello.py\n </s> add     $ python -m flask -a hello run </s> remove 5. Finally we use the :meth:`~flask.Flask.run` function to run the local server\n   with our application.  The ``if __name__ == '__main__':`` makes sure the\n   server only runs if the script is executed directly from the Python\n   interpreter and not used as an imported module.\n </s> add 5. Finally we use the Flask development server to run the local server\n   with our application. </s> remove The :meth:`~flask.Flask.run` method is nice to start a local\ndevelopment server, but you would have to restart it manually after each\nchange to your code.  That is not very nice and Flask can do better.  If\nyou enable debug support the server will reload itself on code changes,\nand it will also provide you with a helpful debugger if things go wrong.\n </s> add The ``flask`` script is nice to start a local development server, but\nyou would have to restart it manually after each change to your code.\nThat is not very nice and Flask can do better.  If you enable debug\nsupport the server will reload itself on code changes, and it will also\nprovide you with a helpful debugger if things go wrong. </s> remove There are two ways to enable debugging.  Either set that flag on the\napplication object::\n </s> add There are different ways to enable the debug mode.  The most obvious one\nis the ``--debug`` parameter to the ``flask`` command:: </s> remove Why would you want to build URLs using the URL reversing function :func:`~flask.url_for` \ninstead of hard-coding them into your templates?  There are three good reasons \nfor this:\n </s> add Why would you want to build URLs using the URL reversing function\n:func:`~flask.url_for` instead of hard-coding them into your templates?\nThere are three good reasons for this:", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> would conflict with Flask itself.\n <mask> \n <mask> ::\n <mask> \n <mask>     $ python hello.py\n <mask>      * Running on http://127.0.0.1:5000/\n <mask> \n <mask> Now head over to `http://127.0.0.1:5000/ <http://127.0.0.1:5000/>`_, and you\n <mask> should see your hello world greeting.\n <mask> \n </s> Updated docs for click support </s> remove ::\n </s> add To run the application you can either use the ``flask`` command or\npython's ``-m`` switch with Flask::\n\n    $ flask -a hello run\n     * Running on http://127.0.0.1:5000/\n\nor alternatively:: </s> remove     if __name__ == '__main__':\n        app.run()\n\n </s> add  </s> remove The :meth:`~flask.Flask.run` method is nice to start a local\ndevelopment server, but you would have to restart it manually after each\nchange to your code.  That is not very nice and Flask can do better.  If\nyou enable debug support the server will reload itself on code changes,\nand it will also provide you with a helpful debugger if things go wrong.\n </s> add The ``flask`` script is nice to start a local development server, but\nyou would have to restart it manually after each change to your code.\nThat is not very nice and Flask can do better.  If you enable debug\nsupport the server will reload itself on code changes, and it will also\nprovide you with a helpful debugger if things go wrong. </s> remove Why would you want to build URLs using the URL reversing function :func:`~flask.url_for` \ninstead of hard-coding them into your templates?  There are three good reasons \nfor this:\n </s> add Why would you want to build URLs using the URL reversing function\n:func:`~flask.url_for` instead of hard-coding them into your templates?\nThere are three good reasons for this: </s> remove        app.run(host='0.0.0.0')\n </s> add        flask -a hello run --host=0.0.0.0 </s> add Command Line Interface\n----------------------\n\nStarting with Flask 1.0 the recommended way to work with the shell is the\n``flask shell`` command which does a lot of this automatically for you.\nFor instance the shell is automatically initialized with a loaded\napplication context.\n\nFor more information see :ref:`cli`.\n", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>    should trigger our function.\n <mask> 4. The function is given a name which is also used to generate URLs for that\n <mask>    particular function, and returns the message we want to display in the\n <mask>    user's browser.\n <mask> 5. Finally we use the :meth:`~flask.Flask.run` function to run the local server\n <mask>    with our application.  The ``if __name__ == '__main__':`` makes sure the\n <mask>    server only runs if the script is executed directly from the Python\n <mask>    interpreter and not used as an imported module.\n <mask> \n <mask> To stop the server, hit control-C.\n <mask> \n <mask> .. _public-server:\n <mask> \n </s> Updated docs for click support </s> remove Why would you want to build URLs using the URL reversing function :func:`~flask.url_for` \ninstead of hard-coding them into your templates?  There are three good reasons \nfor this:\n </s> add Why would you want to build URLs using the URL reversing function\n:func:`~flask.url_for` instead of hard-coding them into your templates?\nThere are three good reasons for this: </s> remove The :meth:`~flask.Flask.run` method is nice to start a local\ndevelopment server, but you would have to restart it manually after each\nchange to your code.  That is not very nice and Flask can do better.  If\nyou enable debug support the server will reload itself on code changes,\nand it will also provide you with a helpful debugger if things go wrong.\n </s> add The ``flask`` script is nice to start a local development server, but\nyou would have to restart it manually after each change to your code.\nThat is not very nice and Flask can do better.  If you enable debug\nsupport the server will reload itself on code changes, and it will also\nprovide you with a helpful debugger if things go wrong. </s> add Command Line Interface\n----------------------\n\nStarting with Flask 1.0 the recommended way to work with the shell is the\n``flask shell`` command which does a lot of this automatically for you.\nFor instance the shell is automatically initialized with a loaded\napplication context.\n\nFor more information see :ref:`cli`.\n </s> remove There are two ways to enable debugging.  Either set that flag on the\napplication object::\n </s> add There are different ways to enable the debug mode.  The most obvious one\nis the ``--debug`` parameter to the ``flask`` command:: </s> remove    If you have `debug` disabled or trust the users on your network, you can\n   make the server publicly available simply by changing the call of the\n   :meth:`~flask.Flask.run` method to look like this::\n </s> add    If you have the debugger disabled or trust the users on your network,\n   you can make the server publicly available simply by adding\n   ``--host=0.0.0.0`` to the command line:: </s> remove Both methods have the exact same effect.\n </s> add There are more parameters that are explained in the :ref:`server` docs.", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep replace replace replace keep replace keep keep keep", "code_tokens": " <mask>    default because in debugging mode a user of the application can execute\n <mask>    arbitrary Python code on your computer.\n <mask> \n <mask>    If you have `debug` disabled or trust the users on your network, you can\n <mask>    make the server publicly available simply by changing the call of the\n <mask>    :meth:`~flask.Flask.run` method to look like this::\n <mask> \n <mask>        app.run(host='0.0.0.0')\n <mask> \n <mask>    This tells your operating system to listen on all public IPs.\n <mask> \n </s> Updated docs for click support </s> remove The :meth:`~flask.Flask.run` method is nice to start a local\ndevelopment server, but you would have to restart it manually after each\nchange to your code.  That is not very nice and Flask can do better.  If\nyou enable debug support the server will reload itself on code changes,\nand it will also provide you with a helpful debugger if things go wrong.\n </s> add The ``flask`` script is nice to start a local development server, but\nyou would have to restart it manually after each change to your code.\nThat is not very nice and Flask can do better.  If you enable debug\nsupport the server will reload itself on code changes, and it will also\nprovide you with a helpful debugger if things go wrong. </s> remove ::\n </s> add To run the application you can either use the ``flask`` command or\npython's ``-m`` switch with Flask::\n\n    $ flask -a hello run\n     * Running on http://127.0.0.1:5000/\n\nor alternatively:: </s> remove Why would you want to build URLs using the URL reversing function :func:`~flask.url_for` \ninstead of hard-coding them into your templates?  There are three good reasons \nfor this:\n </s> add Why would you want to build URLs using the URL reversing function\n:func:`~flask.url_for` instead of hard-coding them into your templates?\nThere are three good reasons for this: </s> remove There are two ways to enable debugging.  Either set that flag on the\napplication object::\n </s> add There are different ways to enable the debug mode.  The most obvious one\nis the ``--debug`` parameter to the ``flask`` command:: </s> add Command Line Interface\n----------------------\n\nStarting with Flask 1.0 the recommended way to work with the shell is the\n``flask shell`` command which does a lot of this automatically for you.\nFor instance the shell is automatically initialized with a loaded\napplication context.\n\nFor more information see :ref:`cli`.\n", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep replace replace keep", "code_tokens": " <mask> \n <mask> Debug Mode\n <mask> ----------\n <mask> \n <mask> The :meth:`~flask.Flask.run` method is nice to start a local\n <mask> development server, but you would have to restart it manually after each\n <mask> change to your code.  That is not very nice and Flask can do better.  If\n <mask> you enable debug support the server will reload itself on code changes,\n <mask> and it will also provide you with a helpful debugger if things go wrong.\n <mask> \n <mask> There are two ways to enable debugging.  Either set that flag on the\n <mask> application object::\n <mask> \n </s> Updated docs for click support </s> remove     app.debug = True\n    app.run()\n </s> add     flask --debug -a hello run </s> remove 5. Finally we use the :meth:`~flask.Flask.run` function to run the local server\n   with our application.  The ``if __name__ == '__main__':`` makes sure the\n   server only runs if the script is executed directly from the Python\n   interpreter and not used as an imported module.\n </s> add 5. Finally we use the Flask development server to run the local server\n   with our application. </s> remove    If you have `debug` disabled or trust the users on your network, you can\n   make the server publicly available simply by changing the call of the\n   :meth:`~flask.Flask.run` method to look like this::\n </s> add    If you have the debugger disabled or trust the users on your network,\n   you can make the server publicly available simply by adding\n   ``--host=0.0.0.0`` to the command line:: </s> remove Why would you want to build URLs using the URL reversing function :func:`~flask.url_for` \ninstead of hard-coding them into your templates?  There are three good reasons \nfor this:\n </s> add Why would you want to build URLs using the URL reversing function\n:func:`~flask.url_for` instead of hard-coding them into your templates?\nThere are three good reasons for this: </s> remove        app.run(host='0.0.0.0')\n </s> add        flask -a hello run --host=0.0.0.0", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep replace replace keep keep keep keep keep keep keep keep replace keep keep keep", "code_tokens": " <mask> application object::\n <mask> \n <mask>     app.debug = True\n <mask>     app.run()\n <mask> \n <mask> Or pass it as a parameter to run::\n <mask> \n <mask>     app.run(debug=True)\n <mask> \n <mask>     app.debug = True\n <mask>     app.run()\n <mask> \n <mask> Or pass it as a parameter to run::\n <mask> \n <mask>     app.run(debug=True)\n <mask> \n </s> Updated docs for click support </s> remove There are two ways to enable debugging.  Either set that flag on the\napplication object::\n </s> add There are different ways to enable the debug mode.  The most obvious one\nis the ``--debug`` parameter to the ``flask`` command:: </s> remove     app.run(debug=True)\n </s> add 1.  it activates the debugger\n2.  it activates the automatic reloader\n3.  it enables the debug mode on the Flask application. </s> remove Both methods have the exact same effect.\n </s> add There are more parameters that are explained in the :ref:`server` docs. </s> remove The :meth:`~flask.Flask.run` method is nice to start a local\ndevelopment server, but you would have to restart it manually after each\nchange to your code.  That is not very nice and Flask can do better.  If\nyou enable debug support the server will reload itself on code changes,\nand it will also provide you with a helpful debugger if things go wrong.\n </s> add The ``flask`` script is nice to start a local development server, but\nyou would have to restart it manually after each change to your code.\nThat is not very nice and Flask can do better.  If you enable debug\nsupport the server will reload itself on code changes, and it will also\nprovide you with a helpful debugger if things go wrong. </s> remove     if __name__ == '__main__':\n        app.run()\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask> Or pass it as a parameter to run::\n <mask> \n <mask>     app.run(debug=True)\n <mask> \n <mask> Both methods have the exact same effect.\n <mask> \n <mask> .. admonition:: Attention\n <mask> \n <mask>    Even though the interactive debugger does not work in forking environments\n </s> Updated docs for click support </s> remove Or pass it as a parameter to run::\n </s> add This does the following things: </s> remove     app.debug = True\n    app.run()\n </s> add     flask --debug -a hello run </s> remove There are two ways to enable debugging.  Either set that flag on the\napplication object::\n </s> add There are different ways to enable the debug mode.  The most obvious one\nis the ``--debug`` parameter to the ``flask`` command:: </s> remove Why would you want to build URLs using the URL reversing function :func:`~flask.url_for` \ninstead of hard-coding them into your templates?  There are three good reasons \nfor this:\n </s> add Why would you want to build URLs using the URL reversing function\n:func:`~flask.url_for` instead of hard-coding them into your templates?\nThere are three good reasons for this: </s> add Command Line Interface\n----------------------\n\nStarting with Flask 1.0 the recommended way to work with the shell is the\n``flask shell`` command which does a lot of this automatically for you.\nFor instance the shell is automatically initialized with a loaded\napplication context.\n\nFor more information see :ref:`cli`.\n", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> below.  It tells Flask to behave as though it is handling a request, even\n <mask> though we are interacting with it through a Python shell.  Have a look at the\n <mask> explanation below. :ref:`context-locals`).\n <mask> \n <mask> Why would you want to build URLs using the URL reversing function :func:`~flask.url_for` \n <mask> instead of hard-coding them into your templates?  There are three good reasons \n <mask> for this:\n <mask> \n <mask> 1. Reversing is often more descriptive than hard-coding the URLs.  More\n <mask>    importantly, it allows you to change URLs in one go, without having to\n <mask>    remember to change URLs all over the place.\n <mask> 2. URL building will handle escaping of special characters and Unicode\n </s> Updated docs for click support </s> remove 5. Finally we use the :meth:`~flask.Flask.run` function to run the local server\n   with our application.  The ``if __name__ == '__main__':`` makes sure the\n   server only runs if the script is executed directly from the Python\n   interpreter and not used as an imported module.\n </s> add 5. Finally we use the Flask development server to run the local server\n   with our application. </s> remove There are two ways to enable debugging.  Either set that flag on the\napplication object::\n </s> add There are different ways to enable the debug mode.  The most obvious one\nis the ``--debug`` parameter to the ``flask`` command:: </s> remove The :meth:`~flask.Flask.run` method is nice to start a local\ndevelopment server, but you would have to restart it manually after each\nchange to your code.  That is not very nice and Flask can do better.  If\nyou enable debug support the server will reload itself on code changes,\nand it will also provide you with a helpful debugger if things go wrong.\n </s> add The ``flask`` script is nice to start a local development server, but\nyou would have to restart it manually after each change to your code.\nThat is not very nice and Flask can do better.  If you enable debug\nsupport the server will reload itself on code changes, and it will also\nprovide you with a helpful debugger if things go wrong. </s> remove Both methods have the exact same effect.\n </s> add There are more parameters that are explained in the :ref:`server` docs. </s> remove    If you have `debug` disabled or trust the users on your network, you can\n   make the server publicly available simply by changing the call of the\n   :meth:`~flask.Flask.run` method to look like this::\n </s> add    If you have the debugger disabled or trust the users on your network,\n   you can make the server publicly available simply by adding\n   ``--host=0.0.0.0`` to the command line:: </s> add Command Line Interface\n----------------------\n\nStarting with Flask 1.0 the recommended way to work with the shell is the\n``flask shell`` command which does a lot of this automatically for you.\nFor instance the shell is automatically initialized with a loaded\napplication context.\n\nFor more information see :ref:`cli`.\n", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> Generally it's recommended that you read the :ref:`request-context`\n <mask> chapter of the documentation first.\n <mask> \n <mask> Creating a Request Context\n <mask> --------------------------\n <mask> \n <mask> The easiest way to create a proper request context from the shell is by\n </s> Updated docs for click support </s> remove    If you have `debug` disabled or trust the users on your network, you can\n   make the server publicly available simply by changing the call of the\n   :meth:`~flask.Flask.run` method to look like this::\n </s> add    If you have the debugger disabled or trust the users on your network,\n   you can make the server publicly available simply by adding\n   ``--host=0.0.0.0`` to the command line:: </s> remove 5. Finally we use the :meth:`~flask.Flask.run` function to run the local server\n   with our application.  The ``if __name__ == '__main__':`` makes sure the\n   server only runs if the script is executed directly from the Python\n   interpreter and not used as an imported module.\n </s> add 5. Finally we use the Flask development server to run the local server\n   with our application. </s> remove There are two ways to enable debugging.  Either set that flag on the\napplication object::\n </s> add There are different ways to enable the debug mode.  The most obvious one\nis the ``--debug`` parameter to the ``flask`` command:: </s> remove Why would you want to build URLs using the URL reversing function :func:`~flask.url_for` \ninstead of hard-coding them into your templates?  There are three good reasons \nfor this:\n </s> add Why would you want to build URLs using the URL reversing function\n:func:`~flask.url_for` instead of hard-coding them into your templates?\nThere are three good reasons for this: </s> remove        app.run(host='0.0.0.0')\n </s> add        flask -a hello run --host=0.0.0.0 </s> remove The :meth:`~flask.Flask.run` method is nice to start a local\ndevelopment server, but you would have to restart it manually after each\nchange to your code.  That is not very nice and Flask can do better.  If\nyou enable debug support the server will reload itself on code changes,\nand it will also provide you with a helpful debugger if things go wrong.\n </s> add The ``flask`` script is nice to start a local development server, but\nyou would have to restart it manually after each change to your code.\nThat is not very nice and Flask can do better.  If you enable debug\nsupport the server will reload itself on code changes, and it will also\nprovide you with a helpful debugger if things go wrong.", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> # |version| and |release|, also used in various other places throughout the\n <mask> # built documents.\n <mask> release = __import__('pkg_resources').get_distribution('Flask').version\n <mask> version = '.'.join(release.split('.')[:2])\n <mask> \n <mask> # The language for content autogenerated by Sphinx. Refer to documentation\n <mask> # for a list of supported languages.\n <mask> #language = None\n <mask> \n <mask> # There are two options for replacing |today|: either, you set today to some\n </s> Added a documentation chapter about logging </s> remove         in debug mode.\n </s> add         in debug mode.  This logger can be used to (surprise) log messages.\n        Here some examples::\n\n            app.logger.debug('A value for debugging')\n            app.logger.warning('A warning ocurred (%d apples)', 42)\n            app.logger.error('An error occoured') </s> remove             rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request()\n            response = self.make_response(rv)\n            response = self.process_response(response)\n </s> add             try:\n                rv = self.preprocess_request()\n                if rv is None:\n                    rv = self.dispatch_request()\n                response = self.make_response(rv)\n                response = self.process_response(response)\n            except Exception, e:\n                response = self.make_response(self.handle_exception(e)) </s> remove         '%(levelname)s in %(module)s, %(filename)s:%(lineno)d]:\\n' +\n </s> add         '%(levelname)s in %(module)s, %(pathname)s:%(lineno)d]:\\n' + </s> add For some better examples, checkout the :ref:`uploading-files` pattern.\n </s> remove         except Exception, e:\n            return self.handle_exception(e)\n </s> add  </s> add    errorhandling", "html_url": "https://github.com/pallets/flask/commit/ea5e654e9e19aab5089f9a71e679bcca11581e86", "file_name": "docs/conf.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>    installation\n <mask>    quickstart\n <mask>    tutorial/index\n <mask>    testing\n <mask>    patterns/index\n <mask>    deploying/index\n <mask>    becomingbig\n <mask> \n <mask> API Reference\n </s> Added a documentation chapter about logging </s> remove             rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request()\n            response = self.make_response(rv)\n            response = self.process_response(response)\n </s> add             try:\n                rv = self.preprocess_request()\n                if rv is None:\n                    rv = self.dispatch_request()\n                response = self.make_response(rv)\n                response = self.process_response(response)\n            except Exception, e:\n                response = self.make_response(self.handle_exception(e)) </s> remove         except Exception, e:\n            return self.handle_exception(e)\n </s> add  </s> remove         in debug mode.\n </s> add         in debug mode.  This logger can be used to (surprise) log messages.\n        Here some examples::\n\n            app.logger.debug('A value for debugging')\n            app.logger.warning('A warning ocurred (%d apples)', 42)\n            app.logger.error('An error occoured') </s> remove         '%(levelname)s in %(module)s, %(filename)s:%(lineno)d]:\\n' +\n </s> add         '%(levelname)s in %(module)s, %(pathname)s:%(lineno)d]:\\n' + </s> add For some better examples, checkout the :ref:`uploading-files` pattern.\n </s> add if 'dev' in version:\n    version = version.split('dev')[0]", "html_url": "https://github.com/pallets/flask/commit/ea5e654e9e19aab5089f9a71e679bcca11581e86", "file_name": "docs/contents.rst.inc"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>             f.save('/var/www/uploads/' + secure_filename(f.filename))\n <mask>         ...\n <mask> \n <mask> Cookies\n <mask> ```````\n <mask> \n <mask> To access cookies you can use the :attr:`~flask.request.cookies`\n <mask> attribute.  Again this is a dictionary with all the cookies the client\n </s> Added a documentation chapter about logging </s> remove             rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request()\n            response = self.make_response(rv)\n            response = self.process_response(response)\n </s> add             try:\n                rv = self.preprocess_request()\n                if rv is None:\n                    rv = self.dispatch_request()\n                response = self.make_response(rv)\n                response = self.process_response(response)\n            except Exception, e:\n                response = self.make_response(self.handle_exception(e)) </s> remove         '%(levelname)s in %(module)s, %(filename)s:%(lineno)d]:\\n' +\n </s> add         '%(levelname)s in %(module)s, %(pathname)s:%(lineno)d]:\\n' + </s> remove         in debug mode.\n </s> add         in debug mode.  This logger can be used to (surprise) log messages.\n        Here some examples::\n\n            app.logger.debug('A value for debugging')\n            app.logger.warning('A warning ocurred (%d apples)', 42)\n            app.logger.error('An error occoured') </s> remove         except Exception, e:\n            return self.handle_exception(e)\n </s> add  </s> add if 'dev' in version:\n    version = version.split('dev')[0] </s> add    errorhandling", "html_url": "https://github.com/pallets/flask/commit/ea5e654e9e19aab5089f9a71e679bcca11581e86", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     #:\n <mask>     #: .. versionadded:: 0.5\n <mask>     debug_log_format = (\n <mask>         '-' * 80 + '\\n' +\n <mask>         '%(levelname)s in %(module)s, %(filename)s:%(lineno)d]:\\n' +\n <mask>         '%(message)s\\n' +\n <mask>         '-' * 80\n <mask>     )\n <mask> \n <mask>     #: options that are passed directly to the Jinja2 environment\n </s> Added a documentation chapter about logging </s> add For some better examples, checkout the :ref:`uploading-files` pattern.\n </s> add if 'dev' in version:\n    version = version.split('dev')[0] </s> remove             rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request()\n            response = self.make_response(rv)\n            response = self.process_response(response)\n </s> add             try:\n                rv = self.preprocess_request()\n                if rv is None:\n                    rv = self.dispatch_request()\n                response = self.make_response(rv)\n                response = self.process_response(response)\n            except Exception, e:\n                response = self.make_response(self.handle_exception(e)) </s> remove         except Exception, e:\n            return self.handle_exception(e)\n </s> add  </s> remove         in debug mode.\n </s> add         in debug mode.  This logger can be used to (surprise) log messages.\n        Here some examples::\n\n            app.logger.debug('A value for debugging')\n            app.logger.warning('A warning ocurred (%d apples)', 42)\n            app.logger.error('An error occoured') </s> add    errorhandling", "html_url": "https://github.com/pallets/flask/commit/ea5e654e9e19aab5089f9a71e679bcca11581e86", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @cached_property\n <mask>     def logger(self):\n <mask>         \"\"\"A :class:`logging.Logger` object for this application.  The\n <mask>         default configuration is to log to stderr if the application is\n <mask>         in debug mode.\n <mask>         \"\"\"\n <mask>         from logging import getLogger, StreamHandler, Formatter, DEBUG\n <mask>         class DebugHandler(StreamHandler):\n <mask>             def emit(x, record):\n <mask>                 if self.debug:\n </s> Added a documentation chapter about logging </s> remove             rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request()\n            response = self.make_response(rv)\n            response = self.process_response(response)\n </s> add             try:\n                rv = self.preprocess_request()\n                if rv is None:\n                    rv = self.dispatch_request()\n                response = self.make_response(rv)\n                response = self.process_response(response)\n            except Exception, e:\n                response = self.make_response(self.handle_exception(e)) </s> add if 'dev' in version:\n    version = version.split('dev')[0] </s> remove         except Exception, e:\n            return self.handle_exception(e)\n </s> add  </s> add For some better examples, checkout the :ref:`uploading-files` pattern.\n </s> remove         '%(levelname)s in %(module)s, %(filename)s:%(lineno)d]:\\n' +\n </s> add         '%(levelname)s in %(module)s, %(pathname)s:%(lineno)d]:\\n' + </s> add    errorhandling", "html_url": "https://github.com/pallets/flask/commit/ea5e654e9e19aab5089f9a71e679bcca11581e86", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 raise req.routing_exception\n <mask>             return self.view_functions[req.endpoint](**req.view_args)\n <mask>         except HTTPException, e:\n <mask>             return self.handle_http_exception(e)\n <mask>         except Exception, e:\n <mask>             return self.handle_exception(e)\n <mask> \n <mask>     def make_response(self, rv):\n <mask>         \"\"\"Converts the return value from a view function to a real\n <mask>         response object that is an instance of :attr:`response_class`.\n <mask> \n </s> Added a documentation chapter about logging </s> remove             rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request()\n            response = self.make_response(rv)\n            response = self.process_response(response)\n </s> add             try:\n                rv = self.preprocess_request()\n                if rv is None:\n                    rv = self.dispatch_request()\n                response = self.make_response(rv)\n                response = self.process_response(response)\n            except Exception, e:\n                response = self.make_response(self.handle_exception(e)) </s> remove         in debug mode.\n </s> add         in debug mode.  This logger can be used to (surprise) log messages.\n        Here some examples::\n\n            app.logger.debug('A value for debugging')\n            app.logger.warning('A warning ocurred (%d apples)', 42)\n            app.logger.error('An error occoured') </s> add For some better examples, checkout the :ref:`uploading-files` pattern.\n </s> remove         '%(levelname)s in %(module)s, %(filename)s:%(lineno)d]:\\n' +\n </s> add         '%(levelname)s in %(module)s, %(pathname)s:%(lineno)d]:\\n' + </s> add if 'dev' in version:\n    version = version.split('dev')[0] </s> add    errorhandling", "html_url": "https://github.com/pallets/flask/commit/ea5e654e9e19aab5089f9a71e679bcca11581e86", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                                a list of headers and an optional\n <mask>                                exception context to start the response\n <mask>         \"\"\"\n <mask>         with self.request_context(environ):\n <mask>             rv = self.preprocess_request()\n <mask>             if rv is None:\n <mask>                 rv = self.dispatch_request()\n <mask>             response = self.make_response(rv)\n <mask>             response = self.process_response(response)\n <mask>             return response(environ, start_response)\n <mask> \n <mask>     def request_context(self, environ):\n <mask>         \"\"\"Creates a request context from the given environment and binds\n <mask>         it to the current context.  This must be used in combination with\n </s> Added a documentation chapter about logging </s> remove         except Exception, e:\n            return self.handle_exception(e)\n </s> add  </s> add if 'dev' in version:\n    version = version.split('dev')[0] </s> remove         in debug mode.\n </s> add         in debug mode.  This logger can be used to (surprise) log messages.\n        Here some examples::\n\n            app.logger.debug('A value for debugging')\n            app.logger.warning('A warning ocurred (%d apples)', 42)\n            app.logger.error('An error occoured') </s> add For some better examples, checkout the :ref:`uploading-files` pattern.\n </s> remove         '%(levelname)s in %(module)s, %(filename)s:%(lineno)d]:\\n' +\n </s> add         '%(levelname)s in %(module)s, %(pathname)s:%(lineno)d]:\\n' + </s> add    errorhandling", "html_url": "https://github.com/pallets/flask/commit/ea5e654e9e19aab5089f9a71e679bcca11581e86", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         if isinstance(code_or_exception, integer_types):\n <mask>             assert code_or_exception != 500 or key is None, \\\n <mask>                 'It is currently not possible to register a 500 internal ' \\\n <mask>                 'server error on a per-blueprint level.'\n <mask>             self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n <mask>         else:\n <mask>             self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n <mask>                 .append((code_or_exception, f))\n <mask> \n <mask>     @setupmethod\n <mask>     def template_filter(self, name=None):\n <mask>         \"\"\"A decorator that is used to register custom template filter.\n <mask>         You can specify a name for the filter, otherwise the function\n </s> Fixed and intuitivized exception handling </s> remove \n        blueprint_handlers = ()\n        handlers = self.error_handler_spec.get(request.blueprint)\n        if handlers is not None:\n            blueprint_handlers = handlers.get(None, ())\n        app_handlers = self.error_handler_spec[None].get(None, ())\n        for typecheck, handler in chain(blueprint_handlers, app_handlers):\n            if isinstance(e, typecheck):\n                return handler(e)\n\n </s> add          </s> remove         reraise(exc_type, exc_value, tb)\n </s> add         handler = self._find_error_handler(e)\n        \n        if handler is None:\n            reraise(exc_type, exc_value, tb)\n        return handler(e) </s> remove         if handlers and e.code in handlers:\n            handler = handlers[e.code]\n        else:\n            handler = self.error_handler_spec[None].get(e.code)\n </s> add         \n        handler = self._find_error_handler(e) </s> remove         handlers = self.error_handler_spec.get(request.blueprint)\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/eae48d97b085626c1860a900a27ff63c439e0edb", "file_name": "flask/app.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace replace replace replace keep", "code_tokens": " <mask>         \"\"\"\n <mask>         handlers = self.error_handler_spec.get(request.blueprint)\n <mask>         # Proxy exceptions don't have error codes.  We want to always return\n <mask>         # those unchanged as errors\n <mask>         if e.code is None:\n <mask>             return e\n <mask>         if handlers and e.code in handlers:\n <mask>             handler = handlers[e.code]\n <mask>         else:\n <mask>             handler = self.error_handler_spec[None].get(e.code)\n <mask>         if handler is None:\n </s> Fixed and intuitivized exception handling </s> remove \n        blueprint_handlers = ()\n        handlers = self.error_handler_spec.get(request.blueprint)\n        if handlers is not None:\n            blueprint_handlers = handlers.get(None, ())\n        app_handlers = self.error_handler_spec[None].get(None, ())\n        for typecheck, handler in chain(blueprint_handlers, app_handlers):\n            if isinstance(e, typecheck):\n                return handler(e)\n\n </s> add          </s> remove         reraise(exc_type, exc_value, tb)\n </s> add         handler = self._find_error_handler(e)\n        \n        if handler is None:\n            reraise(exc_type, exc_value, tb)\n        return handler(e) </s> remove             self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f))\n </s> add         \n        handlers[code_or_exception] = f", "html_url": "https://github.com/pallets/flask/commit/eae48d97b085626c1860a900a27ff63c439e0edb", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep keep keep keep replace keep", "code_tokens": " <mask>         # ensure not to trash sys.exc_info() at that point in case someone\n <mask>         # wants the traceback preserved in handle_http_exception.  Of course\n <mask>         # we cannot prevent users from trashing it themselves in a custom\n <mask>         # trap_http_exception method so that's their fault then.\n <mask> \n <mask>         blueprint_handlers = ()\n <mask>         handlers = self.error_handler_spec.get(request.blueprint)\n <mask>         if handlers is not None:\n <mask>             blueprint_handlers = handlers.get(None, ())\n <mask>         app_handlers = self.error_handler_spec[None].get(None, ())\n <mask>         for typecheck, handler in chain(blueprint_handlers, app_handlers):\n <mask>             if isinstance(e, typecheck):\n <mask>                 return handler(e)\n <mask> \n <mask>         if isinstance(e, HTTPException) and not self.trap_http_exception(e):\n <mask>             return self.handle_http_exception(e)\n <mask> \n <mask>         reraise(exc_type, exc_value, tb)\n <mask> \n <mask>         if isinstance(e, HTTPException) and not self.trap_http_exception(e):\n <mask>             return self.handle_http_exception(e)\n <mask> \n <mask>         reraise(exc_type, exc_value, tb)\n <mask> \n </s> Fixed and intuitivized exception handling </s> remove         if handlers and e.code in handlers:\n            handler = handlers[e.code]\n        else:\n            handler = self.error_handler_spec[None].get(e.code)\n </s> add         \n        handler = self._find_error_handler(e) </s> remove         handlers = self.error_handler_spec.get(request.blueprint)\n </s> add  </s> remove             self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f))\n </s> add         \n        handlers[code_or_exception] = f", "html_url": "https://github.com/pallets/flask/commit/eae48d97b085626c1860a900a27ff63c439e0edb", "file_name": "flask/app.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> -   Refactor ``register_error_handler`` to consolidate error checking.\n <mask>     Rewrite some error messages to be more consistent. :issue:`4559`\n <mask> \n <mask> \n <mask> Version 2.1.2\n <mask> -------------\n <mask> \n </s> always warn on blueprint setupmethod after registration </s> remove         if self._got_registered_once and self.warn_on_modifications:\n </s> add         if self._got_registered_once:\n            # TODO: Upgrade this to an error and unify it setupmethod in 2.3 </s> add     @setupmethod </s> remove     warn_on_modifications = False\n </s> add  </s> remove                     \" up.\"\n </s> add                     \" up.\\n This warning will be become an exception in 2.3.\" </s> add     @setupmethod </s> add     from .wrappers import Response", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     .. versionadded:: 0.7\n <mask>     \"\"\"\n <mask> \n <mask>     warn_on_modifications = False\n <mask>     _got_registered_once = False\n <mask> \n <mask>     #: Blueprint local JSON encoder class to use. Set to ``None`` to use\n <mask>     #: the app's :class:`~flask.Flask.json_encoder`.\n <mask>     json_encoder = None\n </s> always warn on blueprint setupmethod after registration </s> add -   Use Blueprint decorators and functions intended for setup after\n    registering the blueprint will show a warning. In the next version,\n    this will become an error just like the application setup methods.\n    :issue:`4571` </s> add     @setupmethod </s> remove         if self._got_registered_once and self.warn_on_modifications:\n </s> add         if self._got_registered_once:\n            # TODO: Upgrade this to an error and unify it setupmethod in 2.3 </s> add     @setupmethod </s> remove         return self.warn_on_modifications and self._got_registered_once\n </s> add         return self._got_registered_once </s> add     from .wrappers import Response", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.cli_group = cli_group\n <mask>         self._blueprints: t.List[t.Tuple[\"Blueprint\", dict]] = []\n <mask> \n <mask>     def _is_setup_finished(self) -> bool:\n <mask>         return self.warn_on_modifications and self._got_registered_once\n <mask> \n <mask>     def record(self, func: t.Callable) -> None:\n <mask>         \"\"\"Registers a function that is called when the blueprint is\n <mask>         registered on the application.  This function is called with the\n <mask>         state as argument as returned by the :meth:`make_setup_state`\n </s> always warn on blueprint setupmethod after registration </s> remove         if self._got_registered_once and self.warn_on_modifications:\n </s> add         if self._got_registered_once:\n            # TODO: Upgrade this to an error and unify it setupmethod in 2.3 </s> add     @setupmethod </s> remove                     \" up.\"\n </s> add                     \" up.\\n This warning will be become an exception in 2.3.\" </s> add     @setupmethod </s> add -   Use Blueprint decorators and functions intended for setup after\n    registering the blueprint will show a warning. In the next version,\n    this will become an error just like the application setup methods.\n    :issue:`4571` </s> remove     warn_on_modifications = False\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         registered on the application.  This function is called with the\n <mask>         state as argument as returned by the :meth:`make_setup_state`\n <mask>         method.\n <mask>         \"\"\"\n <mask>         if self._got_registered_once and self.warn_on_modifications:\n <mask>             from warnings import warn\n <mask> \n <mask>             warn(\n <mask>                 Warning(\n <mask>                     \"The blueprint was already registered once but is\"\n </s> always warn on blueprint setupmethod after registration </s> remove         return self.warn_on_modifications and self._got_registered_once\n </s> add         return self._got_registered_once </s> remove                     \" up.\"\n </s> add                     \" up.\\n This warning will be become an exception in 2.3.\" </s> add     @setupmethod </s> remove     from .wrappers import Response\n </s> add  </s> add     @setupmethod </s> add     from .wrappers import Response", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             warn(\n <mask>                 Warning(\n <mask>                     \"The blueprint was already registered once but is\"\n <mask>                     \" getting modified now. These changes will not show\"\n <mask>                     \" up.\"\n <mask>                 )\n <mask>             )\n <mask>         self.deferred_functions.append(func)\n <mask> \n <mask>     def record_once(self, func: t.Callable) -> None:\n </s> always warn on blueprint setupmethod after registration </s> remove         if self._got_registered_once and self.warn_on_modifications:\n </s> add         if self._got_registered_once:\n            # TODO: Upgrade this to an error and unify it setupmethod in 2.3 </s> remove         return self.warn_on_modifications and self._got_registered_once\n </s> add         return self._got_registered_once </s> add -   Use Blueprint decorators and functions intended for setup after\n    registering the blueprint will show a warning. In the next version,\n    this will become an error just like the application setup methods.\n    :issue:`4571` </s> add     @setupmethod </s> add     @setupmethod </s> add     from .wrappers import Response", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from .typing import URLDefaultCallable\n <mask> from .typing import URLValuePreprocessorCallable\n <mask> \n <mask> if t.TYPE_CHECKING:  # pragma: no cover\n <mask>     from .wrappers import Response\n <mask>     from .typing import ErrorHandlerCallable\n <mask> \n <mask> # a singleton sentinel value for parameter defaults\n <mask> _sentinel = object()\n <mask> \n </s> always warn on blueprint setupmethod after registration </s> add     from .wrappers import Response </s> remove         if self._got_registered_once and self.warn_on_modifications:\n </s> add         if self._got_registered_once:\n            # TODO: Upgrade this to an error and unify it setupmethod in 2.3 </s> add     @setupmethod </s> remove         return self.warn_on_modifications and self._got_registered_once\n </s> add         return self._got_registered_once </s> add -   Use Blueprint decorators and functions intended for setup after\n    registering the blueprint will show a warning. In the next version,\n    this will become an error just like the application setup methods.\n    :issue:`4571` </s> add     @setupmethod", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> if t.TYPE_CHECKING:  # pragma: no cover\n <mask>     from .typing import ErrorHandlerCallable\n <mask> \n <mask> # a singleton sentinel value for parameter defaults\n <mask> _sentinel = object()\n <mask> \n <mask> F = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n <mask> \n </s> always warn on blueprint setupmethod after registration </s> remove     from .wrappers import Response\n </s> add  </s> remove         if self._got_registered_once and self.warn_on_modifications:\n </s> add         if self._got_registered_once:\n            # TODO: Upgrade this to an error and unify it setupmethod in 2.3 </s> add     @setupmethod </s> remove         return self.warn_on_modifications and self._got_registered_once\n </s> add         return self._got_registered_once </s> remove     warn_on_modifications = False\n </s> add  </s> add -   Use Blueprint decorators and functions intended for setup after\n    registering the blueprint will show a warning. In the next version,\n    this will become an error just like the application setup methods.\n    :issue:`4571`", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         return self._method_route(\"PATCH\", rule, options)\n <mask> \n <mask>     def route(self, rule: str, **options: t.Any) -> t.Callable[[F], F]:\n <mask>         \"\"\"Decorate a view function to register it with the given URL\n <mask>         rule and options. Calls :meth:`add_url_rule`, which has more\n <mask>         details about the implementation.\n </s> always warn on blueprint setupmethod after registration </s> add     @setupmethod </s> remove         return self.warn_on_modifications and self._got_registered_once\n </s> add         return self._got_registered_once </s> remove         if self._got_registered_once and self.warn_on_modifications:\n </s> add         if self._got_registered_once:\n            # TODO: Upgrade this to an error and unify it setupmethod in 2.3 </s> add -   Use Blueprint decorators and functions intended for setup after\n    registering the blueprint will show a warning. In the next version,\n    this will become an error just like the application setup methods.\n    :issue:`4571` </s> remove     warn_on_modifications = False\n </s> add  </s> add     from .wrappers import Response", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         raise NotImplementedError\n <mask> \n <mask>     def endpoint(self, endpoint: str) -> t.Callable:\n <mask>         \"\"\"Decorate a view function to register it for the given\n <mask>         endpoint. Used if a rule is added without a ``view_func`` with\n <mask>         :meth:`add_url_rule`.\n <mask> \n </s> always warn on blueprint setupmethod after registration </s> add     @setupmethod </s> remove         return self.warn_on_modifications and self._got_registered_once\n </s> add         return self._got_registered_once </s> remove         if self._got_registered_once and self.warn_on_modifications:\n </s> add         if self._got_registered_once:\n            # TODO: Upgrade this to an error and unify it setupmethod in 2.3 </s> add -   Use Blueprint decorators and functions intended for setup after\n    registering the blueprint will show a warning. In the next version,\n    this will become an error just like the application setup methods.\n    :issue:`4571` </s> add     from .wrappers import Response </s> remove     from .wrappers import Response\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Unreleased\n <mask> \n <mask> -   Add an ``app.redirect`` method, which ``flask.redirect`` will call.\n <mask>     This makes it possible for an app to override how redirects work.\n <mask>     :issue:`4569`\n <mask> -   Refactor ``register_error_handler`` to consolidate error checking.\n <mask>     Rewrite some error messages to be more consistent. :issue:`4559`\n <mask> \n </s> add aborter object to app </s> add     def make_aborter(self) -> Aborter:\n        \"\"\"Create the object to assign to :attr:`aborter`. That object\n        is called by :func:`flask.abort` to raise HTTP errors, and can\n        be called directly as well.\n\n        By default, this creates an instance of :attr:`aborter_class`,\n        which defaults to :class:`werkzeug.exceptions.Aborter`.\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return self.aborter_class()\n </s> add     #: The class of the object assigned to :attr:`aborter`, created by\n    #: :meth:`create_aborter`. That object is called by\n    #: :func:`flask.abort` to raise HTTP errors, and can be\n    #: called directly as well.\n    #:\n    #: Defaults to :class:`werkzeug.exceptions.Aborter`.\n    #:\n    #: .. versionadded:: 2.2\n    aborter_class = Aborter\n </s> add         #: An instance of :attr:`aborter_class` created by\n        #: :meth:`make_aborter`. This is called by :func:`flask.abort`\n        #: to raise HTTP errors, and can be called directly as well.\n        #:\n        #: .. versionadded:: 2.2\n        self.aborter = self.make_aborter()\n </s> add     import typing_extensions as te </s> add from werkzeug.exceptions import abort as _wz_abort </s> add from werkzeug.exceptions import Aborter", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from markupsafe import escape\n <mask> from markupsafe import Markup\n <mask> from werkzeug.exceptions import abort as abort\n <mask> \n <mask> from . import json as json\n <mask> from .app import Flask as Flask\n <mask> from .app import Request as Request\n <mask> from .app import Response as Response\n </s> add aborter object to app </s> add from .helpers import abort as abort </s> add from werkzeug.exceptions import abort as _wz_abort </s> add     import typing_extensions as te </s> add from werkzeug.exceptions import Aborter </s> add     #: The class of the object assigned to :attr:`aborter`, created by\n    #: :meth:`create_aborter`. That object is called by\n    #: :func:`flask.abort` to raise HTTP errors, and can be\n    #: called directly as well.\n    #:\n    #: Defaults to :class:`werkzeug.exceptions.Aborter`.\n    #:\n    #: .. versionadded:: 2.2\n    aborter_class = Aborter\n </s> add -   Add ``aborter_class`` and ``aborter`` attributes to the Flask app\n    object. ``flask.abort`` will call ``app.aborter``. This makes it\n    possible for an app to override how aborts work, including custom\n    status codes. :issue:`4567`", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "src/flask/__init__.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> from .globals import g as g\n <mask> from .globals import request as request\n <mask> from .globals import session as session\n <mask> from .helpers import flash as flash\n <mask> from .helpers import get_flashed_messages as get_flashed_messages\n <mask> from .helpers import get_template_attribute as get_template_attribute\n <mask> from .helpers import make_response as make_response\n <mask> from .helpers import redirect as redirect\n </s> add aborter object to app </s> add from werkzeug.exceptions import abort as _wz_abort </s> remove from werkzeug.exceptions import abort as abort\n </s> add  </s> add     import typing_extensions as te </s> add from werkzeug.exceptions import Aborter </s> add         #: An instance of :attr:`aborter_class` created by\n        #: :meth:`make_aborter`. This is called by :func:`flask.abort`\n        #: to raise HTTP errors, and can be called directly as well.\n        #:\n        #: .. versionadded:: 2.2\n        self.aborter = self.make_aborter()\n </s> add     def make_aborter(self) -> Aborter:\n        \"\"\"Create the object to assign to :attr:`aborter`. That object\n        is called by :func:`flask.abort` to raise HTTP errors, and can\n        be called directly as well.\n\n        By default, this creates an instance of :attr:`aborter_class`,\n        which defaults to :class:`werkzeug.exceptions.Aborter`.\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return self.aborter_class()\n", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "src/flask/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> from werkzeug.datastructures import Headers\n <mask> from werkzeug.datastructures import ImmutableDict\n <mask> from werkzeug.exceptions import BadRequest\n <mask> from werkzeug.exceptions import BadRequestKeyError\n <mask> from werkzeug.exceptions import HTTPException\n <mask> from werkzeug.exceptions import InternalServerError\n </s> add aborter object to app </s> add from werkzeug.exceptions import abort as _wz_abort </s> remove from werkzeug.exceptions import abort as abort\n </s> add  </s> add from .helpers import abort as abort </s> add     import typing_extensions as te </s> add     def make_aborter(self) -> Aborter:\n        \"\"\"Create the object to assign to :attr:`aborter`. That object\n        is called by :func:`flask.abort` to raise HTTP errors, and can\n        be called directly as well.\n\n        By default, this creates an instance of :attr:`aborter_class`,\n        which defaults to :class:`werkzeug.exceptions.Aborter`.\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return self.aborter_class()\n </s> add         #: An instance of :attr:`aborter_class` created by\n        #: :meth:`make_aborter`. This is called by :func:`flask.abort`\n        #: to raise HTTP errors, and can be called directly as well.\n        #:\n        #: .. versionadded:: 2.2\n        self.aborter = self.make_aborter()\n", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     #: The class that is used for response objects.  See\n <mask>     #: :class:`~flask.Response` for more information.\n <mask>     response_class = Response\n <mask> \n <mask>     #: The class that is used for the Jinja environment.\n <mask>     #:\n <mask>     #: .. versionadded:: 0.11\n <mask>     jinja_environment = Environment\n <mask> \n <mask>     #: The class that is used for the :data:`~flask.g` instance.\n </s> add aborter object to app </s> add         #: An instance of :attr:`aborter_class` created by\n        #: :meth:`make_aborter`. This is called by :func:`flask.abort`\n        #: to raise HTTP errors, and can be called directly as well.\n        #:\n        #: .. versionadded:: 2.2\n        self.aborter = self.make_aborter()\n </s> add -   Add ``aborter_class`` and ``aborter`` attributes to the Flask app\n    object. ``flask.abort`` will call ``app.aborter``. This makes it\n    possible for an app to override how aborts work, including custom\n    status codes. :issue:`4567` </s> add     import typing_extensions as te </s> add     def make_aborter(self) -> Aborter:\n        \"\"\"Create the object to assign to :attr:`aborter`. That object\n        is called by :func:`flask.abort` to raise HTTP errors, and can\n        be called directly as well.\n\n        By default, this creates an instance of :attr:`aborter_class`,\n        which defaults to :class:`werkzeug.exceptions.Aborter`.\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return self.aborter_class()\n </s> remove from werkzeug.exceptions import abort as abort\n </s> add  </s> add from werkzeug.exceptions import abort as _wz_abort", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         self.config = self.make_config(instance_relative_config)\n <mask> \n <mask>         #: A list of functions that are called when :meth:`url_for` raises a\n <mask>         #: :exc:`~werkzeug.routing.BuildError`.  Each function registered here\n <mask>         #: is called with `error`, `endpoint` and `values`.  If a function\n <mask>         #: returns ``None`` or raises a :exc:`BuildError` the next function is\n </s> add aborter object to app </s> add     #: The class of the object assigned to :attr:`aborter`, created by\n    #: :meth:`create_aborter`. That object is called by\n    #: :func:`flask.abort` to raise HTTP errors, and can be\n    #: called directly as well.\n    #:\n    #: Defaults to :class:`werkzeug.exceptions.Aborter`.\n    #:\n    #: .. versionadded:: 2.2\n    aborter_class = Aborter\n </s> add     def make_aborter(self) -> Aborter:\n        \"\"\"Create the object to assign to :attr:`aborter`. That object\n        is called by :func:`flask.abort` to raise HTTP errors, and can\n        be called directly as well.\n\n        By default, this creates an instance of :attr:`aborter_class`,\n        which defaults to :class:`werkzeug.exceptions.Aborter`.\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return self.aborter_class()\n </s> add     import typing_extensions as te </s> add -   Add ``aborter_class`` and ``aborter`` attributes to the Flask app\n    object. ``flask.abort`` will call ``app.aborter``. This makes it\n    possible for an app to override how aborts work, including custom\n    status codes. :issue:`4567` </s> add from werkzeug.exceptions import abort as _wz_abort </s> add from werkzeug.exceptions import Aborter", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         defaults[\"DEBUG\"] = get_debug_flag()\n <mask>         return self.config_class(root_path, defaults)\n <mask> \n <mask>     def auto_find_instance_path(self) -> str:\n <mask>         \"\"\"Tries to locate the instance path if it was not provided to the\n <mask>         constructor of the application class.  It will basically calculate\n <mask>         the path to a folder named ``instance`` next to your main file or\n </s> add aborter object to app </s> add         #: An instance of :attr:`aborter_class` created by\n        #: :meth:`make_aborter`. This is called by :func:`flask.abort`\n        #: to raise HTTP errors, and can be called directly as well.\n        #:\n        #: .. versionadded:: 2.2\n        self.aborter = self.make_aborter()\n </s> add     import typing_extensions as te </s> add -   Add ``aborter_class`` and ``aborter`` attributes to the Flask app\n    object. ``flask.abort`` will call ``app.aborter``. This makes it\n    possible for an app to override how aborts work, including custom\n    status codes. :issue:`4567` </s> add     #: The class of the object assigned to :attr:`aborter`, created by\n    #: :meth:`create_aborter`. That object is called by\n    #: :func:`flask.abort` to raise HTTP errors, and can be\n    #: called directly as well.\n    #:\n    #: Defaults to :class:`werkzeug.exceptions.Aborter`.\n    #:\n    #: .. versionadded:: 2.2\n    aborter_class = Aborter\n </s> add from werkzeug.exceptions import abort as _wz_abort </s> add from werkzeug.exceptions import Aborter", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> from functools import update_wrapper\n <mask> from threading import RLock\n <mask> \n <mask> import werkzeug.utils\n <mask> from werkzeug.routing import BuildError\n <mask> from werkzeug.urls import url_quote\n <mask> from werkzeug.utils import redirect as _wz_redirect\n <mask> \n <mask> from .globals import _app_ctx_stack\n </s> add aborter object to app </s> add from .helpers import abort as abort </s> remove from werkzeug.exceptions import abort as abort\n </s> add  </s> add from werkzeug.exceptions import Aborter </s> add     import typing_extensions as te </s> add         #: An instance of :attr:`aborter_class` created by\n        #: :meth:`make_aborter`. This is called by :func:`flask.abort`\n        #: to raise HTTP errors, and can be called directly as well.\n        #:\n        #: .. versionadded:: 2.2\n        self.aborter = self.make_aborter()\n </s> add     def make_aborter(self) -> Aborter:\n        \"\"\"Create the object to assign to :attr:`aborter`. That object\n        is called by :func:`flask.abort` to raise HTTP errors, and can\n        be called directly as well.\n\n        By default, this creates an instance of :attr:`aborter_class`,\n        which defaults to :class:`werkzeug.exceptions.Aborter`.\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return self.aborter_class()\n", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "src/flask/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     from werkzeug.wrappers import Response as BaseResponse\n <mask>     from .wrappers import Response\n <mask> \n <mask> \n <mask> def get_env() -> str:\n <mask>     \"\"\"Get the environment the app is running in, indicated by the\n <mask>     :envvar:`FLASK_ENV` environment variable. The default is\n </s> add aborter object to app </s> add     def make_aborter(self) -> Aborter:\n        \"\"\"Create the object to assign to :attr:`aborter`. That object\n        is called by :func:`flask.abort` to raise HTTP errors, and can\n        be called directly as well.\n\n        By default, this creates an instance of :attr:`aborter_class`,\n        which defaults to :class:`werkzeug.exceptions.Aborter`.\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return self.aborter_class()\n </s> remove from werkzeug.exceptions import abort as abort\n </s> add  </s> add     #: The class of the object assigned to :attr:`aborter`, created by\n    #: :meth:`create_aborter`. That object is called by\n    #: :func:`flask.abort` to raise HTTP errors, and can be\n    #: called directly as well.\n    #:\n    #: Defaults to :class:`werkzeug.exceptions.Aborter`.\n    #:\n    #: .. versionadded:: 2.2\n    aborter_class = Aborter\n </s> add from .helpers import abort as abort </s> add from werkzeug.exceptions import abort as _wz_abort </s> add from werkzeug.exceptions import Aborter", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "src/flask/helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         with app.test_request_context():\n <mask>             self.assert_equal(flask.url_for('static', filename='index.html'),\n <mask>                               '/static/index.html')\n <mask> \n <mask>     def test_none_response(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         @app.route('/')\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add         rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         rv = c.get('/admin/static/test.txt')\n <mask>         self.assert_equal(rv.data.strip(), b'Admin File')\n <mask>         rv = c.get('/admin/static/css/test.css')\n <mask>         self.assert_equal(rv.data.strip(), b'/* nested file */')\n <mask>         rv.close()\n <mask> \n <mask>         with app.test_request_context():\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add         rv.close() </s> add         rv.close() </s> add         rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         rv.close()\n <mask>         rv = c.get('/admin/static/css/test.css')\n <mask>         self.assert_equal(rv.data.strip(), b'/* nested file */')\n <mask> \n <mask>         with app.test_request_context():\n <mask>             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n <mask>                               '/admin/static/test.txt')\n <mask> \n <mask>         with app.test_request_context():\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add         rv.close() </s> add         rv.close() </s> add         rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         rv = c.get('/admin/static/test.txt')\n <mask>         self.assert_equal(rv.data.strip(), b'Admin File')\n <mask>         rv = c.get('/admin/static/css/test.css')\n <mask>         self.assert_equal(rv.data.strip(), b'/* nested file */')\n <mask>         rv.close()\n <mask> \n <mask>         # try/finally, in case other tests use this app for Blueprint tests.\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add         rv.close() </s> add         rv.close() </s> add         rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         self.assert_equal(rv.data.strip(), b'Admin File')\n <mask>         rv.close()\n <mask>         rv = c.get('/admin/static/css/test.css')\n <mask>         self.assert_equal(rv.data.strip(), b'/* nested file */')\n <mask> \n <mask>         # try/finally, in case other tests use this app for Blueprint tests.\n <mask>         max_age_default = app.config['SEND_FILE_MAX_AGE_DEFAULT']\n <mask>         try:\n <mask>             expected_max_age = 3600\n <mask>             if app.config['SEND_FILE_MAX_AGE_DEFAULT'] == expected_max_age:\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add         rv.close() </s> add         rv.close() </s> add         rv.close() </s> add                 rv.close() </s> add             rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>                 cc = parse_cache_control_header(rv.headers['Cache-Control'])\n <mask>                 self.assert_equal(cc.max_age, 100)\n <mask>         finally:\n <mask>             app.config['SEND_FILE_MAX_AGE_DEFAULT'] = max_age_default\n <mask> \n <mask>     def test_templates_list(self):\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add             rv.close() </s> add             rv.close() </s> add         rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>             self.assert_true(rv.direct_passthrough)\n <mask>             self.assert_equal(rv.mimetype, 'text/html')\n <mask>             with app.open_resource('static/index.html') as f:\n <mask>                 self.assert_equal(rv.data, f.read())\n <mask> \n <mask>     def test_send_file_xsendfile(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.use_x_sendfile = True\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add                 rv.close() </s> add             rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add         rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             self.assert_in('x-sendfile', rv.headers)\n <mask>             self.assert_equal(rv.headers['x-sendfile'],\n <mask>                 os.path.join(app.root_path, 'static/index.html'))\n <mask>             self.assert_equal(rv.mimetype, 'text/html')\n <mask> \n <mask>     def test_send_file_object(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         with catch_warnings() as captured:\n <mask>             with app.test_request_context():\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add                 rv.close() </s> add             rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add         rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>                 rv = flask.send_file(f)\n <mask>                 with app.open_resource('static/index.html') as f:\n <mask>                     self.assert_equal(rv.data, f.read())\n <mask>                 self.assert_equal(rv.mimetype, 'text/html')\n <mask>             # mimetypes + etag\n <mask>             self.assert_equal(len(captured), 2)\n <mask> \n <mask>         app.use_x_sendfile = True\n <mask>         with catch_warnings() as captured:\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add             rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add             rv.close() </s> add                 rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>                 self.assert_equal(rv.mimetype, 'text/html')\n <mask>                 self.assert_in('x-sendfile', rv.headers)\n <mask>                 self.assert_equal(rv.headers['x-sendfile'],\n <mask>                     os.path.join(app.root_path, 'static/index.html'))\n <mask>             # mimetypes + etag\n <mask>             self.assert_equal(len(captured), 2)\n <mask> \n <mask>         app.use_x_sendfile = False\n <mask>         with app.test_request_context():\n <mask>             with catch_warnings() as captured:\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add             rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add             rv.close() </s> add                 rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>                 self.assert_equal(rv.data, b'Test')\n <mask>                 self.assert_equal(rv.mimetype, 'application/octet-stream')\n <mask>             # etags\n <mask>             self.assert_equal(len(captured), 1)\n <mask>             with catch_warnings() as captured:\n <mask>                 f = StringIO('Test')\n <mask>                 rv = flask.send_file(f, mimetype='text/plain')\n <mask>                 self.assert_equal(rv.data, b'Test')\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add                 rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add             rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>                 self.assert_equal(rv.data, b'Test')\n <mask>                 self.assert_equal(rv.mimetype, 'text/plain')\n <mask>             # etags\n <mask>             self.assert_equal(len(captured), 1)\n <mask> \n <mask>         app.use_x_sendfile = True\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add                 rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add             rv.close() </s> add                 rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>                 rv = flask.send_file(f)\n <mask>                 self.assert_not_in('x-sendfile', rv.headers)\n <mask>             # etags\n <mask>             self.assert_equal(len(captured), 1)\n <mask> \n <mask>     def test_attachment(self):\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add                 rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add             rv.close() </s> add                 rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>                 value, options = parse_options_header(rv.headers['Content-Disposition'])\n <mask>                 self.assert_equal(value, 'attachment')\n <mask>             # mimetypes + etag\n <mask>             self.assert_equal(len(captured), 2)\n <mask> \n <mask>         with app.test_request_context():\n <mask>             self.assert_equal(options['filename'], 'index.html')\n <mask>             rv = flask.send_file('static/index.html', as_attachment=True)\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add             rv.close() </s> add             rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>             self.assert_equal(value, 'attachment')\n <mask>             self.assert_equal(options['filename'], 'index.html')\n <mask> \n <mask>         with app.test_request_context():\n <mask>             rv = flask.send_file(StringIO('Test'), as_attachment=True,\n <mask>                                  attachment_filename='index.txt',\n <mask>                                  add_etags=False)\n <mask>             self.assert_equal(rv.mimetype, 'text/plain')\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add                 rv.close() </s> add             rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add             rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>             value, options = parse_options_header(rv.headers['Content-Disposition'])\n <mask>             self.assert_equal(value, 'attachment')\n <mask>             self.assert_equal(options['filename'], 'index.txt')\n <mask> \n <mask>     def test_static_file(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         # default cache timeout is 12 hours\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add                 rv.close() </s> add             rv.close() </s> add         rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>             cc = parse_cache_control_header(rv.headers['Cache-Control'])\n <mask>             self.assert_equal(cc.max_age, 12 * 60 * 60)\n <mask>             # Test again with direct use of send_file utility.\n <mask>             rv = flask.send_file('static/index.html')\n <mask>             cc = parse_cache_control_header(rv.headers['Cache-Control'])\n <mask>             self.assert_equal(cc.max_age, 12 * 60 * 60)\n <mask>             rv.close()\n <mask>         app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 3600\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add                 rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>             rv = flask.send_file('static/index.html')\n <mask>             cc = parse_cache_control_header(rv.headers['Cache-Control'])\n <mask>             self.assert_equal(cc.max_age, 12 * 60 * 60)\n <mask>         app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 3600\n <mask>         with app.test_request_context():\n <mask>             # Test with static file handler.\n <mask>             rv = app.send_static_file('index.html')\n <mask>             cc = parse_cache_control_header(rv.headers['Cache-Control'])\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add                 rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             # Test with static file handler.\n <mask>             rv = app.send_static_file('index.html')\n <mask>             cc = parse_cache_control_header(rv.headers['Cache-Control'])\n <mask>             self.assert_equal(cc.max_age, 3600)\n <mask>             # Test again with direct use of send_file utility.\n <mask>             rv = flask.send_file('static/index.html')\n <mask>             cc = parse_cache_control_header(rv.headers['Cache-Control'])\n <mask>             self.assert_equal(cc.max_age, 3600)\n <mask>             rv.close()\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add                 rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>             cc = parse_cache_control_header(rv.headers['Cache-Control'])\n <mask>             self.assert_equal(cc.max_age, 3600)\n <mask>         class StaticFileApp(flask.Flask):\n <mask>             def get_send_file_max_age(self, filename):\n <mask>                 return 10\n <mask>         app = StaticFileApp(__name__)\n <mask>         with app.test_request_context():\n <mask>             # Test with static file handler.\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add                 rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>             cc = parse_cache_control_header(rv.headers['Cache-Control'])\n <mask>             self.assert_equal(cc.max_age, 10)\n <mask>             # Test again with direct use of send_file utility.\n <mask>             rv = flask.send_file('static/index.html')\n <mask>             cc = parse_cache_control_header(rv.headers['Cache-Control'])\n <mask>             self.assert_equal(cc.max_age, 10)\n <mask>             rv.close()\n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add                 rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>             rv = flask.send_file('static/index.html')\n <mask>             cc = parse_cache_control_header(rv.headers['Cache-Control'])\n <mask>             self.assert_equal(cc.max_age, 10)\n <mask> \n <mask> \n <mask> class LoggingTestCase(FlaskTestCase):\n <mask> \n </s> Fixed a whole bunch of resource warnings in the flask testsuite </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close() </s> add                 rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> from werkzeug.http import parse_cache_control_header, parse_options_header\n <mask> from werkzeug.http import http_date\n <mask> from flask._compat import StringIO, text_type\n <mask> from flask.helpers import get_debug_flag, make_response\n <mask> \n <mask> \n <mask> def has_encoding(name):\n <mask>     try:\n </s> Use pytz again for tests\n\nThis is because datetime.timezone is Python 3 only.  The only\nalternative would be to hand-spin a datetime.tzinfo subclass, an\noverkill.\n\nThis reverts commit 0e6cab357690614791ab4ca0da0ac65dbb803041. </s> remove     @pytest.mark.parametrize('tz', (('UTC', 0), ('PST', -8), ('KST', 9)))\n    def test_jsonify_aware_datetimes(self, tz):\n </s> add     @pytest.mark.parametrize('tzname', ('UTC', 'PST8PDT', 'Asia/Seoul'))\n    def test_jsonify_aware_datetimes(self, tzname): </s> remove         tzinfo = datetime.timezone(datetime.timedelta(hours=tz[1]), name=tz[0])\n        dt = datetime.datetime(2017, 1, 1, 12, 34, 56, tzinfo=tzinfo)\n        gmt = datetime.timezone(datetime.timedelta(), name='GMT')\n        expected = dt.astimezone(gmt).strftime('\"%a, %d %b %Y %H:%M:%S %Z\"')\n        assert flask.json.JSONEncoder().encode(dt) == expected\n </s> add         dt_naive = datetime.datetime(2017, 1, 1, 12, 34, 56)\n        dt_aware = timezone(tzname).localize(dt_naive)\n        dt_as_gmt = dt_aware.astimezone(timezone('GMT'))\n        expected = dt_as_gmt.strftime('\"%a, %d %b %Y %H:%M:%S %Z\"')\n        assert flask.json.JSONEncoder().encode(dt_aware) == expected </s> add     pytz", "html_url": "https://github.com/pallets/flask/commit/eb9618347c680a038e2e6310228d85a53b080f93", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep replace replace replace replace replace keep", "code_tokens": " <mask>             rv = client.get(url)\n <mask>             assert rv.mimetype == 'application/json'\n <mask>             assert flask.json.loads(rv.data)['x'] == http_date(d.timetuple())\n <mask> \n <mask>     @pytest.mark.parametrize('tz', (('UTC', 0), ('PST', -8), ('KST', 9)))\n <mask>     def test_jsonify_aware_datetimes(self, tz):\n <mask>         \"\"\"Test if aware datetime.datetime objects are converted into GMT.\"\"\"\n <mask>         tzinfo = datetime.timezone(datetime.timedelta(hours=tz[1]), name=tz[0])\n <mask>         dt = datetime.datetime(2017, 1, 1, 12, 34, 56, tzinfo=tzinfo)\n <mask>         gmt = datetime.timezone(datetime.timedelta(), name='GMT')\n <mask>         expected = dt.astimezone(gmt).strftime('\"%a, %d %b %Y %H:%M:%S %Z\"')\n <mask>         assert flask.json.JSONEncoder().encode(dt) == expected\n <mask> \n </s> Use pytz again for tests\n\nThis is because datetime.timezone is Python 3 only.  The only\nalternative would be to hand-spin a datetime.tzinfo subclass, an\noverkill.\n\nThis reverts commit 0e6cab357690614791ab4ca0da0ac65dbb803041. </s> add from pytz import timezone </s> add     pytz", "html_url": "https://github.com/pallets/flask/commit/eb9618347c680a038e2e6310228d85a53b080f93", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     coverage\n <mask>     greenlet\n <mask>     blinker\n <mask> \n <mask>     lowest: Werkzeug==0.9\n <mask>     lowest: Jinja2==2.4\n <mask>     lowest: itsdangerous==0.21\n <mask>     lowest: Click==4.0\n <mask> \n </s> Use pytz again for tests\n\nThis is because datetime.timezone is Python 3 only.  The only\nalternative would be to hand-spin a datetime.tzinfo subclass, an\noverkill.\n\nThis reverts commit 0e6cab357690614791ab4ca0da0ac65dbb803041. </s> remove         tzinfo = datetime.timezone(datetime.timedelta(hours=tz[1]), name=tz[0])\n        dt = datetime.datetime(2017, 1, 1, 12, 34, 56, tzinfo=tzinfo)\n        gmt = datetime.timezone(datetime.timedelta(), name='GMT')\n        expected = dt.astimezone(gmt).strftime('\"%a, %d %b %Y %H:%M:%S %Z\"')\n        assert flask.json.JSONEncoder().encode(dt) == expected\n </s> add         dt_naive = datetime.datetime(2017, 1, 1, 12, 34, 56)\n        dt_aware = timezone(tzname).localize(dt_naive)\n        dt_as_gmt = dt_aware.astimezone(timezone('GMT'))\n        expected = dt_as_gmt.strftime('\"%a, %d %b %Y %H:%M:%S %Z\"')\n        assert flask.json.JSONEncoder().encode(dt_aware) == expected </s> remove     @pytest.mark.parametrize('tz', (('UTC', 0), ('PST', -8), ('KST', 9)))\n    def test_jsonify_aware_datetimes(self, tz):\n </s> add     @pytest.mark.parametrize('tzname', ('UTC', 'PST8PDT', 'Asia/Seoul'))\n    def test_jsonify_aware_datetimes(self, tzname): </s> add from pytz import timezone", "html_url": "https://github.com/pallets/flask/commit/eb9618347c680a038e2e6310228d85a53b080f93", "file_name": "tox.ini"}
{"docstring_tokens": "keep replace keep replace replace replace replace replace replace keep", "code_tokens": " <mask> \n <mask>     def test_uninstalled_module_paths(self):\n <mask>         here = os.path.abspath(os.path.dirname(__file__))\n <mask>         app = flask.Flask(__name__)\n <mask>         self.assertEqual(app.instance_path, os.path.join(here, 'instance'))\n <mask> \n <mask>         app = flask.Flask(__name__, instance_path=here)\n <mask>         self.assertEqual(app.instance_path, here)\n <mask> \n <mask>         try:\n </s> Split up a test into two </s> add         app = flask.Flask(__name__, instance_path=here)\n        self.assertEqual(app.instance_path, here)\n\n    def test_uninstalled_module_paths(self):\n        here = os.path.abspath(os.path.dirname(__file__))\n        app = flask.Flask(__name__)\n        self.assertEqual(app.instance_path, os.path.join(here, 'instance'))\n", "html_url": "https://github.com/pallets/flask/commit/eb9a14e1581fd379f25986bb206fe0d8fdc6b1a3", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>             self.fail('Expected value error')\n <mask> \n <mask>     def test_uninstalled_package_paths(self):\n <mask>         from blueprintapp import app\n <mask>         here = os.path.abspath(os.path.dirname(__file__))\n <mask>         self.assertEqual(app.instance_path, os.path.join(here, 'instance'))\n <mask> \n </s> Split up a test into two </s> remove         app = flask.Flask(__name__)\n        self.assertEqual(app.instance_path, os.path.join(here, 'instance'))\n\n        app = flask.Flask(__name__, instance_path=here)\n        self.assertEqual(app.instance_path, here)\n\n </s> add  </s> remove     def test_uninstalled_module_paths(self):\n </s> add     def test_explicit_instance_paths(self):", "html_url": "https://github.com/pallets/flask/commit/eb9a14e1581fd379f25986bb206fe0d8fdc6b1a3", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>   instruct Flask to explain how it locates templates.  This should help\n <mask>   users debug when the wrong templates are loaded.\n <mask> - Enforce blueprint handling in the order they were registered for template\n <mask>   loading.\n <mask> - Ported testsuite to py.test.\n <mask> - Deprecated ``request.json`` in favour of ``request.get_json()``.\n <mask> - Add \"pretty\" and \"compressed\" separators definitions in jsonify() method.\n <mask>   Reduces JSON response size when JSONIFY_PRETTYPRINT_REGULAR=False by removing\n <mask>   unnecessary white space included by default after separators.\n <mask> \n </s> Unify the uses of \"testsuite\" vs \"test suite\".\n\nUse \"test suite\", which is more prevailing in the source code. </s> remove         # memory.  This is usually only a problem in testsuite since this\n </s> add         # memory.  This is usually only a problem in test suite since this </s> remove since fixed but might require some changes in your testsuites if you\n </s> add since fixed but might require some changes in your test suites if you </s> remove     server and run the testsuite.\n </s> add     server and run the test suite.", "html_url": "https://github.com/pallets/flask/commit/ebab6718f7dbafaa2e893f2347e6fdc6acad8504", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> -   You could also put your application code into a repository and check\n <mask>     out the latest version on the server and then install.  That way you\n <mask>     can also easily go back to older versions.\n <mask> -   hook in testing functionality so that you can deploy to an external\n <mask>     server and run the testsuite.\n <mask> \n <mask> Working with Fabric is fun and you will notice that it's quite magical to\n <mask> type ``fab deploy`` and see your application being deployed automatically\n <mask> to one or more remote servers.\n <mask> \n </s> Unify the uses of \"testsuite\" vs \"test suite\".\n\nUse \"test suite\", which is more prevailing in the source code. </s> remove         # memory.  This is usually only a problem in testsuite since this\n </s> add         # memory.  This is usually only a problem in test suite since this </s> remove since fixed but might require some changes in your testsuites if you\n </s> add since fixed but might require some changes in your test suites if you </s> remove - Ported testsuite to py.test.\n </s> add - Ported test suite to py.test.", "html_url": "https://github.com/pallets/flask/commit/ebab6718f7dbafaa2e893f2347e6fdc6acad8504", "file_name": "docs/patterns/fabric.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> as `ValueError` you will need to change this.\n <mask> \n <mask> Due to a bug in the test client Flask 0.7 did not trigger teardown\n <mask> handlers when the test client was used in a with statement.  This was\n <mask> since fixed but might require some changes in your testsuites if you\n <mask> relied on this behavior.\n <mask> \n <mask> Version 0.7\n <mask> -----------\n <mask> \n </s> Unify the uses of \"testsuite\" vs \"test suite\".\n\nUse \"test suite\", which is more prevailing in the source code. </s> remove         # memory.  This is usually only a problem in testsuite since this\n </s> add         # memory.  This is usually only a problem in test suite since this </s> remove     server and run the testsuite.\n </s> add     server and run the test suite. </s> remove - Ported testsuite to py.test.\n </s> add - Ported test suite to py.test.", "html_url": "https://github.com/pallets/flask/commit/ebab6718f7dbafaa2e893f2347e6fdc6acad8504", "file_name": "docs/upgrading.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # on the stack.  The rationale is that you want to access that\n <mask>         # information under debug situations.  However if someone forgets to\n <mask>         # pop that context again we want to make sure that on the next push\n <mask>         # it's invalidated, otherwise we run at risk that something leaks\n <mask>         # memory.  This is usually only a problem in testsuite since this\n <mask>         # functionality is not active in production environments.\n <mask>         top = _request_ctx_stack.top\n <mask>         if top is not None and top.preserved:\n <mask>             top.pop(top._preserved_exc)\n <mask> \n </s> Unify the uses of \"testsuite\" vs \"test suite\".\n\nUse \"test suite\", which is more prevailing in the source code. </s> remove since fixed but might require some changes in your testsuites if you\n </s> add since fixed but might require some changes in your test suites if you </s> remove     server and run the testsuite.\n </s> add     server and run the test suite. </s> remove - Ported testsuite to py.test.\n </s> add - Ported test suite to py.test.", "html_url": "https://github.com/pallets/flask/commit/ebab6718f7dbafaa2e893f2347e6fdc6acad8504", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> # a lock used for logger initialization\n <mask> _logger_lock = Lock()\n <mask> \n <mask> \n <mask> def _make_timedelta(value):\n <mask>     if not isinstance(value, timedelta):\n <mask>         return timedelta(seconds=value)\n <mask>     return value\n </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n\n </s> remove     def do_teardown_request(self, exc=None):\n </s> add     def do_teardown_request(self, exc=_sentinel): </s> remove             if exc is None:\n </s> add             if exc is _sentinel: </s> remove         if exc is None:\n </s> add         if exc is _sentinel: </s> remove         if exc is None:\n </s> add         if exc is _sentinel: </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel):", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if not self.session_interface.is_null_session(ctx.session):\n <mask>             self.save_session(ctx.session, response)\n <mask>         return response\n <mask> \n <mask>     def do_teardown_request(self, exc=None):\n <mask>         \"\"\"Called after the actual request dispatching and will\n <mask>         call every as :meth:`teardown_request` decorated function.  This is\n <mask>         not actually called by the :class:`Flask` object itself but is always\n <mask>         triggered when the request context is popped.  That way we have a\n <mask>         tighter control over certain resources under testing environments.\n </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> remove     def do_teardown_appcontext(self, exc=None):\n </s> add     def do_teardown_appcontext(self, exc=_sentinel): </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel): </s> remove         if exc is None:\n </s> add         if exc is _sentinel: </s> remove             if exc is None:\n </s> add             if exc is _sentinel: </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel):", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         .. versionchanged:: 0.9\n <mask>            Added the `exc` argument.  Previously this was always using the\n <mask>            current exception information.\n <mask>         \"\"\"\n <mask>         if exc is None:\n <mask>             exc = sys.exc_info()[1]\n <mask>         funcs = reversed(self.teardown_request_funcs.get(None, ()))\n <mask>         bp = _request_ctx_stack.top.request.blueprint\n <mask>         if bp is not None and bp in self.teardown_request_funcs:\n <mask>             funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))\n </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> remove             if exc is None:\n </s> add             if exc is _sentinel: </s> remove         if exc is None:\n </s> add         if exc is _sentinel: </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel): </s> remove             if exc is None:\n </s> add             if exc is _sentinel: </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel): </s> remove     def do_teardown_request(self, exc=None):\n </s> add     def do_teardown_request(self, exc=_sentinel):", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         for func in funcs:\n <mask>             func(exc)\n <mask>         request_tearing_down.send(self, exc=exc)\n <mask> \n <mask>     def do_teardown_appcontext(self, exc=None):\n <mask>         \"\"\"Called when an application context is popped.  This works pretty\n <mask>         much the same as :meth:`do_teardown_request` but for the application\n <mask>         context.\n <mask> \n <mask>         .. versionadded:: 0.9\n </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> remove         if exc is None:\n </s> add         if exc is _sentinel: </s> remove     def do_teardown_request(self, exc=None):\n </s> add     def do_teardown_request(self, exc=_sentinel): </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel): </s> remove         if exc is None:\n </s> add         if exc is _sentinel: </s> remove             if exc is None:\n </s> add             if exc is _sentinel: </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel):", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         context.\n <mask> \n <mask>         .. versionadded:: 0.9\n <mask>         \"\"\"\n <mask>         if exc is None:\n <mask>             exc = sys.exc_info()[1]\n <mask>         for func in reversed(self.teardown_appcontext_funcs):\n <mask>             func(exc)\n <mask>         appcontext_tearing_down.send(self, exc=exc)\n <mask> \n </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> remove     def do_teardown_appcontext(self, exc=None):\n </s> add     def do_teardown_appcontext(self, exc=_sentinel): </s> remove         if exc is None:\n </s> add         if exc is _sentinel: </s> remove             if exc is None:\n </s> add             if exc is _sentinel: </s> remove             if exc is None:\n </s> add             if exc is _sentinel: </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel): </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel):", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> from .signals import appcontext_pushed, appcontext_popped\n <mask> from ._compat import BROKEN_PYPY_CTXMGR_EXIT, reraise\n <mask> \n <mask> \n <mask> class _AppCtxGlobals(object):\n <mask>     \"\"\"A plain object.\"\"\"\n <mask> \n <mask>     def get(self, name, default=None):\n <mask>         return self.__dict__.get(name, default)\n <mask> \n </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> add def test_app_tearing_down_with_handled_exception():\n    cleanup_stuff = []\n    app = flask.Flask(__name__)\n    @app.teardown_appcontext\n    def cleanup(exception):\n        cleanup_stuff.append(exception)\n\n    with app.app_context():\n        try:\n            raise Exception('dummy')\n        except Exception:\n            pass\n\n    assert cleanup_stuff == [None]\n </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n </s> remove     def do_teardown_request(self, exc=None):\n </s> add     def do_teardown_request(self, exc=_sentinel): </s> add def test_teardown_with_handled_exception():\n    buffer = []\n    app = flask.Flask(__name__)\n    @app.teardown_request\n    def end_of_request(exception):\n        buffer.append(exception)\n\n    with app.test_request_context():\n        assert buffer == []\n        try:\n            raise Exception('dummy')\n        except Exception:\n            pass\n    assert buffer == [None]\n </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel): </s> remove     def do_teardown_appcontext(self, exc=None):\n </s> add     def do_teardown_appcontext(self, exc=_sentinel):", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep replace keep keep keep replace keep keep", "code_tokens": " <mask> \n <mask>     def pop(self, exc=None):\n <mask>         \"\"\"Pops the app context.\"\"\"\n <mask>         self._refcnt -= 1\n <mask>         if self._refcnt <= 0:\n <mask>             if exc is None:\n <mask>                 exc = sys.exc_info()[1]\n <mask>             self.app.do_teardown_appcontext(exc)\n </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel): </s> remove         if exc is None:\n </s> add         if exc is _sentinel: </s> remove             if exc is None:\n </s> add             if exc is _sentinel: </s> remove         if exc is None:\n </s> add         if exc is _sentinel: </s> remove     def do_teardown_request(self, exc=None):\n </s> add     def do_teardown_request(self, exc=_sentinel):", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.session = self.app.open_session(self.request)\n <mask>         if self.session is None:\n <mask>             self.session = self.app.make_null_session()\n <mask> \n <mask>     def pop(self, exc=None):\n <mask>         \"\"\"Pops the request context and unbinds it by doing that.  This will\n <mask>         also trigger the execution of functions registered by the\n <mask>         :meth:`~flask.Flask.teardown_request` decorator.\n <mask> \n <mask>         .. versionchanged:: 0.9\n </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> remove     def do_teardown_request(self, exc=None):\n </s> add     def do_teardown_request(self, exc=_sentinel): </s> remove         if exc is None:\n </s> add         if exc is _sentinel: </s> remove             if exc is None:\n </s> add             if exc is _sentinel: </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel): </s> remove     def do_teardown_appcontext(self, exc=None):\n </s> add     def do_teardown_appcontext(self, exc=_sentinel): </s> remove             if exc is None:\n </s> add             if exc is _sentinel:", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         clear_request = False\n <mask>         if not self._implicit_app_ctx_stack:\n <mask>             self.preserved = False\n <mask>             self._preserved_exc = None\n <mask>             if exc is None:\n <mask>                 exc = sys.exc_info()[1]\n <mask>             self.app.do_teardown_request(exc)\n <mask> \n <mask>             # If this interpreter supports clearing the exception information\n <mask>             # we do that now.  This will only go into effect on Python 2.x,\n </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> remove         if exc is None:\n </s> add         if exc is _sentinel: </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n </s> remove             if exc is None:\n </s> add             if exc is _sentinel: </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel): </s> remove         if exc is None:\n </s> add         if exc is _sentinel: </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel):", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>         pass\n <mask> \n <mask>     assert cleanup_stuff == [None]\n <mask> \n <mask> def test_custom_app_ctx_globals_class():\n <mask>     class CustomRequestGlobals(object):\n <mask>         def __init__(self):\n <mask>             self.spam = 'eggs'\n <mask>     app = flask.Flask(__name__)\n </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> add def test_teardown_with_handled_exception():\n    buffer = []\n    app = flask.Flask(__name__)\n    @app.teardown_request\n    def end_of_request(exception):\n        buffer.append(exception)\n\n    with app.test_request_context():\n        assert buffer == []\n        try:\n            raise Exception('dummy')\n        except Exception:\n            pass\n    assert buffer == [None]\n </s> remove             if exc is None:\n </s> add             if exc is _sentinel: </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n\n </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel): </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel): </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "tests/test_appctx.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>     with app.test_request_context():\n <mask>         assert buffer == []\n <mask>     assert buffer == [None]\n <mask> \n <mask> def test_proper_test_request_context():\n <mask>     app = flask.Flask(__name__)\n <mask>     app.config.update(\n <mask>         SERVER_NAME='localhost.localdomain:5000'\n <mask>     )\n </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> add def test_app_tearing_down_with_handled_exception():\n    cleanup_stuff = []\n    app = flask.Flask(__name__)\n    @app.teardown_appcontext\n    def cleanup(exception):\n        cleanup_stuff.append(exception)\n\n    with app.app_context():\n        try:\n            raise Exception('dummy')\n        except Exception:\n            pass\n\n    assert cleanup_stuff == [None]\n </s> remove             if exc is None:\n </s> add             if exc is _sentinel: </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel): </s> remove     def pop(self, exc=None):\n </s> add     def pop(self, exc=_sentinel): </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n\n", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "tests/test_reqctx.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     a dict will call ``jsonify`` to produce a ``application/json``\n <mask>     response. :pr:`3111`\n <mask> \n <mask> .. _#2935: https://github.com/pallets/flask/issues/2935\n <mask> .. _#2957: https://github.com/pallets/flask/issues/2957\n <mask> .. _#2994: https://github.com/pallets/flask/pull/2994\n <mask> .. _#3059: https://github.com/pallets/flask/pull/3059\n </s> Add Blueprint level cli command registration\n\nImplements #1357.\nAdds ability to register click cli commands onto blueprint. </s> add     .. versionchanged:: 1.1.0\n        Blueprints have a ``cli`` group to register nested CLI commands.\n        The ``cli_group`` parameter controls the name of the group under\n        the ``flask`` command.\n </s> remove         #: The click command line context for this application.  Commands\n        #: registered here show up in the :command:`flask` command once the\n        #: application has been discovered.  The default commands are\n        #: provided by Flask itself and can be overridden.\n        #:\n        #: This is an instance of a :class:`click.Group` object.\n        self.cli = cli.AppGroup(self.name)\n </s> add         # Set the name of the Click group in case someone wants to add\n        # the app's commands to another CLI tool.\n        self.cli.name = self.name </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n </s> add         self.cli_group = cli_group </s> add         cli_resolved_group = options.get(\"cli_group\", self.cli_group)\n\n        if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli)\n </s> remove from flask import Flask, current_app\n </s> add from flask import Flask, current_app, Blueprint", "html_url": "https://github.com/pallets/flask/commit/ec1ccd753084c6ff3215b9a64ba46d6af56715bd", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                 host=static_host,\n <mask>                 view_func=self.send_static_file,\n <mask>             )\n <mask> \n <mask>         #: The click command line context for this application.  Commands\n <mask>         #: registered here show up in the :command:`flask` command once the\n <mask>         #: application has been discovered.  The default commands are\n <mask>         #: provided by Flask itself and can be overridden.\n <mask>         #:\n <mask>         #: This is an instance of a :class:`click.Group` object.\n <mask>         self.cli = cli.AppGroup(self.name)\n <mask> \n <mask>     @locked_cached_property\n <mask>     def name(self):\n <mask>         \"\"\"The name of the application.  This is usually the import name\n <mask>         with the difference that it's guessed from the run file if the\n </s> Add Blueprint level cli command registration\n\nImplements #1357.\nAdds ability to register click cli commands onto blueprint. </s> add         # circular import\n        from .cli import AppGroup\n\n        #: The Click command group for registration of CLI commands\n        #: on the application and associated blueprints. These commands\n        #: are accessible via the :command:`flask` command once the\n        #: application has been discovered and blueprints registered.\n        self.cli = AppGroup()\n </s> add         self.cli_group = cli_group </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n </s> add         cli_resolved_group = options.get(\"cli_group\", self.cli_group)\n\n        if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli)\n </s> add     .. versionchanged:: 1.1.0\n        Blueprints have a ``cli`` group to register nested CLI commands.\n        The ``cli_group`` parameter controls the name of the group under\n        the ``flask`` command.\n </s> add -   Blueprints have a ``cli`` Click group like ``app.cli``. CLI commands\n    registered with a blueprint will be available as a group under the\n    ``flask`` command. :issue:`1357`.", "html_url": "https://github.com/pallets/flask/commit/ec1ccd753084c6ff3215b9a64ba46d6af56715bd", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from .helpers import _PackageBoundObject, _endpoint_from_view_func\n <mask> \n <mask> \n <mask> class BlueprintSetupState(object):\n <mask>     \"\"\"Temporary holder object for registering a blueprint with the\n <mask>     application.  An instance of this class is created by the\n <mask>     :meth:`~flask.Blueprint.make_setup_state` method and later passed\n </s> Add Blueprint level cli command registration\n\nImplements #1357.\nAdds ability to register click cli commands onto blueprint. </s> remove         #: The click command line context for this application.  Commands\n        #: registered here show up in the :command:`flask` command once the\n        #: application has been discovered.  The default commands are\n        #: provided by Flask itself and can be overridden.\n        #:\n        #: This is an instance of a :class:`click.Group` object.\n        self.cli = cli.AppGroup(self.name)\n </s> add         # Set the name of the Click group in case someone wants to add\n        # the app's commands to another CLI tool.\n        self.cli.name = self.name </s> add         self.cli_group = cli_group </s> add         cli_resolved_group = options.get(\"cli_group\", self.cli_group)\n\n        if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli)\n </s> add         # circular import\n        from .cli import AppGroup\n\n        #: The Click command group for registration of CLI commands\n        #: on the application and associated blueprints. These commands\n        #: are accessible via the :command:`flask` command once the\n        #: application has been discovered and blueprints registered.\n        self.cli = AppGroup()\n </s> add -   Blueprints have a ``cli`` Click group like ``app.cli``. CLI commands\n    registered with a blueprint will be available as a group under the\n    ``flask`` command. :issue:`1357`. </s> add     .. versionchanged:: 1.1.0\n        Blueprints have a ``cli`` group to register nested CLI commands.\n        The ``cli_group`` parameter controls the name of the group under\n        the ``flask`` command.\n", "html_url": "https://github.com/pallets/flask/commit/ec1ccd753084c6ff3215b9a64ba46d6af56715bd", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     information.\n <mask> \n <mask>     .. versionadded:: 0.7\n <mask>     \"\"\"\n <mask> \n <mask>     warn_on_modifications = False\n </s> Add Blueprint level cli command registration\n\nImplements #1357.\nAdds ability to register click cli commands onto blueprint. </s> add -   Blueprints have a ``cli`` Click group like ``app.cli``. CLI commands\n    registered with a blueprint will be available as a group under the\n    ``flask`` command. :issue:`1357`. </s> add         cli_resolved_group = options.get(\"cli_group\", self.cli_group)\n\n        if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli)\n </s> add         cli_group=_sentinel, </s> add         self.cli_group = cli_group </s> add         # circular import\n        from .cli import AppGroup\n\n        #: The Click command group for registration of CLI commands\n        #: on the application and associated blueprints. These commands\n        #: are accessible via the :command:`flask` command once the\n        #: application has been discovered and blueprints registered.\n        self.cli = AppGroup()\n </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n", "html_url": "https://github.com/pallets/flask/commit/ec1ccd753084c6ff3215b9a64ba46d6af56715bd", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         subdomain=None,\n <mask>         url_defaults=None,\n <mask>         root_path=None,\n <mask>     ):\n <mask>         _PackageBoundObject.__init__(\n <mask>             self, import_name, template_folder, root_path=root_path\n <mask>         )\n <mask>         self.name = name\n <mask>         self.url_prefix = url_prefix\n </s> Add Blueprint level cli command registration\n\nImplements #1357.\nAdds ability to register click cli commands onto blueprint. </s> remove         #: The click command line context for this application.  Commands\n        #: registered here show up in the :command:`flask` command once the\n        #: application has been discovered.  The default commands are\n        #: provided by Flask itself and can be overridden.\n        #:\n        #: This is an instance of a :class:`click.Group` object.\n        self.cli = cli.AppGroup(self.name)\n </s> add         # Set the name of the Click group in case someone wants to add\n        # the app's commands to another CLI tool.\n        self.cli.name = self.name </s> add         cli_resolved_group = options.get(\"cli_group\", self.cli_group)\n\n        if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli)\n </s> add         self.cli_group = cli_group </s> add         # circular import\n        from .cli import AppGroup\n\n        #: The Click command group for registration of CLI commands\n        #: on the application and associated blueprints. These commands\n        #: are accessible via the :command:`flask` command once the\n        #: application has been discovered and blueprints registered.\n        self.cli = AppGroup()\n </s> add     .. versionchanged:: 1.1.0\n        Blueprints have a ``cli`` group to register nested CLI commands.\n        The ``cli_group`` parameter controls the name of the group under\n        the ``flask`` command.\n </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n", "html_url": "https://github.com/pallets/flask/commit/ec1ccd753084c6ff3215b9a64ba46d6af56715bd", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>             url_defaults = {}\n <mask>         self.url_values_defaults = url_defaults\n <mask> \n <mask>     def record(self, func):\n <mask>         \"\"\"Registers a function that is called when the blueprint is\n <mask>         registered on the application.  This function is called with the\n <mask>         state as argument as returned by the :meth:`make_setup_state`\n <mask>         method.\n </s> Add Blueprint level cli command registration\n\nImplements #1357.\nAdds ability to register click cli commands onto blueprint. </s> remove         #: The click command line context for this application.  Commands\n        #: registered here show up in the :command:`flask` command once the\n        #: application has been discovered.  The default commands are\n        #: provided by Flask itself and can be overridden.\n        #:\n        #: This is an instance of a :class:`click.Group` object.\n        self.cli = cli.AppGroup(self.name)\n </s> add         # Set the name of the Click group in case someone wants to add\n        # the app's commands to another CLI tool.\n        self.cli.name = self.name </s> add         cli_resolved_group = options.get(\"cli_group\", self.cli_group)\n\n        if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli)\n </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n </s> add -   Blueprints have a ``cli`` Click group like ``app.cli``. CLI commands\n    registered with a blueprint will be available as a group under the\n    ``flask`` command. :issue:`1357`. </s> add         # circular import\n        from .cli import AppGroup\n\n        #: The Click command group for registration of CLI commands\n        #: on the application and associated blueprints. These commands\n        #: are accessible via the :command:`flask` command once the\n        #: application has been discovered and blueprints registered.\n        self.cli = AppGroup()\n </s> add     .. versionchanged:: 1.1.0\n        Blueprints have a ``cli`` group to register nested CLI commands.\n        The ``cli_group`` parameter controls the name of the group under\n        the ``flask`` command.\n", "html_url": "https://github.com/pallets/flask/commit/ec1ccd753084c6ff3215b9a64ba46d6af56715bd", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         for deferred in self.deferred_functions:\n <mask>             deferred(state)\n <mask> \n <mask>     def route(self, rule, **options):\n <mask>         \"\"\"Like :meth:`Flask.route` but for a blueprint.  The endpoint for the\n <mask>         :func:`url_for` function is prefixed with the name of the blueprint.\n <mask>         \"\"\"\n <mask> \n <mask>         def decorator(f):\n </s> Add Blueprint level cli command registration\n\nImplements #1357.\nAdds ability to register click cli commands onto blueprint. </s> remove         #: The click command line context for this application.  Commands\n        #: registered here show up in the :command:`flask` command once the\n        #: application has been discovered.  The default commands are\n        #: provided by Flask itself and can be overridden.\n        #:\n        #: This is an instance of a :class:`click.Group` object.\n        self.cli = cli.AppGroup(self.name)\n </s> add         # Set the name of the Click group in case someone wants to add\n        # the app's commands to another CLI tool.\n        self.cli.name = self.name </s> add         self.cli_group = cli_group </s> add     .. versionchanged:: 1.1.0\n        Blueprints have a ``cli`` group to register nested CLI commands.\n        The ``cli_group`` parameter controls the name of the group under\n        the ``flask`` command.\n </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n </s> add         # circular import\n        from .cli import AppGroup\n\n        #: The Click command group for registration of CLI commands\n        #: on the application and associated blueprints. These commands\n        #: are accessible via the :command:`flask` command once the\n        #: application has been discovered and blueprints registered.\n        self.cli = AppGroup()\n </s> add -   Blueprints have a ``cli`` Click group like ``app.cli``. CLI commands\n    registered with a blueprint will be available as a group under the\n    ``flask`` command. :issue:`1357`.", "html_url": "https://github.com/pallets/flask/commit/ec1ccd753084c6ff3215b9a64ba46d6af56715bd", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         self._static_folder = None\n <mask>         self._static_url_path = None\n <mask> \n <mask>     def _get_static_folder(self):\n <mask>         if self._static_folder is not None:\n <mask>             return os.path.join(self.root_path, self._static_folder)\n <mask> \n <mask>     def _set_static_folder(self, value):\n <mask>         self._static_folder = value\n </s> Add Blueprint level cli command registration\n\nImplements #1357.\nAdds ability to register click cli commands onto blueprint. </s> add         cli_resolved_group = options.get(\"cli_group\", self.cli_group)\n\n        if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli)\n </s> add         self.cli_group = cli_group </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n </s> remove         #: The click command line context for this application.  Commands\n        #: registered here show up in the :command:`flask` command once the\n        #: application has been discovered.  The default commands are\n        #: provided by Flask itself and can be overridden.\n        #:\n        #: This is an instance of a :class:`click.Group` object.\n        self.cli = cli.AppGroup(self.name)\n </s> add         # Set the name of the Click group in case someone wants to add\n        # the app's commands to another CLI tool.\n        self.cli.name = self.name </s> add         cli_group=_sentinel, </s> add     .. versionchanged:: 1.1.0\n        Blueprints have a ``cli`` group to register nested CLI commands.\n        The ``cli_group`` parameter controls the name of the group under\n        the ``flask`` command.\n", "html_url": "https://github.com/pallets/flask/commit/ec1ccd753084c6ff3215b9a64ba46d6af56715bd", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import pytest\n <mask> from _pytest.monkeypatch import notset\n <mask> from click.testing import CliRunner\n <mask> \n <mask> from flask import Flask, current_app\n <mask> from flask.cli import (\n <mask>     AppGroup,\n <mask>     FlaskGroup,\n <mask>     NoAppException,\n <mask>     ScriptInfo,\n </s> Add Blueprint level cli command registration\n\nImplements #1357.\nAdds ability to register click cli commands onto blueprint. </s> add         # circular import\n        from .cli import AppGroup\n\n        #: The Click command group for registration of CLI commands\n        #: on the application and associated blueprints. These commands\n        #: are accessible via the :command:`flask` command once the\n        #: application has been discovered and blueprints registered.\n        self.cli = AppGroup()\n </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()\n </s> remove         #: The click command line context for this application.  Commands\n        #: registered here show up in the :command:`flask` command once the\n        #: application has been discovered.  The default commands are\n        #: provided by Flask itself and can be overridden.\n        #:\n        #: This is an instance of a :class:`click.Group` object.\n        self.cli = cli.AppGroup(self.name)\n </s> add         # Set the name of the Click group in case someone wants to add\n        # the app's commands to another CLI tool.\n        self.cli.name = self.name </s> add         cli_resolved_group = options.get(\"cli_group\", self.cli_group)\n\n        if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli)\n </s> add         self.cli_group = cli_group </s> add         cli_group=_sentinel,", "html_url": "https://github.com/pallets/flask/commit/ec1ccd753084c6ff3215b9a64ba46d6af56715bd", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         'SESSION_COOKIE_HTTPONLY':              True,\n <mask>         'SESSION_COOKIE_SECURE':                False,\n <mask>         'SESSION_REFRESH_EACH_REQUEST':         True,\n <mask>         'MAX_CONTENT_LENGTH':                   None,\n <mask>         'SEND_FILE_MAX_AGE_DEFAULT':            12 * 60 * 60, # 12 hours\n <mask>         'TRAP_BAD_REQUEST_ERRORS':              False,\n <mask>         'TRAP_HTTP_EXCEPTIONS':                 False,\n <mask>         'EXPLAIN_TEMPLATE_LOADING':             False,\n <mask>         'PREFERRED_URL_SCHEME':                 'http',\n <mask>         'JSON_AS_ASCII':                        True,\n </s> Put two spaces before inline comments when there is only one space.\n\nPEP8 (E261) suggests to use at least two spaces before inline comments. </s> remove             ['no_template.xml', # should skip this one\n            'simple_template.html', # should render this\n </s> add             ['no_template.xml',  # should skip this one\n            'simple_template.html',  # should render this </s> remove                 content = fd.read() # Read and process the file content...\n </s> add                 content = fd.read()  # Read and process the file content...", "html_url": "https://github.com/pallets/flask/commit/ec3d5800f2c8d6803c426babb0b6df0fa36f866f", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         @app.route('/wiki/<path:filename>')\n <mask>         def wiki_page(filename):\n <mask>             filename = safe_join(app.config['WIKI_FOLDER'], filename)\n <mask>             with open(filename, 'rb') as fd:\n <mask>                 content = fd.read() # Read and process the file content...\n <mask> \n <mask>     :param directory: the base directory.\n <mask>     :param filename: the untrusted filename relative to that directory.\n <mask>     :raises: :class:`~werkzeug.exceptions.NotFound` if the resulting path\n <mask>              would fall out of `directory`.\n </s> Put two spaces before inline comments when there is only one space.\n\nPEP8 (E261) suggests to use at least two spaces before inline comments. </s> remove             ['no_template.xml', # should skip this one\n            'simple_template.html', # should render this\n </s> add             ['no_template.xml',  # should skip this one\n            'simple_template.html',  # should render this </s> remove         'SEND_FILE_MAX_AGE_DEFAULT':            12 * 60 * 60, # 12 hours\n </s> add         'SEND_FILE_MAX_AGE_DEFAULT':            12 * 60 * 60,  # 12 hours", "html_url": "https://github.com/pallets/flask/commit/ec3d5800f2c8d6803c426babb0b6df0fa36f866f", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         return {'whiskey': 'Jameson'}\n <mask>     @app.route('/')\n <mask>     def index():\n <mask>         return flask.render_template(\n <mask>             ['no_template.xml', # should skip this one\n <mask>             'simple_template.html', # should render this\n <mask>             'context_template.html'],\n <mask>             value=23)\n <mask> \n <mask>     rv = app.test_client().get('/')\n <mask>     assert rv.data == b'<h1>Jameson</h1>'\n </s> Put two spaces before inline comments when there is only one space.\n\nPEP8 (E261) suggests to use at least two spaces before inline comments. </s> remove                 content = fd.read() # Read and process the file content...\n </s> add                 content = fd.read()  # Read and process the file content... </s> remove         'SEND_FILE_MAX_AGE_DEFAULT':            12 * 60 * 60, # 12 hours\n </s> add         'SEND_FILE_MAX_AGE_DEFAULT':            12 * 60 * 60,  # 12 hours", "html_url": "https://github.com/pallets/flask/commit/ec3d5800f2c8d6803c426babb0b6df0fa36f866f", "file_name": "tests/test_templating.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>   registration.\n <mask> - OPTIONS is now automatically implemented by Flask unless the\n <mask>   application explictly adds 'OPTIONS' as method to the URL rule.\n <mask>   In this case no automatic OPTIONS handling kicks in.\n <mask> \n <mask> Version 0.5.1\n <mask> -------------\n <mask> \n <mask> Bugfix Release, released on July 6th 2010\n </s> Always register URL rules.  This fixes #81 </s> remove         template_folder = os.path.join(self.root_path, 'templates')\n        if os.path.isdir(template_folder):\n            return FileSystemLoader(template_folder)\n </s> add         return FileSystemLoader(os.path.join(self.root_path, 'templates')) </s> remove         # if there is a static folder, register it for the application.\n        if self.has_static_folder:\n            self.add_url_rule(self.static_path + '/<path:filename>',\n                              endpoint='static',\n                              view_func=self.send_static_file)\n </s> add         # register the static folder for the application.  Do that even\n        # if the folder does not exist.  First of all it might be created\n        # while the server is running (usually happens during development)\n        # but also because google appengine stores static files somewhere\n        # else when mapped with the .yml file.\n        self.add_url_rule(self.static_path + '/<path:filename>',\n                          endpoint='static',\n                          view_func=self.send_static_file)", "html_url": "https://github.com/pallets/flask/commit/ed16ae2183ad44a7ba89aedd331a180455ed0836", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         #:    app = Flask(__name__)\n <mask>         #:    app.url_map.converters['list'] = ListConverter\n <mask>         self.url_map = Map()\n <mask> \n <mask>         # if there is a static folder, register it for the application.\n <mask>         if self.has_static_folder:\n <mask>             self.add_url_rule(self.static_path + '/<path:filename>',\n <mask>                               endpoint='static',\n <mask>                               view_func=self.send_static_file)\n <mask> \n <mask>         #: The Jinja2 environment.  It is created from the\n <mask>         #: :attr:`jinja_options`.\n <mask>         self.jinja_env = self.create_jinja_environment()\n <mask>         self.init_jinja_globals()\n </s> Always register URL rules.  This fixes #81 </s> remove         template_folder = os.path.join(self.root_path, 'templates')\n        if os.path.isdir(template_folder):\n            return FileSystemLoader(template_folder)\n </s> add         return FileSystemLoader(os.path.join(self.root_path, 'templates')) </s> add - static rules are now even in place if there is no static folder\n  for the module.  This was implemented to aid GAE which will\n  remove the static folder if it's part of a mapping in the .yml\n  file.", "html_url": "https://github.com/pallets/flask/commit/ed16ae2183ad44a7ba89aedd331a180455ed0836", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"The Jinja loader for this package bound object.\n <mask> \n <mask>         .. versionadded:: 0.5\n <mask>         \"\"\"\n <mask>         template_folder = os.path.join(self.root_path, 'templates')\n <mask>         if os.path.isdir(template_folder):\n <mask>             return FileSystemLoader(template_folder)\n <mask> \n <mask>     def send_static_file(self, filename):\n <mask>         \"\"\"Function used internally to send static files from the static\n <mask>         folder to the browser.\n <mask> \n </s> Always register URL rules.  This fixes #81 </s> add - static rules are now even in place if there is no static folder\n  for the module.  This was implemented to aid GAE which will\n  remove the static folder if it's part of a mapping in the .yml\n  file. </s> remove         # if there is a static folder, register it for the application.\n        if self.has_static_folder:\n            self.add_url_rule(self.static_path + '/<path:filename>',\n                              endpoint='static',\n                              view_func=self.send_static_file)\n </s> add         # register the static folder for the application.  Do that even\n        # if the folder does not exist.  First of all it might be created\n        # while the server is running (usually happens during development)\n        # but also because google appengine stores static files somewhere\n        # else when mapped with the .yml file.\n        self.add_url_rule(self.static_path + '/<path:filename>',\n                          endpoint='static',\n                          view_func=self.send_static_file)", "html_url": "https://github.com/pallets/flask/commit/ed16ae2183ad44a7ba89aedd331a180455ed0836", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> -   It is no longer required to decorate custom CLI commands on\n <mask>     ``app.cli`` or ``blueprint.cli`` with ``@with_appcontext``, an app\n <mask>     context will already be active at that point. :issue:`2410`\n <mask> \n <mask> \n <mask> Version 2.1.3\n <mask> -------------\n <mask> \n <mask> Unreleased\n </s> session expiration datetime is UTC timezone-aware </s> remove             return datetime.utcnow() + app.permanent_session_lifetime\n </s> add             return datetime.now(timezone.utc) + app.permanent_session_lifetime </s> remove     now = datetime.utcnow().replace(microsecond=0)\n </s> add     now = datetime.now(timezone.utc).replace(microsecond=0) </s> remove     expected = datetime.utcnow() + app.permanent_session_lifetime\n </s> add     expected = datetime.now(timezone.utc) + app.permanent_session_lifetime </s> add from datetime import timezone </s> add from datetime import timezone", "html_url": "https://github.com/pallets/flask/commit/ed42e9292811a95f2a68e06a9ae50cb5872216a3", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> from collections.abc import MutableMapping\n <mask> from datetime import datetime\n <mask> \n <mask> from itsdangerous import BadSignature\n <mask> from itsdangerous import URLSafeTimedSerializer\n <mask> from werkzeug.datastructures import CallbackDict\n <mask> \n </s> session expiration datetime is UTC timezone-aware </s> add from datetime import timezone </s> remove     now = datetime.utcnow().replace(microsecond=0)\n </s> add     now = datetime.now(timezone.utc).replace(microsecond=0) </s> remove     expected = datetime.utcnow() + app.permanent_session_lifetime\n </s> add     expected = datetime.now(timezone.utc) + app.permanent_session_lifetime </s> remove             return datetime.utcnow() + app.permanent_session_lifetime\n </s> add             return datetime.now(timezone.utc) + app.permanent_session_lifetime </s> add -   ``SessionInterface.get_expiration_time`` uses a timezone-aware\n    value. :pr:`4645`", "html_url": "https://github.com/pallets/flask/commit/ed42e9292811a95f2a68e06a9ae50cb5872216a3", "file_name": "src/flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         default implementation returns now + the permanent session\n <mask>         lifetime configured on the application.\n <mask>         \"\"\"\n <mask>         if session.permanent:\n <mask>             return datetime.utcnow() + app.permanent_session_lifetime\n <mask>         return None\n <mask> \n <mask>     def should_set_cookie(self, app: \"Flask\", session: SessionMixin) -> bool:\n <mask>         \"\"\"Used by session backends to determine if a ``Set-Cookie`` header\n <mask>         should be set for this session cookie for this response. If the session\n </s> session expiration datetime is UTC timezone-aware </s> remove     expected = datetime.utcnow() + app.permanent_session_lifetime\n </s> add     expected = datetime.now(timezone.utc) + app.permanent_session_lifetime </s> add -   ``SessionInterface.get_expiration_time`` uses a timezone-aware\n    value. :pr:`4645` </s> remove     now = datetime.utcnow().replace(microsecond=0)\n </s> add     now = datetime.now(timezone.utc).replace(microsecond=0) </s> add from datetime import timezone </s> add from datetime import timezone", "html_url": "https://github.com/pallets/flask/commit/ed42e9292811a95f2a68e06a9ae50cb5872216a3", "file_name": "src/flask/sessions.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> import uuid\n <mask> import warnings\n <mask> import weakref\n <mask> from datetime import datetime\n <mask> from platform import python_implementation\n <mask> from threading import Thread\n <mask> \n <mask> import pytest\n <mask> import werkzeug.serving\n </s> session expiration datetime is UTC timezone-aware </s> add from datetime import timezone </s> remove     now = datetime.utcnow().replace(microsecond=0)\n </s> add     now = datetime.now(timezone.utc).replace(microsecond=0) </s> remove     expected = datetime.utcnow() + app.permanent_session_lifetime\n </s> add     expected = datetime.now(timezone.utc) + app.permanent_session_lifetime </s> remove             return datetime.utcnow() + app.permanent_session_lifetime\n </s> add             return datetime.now(timezone.utc) + app.permanent_session_lifetime </s> add -   ``SessionInterface.get_expiration_time`` uses a timezone-aware\n    value. :pr:`4645`", "html_url": "https://github.com/pallets/flask/commit/ed42e9292811a95f2a68e06a9ae50cb5872216a3", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     rv = client.get(\"/\")\n <mask>     assert \"set-cookie\" in rv.headers\n <mask>     match = re.search(r\"(?i)\\bexpires=([^;]+)\", rv.headers[\"set-cookie\"])\n <mask>     expires = parse_date(match.group())\n <mask>     expected = datetime.utcnow() + app.permanent_session_lifetime\n <mask>     assert expires.year == expected.year\n <mask>     assert expires.month == expected.month\n <mask>     assert expires.day == expected.day\n <mask> \n <mask>     rv = client.get(\"/test\")\n </s> session expiration datetime is UTC timezone-aware </s> remove     now = datetime.utcnow().replace(microsecond=0)\n </s> add     now = datetime.now(timezone.utc).replace(microsecond=0) </s> remove             return datetime.utcnow() + app.permanent_session_lifetime\n </s> add             return datetime.now(timezone.utc) + app.permanent_session_lifetime </s> add from datetime import timezone </s> add from datetime import timezone </s> add -   ``SessionInterface.get_expiration_time`` uses a timezone-aware\n    value. :pr:`4645`", "html_url": "https://github.com/pallets/flask/commit/ed42e9292811a95f2a68e06a9ae50cb5872216a3", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     assert client.get(\"/\").data == b\"42\"\n <mask> \n <mask> \n <mask> def test_session_special_types(app, client):\n <mask>     now = datetime.utcnow().replace(microsecond=0)\n <mask>     the_uuid = uuid.uuid4()\n <mask> \n <mask>     @app.route(\"/\")\n <mask>     def dump_session_contents():\n <mask>         flask.session[\"t\"] = (1, 2, 3)\n </s> session expiration datetime is UTC timezone-aware </s> remove     expected = datetime.utcnow() + app.permanent_session_lifetime\n </s> add     expected = datetime.now(timezone.utc) + app.permanent_session_lifetime </s> remove             return datetime.utcnow() + app.permanent_session_lifetime\n </s> add             return datetime.now(timezone.utc) + app.permanent_session_lifetime </s> add from datetime import timezone </s> add from datetime import timezone </s> add -   ``SessionInterface.get_expiration_time`` uses a timezone-aware\n    value. :pr:`4645`", "html_url": "https://github.com/pallets/flask/commit/ed42e9292811a95f2a68e06a9ae50cb5872216a3", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> - after request functions are now called in reverse order of\n <mask>   registration.\n <mask> - OPTIONS is now automatically implemented by Flask unless the\n <mask>   application explictly adds 'OPTIONS' as method to the URL rule.\n <mask>   In this case no automatic OPTIONS handling kicks in.\n <mask> - static rules are now even in place if there is no static folder\n <mask>   for the module.  This was implemented to aid GAE which will\n <mask>   remove the static folder if it's part of a mapping in the .yml\n <mask>   file.\n </s> Minor spelling fixes\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove - refactored the way url adapters are created.  This process is now\n </s> add - refactored the way URL adapters are created.  This process is now </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding\n </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> remove -   internally you will always use unicode exclusively for text except\n </s> add -   internally you will always use Unicode exclusively for text except </s> remove unicode.  What does working with unicode in Python 2.x mean?\n </s> add Unicode.  What does working with Unicode in Python 2.x mean? </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the\n </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove of course) that give you basic and painless unicode support:\n </s> add of course) that give you basic and painless Unicode support:", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>   creating response object instances in views.\n <mask> - added signalling support based on blinker.  This feature is currently\n <mask>   optional and supposed to be used by extensions and applications.  If\n <mask>   you want to use it, make sure to have `blinker`_ installed.\n <mask> - refactored the way url adapters are created.  This process is now\n <mask>   fully customizable with the :meth:`~flask.Flask.create_url_adapter`\n <mask>   method.\n <mask> - modules can now register for a subdomain instead of just an URL\n <mask>   prefix.  This makes it possible to bind a whole module to a\n <mask>   configurable subdomain.\n </s> Minor spelling fixes\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove   application explictly adds 'OPTIONS' as method to the URL rule.\n </s> add   application explicitly adds 'OPTIONS' as method to the URL rule. </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding\n </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the\n </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove -   internally you will always use unicode exclusively for text except\n </s> add -   internally you will always use Unicode exclusively for text except </s> remove libraries that deal with text.  If you don't know unicode so far, you\n </s> add libraries that deal with text.  If you don't know Unicode so far, you </s> remove Flask like Jinja2 and Werkzeug is totally unicode based when it comes to\n </s> add Flask like Jinja2 and Werkzeug is totally Unicode based when it comes to", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask> Werkzeug and Flask will be ported to Python 3 as soon as a solution for\n <mask> WSGI is found, and we will provide helpful tips how to upgrade existing\n <mask> applications to Python 3.  Until then, we strongly recommend using Python\n <mask> 2.6 and 2.7 with activated Python 3 warnings during development, as well\n <mask> as the unicode literals `__future__` feature.\n </s> Minor spelling fixes\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove unicode.  What does working with unicode in Python 2.x mean?\n </s> add Unicode.  What does working with Unicode in Python 2.x mean? </s> remove Flask like Jinja2 and Werkzeug is totally unicode based when it comes to\n </s> add Flask like Jinja2 and Werkzeug is totally Unicode based when it comes to </s> remove libraries that deal with text.  If you don't know unicode so far, you\n </s> add libraries that deal with text.  If you don't know Unicode so far, you </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the\n </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding\n </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> remove -   internally you will always use unicode exclusively for text except\n </s> add -   internally you will always use Unicode exclusively for text except", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep keep replace keep replace", "code_tokens": " <mask> Unicode in Flask\n <mask> ================\n <mask> \n <mask> Flask like Jinja2 and Werkzeug is totally unicode based when it comes to\n <mask> text.  Not only these libraries, also the majority of web related Python\n <mask> libraries that deal with text.  If you don't know unicode so far, you\n </s> Minor spelling fixes\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the\n </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove pleasant experience with unicode related things.\n </s> add pleasant experience with Unicode related things. </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding\n </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> remove as the unicode literals `__future__` feature.\n </s> add as the Unicode literals `__future__` feature. </s> remove of course) that give you basic and painless unicode support:\n </s> add of course) that give you basic and painless Unicode support:", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> should probably read `The Absolute Minimum Every Software Developer\n <mask> Absolutely, Positively Must Know About Unicode and Character Sets\n <mask> <http://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the\n <mask> documentation just tries to cover the very basics so that you have a\n <mask> pleasant experience with unicode related things.\n <mask> \n <mask> Automatic Conversion\n <mask> --------------------\n <mask> \n <mask> Flask has a few assumptions about your application (which you can change\n </s> Minor spelling fixes\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove libraries that deal with text.  If you don't know unicode so far, you\n </s> add libraries that deal with text.  If you don't know Unicode so far, you </s> remove Flask like Jinja2 and Werkzeug is totally unicode based when it comes to\n </s> add Flask like Jinja2 and Werkzeug is totally Unicode based when it comes to </s> remove of course) that give you basic and painless unicode support:\n </s> add of course) that give you basic and painless Unicode support: </s> remove -   internally you will always use unicode exclusively for text except\n </s> add -   internally you will always use Unicode exclusively for text except </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding\n </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> remove already transmits unicode and if they do not, SQLAlchemy or your other ORM\n </s> add already transmits Unicode and if they do not, SQLAlchemy or your other ORM", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep replace keep keep replace keep keep", "code_tokens": " <mask> \n <mask> Flask has a few assumptions about your application (which you can change\n <mask> of course) that give you basic and painless unicode support:\n <mask> \n <mask> -   the encoding for text on your website is UTF-8\n <mask> -   internally you will always use unicode exclusively for text except\n <mask>     for literal strings with only ASCII character points.\n <mask> -   encoding and decoding happens whenever you are talking over a protocol\n </s> Minor spelling fixes\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove pleasant experience with unicode related things.\n </s> add pleasant experience with Unicode related things. </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the\n </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding\n </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> remove Anyways.  To load such a file with unicode you can use the built-in\n </s> add Anyways.  To load such a file with Unicode you can use the built-in </s> remove already transmits unicode and if they do not, SQLAlchemy or your other ORM\n </s> add already transmits Unicode and if they do not, SQLAlchemy or your other ORM", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace keep", "code_tokens": " <mask> character sets and which ones are used, are transmitted in an HTTP header.\n <mask> To not make this too complex Flask just assumes that if you are sending\n <mask> unicode out you want it to be UTF-8 encoded.  Flask will do the encoding\n <mask> and setting of the appropriate headers for you.\n <mask> \n <mask> The same is true if you are talking to databases with the help of\n <mask> SQLAlchemy or a similar ORM system.  Some databases have a protocol that\n <mask> already transmits unicode and if they do not, SQLAlchemy or your other ORM\n <mask> should take care of that.\n </s> Minor spelling fixes\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the\n </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove -   internally you will always use unicode exclusively for text except\n </s> add -   internally you will always use Unicode exclusively for text except </s> remove of course) that give you basic and painless unicode support:\n </s> add of course) that give you basic and painless Unicode support: </s> remove - refactored the way url adapters are created.  This process is now\n </s> add - refactored the way URL adapters are created.  This process is now </s> remove Anyways.  To load such a file with unicode you can use the built-in\n </s> add Anyways.  To load such a file with Unicode you can use the built-in", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> The Golden Rule\n <mask> ---------------\n <mask> \n <mask> So the rule of thumb: if you are not dealing with binary data, work with\n <mask> unicode.  What does working with unicode in Python 2.x mean?\n <mask> \n <mask> -   as long as you are using ASCII charpoints only (basically numbers,\n <mask>     some special characters of latin letters without umlauts or anything\n <mask>     fancy) you can use regular string literals (``'Hello World'``).\n <mask> -   if you need anything else than ASCII in a string you have to mark\n </s> Minor spelling fixes\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove already transmits unicode and if they do not, SQLAlchemy or your other ORM\n </s> add already transmits Unicode and if they do not, SQLAlchemy or your other ORM </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the\n </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove -   internally you will always use unicode exclusively for text except\n </s> add -   internally you will always use Unicode exclusively for text except </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding\n </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> remove of course) that give you basic and painless unicode support:\n </s> add of course) that give you basic and painless Unicode support: </s> remove Anyways.  To load such a file with unicode you can use the built-in\n </s> add Anyways.  To load such a file with Unicode you can use the built-in", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> Encoding and Decoding Yourself\n <mask> ------------------------------\n <mask> \n <mask> If you are talking with a filesystem or something that is not really based\n <mask> on unicode you will have to ensure that you decode properly when working\n <mask> with unicode interface.  So for example if you want to load a file on the\n <mask> filesystem and embed it into a Jinja2 template you will have to decode it\n <mask> from the encoding of that file.  Here the old problem that text files do\n <mask> not specify their encoding comes into play.  So do yourself a favour and\n <mask> limit yourself to UTF-8 for text files as well.\n <mask> \n </s> Minor spelling fixes\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove Anyways.  To load such a file with unicode you can use the built-in\n </s> add Anyways.  To load such a file with Unicode you can use the built-in </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding\n </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> remove -   internally you will always use unicode exclusively for text except\n </s> add -   internally you will always use Unicode exclusively for text except </s> remove of course) that give you basic and painless unicode support:\n </s> add of course) that give you basic and painless Unicode support: </s> remove libraries that deal with text.  If you don't know unicode so far, you\n </s> add libraries that deal with text.  If you don't know Unicode so far, you </s> remove Flask like Jinja2 and Werkzeug is totally unicode based when it comes to\n </s> add Flask like Jinja2 and Werkzeug is totally Unicode based when it comes to", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from the encoding of that file.  Here the old problem that text files do\n <mask> not specify their encoding comes into play.  So do yourself a favour and\n <mask> limit yourself to UTF-8 for text files as well.\n <mask> \n <mask> Anyways.  To load such a file with unicode you can use the built-in\n <mask> :meth:`str.decode` method::\n <mask> \n <mask>     def read_file(filename, charset='utf-8'):\n <mask>         with open(filename, 'r') as f:\n <mask>             return f.read().decode(charset)\n </s> Minor spelling fixes\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the\n </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove To go from unicode into a specific charset such as UTF-8 you can use the\n </s> add To go from Unicode into a specific charset such as UTF-8 you can use the </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding\n </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> remove -   internally you will always use unicode exclusively for text except\n </s> add -   internally you will always use Unicode exclusively for text except </s> remove of course) that give you basic and painless unicode support:\n </s> add of course) that give you basic and painless Unicode support: </s> remove already transmits unicode and if they do not, SQLAlchemy or your other ORM\n </s> add already transmits Unicode and if they do not, SQLAlchemy or your other ORM", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def read_file(filename, charset='utf-8'):\n <mask>         with open(filename, 'r') as f:\n <mask>             return f.read().decode(charset)\n <mask> \n <mask> To go from unicode into a specific charset such as UTF-8 you can use the\n <mask> :meth:`unicode.encode` method::\n <mask> \n <mask>     def write_file(filename, contents, charset='utf-8'):\n <mask>         with open(filename, 'w') as f:\n <mask>             f.write(contents.encode(charset))\n </s> Minor spelling fixes\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove Anyways.  To load such a file with unicode you can use the built-in\n </s> add Anyways.  To load such a file with Unicode you can use the built-in </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the\n </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove unicode.  What does working with unicode in Python 2.x mean?\n </s> add Unicode.  What does working with Unicode in Python 2.x mean? </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding\n </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> remove as the unicode literals `__future__` feature.\n </s> add as the Unicode literals `__future__` feature. </s> remove of course) that give you basic and painless unicode support:\n </s> add of course) that give you basic and painless Unicode support:", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     f.__flask_without_appcontext__ = True\n <mask>     return f\n <mask> \n <mask> \n <mask> class FlaskGroup(click.Group):\n <mask>     \"\"\"Special subclass of the a regular click group that supports\n <mask>     loading more commands from the configured Flask app.\n <mask>     \"\"\"\n <mask> \n <mask>     def __init__(self, help=None):\n <mask>         def set_app_id(ctx, value):\n <mask>             if value is not None:\n <mask>                 if os.path.isfile(value):\n <mask>                     value = prepare_exec_for_file(value)\n <mask>                 elif '.' not in sys.path:\n <mask>                     sys.path.insert(0, '.')\n <mask>             ctx.ensure_object(ScriptInfo).app_import_path = value\n <mask>         def set_debug(ctx, value):\n <mask>             ctx.ensure_object(ScriptInfo).debug = value\n <mask> \n <mask>         click.Group.__init__(self, help=help, params=[\n <mask>             click.Option(['-a', '--app'],\n <mask>                          help='The application to run',\n <mask>                          callback=set_app_id, is_eager=True),\n <mask>             click.Option(['--debug/--no-debug'],\n <mask>                          help='Enable or disable debug mode.',\n <mask>                          default=None, callback=set_debug)\n <mask>         ])\n <mask> \n <mask>     def get_command(self, ctx, name):\n <mask>         info = ctx.find_object(ScriptInfo)\n <mask>         # Find the command in the application first, if we can find it.\n <mask>         # If the app is not available, we just ignore this silently.\n </s> Refactored loading logic to super properly. </s> remove         return click.Group.get_command(self, ctx, name)\n </s> add         return super(ContextGroupMixin, self).get_command(ctx, name) </s> remove             return click.Group.invoke_subcommand(\n                self, ctx, cmd, cmd_name, args)\n </s> add             return super(ContextGroupMixin, self).invoke_subcommand(\n                ctx, cmd, cmd_name, args)\n\n\nclass FlaskGroup(ContextGroupMixin, click.Group):\n    \"\"\"Special subclass of the a regular click group that supports\n    loading more commands from the configured Flask app.\n    \"\"\"\n\n    def __init__(self, help=None):\n        def set_app_id(ctx, value):\n            if value is not None:\n                if os.path.isfile(value):\n                    value = prepare_exec_for_file(value)\n                elif '.' not in sys.path:\n                    sys.path.insert(0, '.')\n            ctx.ensure_object(ScriptInfo).app_import_path = value\n        def set_debug(ctx, value):\n            ctx.ensure_object(ScriptInfo).debug = value\n\n        click.Group.__init__(self, help=help, params=[\n            click.Option(['-a', '--app'],\n                         help='The application to run',\n                         callback=set_app_id, is_eager=True),\n            click.Option(['--debug/--no-debug'],\n                         help='Enable or disable debug mode.',\n                         default=None, callback=set_debug)\n        ]) </s> remove         rv = set(click.Group.list_commands(self, ctx))\n </s> add         rv = set(super(ContextGroupMixin, self).list_commands(ctx))", "html_url": "https://github.com/pallets/flask/commit/ed7b4ccac1b646aa725007db7fd3ec2d359beaf4", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace", "code_tokens": " <mask>         except NoAppException:\n <mask>             pass\n <mask>         return click.Group.get_command(self, ctx, name)\n <mask> \n <mask>     def list_commands(self, ctx):\n <mask>         # The commands available is the list of both the application (if\n <mask>         # available) plus the builtin commands.\n <mask>         rv = set(click.Group.list_commands(self, ctx))\n </s> Refactored loading logic to super properly. </s> remove class FlaskGroup(click.Group):\n    \"\"\"Special subclass of the a regular click group that supports\n    loading more commands from the configured Flask app.\n    \"\"\"\n\n    def __init__(self, help=None):\n        def set_app_id(ctx, value):\n            if value is not None:\n                if os.path.isfile(value):\n                    value = prepare_exec_for_file(value)\n                elif '.' not in sys.path:\n                    sys.path.insert(0, '.')\n            ctx.ensure_object(ScriptInfo).app_import_path = value\n        def set_debug(ctx, value):\n            ctx.ensure_object(ScriptInfo).debug = value\n\n        click.Group.__init__(self, help=help, params=[\n            click.Option(['-a', '--app'],\n                         help='The application to run',\n                         callback=set_app_id, is_eager=True),\n            click.Option(['--debug/--no-debug'],\n                         help='Enable or disable debug mode.',\n                         default=None, callback=set_debug)\n        ])\n </s> add class ContextGroupMixin(object): </s> remove             return click.Group.invoke_subcommand(\n                self, ctx, cmd, cmd_name, args)\n </s> add             return super(ContextGroupMixin, self).invoke_subcommand(\n                ctx, cmd, cmd_name, args)\n\n\nclass FlaskGroup(ContextGroupMixin, click.Group):\n    \"\"\"Special subclass of the a regular click group that supports\n    loading more commands from the configured Flask app.\n    \"\"\"\n\n    def __init__(self, help=None):\n        def set_app_id(ctx, value):\n            if value is not None:\n                if os.path.isfile(value):\n                    value = prepare_exec_for_file(value)\n                elif '.' not in sys.path:\n                    sys.path.insert(0, '.')\n            ctx.ensure_object(ScriptInfo).app_import_path = value\n        def set_debug(ctx, value):\n            ctx.ensure_object(ScriptInfo).debug = value\n\n        click.Group.__init__(self, help=help, params=[\n            click.Option(['-a', '--app'],\n                         help='The application to run',\n                         callback=set_app_id, is_eager=True),\n            click.Option(['--debug/--no-debug'],\n                         help='Enable or disable debug mode.',\n                         default=None, callback=set_debug)\n        ])", "html_url": "https://github.com/pallets/flask/commit/ed7b4ccac1b646aa725007db7fd3ec2d359beaf4", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         with_context = cmd.callback is None or \\\n <mask>            not getattr(cmd.callback, '__flask_without_appcontext__', False)\n <mask> \n <mask>         with ctx.find_object(ScriptInfo).conditional_context(with_context):\n <mask>             return click.Group.invoke_subcommand(\n <mask>                 self, ctx, cmd, cmd_name, args)\n <mask> \n <mask> \n <mask> cli = FlaskGroup(help='''\\\n <mask> This shell command acts as general utility script for Flask applications.\n <mask> \n </s> Refactored loading logic to super properly. </s> remove         return click.Group.get_command(self, ctx, name)\n </s> add         return super(ContextGroupMixin, self).get_command(ctx, name) </s> remove class FlaskGroup(click.Group):\n    \"\"\"Special subclass of the a regular click group that supports\n    loading more commands from the configured Flask app.\n    \"\"\"\n\n    def __init__(self, help=None):\n        def set_app_id(ctx, value):\n            if value is not None:\n                if os.path.isfile(value):\n                    value = prepare_exec_for_file(value)\n                elif '.' not in sys.path:\n                    sys.path.insert(0, '.')\n            ctx.ensure_object(ScriptInfo).app_import_path = value\n        def set_debug(ctx, value):\n            ctx.ensure_object(ScriptInfo).debug = value\n\n        click.Group.__init__(self, help=help, params=[\n            click.Option(['-a', '--app'],\n                         help='The application to run',\n                         callback=set_app_id, is_eager=True),\n            click.Option(['--debug/--no-debug'],\n                         help='Enable or disable debug mode.',\n                         default=None, callback=set_debug)\n        ])\n </s> add class ContextGroupMixin(object): </s> remove         rv = set(click.Group.list_commands(self, ctx))\n </s> add         rv = set(super(ContextGroupMixin, self).list_commands(ctx))", "html_url": "https://github.com/pallets/flask/commit/ed7b4ccac1b646aa725007db7fd3ec2d359beaf4", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     dependency to >= 0.15. :issue:`3022`\n <mask> -   Support ``static_url_path`` that ends with a forward slash.\n <mask>     :issue:`3134`\n <mask> -   :meth:`jsonify` supports :class:`dataclasses.dataclass` objects.\n <mask>     :pr:`3195`\n <mask> -   Allow customizing the :attr:`Flask.url_map_class` used for routing.\n <mask>     :pr:`3069`\n </s> strip static url trailing slash at assignment </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path\n </s> add         self._static_url_path = value </s> remove     def _get_static_url_path(self):\n </s> add     @property\n    def static_url_path(self):\n        \"\"\"The URL prefix that the static route will be accessible from.\n\n        If it was not configured during init, it is derived from\n        :attr:`static_folder`.\n        \"\"\" </s> remove def test_static_url_null_path(app):\n </s> add def test_static_url_empty_path(app): </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\",\n </s> add                 self.static_url_path + \"/<path:filename>\", </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value\n </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove def test_static_url_null_path_defaulting(app):\n </s> add def test_static_url_empty_path_default(app):", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         _PackageBoundObject.__init__(\n <mask>             self, import_name, template_folder=template_folder, root_path=root_path\n <mask>         )\n <mask> \n <mask>         if static_url_path is not None:\n <mask>             self.static_url_path = static_url_path\n <mask> \n <mask>         if static_folder is not None:\n <mask>             self.static_folder = static_folder\n <mask> \n <mask>         if instance_path is None:\n <mask>             instance_path = self.auto_find_instance_path()\n <mask>         elif not os.path.isabs(instance_path):\n <mask>             raise ValueError(\n </s> strip static url trailing slash at assignment </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value\n </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove             return \"/\" + basename if basename else \"\"\n </s> add             return (\"/\" + basename).rstrip(\"/\") </s> remove     def _get_static_url_path(self):\n </s> add     @property\n    def static_url_path(self):\n        \"\"\"The URL prefix that the static route will be accessible from.\n\n        If it was not configured during init, it is derived from\n        :attr:`static_folder`.\n        \"\"\" </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\",\n </s> add                 self.static_url_path + \"/<path:filename>\", </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path\n </s> add         self._static_url_path = value </s> remove def test_static_url_null_path_defaulting(app):\n </s> add def test_static_url_empty_path_default(app):", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             assert (\n <mask>                 bool(static_host) == host_matching\n <mask>             ), \"Invalid static_host/host_matching combination\"\n <mask>             self.add_url_rule(\n <mask>                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\",\n <mask>                 endpoint=\"static\",\n <mask>                 host=static_host,\n <mask>                 view_func=self.send_static_file,\n <mask>             )\n <mask> \n </s> strip static url trailing slash at assignment </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\",\n </s> add                 self.static_url_path + \"/<path:filename>\", </s> remove def test_static_url_null_path_defaulting(app):\n </s> add def test_static_url_empty_path_default(app): </s> remove def test_static_url_null_path(app):\n </s> add def test_static_url_empty_path(app): </s> remove             return \"/\" + basename if basename else \"\"\n </s> add             return (\"/\" + basename).rstrip(\"/\") </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value\n </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path\n </s> add         self._static_url_path = value", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         state = self.make_setup_state(app, options, first_registration)\n <mask> \n <mask>         if self.has_static_folder:\n <mask>             state.add_url_rule(\n <mask>                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\",\n <mask>                 view_func=self.send_static_file,\n <mask>                 endpoint=\"static\",\n <mask>             )\n <mask> \n <mask>         for deferred in self.deferred_functions:\n </s> strip static url trailing slash at assignment </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\",\n </s> add                 self.static_url_path + \"/<path:filename>\", </s> remove             return \"/\" + basename if basename else \"\"\n </s> add             return (\"/\" + basename).rstrip(\"/\") </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path\n </s> add         self._static_url_path = value </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value\n </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove         if static_url_path is not None:\n            self.static_url_path = static_url_path\n\n        if static_folder is not None:\n            self.static_folder = static_folder\n </s> add         self.static_url_path = static_url_path\n        self.static_folder = static_folder </s> remove     def _get_static_url_path(self):\n </s> add     @property\n    def static_url_path(self):\n        \"\"\"The URL prefix that the static route will be accessible from.\n\n        If it was not configured during init, it is derived from\n        :attr:`static_folder`.\n        \"\"\"", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         doc=\"The absolute path to the configured static folder.\",\n <mask>     )\n <mask>     del _get_static_folder, _set_static_folder\n <mask> \n <mask>     def _get_static_url_path(self):\n <mask>         if self._static_url_path is not None:\n <mask>             return self._static_url_path\n <mask> \n <mask>         if self.static_folder is not None:\n <mask>             basename = os.path.basename(self.static_folder)\n </s> strip static url trailing slash at assignment </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value\n </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove             return \"/\" + basename if basename else \"\"\n </s> add             return (\"/\" + basename).rstrip(\"/\") </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path\n </s> add         self._static_url_path = value </s> remove         if static_url_path is not None:\n            self.static_url_path = static_url_path\n\n        if static_folder is not None:\n            self.static_folder = static_folder\n </s> add         self.static_url_path = static_url_path\n        self.static_folder = static_folder </s> add -   Support empty ``static_folder`` without requiring setting an empty\n    ``static_url_path`` as well. :pr:`3124` </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\",\n </s> add                 self.static_url_path + \"/<path:filename>\",", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep replace keep replace replace", "code_tokens": " <mask>             basename = os.path.basename(self.static_folder)\n <mask>             return \"/\" + basename if basename else \"\"\n <mask> \n <mask>     def _set_static_url_path(self, value):\n <mask>         self._static_url_path = value\n </s> strip static url trailing slash at assignment </s> remove     def _get_static_url_path(self):\n </s> add     @property\n    def static_url_path(self):\n        \"\"\"The URL prefix that the static route will be accessible from.\n\n        If it was not configured during init, it is derived from\n        :attr:`static_folder`.\n        \"\"\" </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path\n </s> add         self._static_url_path = value </s> remove         if static_url_path is not None:\n            self.static_url_path = static_url_path\n\n        if static_folder is not None:\n            self.static_folder = static_folder\n </s> add         self.static_url_path = static_url_path\n        self.static_folder = static_folder </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\",\n </s> add                 self.static_url_path + \"/<path:filename>\", </s> remove def test_static_url_null_path_defaulting(app):\n </s> add def test_static_url_empty_path_default(app):", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def _set_static_url_path(self, value):\n <mask>         self._static_url_path = value\n <mask> \n <mask>     static_url_path = property(\n <mask>         _get_static_url_path,\n <mask>         _set_static_url_path,\n <mask>         doc=\"The URL prefix that the static route will be registered for.\",\n <mask>     )\n <mask>     del _get_static_url_path, _set_static_url_path\n <mask> \n <mask>     @property\n <mask>     def has_static_folder(self):\n <mask>         \"\"\"This is ``True`` if the package bound object's container has a\n <mask>         folder for static files.\n </s> strip static url trailing slash at assignment </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value\n </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove     def _get_static_url_path(self):\n </s> add     @property\n    def static_url_path(self):\n        \"\"\"The URL prefix that the static route will be accessible from.\n\n        If it was not configured during init, it is derived from\n        :attr:`static_folder`.\n        \"\"\" </s> remove             return \"/\" + basename if basename else \"\"\n </s> add             return (\"/\" + basename).rstrip(\"/\") </s> add -   Support empty ``static_folder`` without requiring setting an empty\n    ``static_url_path`` as well. :pr:`3124` </s> remove         if static_url_path is not None:\n            self.static_url_path = static_url_path\n\n        if static_folder is not None:\n            self.static_folder = static_folder\n </s> add         self.static_url_path = static_url_path\n        self.static_folder = static_folder </s> remove def test_static_url_null_path_defaulting(app):\n </s> add def test_static_url_empty_path_default(app):", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     with app.test_request_context():\n <mask>         assert flask.url_for(\"static\", filename=\"index.html\") == \"/foo/index.html\"\n <mask> \n <mask> \n <mask> def test_static_url_null_path(app):\n <mask>     app = flask.Flask(__name__, static_folder='', static_url_path='')\n <mask>     rv = app.test_client().open('/static/index.html', method='GET')\n <mask>     assert rv.status_code == 200\n <mask>     rv.close()\n <mask> \n </s> strip static url trailing slash at assignment </s> remove def test_static_url_null_path_defaulting(app):\n </s> add def test_static_url_empty_path_default(app): </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\",\n </s> add                 self.static_url_path + \"/<path:filename>\", </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value\n </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove             return \"/\" + basename if basename else \"\"\n </s> add             return (\"/\" + basename).rstrip(\"/\") </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path\n </s> add         self._static_url_path = value </s> remove         if static_url_path is not None:\n            self.static_url_path = static_url_path\n\n        if static_folder is not None:\n            self.static_folder = static_folder\n </s> add         self.static_url_path = static_url_path\n        self.static_folder = static_folder", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     assert rv.status_code == 200\n <mask>     rv.close()\n <mask> \n <mask> \n <mask> def test_static_url_null_path_defaulting(app):\n <mask>     app = flask.Flask(__name__, static_folder='')\n <mask>     rv = app.test_client().open('/static/index.html', method='GET')\n <mask>     assert rv.status_code == 200\n <mask>     rv.close()\n <mask> \n </s> strip static url trailing slash at assignment </s> remove def test_static_url_null_path(app):\n </s> add def test_static_url_empty_path(app): </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\",\n </s> add                 self.static_url_path + \"/<path:filename>\", </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value\n </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove             return \"/\" + basename if basename else \"\"\n </s> add             return (\"/\" + basename).rstrip(\"/\") </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path\n </s> add         self._static_url_path = value </s> remove         if static_url_path is not None:\n            self.static_url_path = static_url_path\n\n        if static_folder is not None:\n            self.static_folder = static_folder\n </s> add         self.static_url_path = static_url_path\n        self.static_folder = static_folder", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "replace keep replace replace keep keep keep keep keep", "code_tokens": " <mask> .. mongoengine-pattern:\n <mask> \n <mask> MongoEngine in Flask\n <mask> ====================\n <mask> \n <mask> Using a document database rather than a full DBMS gets more common these days.\n <mask> This pattern shows how to use MongoEngine, a document mapper library, to\n <mask> integrate with MongoDB.\n <mask> \n </s> simplify mongoengine doc, redirect from mongokit </s> remove Using a document database rather than a full DBMS gets more common these days.\nThis pattern shows how to use MongoEngine, a document mapper library, to\nintegrate with MongoDB.\n\nThis pattern requires a running MongoDB server, MongoEngine_ and Flask-MongoEngine_\nlibraries installed::\n </s> add A running MongoDB server and `Flask-MongoEngine`_ are required. :: </s> remove     conn = get_connection()\n    collection = conn.mydb.movie\n    collection({'title': u'Days of Thunder'})\n </s> add There are many more ways to define and query documents with MongoEngine.\nFor more information, check out the `official documentation\n<MongoEngine_>`_. </s> remove Available operators are as follows:\n\n* ``ne`` -- not equal to\n* ``lt`` -- less than\n* ``lte`` -- less than or equal to\n* ``gt`` -- greater than\n* ``gte`` -- greater than or equal to\n* ``not`` -- negate a standard check, may be used before other operators (e.g.\n  ``Q(age__not__mod=5)``)\n* ``in`` -- value is in list (a list of values should be provided)\n* ``nin`` -- value is not in list (a list of values should be provided)\n* ``mod`` -- ``value % x == y``, where ``x`` and ``y`` are two provided values\n* ``all`` -- every item in list of values provided is in array\n* ``size`` -- the size of the array is\n* ``exists`` -- value for field exists\n\nString queries\n::::::::::::::\n </s> add  </s> remove     class Imdb(EmbeddedDocument):\n </s> add If the document has nested fields, use ``EmbeddedDocument`` to\ndefined the fields of the embedded document and\n``EmbeddedDocumentField`` to declare it on the parent document. :: </s> remove For more information about MongoEngine, head over to the\n`website <http://docs.mongoengine.org/>`_.\n </s> add Flask-MongoEngine adds helpful utilities on top of MongoEngine. Check\nout their `documentation <Flask-MongoEngine_>`_ as well.", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> MongoEngine in Flask\n <mask> ====================\n <mask> \n <mask> Using a document database rather than a full DBMS gets more common these days.\n <mask> This pattern shows how to use MongoEngine, a document mapper library, to\n <mask> integrate with MongoDB.\n <mask> \n <mask> This pattern requires a running MongoDB server, MongoEngine_ and Flask-MongoEngine_\n <mask> libraries installed::\n <mask> \n <mask>     pip install flask-mongoengine\n <mask> \n <mask> .. _MongoEngine: http://mongoengine.org\n <mask> .. _Flask-MongoEngine: http://docs.mongoengine.org/projects/flask-mongoengine/en/latest/>`_\n </s> simplify mongoengine doc, redirect from mongokit </s> remove MongoEngine in Flask\n====================\n </s> add Using a document database like MongoDB is a common alternative to\nrelational SQL databases. This pattern shows how to use\n`MongoEngine`_, a document mapper library, to integrate with MongoDB. </s> remove .. mongoengine-pattern:\n </s> add MongoDB with MongoEngine\n======================== </s> remove .. _Flask-MongoEngine: http://docs.mongoengine.org/projects/flask-mongoengine/en/latest/>`_\n </s> add .. _Flask-MongoEngine: https://flask-mongoengine.readthedocs.io\n </s> remove     conn = get_connection()\n    collection = conn.mydb.movie\n    collection({'title': u'Days of Thunder'})\n </s> add There are many more ways to define and query documents with MongoEngine.\nFor more information, check out the `official documentation\n<MongoEngine_>`_. </s> remove Available operators are as follows:\n\n* ``ne`` -- not equal to\n* ``lt`` -- less than\n* ``lte`` -- less than or equal to\n* ``gt`` -- greater than\n* ``gte`` -- greater than or equal to\n* ``not`` -- negate a standard check, may be used before other operators (e.g.\n  ``Q(age__not__mod=5)``)\n* ``in`` -- value is in list (a list of values should be provided)\n* ``nin`` -- value is not in list (a list of values should be provided)\n* ``mod`` -- ``value % x == y``, where ``x`` and ``y`` are two provided values\n* ``all`` -- every item in list of values provided is in array\n* ``size`` -- the size of the array is\n* ``exists`` -- value for field exists\n\nString queries\n::::::::::::::\n </s> add  </s> remove     class Imdb(EmbeddedDocument):\n </s> add If the document has nested fields, use ``EmbeddedDocument`` to\ndefined the fields of the embedded document and\n``EmbeddedDocumentField`` to declare it on the parent document. ::", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     pip install flask-mongoengine\n <mask> \n <mask> .. _MongoEngine: http://mongoengine.org\n <mask> .. _Flask-MongoEngine: http://docs.mongoengine.org/projects/flask-mongoengine/en/latest/>`_\n <mask> \n <mask> Configuration\n <mask> -------------\n <mask> \n <mask> Basic setup can be done by defining ``MONGODB_SETTINGS`` on App config and then\n </s> simplify mongoengine doc, redirect from mongokit </s> remove Basic setup can be done by defining ``MONGODB_SETTINGS`` on App config and then\ncreating a ``MongoEngine`` instance::\n </s> add Basic setup can be done by defining ``MONGODB_SETTINGS`` on\n``app.config`` and creating a ``MongoEngine`` instance. :: </s> remove Using a document database rather than a full DBMS gets more common these days.\nThis pattern shows how to use MongoEngine, a document mapper library, to\nintegrate with MongoDB.\n\nThis pattern requires a running MongoDB server, MongoEngine_ and Flask-MongoEngine_\nlibraries installed::\n </s> add A running MongoDB server and `Flask-MongoEngine`_ are required. :: </s> remove .. mongoengine-pattern:\n </s> add MongoDB with MongoEngine\n======================== </s> remove Just create the objects and call ``save()``::\n </s> add Instantiate your document class with keyword arguments for the fields.\nYou can also assign values to the field attributes after instantiation.\nThen call ``doc.save()``. :: </s> remove ``objects`` is an iterable. Query operators may be user by concatenating it with the document\nkey using a double-underscore::\n </s> add Query operators may be used by concatenating them with the field name\nusing a double-underscore. ``objects``, and queries returned by\ncalling it, are iterable. :: </s> remove The following operators are available as shortcuts to querying with regular\nexpressions:\n\n* ``exact`` -- string field exactly matches value\n* ``iexact`` -- string field exactly matches value (case insensitive)\n* ``contains`` -- string field contains value\n* ``icontains`` -- string field contains value (case insensitive)\n* ``startswith`` -- string field starts with value\n* ``istartswith`` -- string field starts with value (case insensitive)\n* ``endswith`` -- string field ends with value\n* ``iendswith`` -- string field ends with value (case insensitive)\n* ``match``  -- performs an $elemMatch so you can match an entire document within an array\n\nSome Tips\n---------\n\n* Attributes can be set as ``unique``\n* ``MongoEngine`` creates the ``_id`` attribute automatically to acess ``ObjectIds``\n* You can add choices to string fields: ``StringField(choices=['Apple', 'Banana'])``\n* If you don't want your class name to be the same name as the collection, you can define\n  a ``meta`` class member and use the ``collection`` parameter::\n\n    class Movie(Document):\n\n        meta ={'collection': 'movie_documents'}\n\nAccessing PyMongo MongoClient\n-----------------------------\n\nIf, for some reason, you want to access PyMongo instance, use ``get_connection`` function::\n\n    from mongoengine.connection import get_connection\n </s> add Documentation\n-------------", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Configuration\n <mask> -------------\n <mask> \n <mask> Basic setup can be done by defining ``MONGODB_SETTINGS`` on App config and then\n <mask> creating a ``MongoEngine`` instance::\n <mask> \n <mask>     from flask import Flask\n <mask>     from flask_mongoengine import MongoEngine\n <mask> \n <mask>     app = Flask(__name__)\n </s> simplify mongoengine doc, redirect from mongokit </s> remove .. _Flask-MongoEngine: http://docs.mongoengine.org/projects/flask-mongoengine/en/latest/>`_\n </s> add .. _Flask-MongoEngine: https://flask-mongoengine.readthedocs.io\n </s> remove         'host': \"mongodb://localhost:27017/mydb\"\n </s> add         \"db\": \"myapp\", </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document):\n </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. :: </s> remove The following operators are available as shortcuts to querying with regular\nexpressions:\n\n* ``exact`` -- string field exactly matches value\n* ``iexact`` -- string field exactly matches value (case insensitive)\n* ``contains`` -- string field contains value\n* ``icontains`` -- string field contains value (case insensitive)\n* ``startswith`` -- string field starts with value\n* ``istartswith`` -- string field starts with value (case insensitive)\n* ``endswith`` -- string field ends with value\n* ``iendswith`` -- string field ends with value (case insensitive)\n* ``match``  -- performs an $elemMatch so you can match an entire document within an array\n\nSome Tips\n---------\n\n* Attributes can be set as ``unique``\n* ``MongoEngine`` creates the ``_id`` attribute automatically to acess ``ObjectIds``\n* You can add choices to string fields: ``StringField(choices=['Apple', 'Banana'])``\n* If you don't want your class name to be the same name as the collection, you can define\n  a ``meta`` class member and use the ``collection`` parameter::\n\n    class Movie(Document):\n\n        meta ={'collection': 'movie_documents'}\n\nAccessing PyMongo MongoClient\n-----------------------------\n\nIf, for some reason, you want to access PyMongo instance, use ``get_connection`` function::\n\n    from mongoengine.connection import get_connection\n </s> add Documentation\n------------- </s> remove     conn = get_connection()\n    collection = conn.mydb.movie\n    collection({'title': u'Days of Thunder'})\n </s> add There are many more ways to define and query documents with MongoEngine.\nFor more information, check out the `official documentation\n<MongoEngine_>`_. </s> remove         title = StringField(required=True)\n        year = IntField()\n        rated = StringField()\n        director = StringField()\n        actors = ListField()\n </s> add     import mongoengine as me", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     from flask_mongoengine import MongoEngine\n <mask> \n <mask>     app = Flask(__name__)\n <mask>     app.config['MONGODB_SETTINGS'] = {\n <mask>         'host': \"mongodb://localhost:27017/mydb\"\n <mask>     }\n <mask>     db = MongoEngine(app)\n <mask> \n <mask> \n <mask> Mapping Documents\n </s> simplify mongoengine doc, redirect from mongokit </s> remove Basic setup can be done by defining ``MONGODB_SETTINGS`` on App config and then\ncreating a ``MongoEngine`` instance::\n </s> add Basic setup can be done by defining ``MONGODB_SETTINGS`` on\n``app.config`` and creating a ``MongoEngine`` instance. :: </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document):\n </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. :: </s> remove     conn = get_connection()\n    collection = conn.mydb.movie\n    collection({'title': u'Days of Thunder'})\n </s> add There are many more ways to define and query documents with MongoEngine.\nFor more information, check out the `official documentation\n<MongoEngine_>`_. </s> remove         title = StringField(required=True)\n        year = IntField()\n        rated = StringField()\n        director = StringField()\n        actors = ListField()\n </s> add     import mongoengine as me </s> remove If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\nthe embedded document and ``EmbeddedDocumentField`` to declare it on the parent document::\n </s> add     class Movie(me.Document):\n        title = me.StringField(required=True)\n        year = me.IntField()\n        rated = me.StringField()\n        director = me.StringField()\n        actors = me.ListField() </s> remove         imdb_id = StringField()\n        rating = DecimalField()\n        votes = IntField()\n\n\n    class Movie(Document):\n </s> add     class Imdb(me.EmbeddedDocument):\n        imdb_id = me.StringField()\n        rating = me.DecimalField()\n        votes = me.IntField()", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Mapping Documents\n <mask> -----------------\n <mask> \n <mask> To declare models that will represent your Mongo documents, just create a class that\n <mask> inherits from ``Document`` and declare each of the fields::\n <mask> \n <mask>     from mongoengine import *\n <mask> \n <mask> \n <mask>     class Movie(Document):\n <mask> \n <mask>         title = StringField(required=True)\n <mask>         year = IntField()\n <mask>         rated = StringField()\n <mask>         director = StringField()\n </s> simplify mongoengine doc, redirect from mongokit </s> remove         title = StringField(required=True)\n        year = IntField()\n        rated = StringField()\n        director = StringField()\n        actors = ListField()\n </s> add     import mongoengine as me </s> remove If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\nthe embedded document and ``EmbeddedDocumentField`` to declare it on the parent document::\n </s> add     class Movie(me.Document):\n        title = me.StringField(required=True)\n        year = me.IntField()\n        rated = me.StringField()\n        director = me.StringField()\n        actors = me.ListField() </s> remove         imdb_id = StringField()\n        rating = DecimalField()\n        votes = IntField()\n\n\n    class Movie(Document):\n </s> add     class Imdb(me.EmbeddedDocument):\n        imdb_id = me.StringField()\n        rating = me.DecimalField()\n        votes = me.IntField() </s> remove     class Imdb(EmbeddedDocument):\n </s> add If the document has nested fields, use ``EmbeddedDocument`` to\ndefined the fields of the embedded document and\n``EmbeddedDocumentField`` to declare it on the parent document. :: </s> remove         'host': \"mongodb://localhost:27017/mydb\"\n </s> add         \"db\": \"myapp\", </s> remove Just create the objects and call ``save()``::\n </s> add Instantiate your document class with keyword arguments for the fields.\nYou can also assign values to the field attributes after instantiation.\nThen call ``doc.save()``. ::", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep replace replace keep keep", "code_tokens": " <mask> \n <mask> \n <mask>     class Movie(Document):\n <mask> \n <mask>         title = StringField(required=True)\n <mask>         year = IntField()\n <mask>         rated = StringField()\n <mask>         director = StringField()\n <mask>         actors = ListField()\n <mask> \n <mask> If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\n <mask> the embedded document and ``EmbeddedDocumentField`` to declare it on the parent document::\n <mask> \n <mask>     class Imdb(EmbeddedDocument):\n </s> simplify mongoengine doc, redirect from mongokit </s> remove     class Imdb(EmbeddedDocument):\n </s> add If the document has nested fields, use ``EmbeddedDocument`` to\ndefined the fields of the embedded document and\n``EmbeddedDocumentField`` to declare it on the parent document. :: </s> remove         imdb_id = StringField()\n        rating = DecimalField()\n        votes = IntField()\n\n\n    class Movie(Document):\n </s> add     class Imdb(me.EmbeddedDocument):\n        imdb_id = me.StringField()\n        rating = me.DecimalField()\n        votes = me.IntField() </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document):\n </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. :: </s> remove     bttf = Movies.objects(title=\"Back To The Future\").get()  # Throw error if not unique\n </s> add     bttf = Movies.objects(title=\"Back To The Future\").get_or_404() </s> remove Just create the objects and call ``save()``::\n </s> add Instantiate your document class with keyword arguments for the fields.\nYou can also assign values to the field attributes after instantiation.\nThen call ``doc.save()``. ::", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace replace replace replace replace", "code_tokens": " <mask> \n <mask> If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\n <mask> the embedded document and ``EmbeddedDocumentField`` to declare it on the parent document::\n <mask> \n <mask>     class Imdb(EmbeddedDocument):\n <mask> \n <mask>         imdb_id = StringField()\n <mask>         rating = DecimalField()\n <mask>         votes = IntField()\n <mask> \n <mask> \n <mask>     class Movie(Document):\n </s> simplify mongoengine doc, redirect from mongokit </s> remove If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\nthe embedded document and ``EmbeddedDocumentField`` to declare it on the parent document::\n </s> add     class Movie(me.Document):\n        title = me.StringField(required=True)\n        year = me.IntField()\n        rated = me.StringField()\n        director = me.StringField()\n        actors = me.ListField() </s> remove         title = StringField(required=True)\n        year = IntField()\n        rated = StringField()\n        director = StringField()\n        actors = ListField()\n </s> add     import mongoengine as me </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document):\n </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. :: </s> remove Use the class ``objects`` attribute to make queries::\n </s> add Use the class ``objects`` attribute to make queries. A keyword argument\nlooks for an equal value on the field. :: </s> remove     bttf = Movies.objects(title=\"Back To The Future\").get()  # Throw error if not unique\n </s> add     bttf = Movies.objects(title=\"Back To The Future\").get_or_404()", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         votes = me.IntField()\n <mask> \n <mask>         ...\n <mask>         imdb = me.EmbeddedDocumentField(Imdb)\n <mask> \n <mask> \n </s> simplify mongoengine doc, redirect from mongokit </s> remove         imdb = EmbeddedDocumentField(Imdb)\n </s> add         imdb = me.EmbeddedDocumentField(Imdb) </s> remove         imdb_id = StringField()\n        rating = DecimalField()\n        votes = IntField()\n\n\n    class Movie(Document):\n </s> add     class Imdb(me.EmbeddedDocument):\n        imdb_id = me.StringField()\n        rating = me.DecimalField()\n        votes = me.IntField() </s> remove If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\nthe embedded document and ``EmbeddedDocumentField`` to declare it on the parent document::\n </s> add     class Movie(me.Document):\n        title = me.StringField(required=True)\n        year = me.IntField()\n        rated = me.StringField()\n        director = me.StringField()\n        actors = me.ListField() </s> remove     class Imdb(EmbeddedDocument):\n </s> add If the document has nested fields, use ``EmbeddedDocument`` to\ndefined the fields of the embedded document and\n``EmbeddedDocumentField`` to declare it on the parent document. :: </s> remove         'host': \"mongodb://localhost:27017/mydb\"\n </s> add         \"db\": \"myapp\", </s> remove         title = StringField(required=True)\n        year = IntField()\n        rated = StringField()\n        director = StringField()\n        actors = ListField()\n </s> add     import mongoengine as me", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     class Movie(Document):\n <mask> \n <mask>         ...\n <mask>         imdb = EmbeddedDocumentField(Imdb)\n <mask> \n <mask> \n <mask> Creating Data\n <mask> -------------\n <mask> \n </s> simplify mongoengine doc, redirect from mongokit </s> remove         imdb_id = StringField()\n        rating = DecimalField()\n        votes = IntField()\n\n\n    class Movie(Document):\n </s> add     class Imdb(me.EmbeddedDocument):\n        imdb_id = me.StringField()\n        rating = me.DecimalField()\n        votes = me.IntField() </s> add     class Movie(me.Document): </s> remove Just create the objects and call ``save()``::\n </s> add Instantiate your document class with keyword arguments for the fields.\nYou can also assign values to the field attributes after instantiation.\nThen call ``doc.save()``. :: </s> remove         title = StringField(required=True)\n        year = IntField()\n        rated = StringField()\n        director = StringField()\n        actors = ListField()\n </s> add     import mongoengine as me </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document):\n </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. :: </s> remove The following operators are available as shortcuts to querying with regular\nexpressions:\n\n* ``exact`` -- string field exactly matches value\n* ``iexact`` -- string field exactly matches value (case insensitive)\n* ``contains`` -- string field contains value\n* ``icontains`` -- string field contains value (case insensitive)\n* ``startswith`` -- string field starts with value\n* ``istartswith`` -- string field starts with value (case insensitive)\n* ``endswith`` -- string field ends with value\n* ``iendswith`` -- string field ends with value (case insensitive)\n* ``match``  -- performs an $elemMatch so you can match an entire document within an array\n\nSome Tips\n---------\n\n* Attributes can be set as ``unique``\n* ``MongoEngine`` creates the ``_id`` attribute automatically to acess ``ObjectIds``\n* You can add choices to string fields: ``StringField(choices=['Apple', 'Banana'])``\n* If you don't want your class name to be the same name as the collection, you can define\n  a ``meta`` class member and use the ``collection`` parameter::\n\n    class Movie(Document):\n\n        meta ={'collection': 'movie_documents'}\n\nAccessing PyMongo MongoClient\n-----------------------------\n\nIf, for some reason, you want to access PyMongo instance, use ``get_connection`` function::\n\n    from mongoengine.connection import get_connection\n </s> add Documentation\n-------------", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Creating Data\n <mask> -------------\n <mask> \n <mask> Just create the objects and call ``save()``::\n <mask> \n <mask>     bttf = Movie(title=\"Back To The Future\", year=1985)\n <mask>     bttf.actors = [\n <mask>         \"Michael J. Fox\",\n <mask>         \"Christopher Lloyd\"\n </s> simplify mongoengine doc, redirect from mongokit </s> remove         imdb = EmbeddedDocumentField(Imdb)\n </s> add         imdb = me.EmbeddedDocumentField(Imdb) </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document):\n </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. :: </s> remove     bttf = Movies.objects(title=\"Back To The Future\").get()  # Throw error if not unique\n </s> add     bttf = Movies.objects(title=\"Back To The Future\").get_or_404() </s> remove ``objects`` is an iterable. Query operators may be user by concatenating it with the document\nkey using a double-underscore::\n </s> add Query operators may be used by concatenating them with the field name\nusing a double-underscore. ``objects``, and queries returned by\ncalling it, are iterable. :: </s> remove Use the class ``objects`` attribute to make queries::\n </s> add Use the class ``objects`` attribute to make queries. A keyword argument\nlooks for an equal value on the field. :: </s> remove If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\nthe embedded document and ``EmbeddedDocumentField`` to declare it on the parent document::\n </s> add     class Movie(me.Document):\n        title = me.StringField(required=True)\n        year = me.IntField()\n        rated = me.StringField()\n        director = me.StringField()\n        actors = me.ListField()", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep replace keep replace", "code_tokens": " <mask> -------\n <mask> \n <mask> Use the class ``objects`` attribute to make queries::\n <mask> \n <mask>     bttf = Movies.objects(title=\"Back To The Future\").get()  # Throw error if not unique\n </s> simplify mongoengine doc, redirect from mongokit </s> remove ``objects`` is an iterable. Query operators may be user by concatenating it with the document\nkey using a double-underscore::\n </s> add Query operators may be used by concatenating them with the field name\nusing a double-underscore. ``objects``, and queries returned by\ncalling it, are iterable. :: </s> remove Just create the objects and call ``save()``::\n </s> add Instantiate your document class with keyword arguments for the fields.\nYou can also assign values to the field attributes after instantiation.\nThen call ``doc.save()``. :: </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document):\n </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. :: </s> remove         title = StringField(required=True)\n        year = IntField()\n        rated = StringField()\n        director = StringField()\n        actors = ListField()\n </s> add     import mongoengine as me </s> remove If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\nthe embedded document and ``EmbeddedDocumentField`` to declare it on the parent document::\n </s> add     class Movie(me.Document):\n        title = me.StringField(required=True)\n        year = me.IntField()\n        rated = me.StringField()\n        director = me.StringField()\n        actors = me.ListField()", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> Use the class ``objects`` attribute to make queries::\n <mask> \n <mask>     bttf = Movies.objects(title=\"Back To The Future\").get()  # Throw error if not unique\n <mask> \n <mask> ``objects`` is an iterable. Query operators may be user by concatenating it with the document\n <mask> key using a double-underscore::\n <mask> \n <mask>     some_theron_movie = Movie.objects(actors__in=[\"Charlize Theron\"]).first()\n <mask> \n <mask>     for recents in Movie.objects(year__gte=2017):\n <mask>         print(recents.title)\n </s> simplify mongoengine doc, redirect from mongokit </s> remove     bttf = Movies.objects(title=\"Back To The Future\").get()  # Throw error if not unique\n </s> add     bttf = Movies.objects(title=\"Back To The Future\").get_or_404() </s> remove Use the class ``objects`` attribute to make queries::\n </s> add Use the class ``objects`` attribute to make queries. A keyword argument\nlooks for an equal value on the field. :: </s> remove Available operators are as follows:\n\n* ``ne`` -- not equal to\n* ``lt`` -- less than\n* ``lte`` -- less than or equal to\n* ``gt`` -- greater than\n* ``gte`` -- greater than or equal to\n* ``not`` -- negate a standard check, may be used before other operators (e.g.\n  ``Q(age__not__mod=5)``)\n* ``in`` -- value is in list (a list of values should be provided)\n* ``nin`` -- value is not in list (a list of values should be provided)\n* ``mod`` -- ``value % x == y``, where ``x`` and ``y`` are two provided values\n* ``all`` -- every item in list of values provided is in array\n* ``size`` -- the size of the array is\n* ``exists`` -- value for field exists\n\nString queries\n::::::::::::::\n </s> add  </s> remove Just create the objects and call ``save()``::\n </s> add Instantiate your document class with keyword arguments for the fields.\nYou can also assign values to the field attributes after instantiation.\nThen call ``doc.save()``. :: </s> remove The following operators are available as shortcuts to querying with regular\nexpressions:\n\n* ``exact`` -- string field exactly matches value\n* ``iexact`` -- string field exactly matches value (case insensitive)\n* ``contains`` -- string field contains value\n* ``icontains`` -- string field contains value (case insensitive)\n* ``startswith`` -- string field starts with value\n* ``istartswith`` -- string field starts with value (case insensitive)\n* ``endswith`` -- string field ends with value\n* ``iendswith`` -- string field ends with value (case insensitive)\n* ``match``  -- performs an $elemMatch so you can match an entire document within an array\n\nSome Tips\n---------\n\n* Attributes can be set as ``unique``\n* ``MongoEngine`` creates the ``_id`` attribute automatically to acess ``ObjectIds``\n* You can add choices to string fields: ``StringField(choices=['Apple', 'Banana'])``\n* If you don't want your class name to be the same name as the collection, you can define\n  a ``meta`` class member and use the ``collection`` parameter::\n\n    class Movie(Document):\n\n        meta ={'collection': 'movie_documents'}\n\nAccessing PyMongo MongoClient\n-----------------------------\n\nIf, for some reason, you want to access PyMongo instance, use ``get_connection`` function::\n\n    from mongoengine.connection import get_connection\n </s> add Documentation\n------------- </s> remove     class Imdb(EmbeddedDocument):\n </s> add If the document has nested fields, use ``EmbeddedDocument`` to\ndefined the fields of the embedded document and\n``EmbeddedDocumentField`` to declare it on the parent document. ::", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     for recents in Movie.objects(year__gte=2017):\n <mask>         print(recents.title)\n <mask> \n <mask> Available operators are as follows:\n <mask> \n <mask> * ``ne`` -- not equal to\n <mask> * ``lt`` -- less than\n <mask> * ``lte`` -- less than or equal to\n <mask> * ``gt`` -- greater than\n <mask> * ``gte`` -- greater than or equal to\n <mask> * ``not`` -- negate a standard check, may be used before other operators (e.g.\n <mask>   ``Q(age__not__mod=5)``)\n <mask> * ``in`` -- value is in list (a list of values should be provided)\n <mask> * ``nin`` -- value is not in list (a list of values should be provided)\n <mask> * ``mod`` -- ``value % x == y``, where ``x`` and ``y`` are two provided values\n <mask> * ``all`` -- every item in list of values provided is in array\n <mask> * ``size`` -- the size of the array is\n <mask> * ``exists`` -- value for field exists\n <mask> \n <mask> String queries\n <mask> ::::::::::::::\n <mask> \n <mask> The following operators are available as shortcuts to querying with regular\n <mask> expressions:\n <mask> \n <mask> * ``exact`` -- string field exactly matches value\n </s> simplify mongoengine doc, redirect from mongokit </s> remove The following operators are available as shortcuts to querying with regular\nexpressions:\n\n* ``exact`` -- string field exactly matches value\n* ``iexact`` -- string field exactly matches value (case insensitive)\n* ``contains`` -- string field contains value\n* ``icontains`` -- string field contains value (case insensitive)\n* ``startswith`` -- string field starts with value\n* ``istartswith`` -- string field starts with value (case insensitive)\n* ``endswith`` -- string field ends with value\n* ``iendswith`` -- string field ends with value (case insensitive)\n* ``match``  -- performs an $elemMatch so you can match an entire document within an array\n\nSome Tips\n---------\n\n* Attributes can be set as ``unique``\n* ``MongoEngine`` creates the ``_id`` attribute automatically to acess ``ObjectIds``\n* You can add choices to string fields: ``StringField(choices=['Apple', 'Banana'])``\n* If you don't want your class name to be the same name as the collection, you can define\n  a ``meta`` class member and use the ``collection`` parameter::\n\n    class Movie(Document):\n\n        meta ={'collection': 'movie_documents'}\n\nAccessing PyMongo MongoClient\n-----------------------------\n\nIf, for some reason, you want to access PyMongo instance, use ``get_connection`` function::\n\n    from mongoengine.connection import get_connection\n </s> add Documentation\n------------- </s> remove ``objects`` is an iterable. Query operators may be user by concatenating it with the document\nkey using a double-underscore::\n </s> add Query operators may be used by concatenating them with the field name\nusing a double-underscore. ``objects``, and queries returned by\ncalling it, are iterable. :: </s> remove Use the class ``objects`` attribute to make queries::\n </s> add Use the class ``objects`` attribute to make queries. A keyword argument\nlooks for an equal value on the field. :: </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document):\n </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. :: </s> remove     bttf = Movies.objects(title=\"Back To The Future\").get()  # Throw error if not unique\n </s> add     bttf = Movies.objects(title=\"Back To The Future\").get_or_404() </s> remove Just create the objects and call ``save()``::\n </s> add Instantiate your document class with keyword arguments for the fields.\nYou can also assign values to the field attributes after instantiation.\nThen call ``doc.save()``. ::", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep replace replace replace keep", "code_tokens": " <mask> \n <mask> String queries\n <mask> ::::::::::::::\n <mask> \n <mask> The following operators are available as shortcuts to querying with regular\n <mask> expressions:\n <mask> \n <mask> * ``exact`` -- string field exactly matches value\n <mask> * ``iexact`` -- string field exactly matches value (case insensitive)\n <mask> * ``contains`` -- string field contains value\n <mask> * ``icontains`` -- string field contains value (case insensitive)\n <mask> * ``startswith`` -- string field starts with value\n <mask> * ``istartswith`` -- string field starts with value (case insensitive)\n <mask> * ``endswith`` -- string field ends with value\n <mask> * ``iendswith`` -- string field ends with value (case insensitive)\n <mask> * ``match``  -- performs an $elemMatch so you can match an entire document within an array\n <mask> \n <mask> Some Tips\n <mask> ---------\n <mask> \n <mask> * Attributes can be set as ``unique``\n <mask> * ``MongoEngine`` creates the ``_id`` attribute automatically to acess ``ObjectIds``\n <mask> * You can add choices to string fields: ``StringField(choices=['Apple', 'Banana'])``\n <mask> * If you don't want your class name to be the same name as the collection, you can define\n <mask>   a ``meta`` class member and use the ``collection`` parameter::\n <mask> \n <mask>     class Movie(Document):\n <mask> \n <mask>         meta ={'collection': 'movie_documents'}\n <mask> \n <mask> Accessing PyMongo MongoClient\n <mask> -----------------------------\n <mask> \n <mask> If, for some reason, you want to access PyMongo instance, use ``get_connection`` function::\n <mask> \n <mask>     from mongoengine.connection import get_connection\n <mask> \n <mask>     conn = get_connection()\n <mask>     collection = conn.mydb.movie\n <mask>     collection({'title': u'Days of Thunder'})\n <mask> \n </s> simplify mongoengine doc, redirect from mongokit </s> remove Available operators are as follows:\n\n* ``ne`` -- not equal to\n* ``lt`` -- less than\n* ``lte`` -- less than or equal to\n* ``gt`` -- greater than\n* ``gte`` -- greater than or equal to\n* ``not`` -- negate a standard check, may be used before other operators (e.g.\n  ``Q(age__not__mod=5)``)\n* ``in`` -- value is in list (a list of values should be provided)\n* ``nin`` -- value is not in list (a list of values should be provided)\n* ``mod`` -- ``value % x == y``, where ``x`` and ``y`` are two provided values\n* ``all`` -- every item in list of values provided is in array\n* ``size`` -- the size of the array is\n* ``exists`` -- value for field exists\n\nString queries\n::::::::::::::\n </s> add  </s> remove Use the class ``objects`` attribute to make queries::\n </s> add Use the class ``objects`` attribute to make queries. A keyword argument\nlooks for an equal value on the field. :: </s> remove ``objects`` is an iterable. Query operators may be user by concatenating it with the document\nkey using a double-underscore::\n </s> add Query operators may be used by concatenating them with the field name\nusing a double-underscore. ``objects``, and queries returned by\ncalling it, are iterable. :: </s> remove Just create the objects and call ``save()``::\n </s> add Instantiate your document class with keyword arguments for the fields.\nYou can also assign values to the field attributes after instantiation.\nThen call ``doc.save()``. :: </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document):\n </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. ::", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace", "code_tokens": " <mask>     conn = get_connection()\n <mask>     collection = conn.mydb.movie\n <mask>     collection({'title': u'Days of Thunder'})\n <mask> \n <mask> For more information about MongoEngine, head over to the\n <mask> `website <http://docs.mongoengine.org/>`_.\n </s> simplify mongoengine doc, redirect from mongokit </s> remove     conn = get_connection()\n    collection = conn.mydb.movie\n    collection({'title': u'Days of Thunder'})\n </s> add There are many more ways to define and query documents with MongoEngine.\nFor more information, check out the `official documentation\n<MongoEngine_>`_. </s> remove The following operators are available as shortcuts to querying with regular\nexpressions:\n\n* ``exact`` -- string field exactly matches value\n* ``iexact`` -- string field exactly matches value (case insensitive)\n* ``contains`` -- string field contains value\n* ``icontains`` -- string field contains value (case insensitive)\n* ``startswith`` -- string field starts with value\n* ``istartswith`` -- string field starts with value (case insensitive)\n* ``endswith`` -- string field ends with value\n* ``iendswith`` -- string field ends with value (case insensitive)\n* ``match``  -- performs an $elemMatch so you can match an entire document within an array\n\nSome Tips\n---------\n\n* Attributes can be set as ``unique``\n* ``MongoEngine`` creates the ``_id`` attribute automatically to acess ``ObjectIds``\n* You can add choices to string fields: ``StringField(choices=['Apple', 'Banana'])``\n* If you don't want your class name to be the same name as the collection, you can define\n  a ``meta`` class member and use the ``collection`` parameter::\n\n    class Movie(Document):\n\n        meta ={'collection': 'movie_documents'}\n\nAccessing PyMongo MongoClient\n-----------------------------\n\nIf, for some reason, you want to access PyMongo instance, use ``get_connection`` function::\n\n    from mongoengine.connection import get_connection\n </s> add Documentation\n------------- </s> remove If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\nthe embedded document and ``EmbeddedDocumentField`` to declare it on the parent document::\n </s> add     class Movie(me.Document):\n        title = me.StringField(required=True)\n        year = me.IntField()\n        rated = me.StringField()\n        director = me.StringField()\n        actors = me.ListField() </s> remove     class Imdb(EmbeddedDocument):\n </s> add If the document has nested fields, use ``EmbeddedDocument`` to\ndefined the fields of the embedded document and\n``EmbeddedDocumentField`` to declare it on the parent document. :: </s> remove         title = StringField(required=True)\n        year = IntField()\n        rated = StringField()\n        director = StringField()\n        actors = ListField()\n </s> add     import mongoengine as me </s> remove         imdb_id = StringField()\n        rating = DecimalField()\n        votes = IntField()\n\n\n    class Movie(Document):\n </s> add     class Imdb(me.EmbeddedDocument):\n        imdb_id = me.StringField()\n        rating = me.DecimalField()\n        votes = me.IntField()", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ===========================\n <mask> \n <mask> .. versionadded:: 0.3\n <mask> \n <mask> Applications fail, server fail.  Sooner or later you will see an exception\n <mask> in production.  Even if your code is 100% correct, you will still see\n <mask> exceptions from time to time.  Why?  Because everything else involved will\n <mask> fail.  Here some situations where perfectly fine code can lead to server\n <mask> errors:\n <mask> \n </s> Error Handling documentation fixes (grammar, etc) </s> remove And that's just a small sample of issues you could be facing.  So how to\n </s> add And that's just a small sample of issues you could be facing.  So how do we </s> remove server) you won't see any log messages by default.  Why that?  Flask tries\nto be a zero-configuration framework and where should it drop the logs for\nyou if there is no configuration.  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has the\n </s> add server) you won't see any log messages by default.  Why is that?  Flask\ntries to be a zero-configuration framework.  Where should it drop the logs\nfor you if there is no configuration?  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has </s> remove your mail server requires credentials these can also provided, for that\ncheck out the documentation for the :class:`~logging.handlers.SMTPHandler`.\n </s> add your mail server requires credentials, these can also be provided.  For\nthat check out the documentation for the\n:class:`~logging.handlers.SMTPHandler`. </s> remove Flask is using the Python builtin logging system and that one can actually\nsend you mails for errors which is probably what you want.  Here is how\nyou can configure the Flask logger to send you mails for exceptions::\n </s> add Flask uses the Python builtin logging system, and it can actually send\nyou mails for errors which is probably what you want.  Here is how you can\nconfigure the Flask logger to send you mails for exceptions:: </s> remove     called for exception formatting.  It is passed a :attr:`~sys.exc_info`\n </s> add     called for exception formatting.  It is passed an :attr:`~sys.exc_info` </s> remove A formatter can be instanciated with a format string.  Note that\n </s> add A formatter can be instantiated with a format string.  Note that", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> -   a backend server overloaded\n <mask> -   a programming error in a library you are using\n <mask> -   network connection of the server to another system failed.\n <mask> \n <mask> And that's just a small sample of issues you could be facing.  So how to\n <mask> deal with that sort of problem?  By default if your application runs in\n <mask> production mode, Flask will display a very simple page for you and log the\n <mask> exception to the :attr:`~flask.Flask.logger`.\n <mask> \n <mask> But there is more you can do, and we will cover some better setups to deal\n </s> Error Handling documentation fixes (grammar, etc) </s> remove send you that message as mail.  But a log record stores more information\n </s> add send you that message as mail.  A log record stores more information, </s> remove A formatter can be instanciated with a format string.  Note that\n </s> add A formatter can be instantiated with a format string.  Note that </s> remove server) you won't see any log messages by default.  Why that?  Flask tries\nto be a zero-configuration framework and where should it drop the logs for\nyou if there is no configuration.  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has the\n </s> add server) you won't see any log messages by default.  Why is that?  Flask\ntries to be a zero-configuration framework.  Where should it drop the logs\nfor you if there is no configuration?  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has </s> remove Flask is using the Python builtin logging system and that one can actually\nsend you mails for errors which is probably what you want.  Here is how\nyou can configure the Flask logger to send you mails for exceptions::\n </s> add Flask uses the Python builtin logging system, and it can actually send\nyou mails for errors which is probably what you want.  Here is how you can\nconfigure the Flask logger to send you mails for exceptions:: </s> remove Other libraries might log themselves as well.  For example, SQLAlchemy use\nlogging heavily in the core.  While there is a method to configure all\n </s> add Other libraries might log themselves as well.  For example, SQLAlchemy uses\nlogging heavily in its core.  While there is a method to configure all </s> remove your mail server requires credentials these can also provided, for that\ncheck out the documentation for the :class:`~logging.handlers.SMTPHandler`.\n </s> add your mail server requires credentials, these can also be provided.  For\nthat check out the documentation for the\n:class:`~logging.handlers.SMTPHandler`.", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> Error Mails\n <mask> -----------\n <mask> \n <mask> If the application runs in production mode (which it will do on your\n <mask> server) you won't see any log messages by default.  Why that?  Flask tries\n <mask> to be a zero-configuration framework and where should it drop the logs for\n <mask> you if there is no configuration.  Guessing is not a good idea because\n <mask> chances are, the place it guessed is not the place where the user has the\n <mask> permission to create a logfile.  Also, for most small applications nobody\n <mask> will look at the logs anyways.\n <mask> \n <mask> In fact, I promise you right now that if you configure a logfile for the\n <mask> application errors you will never look at it except for debugging an issue\n </s> Error Handling documentation fixes (grammar, etc) </s> remove Other libraries might log themselves as well.  For example, SQLAlchemy use\nlogging heavily in the core.  While there is a method to configure all\n </s> add Other libraries might log themselves as well.  For example, SQLAlchemy uses\nlogging heavily in its core.  While there is a method to configure all </s> remove And that's just a small sample of issues you could be facing.  So how to\n </s> add And that's just a small sample of issues you could be facing.  So how do we </s> remove Flask is using the Python builtin logging system and that one can actually\nsend you mails for errors which is probably what you want.  Here is how\nyou can configure the Flask logger to send you mails for exceptions::\n </s> add Flask uses the Python builtin logging system, and it can actually send\nyou mails for errors which is probably what you want.  Here is how you can\nconfigure the Flask logger to send you mails for exceptions:: </s> remove your mail server requires credentials these can also provided, for that\ncheck out the documentation for the :class:`~logging.handlers.SMTPHandler`.\n </s> add your mail server requires credentials, these can also be provided.  For\nthat check out the documentation for the\n:class:`~logging.handlers.SMTPHandler`. </s> remove send you that message as mail.  But a log record stores more information\n </s> add send you that message as mail.  A log record stores more information, </s> remove     called for exception formatting.  It is passed a :attr:`~sys.exc_info`\n </s> add     called for exception formatting.  It is passed an :attr:`~sys.exc_info`", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> when a user reported it for you.  What you want instead is a mail the\n <mask> second the exception happened.  Then you get an alert and you can do\n <mask> something about it.\n <mask> \n <mask> Flask is using the Python builtin logging system and that one can actually\n <mask> send you mails for errors which is probably what you want.  Here is how\n <mask> you can configure the Flask logger to send you mails for exceptions::\n <mask> \n <mask>     ADMINS = ['yourname@example.com']\n <mask>     if not app.debug:\n <mask>         import logging\n <mask>         from logging.handlers import SMTPHandler\n </s> Error Handling documentation fixes (grammar, etc) </s> remove server) you won't see any log messages by default.  Why that?  Flask tries\nto be a zero-configuration framework and where should it drop the logs for\nyou if there is no configuration.  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has the\n </s> add server) you won't see any log messages by default.  Why is that?  Flask\ntries to be a zero-configuration framework.  Where should it drop the logs\nfor you if there is no configuration?  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has </s> remove Other libraries might log themselves as well.  For example, SQLAlchemy use\nlogging heavily in the core.  While there is a method to configure all\n </s> add Other libraries might log themselves as well.  For example, SQLAlchemy uses\nlogging heavily in its core.  While there is a method to configure all </s> remove And that's just a small sample of issues you could be facing.  So how to\n </s> add And that's just a small sample of issues you could be facing.  So how do we </s> remove your mail server requires credentials these can also provided, for that\ncheck out the documentation for the :class:`~logging.handlers.SMTPHandler`.\n </s> add your mail server requires credentials, these can also be provided.  For\nthat check out the documentation for the\n:class:`~logging.handlers.SMTPHandler`. </s> remove     called for exception formatting.  It is passed a :attr:`~sys.exc_info`\n </s> add     called for exception formatting.  It is passed an :attr:`~sys.exc_info` </s> remove send you that message as mail.  But a log record stores more information\n </s> add send you that message as mail.  A log record stores more information,", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> So what just happened?  We created a new\n <mask> :class:`~logging.handlers.SMTPHandler` that will send mails with the mail\n <mask> server listening on ``127.0.0.1`` to all the `ADMINS` from the address\n <mask> *server-error@example.com* with the subject \"YourApplication Failed\".  If\n <mask> your mail server requires credentials these can also provided, for that\n <mask> check out the documentation for the :class:`~logging.handlers.SMTPHandler`.\n <mask> \n <mask> We also tell the handler to only send errors and more critical messages.\n <mask> Because we certainly don't want to get a mail for warnings or other\n <mask> useless logs that might happen during request handling.\n <mask> \n </s> Error Handling documentation fixes (grammar, etc) </s> remove Flask is using the Python builtin logging system and that one can actually\nsend you mails for errors which is probably what you want.  Here is how\nyou can configure the Flask logger to send you mails for exceptions::\n </s> add Flask uses the Python builtin logging system, and it can actually send\nyou mails for errors which is probably what you want.  Here is how you can\nconfigure the Flask logger to send you mails for exceptions:: </s> remove send you that message as mail.  But a log record stores more information\n </s> add send you that message as mail.  A log record stores more information, </s> remove And that's just a small sample of issues you could be facing.  So how to\n </s> add And that's just a small sample of issues you could be facing.  So how do we </s> remove Other libraries might log themselves as well.  For example, SQLAlchemy use\nlogging heavily in the core.  While there is a method to configure all\n </s> add Other libraries might log themselves as well.  For example, SQLAlchemy uses\nlogging heavily in its core.  While there is a method to configure all </s> remove server) you won't see any log messages by default.  Why that?  Flask tries\nto be a zero-configuration framework and where should it drop the logs for\nyou if there is no configuration.  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has the\n </s> add server) you won't see any log messages by default.  Why is that?  Flask\ntries to be a zero-configuration framework.  Where should it drop the logs\nfor you if there is no configuration?  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has </s> remove A formatter can be instanciated with a format string.  Note that\n </s> add A formatter can be instantiated with a format string.  Note that", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep replace keep keep keep keep replace", "code_tokens": " <mask> By default a handler will only write the message string into a file or\n <mask> send you that message as mail.  But a log record stores more information\n <mask> and it makes a lot of sense to configure your logger to also contain that\n <mask> information so that you have a better idea of why that error happened, and\n <mask> more importantly, where it did.\n <mask> \n <mask> A formatter can be instanciated with a format string.  Note that\n </s> Error Handling documentation fixes (grammar, etc) </s> remove And that's just a small sample of issues you could be facing.  So how to\n </s> add And that's just a small sample of issues you could be facing.  So how do we </s> remove your mail server requires credentials these can also provided, for that\ncheck out the documentation for the :class:`~logging.handlers.SMTPHandler`.\n </s> add your mail server requires credentials, these can also be provided.  For\nthat check out the documentation for the\n:class:`~logging.handlers.SMTPHandler`. </s> remove server) you won't see any log messages by default.  Why that?  Flask tries\nto be a zero-configuration framework and where should it drop the logs for\nyou if there is no configuration.  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has the\n </s> add server) you won't see any log messages by default.  Why is that?  Flask\ntries to be a zero-configuration framework.  Where should it drop the logs\nfor you if there is no configuration?  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has </s> remove Flask is using the Python builtin logging system and that one can actually\nsend you mails for errors which is probably what you want.  Here is how\nyou can configure the Flask logger to send you mails for exceptions::\n </s> add Flask uses the Python builtin logging system, and it can actually send\nyou mails for errors which is probably what you want.  Here is how you can\nconfigure the Flask logger to send you mails for exceptions:: </s> remove Other libraries might log themselves as well.  For example, SQLAlchemy use\nlogging heavily in the core.  While there is a method to configure all\n </s> add Other libraries might log themselves as well.  For example, SQLAlchemy uses\nlogging heavily in its core.  While there is a method to configure all", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> :meth:`~logging.Formatter.formatTime`:\n <mask>     called for `asctime` formatting.  If you want a different time format\n <mask>     you can override this method.\n <mask> :meth:`~logging.Formatter.formatException`\n <mask>     called for exception formatting.  It is passed a :attr:`~sys.exc_info`\n <mask>     tuple and has to return a string.  The default is usually fine, you\n <mask>     don't have to override it.\n <mask> \n <mask> For more information, head over to the official documentation.\n <mask> \n </s> Error Handling documentation fixes (grammar, etc) </s> remove send you that message as mail.  But a log record stores more information\n </s> add send you that message as mail.  A log record stores more information, </s> remove server) you won't see any log messages by default.  Why that?  Flask tries\nto be a zero-configuration framework and where should it drop the logs for\nyou if there is no configuration.  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has the\n </s> add server) you won't see any log messages by default.  Why is that?  Flask\ntries to be a zero-configuration framework.  Where should it drop the logs\nfor you if there is no configuration?  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has </s> remove Flask is using the Python builtin logging system and that one can actually\nsend you mails for errors which is probably what you want.  Here is how\nyou can configure the Flask logger to send you mails for exceptions::\n </s> add Flask uses the Python builtin logging system, and it can actually send\nyou mails for errors which is probably what you want.  Here is how you can\nconfigure the Flask logger to send you mails for exceptions:: </s> remove A formatter can be instanciated with a format string.  Note that\n </s> add A formatter can be instantiated with a format string.  Note that </s> remove Other libraries might log themselves as well.  For example, SQLAlchemy use\nlogging heavily in the core.  While there is a method to configure all\n </s> add Other libraries might log themselves as well.  For example, SQLAlchemy uses\nlogging heavily in its core.  While there is a method to configure all </s> remove And that's just a small sample of issues you could be facing.  So how to\n </s> add And that's just a small sample of issues you could be facing.  So how do we", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> Other Libraries\n <mask> ---------------\n <mask> \n <mask> So far we only configured the logger your application created itself.\n <mask> Other libraries might log themselves as well.  For example, SQLAlchemy use\n <mask> logging heavily in the core.  While there is a method to configure all\n <mask> loggers at once in the :mod:`logging` package, I would not recommend using\n <mask> it.  There might be a situation in which you want to have multiple\n <mask> separate applications running side by side in the same Python interpreter\n <mask> and then it becomes impossible to have different logging setups for those.\n <mask> \n </s> Error Handling documentation fixes (grammar, etc) </s> remove server) you won't see any log messages by default.  Why that?  Flask tries\nto be a zero-configuration framework and where should it drop the logs for\nyou if there is no configuration.  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has the\n </s> add server) you won't see any log messages by default.  Why is that?  Flask\ntries to be a zero-configuration framework.  Where should it drop the logs\nfor you if there is no configuration?  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has </s> remove Flask is using the Python builtin logging system and that one can actually\nsend you mails for errors which is probably what you want.  Here is how\nyou can configure the Flask logger to send you mails for exceptions::\n </s> add Flask uses the Python builtin logging system, and it can actually send\nyou mails for errors which is probably what you want.  Here is how you can\nconfigure the Flask logger to send you mails for exceptions:: </s> remove And that's just a small sample of issues you could be facing.  So how to\n </s> add And that's just a small sample of issues you could be facing.  So how do we </s> remove your mail server requires credentials these can also provided, for that\ncheck out the documentation for the :class:`~logging.handlers.SMTPHandler`.\n </s> add your mail server requires credentials, these can also be provided.  For\nthat check out the documentation for the\n:class:`~logging.handlers.SMTPHandler`. </s> remove send you that message as mail.  But a log record stores more information\n </s> add send you that message as mail.  A log record stores more information, </s> remove A formatter can be instanciated with a format string.  Note that\n </s> add A formatter can be instantiated with a format string.  Note that", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep keep keep keep replace keep keep keep", "code_tokens": " <mask> this behavior was changed and :func:`~flask.jsonify` now supports serializing\n <mask> arrays.\n <mask> \n <mask> \n <mask> SSL/HTTPS\n <mask> ---------\n <mask> \n <mask> For implementing HTTPS on your server.\n <mask> \n <mask> Below are some packages that implement this protocol:\n <mask> \n <mask> * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n <mask> * `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n <mask> * `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n <mask> \n <mask> Security Headers\n <mask> ----------------\n <mask> \n <mask> This section contains a list of headers supported by Flask and some packages that implements them.\n <mask> \n <mask> Security Headers\n <mask> ----------------\n <mask> \n <mask> This section contains a list of headers supported by Flask and some packages that implements them.\n <mask> \n <mask> Content Security Policy (CSP)\n <mask> -----------------------------------------------------------------------------\n </s> Suggest only one package, change the sourcecode block to none </s> remove -----------------------------------------------------------------------------\n </s> add ----------------------------- </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-csp <https://github.com/twaldear/flask-csp>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove -------------------------------------------------------------------------------------------------------------------------\n </s> add ----------------------------------------- </s> remove -------------------------------------------------------------------------------------------------------\n </s> add ------------------------------", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> This section contains a list of headers supported by Flask and some packages that implements them.\n <mask> \n <mask> Content Security Policy (CSP)\n <mask> -----------------------------------------------------------------------------\n <mask> \n <mask> Enhance security and prevents common web vulnerabilities such as cross-site scripting and MITM related attacks.\n <mask> \n <mask> Example:\n <mask> \n </s> Suggest only one package, change the sourcecode block to none </s> remove This section contains a list of headers supported by Flask and some packages that implements them.\n </s> add This section contains a list of headers supported by Flask.\nTo configure HTTPS and handle the headers listed below we suggest the package `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`.  </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove \nSSL/HTTPS\n---------\n\nFor implementing HTTPS on your server.\n\nBelow are some packages that implement this protocol:\n\n* `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove -------------------------------------------------------------------------------------------------------\n </s> add ------------------------------ </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-csp <https://github.com/twaldear/flask-csp>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Enhance security and prevents common web vulnerabilities such as cross-site scripting and MITM related attacks.\n <mask> \n <mask> Example:\n <mask> \n <mask> .. sourcecode:: html\n <mask>    \n <mask>    Content-Security-Policy: default-src https:; script-src 'nonce-{random}'; object-src 'none'\n <mask> \n <mask> \n <mask> See also `Content Security Policy <https://csp.withgoogle.com/docs/index.html>`_.\n </s> Suggest only one package, change the sourcecode block to none </s> remove -----------------------------------------------------------------------------\n </s> add ----------------------------- </s> remove This section contains a list of headers supported by Flask and some packages that implements them.\n </s> add This section contains a list of headers supported by Flask.\nTo configure HTTPS and handle the headers listed below we suggest the package `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`.  </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-csp <https://github.com/twaldear/flask-csp>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep replace replace replace replace keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask> * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n <mask> * `flask-csp <https://github.com/twaldear/flask-csp>`_\n <mask> * `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n <mask> \n <mask> HTTP Strict Transport Security (HSTS)\n <mask> ------------------------------------------------------------------------------------------------------------------------------\n <mask> \n <mask> Redirects http requests to https on all urls, preventing MITM attacks.\n <mask> \n <mask> Example:\n </s> Suggest only one package, change the sourcecode block to none </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove -------------------------------------------------------------------------------------------------------\n </s> add ------------------------------ </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove -------------------------------------------------------------------------------------------------------------\n </s> add ----------------------", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Redirects http requests to https on all urls, preventing MITM attacks.\n <mask> \n <mask> Example:\n <mask> \n <mask> .. sourcecode:: html\n <mask>    \n <mask>    Strict-Transport-Security: max-age=<expire-time \n <mask>    Strict-Transport-Security: max-age=<expire-time>; includeSubDomains \n <mask>    Strict-Transport-Security: max-age=<expire-time>; preload \n <mask> \n </s> Suggest only one package, change the sourcecode block to none </s> remove ------------------------------------------------------------------------------------------------------------------------------\n </s> add ------------------------------------- </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-csp <https://github.com/twaldear/flask-csp>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove -------------------------------------------------------------------------------------------------------------\n </s> add ---------------------- </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep replace keep", "code_tokens": " <mask>    Strict-Transport-Security: max-age=<expire-time>; preload \n <mask> \n <mask> See also `Strict Transport Security <https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Strict-Transport-Security>`_. \n <mask> \n <mask> * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n <mask> * `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n <mask> * `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n <mask> \n <mask> X-FRAME-OPTIONS (Clickjacking protection)\n <mask> -------------------------------------------------------------------------------------------------------------------------\n <mask> \n </s> Suggest only one package, change the sourcecode block to none </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-csp <https://github.com/twaldear/flask-csp>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove \nSSL/HTTPS\n---------\n\nFor implementing HTTPS on your server.\n\nBelow are some packages that implement this protocol:\n\n* `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove ------------------------------------------------------------------------------------------------------------------------------\n </s> add ------------------------------------- </s> remove \n* `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\nReferences\n-----------\n\n* https://docs.djangoproject.com/en/1.11/topics/security/\n* https://blog.appcanary.com/2017/http-security-headers.html\n* https://developer.mozilla.org\n* https://csp.withgoogle.com/docs/index.html\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> -------------------------------------------------------------------------------------------------------------------------\n <mask> \n <mask> Prevents the client from clicking page elements outside of the website, avoiding hijacking or UI redress attacks.\n <mask> \n <mask> .. sourcecode:: html\n <mask>    \n <mask>    X-Frame-Options: DENY \n <mask>    X-Frame-Options: SAMEORIGIN\n <mask>    X-Frame-Options: ALLOW-FROM https://example.com/\n <mask> \n </s> Suggest only one package, change the sourcecode block to none </s> remove -------------------------------------------------------------------------------------------------------------------------\n </s> add ----------------------------------------- </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove -------------------------------------------------------------------------------------------------------------\n </s> add ---------------------- </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep replace keep", "code_tokens": " <mask>    X-Frame-Options: ALLOW-FROM https://example.com/\n <mask> \n <mask> See also `X-Frame-Options <https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Frame-Options>`_. \n <mask> \n <mask> * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n <mask> * `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n <mask> \n <mask> X-Content-Type-Options\n <mask> -------------------------------------------------------------------------------------------------------------\n <mask> \n </s> Suggest only one package, change the sourcecode block to none </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove \n* `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\nReferences\n-----------\n\n* https://docs.djangoproject.com/en/1.11/topics/security/\n* https://blog.appcanary.com/2017/http-security-headers.html\n* https://developer.mozilla.org\n* https://csp.withgoogle.com/docs/index.html\n </s> add  </s> remove ----------------------------------------------------------------------------------------------------------\n </s> add -------------- </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-csp <https://github.com/twaldear/flask-csp>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> -------------------------------------------------------------------------------------------------------------\n <mask> \n <mask> Prevents XSS by blocking requests on clients and forcing them to read the content type instead of first opening it.\n <mask> \n <mask> .. sourcecode:: html\n <mask>    \n <mask>    X-Content-Type-Options: nosniff\n <mask> \n <mask> See also `X-Content-Type-Options <https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Content-Type-Options>`_. \n <mask> \n </s> Suggest only one package, change the sourcecode block to none </s> remove -------------------------------------------------------------------------------------------------------------\n </s> add ---------------------- </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove -------------------------------------------------------------------------------------------------------------------------\n </s> add -----------------------------------------", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep replace replace replace keep replace keep keep keep", "code_tokens": " <mask> See also `X-Content-Type-Options <https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Content-Type-Options>`_. \n <mask> \n <mask> * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n <mask> * `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n <mask> \n <mask> Cookie options\n <mask> ----------------------------------------------------------------------------------------------------------\n <mask> \n <mask> For setting cookies on client-side storage.\n <mask> \n </s> Suggest only one package, change the sourcecode block to none </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove -------------------------------------------------------------------------------------------------------\n </s> add ------------------------------ </s> remove \n* `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\nReferences\n-----------\n\n* https://docs.djangoproject.com/en/1.11/topics/security/\n* https://blog.appcanary.com/2017/http-security-headers.html\n* https://developer.mozilla.org\n* https://csp.withgoogle.com/docs/index.html\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> For setting cookies on client-side storage.\n <mask> \n <mask> Example:\n <mask> \n <mask> .. sourcecode:: html\n <mask>    \n <mask>    Set-Cookie: [cookie-name]=[cookie-value] \n <mask> \n <mask> See also `HTTP cookies <https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#Secure_and_HttpOnly_cookies>`_ .\n <mask> \n </s> Suggest only one package, change the sourcecode block to none </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove ----------------------------------------------------------------------------------------------------------\n </s> add -------------- </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep replace replace replace keep replace keep keep keep keep", "code_tokens": " <mask> See also `HTTP cookies <https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#Secure_and_HttpOnly_cookies>`_ .\n <mask> \n <mask> * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n <mask> * `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n <mask> \n <mask> HTTP Public Key Pinning (HPKP)\n <mask> -------------------------------------------------------------------------------------------------------\n <mask> \n <mask> For associating clients with web servers through a certificate key and prevent MITM attacks.\n <mask> \n <mask> Example:\n </s> Suggest only one package, change the sourcecode block to none </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove .. sourcecode:: html\n </s> add .. sourcecode:: none </s> remove ----------------------------------------------------------------------------------------------------------\n </s> add -------------- </s> remove \n* `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\nReferences\n-----------\n\n* https://docs.djangoproject.com/en/1.11/topics/security/\n* https://blog.appcanary.com/2017/http-security-headers.html\n* https://developer.mozilla.org\n* https://csp.withgoogle.com/docs/index.html\n </s> add  </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace", "code_tokens": " <mask> For associating clients with web servers through a certificate key and prevent MITM attacks.\n <mask> \n <mask> Example:\n <mask> \n <mask> .. sourcecode:: html\n <mask> \n <mask>    Public-Key-Pins: pin-sha256=\"base64==\"; max-age=expireTime [; includeSubDomains][; report-uri=\"reportURI\"] \n <mask> \n <mask> See also `Public Key Pinning <https://developer.mozilla.org/en-US/docs/Web/HTTP/Public_Key_Pinning>`_.\n <mask> \n <mask>    Public-Key-Pins: pin-sha256=\"base64==\"; max-age=expireTime [; includeSubDomains][; report-uri=\"reportURI\"] \n <mask> \n <mask> See also `Public Key Pinning <https://developer.mozilla.org/en-US/docs/Web/HTTP/Public_Key_Pinning>`_.\n <mask> \n <mask> * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n <mask> * `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n <mask> \n <mask> References\n <mask> -----------\n <mask> \n <mask> * https://docs.djangoproject.com/en/1.11/topics/security/\n <mask> * https://blog.appcanary.com/2017/http-security-headers.html\n <mask> * https://developer.mozilla.org\n <mask> * https://csp.withgoogle.com/docs/index.html\n </s> Suggest only one package, change the sourcecode block to none </s> remove -------------------------------------------------------------------------------------------------------\n </s> add ------------------------------ </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add  </s> remove ----------------------------------------------------------------------------------------------------------\n </s> add -------------- </s> remove -------------------------------------------------------------------------------------------------------------\n </s> add ---------------------- </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     A microframework based on Werkzeug.  It's extensively documented\n <mask>     and follows best practice patterns.\n <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> __version__ = '0.8-dev'\n <mask> \n </s> Late but 2010 -> 2011 in some files </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher.", "html_url": "https://github.com/pallets/flask/commit/ee8417dac8364f02524edffddff92329f15b95af", "file_name": "flask/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     ~~~~~~~~~\n <mask> \n <mask>     This module implements the central WSGI application object.\n <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n </s> Late but 2010 -> 2011 in some files </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher.", "html_url": "https://github.com/pallets/flask/commit/ee8417dac8364f02524edffddff92329f15b95af", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     ~~~~~~~~~~~~\n <mask> \n <mask>     Implements the configuration related objects.\n <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n </s> Late but 2010 -> 2011 in some files </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher.", "html_url": "https://github.com/pallets/flask/commit/ee8417dac8364f02524edffddff92329f15b95af", "file_name": "flask/config.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     ~~~~~~~~~\n <mask> \n <mask>     Implements the objects required to keep the context.\n <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from werkzeug.exceptions import HTTPException\n <mask> \n </s> Late but 2010 -> 2011 in some files </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher.", "html_url": "https://github.com/pallets/flask/commit/ee8417dac8364f02524edffddff92329f15b95af", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     Defines all the global objects that are proxies to the current\n <mask>     active context.\n <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from functools import partial\n <mask> from werkzeug.local import LocalStack, LocalProxy\n </s> Late but 2010 -> 2011 in some files </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher.", "html_url": "https://github.com/pallets/flask/commit/ee8417dac8364f02524edffddff92329f15b95af", "file_name": "flask/globals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     ~~~~~~~~~~~~~\n <mask> \n <mask>     Implements various helpers.\n <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n </s> Late but 2010 -> 2011 in some files </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher.", "html_url": "https://github.com/pallets/flask/commit/ee8417dac8364f02524edffddff92329f15b95af", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     ~~~~~~~~~~~~~\n <mask> \n <mask>     Implements the logging support for Flask.\n <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import absolute_import\n <mask> \n </s> Late but 2010 -> 2011 in some files </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher.", "html_url": "https://github.com/pallets/flask/commit/ee8417dac8364f02524edffddff92329f15b95af", "file_name": "flask/logging.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     ~~~~~~~~~~~~\n <mask> \n <mask>     Implements a class that represents module blueprints.\n <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> import os\n <mask> \n </s> Late but 2010 -> 2011 in some files </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher.", "html_url": "https://github.com/pallets/flask/commit/ee8417dac8364f02524edffddff92329f15b95af", "file_name": "flask/module.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     This module used to flask with the session global so we moved it\n <mask>     over to flask.sessions\n <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from warnings import warn\n <mask> warn(DeprecationWarning('please use flask.sessions instead'))\n </s> Late but 2010 -> 2011 in some files </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher.", "html_url": "https://github.com/pallets/flask/commit/ee8417dac8364f02524edffddff92329f15b95af", "file_name": "flask/session.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     Implements cookie based sessions based on Werkzeug's secure cookie\n <mask>     system.\n <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from datetime import datetime\n <mask> from werkzeug.contrib.securecookie import SecureCookie\n </s> Late but 2010 -> 2011 in some files </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher.", "html_url": "https://github.com/pallets/flask/commit/ee8417dac8364f02524edffddff92329f15b95af", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     Implements signals based on blinker if available, otherwise\n <mask>     falls silently back to a noop\n <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> signals_available = False\n <mask> try:\n <mask>     from blinker import Namespace\n </s> Late but 2010 -> 2011 in some files </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher.", "html_url": "https://github.com/pallets/flask/commit/ee8417dac8364f02524edffddff92329f15b95af", "file_name": "flask/signals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     ~~~~~~~~~~~~~~~~\n <mask> \n <mask>     Implements the bridge to Jinja2.\n <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> import posixpath\n <mask> from jinja2 import BaseLoader, Environment as BaseEnvironment, \\\n <mask>      TemplateNotFound\n </s> Late but 2010 -> 2011 in some files </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher.", "html_url": "https://github.com/pallets/flask/commit/ee8417dac8364f02524edffddff92329f15b95af", "file_name": "flask/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     Implements test support helpers.  This module is lazily imported\n <mask>     and usually not used in production environments.\n <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from contextlib import contextmanager\n <mask> from werkzeug.test import Client, EnvironBuilder\n </s> Late but 2010 -> 2011 in some files </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher.", "html_url": "https://github.com/pallets/flask/commit/ee8417dac8364f02524edffddff92329f15b95af", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     ~~~~~~~~~~~~~~\n <mask> \n <mask>     Implements the WSGI wrappers (request and response).\n <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase\n <mask> from werkzeug.exceptions import BadRequest\n </s> Late but 2010 -> 2011 in some files </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher. </s> remove     :copyright: (c) 2010 by Armin Ronacher.\n </s> add     :copyright: (c) 2011 by Armin Ronacher.", "html_url": "https://github.com/pallets/flask/commit/ee8417dac8364f02524edffddff92329f15b95af", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace keep keep keep", "code_tokens": " <mask> repos:\n <mask>   - repo: https://github.com/asottile/pyupgrade\n <mask>     rev: v2.1.0\n <mask>     hooks:\n <mask>       - id: pyupgrade\n <mask>         args: [\"--py36-plus\"]\n <mask>   - repo: https://github.com/asottile/reorder_python_imports\n <mask>     rev: v2.1.0\n <mask>     hooks:\n <mask>       - id: reorder-python-imports\n <mask>         name: Reorder Python imports (src, tests)\n </s> use pip-compile to pin dev requirements </s> remove     rev: 3.7.9\n </s> add     rev: 3.8.2 </s> remove     rev: v2.5.0\n </s> add     rev: v3.1.0 </s> remove     - requirements: docs/requirements.txt\n </s> add  </s> add     - requirements: requirements/docs.txt </s> remove         $ pip install -e \".[dev]\"\n </s> add         $ pip install -e . -r requirements/dev.txt", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": ".pre-commit-config.yaml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     rev: 19.10b0\n <mask>     hooks:\n <mask>       - id: black\n <mask>   - repo: https://gitlab.com/pycqa/flake8\n <mask>     rev: 3.7.9\n <mask>     hooks:\n <mask>       - id: flake8\n <mask>         additional_dependencies:\n <mask>           - flake8-bugbear\n <mask>           - flake8-implicit-str-concat\n </s> use pip-compile to pin dev requirements </s> remove     rev: v2.5.0\n </s> add     rev: v3.1.0 </s> remove     rev: v2.1.0\n </s> add     rev: v2.4.3 </s> remove     rev: v2.1.0\n </s> add     rev: v2.3.0 </s> remove     - requirements: docs/requirements.txt\n </s> add  </s> add     - requirements: requirements/docs.txt </s> remove         $ pip install -e \".[dev]\"\n </s> add         $ pip install -e . -r requirements/dev.txt", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": ".pre-commit-config.yaml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         additional_dependencies:\n <mask>           - flake8-bugbear\n <mask>           - flake8-implicit-str-concat\n <mask>   - repo: https://github.com/pre-commit/pre-commit-hooks\n <mask>     rev: v2.5.0\n <mask>     hooks:\n <mask>       - id: check-byte-order-marker\n <mask>       - id: trailing-whitespace\n <mask>       - id: end-of-file-fixer\n </s> use pip-compile to pin dev requirements </s> remove     rev: 3.7.9\n </s> add     rev: 3.8.2 </s> remove     rev: v2.1.0\n </s> add     rev: v2.4.3 </s> remove     rev: v2.1.0\n </s> add     rev: v2.3.0 </s> remove     - requirements: docs/requirements.txt\n </s> add  </s> add     - requirements: requirements/docs.txt </s> remove         $ pip install -e \".[dev]\"\n </s> add         $ pip install -e . -r requirements/dev.txt", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": ".pre-commit-config.yaml"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> version: 2\n <mask> python:\n <mask>   install:\n <mask>     - method: pip\n <mask>       path: .\n <mask> sphinx:\n <mask>   builder: dirhtml\n </s> use pip-compile to pin dev requirements </s> remove     - requirements: docs/requirements.txt\n </s> add  </s> remove         $ pip install -e \".[dev]\"\n </s> add         $ pip install -e . -r requirements/dev.txt </s> remove -   Install the `pre-commit framework`_.\n </s> add  </s> remove     rev: v2.5.0\n </s> add     rev: v3.1.0 </s> remove     rev: 3.7.9\n </s> add     rev: 3.8.2 </s> remove     rev: v2.1.0\n </s> add     rev: v2.4.3", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": ".readthedocs.yaml"}
{"docstring_tokens": "keep keep keep keep replace keep keep", "code_tokens": " <mask> python:\n <mask>   install:\n <mask>     - method: pip\n <mask>       path: .\n <mask>     - requirements: docs/requirements.txt\n <mask> sphinx:\n <mask>   builder: dirhtml\n </s> use pip-compile to pin dev requirements </s> add     - requirements: requirements/docs.txt </s> remove         $ pip install -e \".[dev]\"\n </s> add         $ pip install -e . -r requirements/dev.txt </s> remove -   Install the `pre-commit framework`_.\n </s> add  </s> remove     rev: v2.5.0\n </s> add     rev: v3.1.0 </s> remove     rev: 3.7.9\n </s> add     rev: 3.8.2 </s> remove     rev: v2.1.0\n </s> add     rev: v2.4.3", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": ".readthedocs.yaml"}
{"docstring_tokens": "keep keep replace keep keep keep keep keep keep keep keep replace keep keep keep", "code_tokens": " <mask>     .. code-block:: text\n <mask> \n <mask>         $ pip install -e \".[dev]\"\n <mask> \n <mask> -   Install the `pre-commit framework`_.\n <mask> -   Install the pre-commit hooks.\n <mask> \n <mask>     .. code-block:: text\n <mask> \n <mask>         $ pip install -e \".[dev]\"\n <mask> \n <mask> -   Install the `pre-commit framework`_.\n <mask> -   Install the pre-commit hooks.\n <mask> \n <mask>     .. code-block:: text\n </s> use pip-compile to pin dev requirements </s> remove     - requirements: docs/requirements.txt\n </s> add  </s> add     - requirements: requirements/docs.txt </s> remove     rev: v2.5.0\n </s> add     rev: v3.1.0 </s> remove     rev: 3.7.9\n </s> add     rev: 3.8.2 </s> remove     rev: v2.1.0\n </s> add     rev: v2.4.3", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": "CONTRIBUTING.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> include CONTRIBUTING.rst\n <mask> include LICENSE.rst\n <mask> include tox.ini\n <mask> graft artwork\n <mask> graft docs\n <mask> prune docs/_build\n <mask> graft examples\n <mask> graft tests\n <mask> global-exclude *.pyc\n </s> use pip-compile to pin dev requirements </s> remove deps = -r docs/requirements.txt\n </s> add deps = -r requirements/docs.txt </s> remove     pytest\n    greenlet\n    blinker\n    python-dotenv\n </s> add     -r requirements/tests.txt </s> remove     extras_require={\n        \"dotenv\": [\"python-dotenv\"],\n        \"dev\": [\n            \"pytest\",\n            \"coverage\",\n            \"tox\",\n            \"sphinx\",\n            \"pallets-sphinx-themes\",\n            \"sphinxcontrib-log-cabinet\",\n            \"sphinx-issues\",\n        ],\n    },\n </s> add     extras_require={\"dotenv\": [\"python-dotenv\"]}, </s> remove -   Install the `pre-commit framework`_.\n </s> add  </s> remove         $ pip install -e \".[dev]\"\n </s> add         $ pip install -e . -r requirements/dev.txt </s> remove     - requirements: docs/requirements.txt\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": "MANIFEST.in"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace keep", "code_tokens": " <mask>         \"Jinja2>=2.10.1\",\n <mask>         \"itsdangerous>=0.24\",\n <mask>         \"click>=5.1\",\n <mask>     ],\n <mask>     extras_require={\n <mask>         \"dotenv\": [\"python-dotenv\"],\n <mask>         \"dev\": [\n <mask>             \"pytest\",\n <mask>             \"coverage\",\n <mask>             \"tox\",\n <mask>             \"sphinx\",\n <mask>             \"pallets-sphinx-themes\",\n <mask>             \"sphinxcontrib-log-cabinet\",\n <mask>             \"sphinx-issues\",\n <mask>         ],\n <mask>     },\n <mask> )\n </s> use pip-compile to pin dev requirements </s> remove deps = -r docs/requirements.txt\n </s> add deps = -r requirements/docs.txt </s> remove     pytest\n    greenlet\n    blinker\n    python-dotenv\n </s> add     -r requirements/tests.txt </s> add include requirements/*.txt </s> remove -   Install the `pre-commit framework`_.\n </s> add  </s> remove         $ pip install -e \".[dev]\"\n </s> add         $ pip install -e . -r requirements/dev.txt </s> remove     - requirements: docs/requirements.txt\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> skip_missing_interpreters = true\n <mask> \n <mask> [testenv]\n <mask> deps =\n <mask>     pytest\n <mask>     greenlet\n <mask>     blinker\n <mask>     python-dotenv\n <mask> \n <mask>     lowest: Werkzeug==0.15.5\n <mask>     lowest: Jinja2==2.10\n <mask>     lowest: itsdangerous==0.24\n <mask>     lowest: Click==5.1\n </s> use pip-compile to pin dev requirements </s> remove deps = -r docs/requirements.txt\n </s> add deps = -r requirements/docs.txt </s> remove     extras_require={\n        \"dotenv\": [\"python-dotenv\"],\n        \"dev\": [\n            \"pytest\",\n            \"coverage\",\n            \"tox\",\n            \"sphinx\",\n            \"pallets-sphinx-themes\",\n            \"sphinxcontrib-log-cabinet\",\n            \"sphinx-issues\",\n        ],\n    },\n </s> add     extras_require={\"dotenv\": [\"python-dotenv\"]}, </s> add include requirements/*.txt </s> remove -   Install the `pre-commit framework`_.\n </s> add  </s> remove         $ pip install -e \".[dev]\"\n </s> add         $ pip install -e . -r requirements/dev.txt </s> remove     - requirements: docs/requirements.txt\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": "tox.ini"}
{"docstring_tokens": "keep keep keep keep replace keep", "code_tokens": " <mask> skip_install = true\n <mask> commands = pre-commit run --all-files --show-diff-on-failure\n <mask> \n <mask> [testenv:docs]\n <mask> deps = -r docs/requirements.txt\n <mask> commands = sphinx-build -W -b html -d {envtmpdir}/doctrees docs {envtmpdir}/html\n </s> use pip-compile to pin dev requirements </s> remove     pytest\n    greenlet\n    blinker\n    python-dotenv\n </s> add     -r requirements/tests.txt </s> remove     - requirements: docs/requirements.txt\n </s> add  </s> remove         $ pip install -e \".[dev]\"\n </s> add         $ pip install -e . -r requirements/dev.txt </s> add include requirements/*.txt </s> remove -   Install the `pre-commit framework`_.\n </s> add  </s> remove     extras_require={\n        \"dotenv\": [\"python-dotenv\"],\n        \"dev\": [\n            \"pytest\",\n            \"coverage\",\n            \"tox\",\n            \"sphinx\",\n            \"pallets-sphinx-themes\",\n            \"sphinxcontrib-log-cabinet\",\n            \"sphinx-issues\",\n        ],\n    },\n </s> add     extras_require={\"dotenv\": [\"python-dotenv\"]},", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": "tox.ini"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>   log request handling exceptions to that logger when not in debug\n <mask>   mode.  This makes it possible to receive mails on server errors\n <mask>   for example.\n <mask> \n <mask> Version 0.2\n <mask> -----------\n <mask> \n </s> Added interactive Python docs, fixed part style. </s> remove             _request_ctx_stack.pop()\n </s> add             self.pop() </s> add     def pop(self):\n        \"\"\"Pops the request context.\"\"\"\n        _request_ctx_stack.pop()\n\n    def __enter__(self):\n        self.push()\n        return self\n </s> remove     {\\parindent \\z@ \\center\n </s> add     {\\parindent \\z@ %\\center </s> remove     {\\parindent \\z@ \\center\n </s> add     {\\parindent \\z@ %\\center </s> remove    \\vspace*{8cm}%\n </s> add    \\vspace*{6cm}% </s> add    \\pagestyle{empty}", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "CHANGES"}
{"docstring_tokens": "replace keep keep keep keep keep", "code_tokens": " <mask> \\pagenumbering{arabic}\n <mask> \\definecolor{TitleColor}{rgb}{0,0,0}\n <mask> \\definecolor{InnerLinkColor}{rgb}{0,0,0}\n <mask> \n <mask> \\renewcommand{\\maketitle}{%\n <mask>   \\begin{titlepage}%\n </s> Added interactive Python docs, fixed part style. </s> remove             _request_ctx_stack.pop()\n </s> add             self.pop() </s> add     def pop(self):\n        \"\"\"Pops the request context.\"\"\"\n        _request_ctx_stack.pop()\n\n    def __enter__(self):\n        self.push()\n        return self\n </s> remove     {\\parindent \\z@ \\center\n </s> add     {\\parindent \\z@ %\\center </s> remove     {\\parindent \\z@ \\center\n </s> add     {\\parindent \\z@ %\\center </s> remove    \\vspace*{8cm}%\n </s> add    \\vspace*{6cm}% </s> add    \\pagestyle{empty}", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "docs/flaskstyle.sty"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \\renewcommand\\thepart{\\@Roman\\c@part}\n <mask> \\renewcommand\\part{%\n <mask>    \\if@noskipsec \\leavevmode \\fi\n <mask>    \\cleardoublepage\n <mask>    \\vspace*{6cm}%\n <mask>    \\@afterindentfalse\n <mask>    \\secdef\\@part\\@spart}\n <mask> \n </s> Added interactive Python docs, fixed part style. </s> remove    \\vspace*{8cm}%\n </s> add    \\vspace*{6cm}% </s> remove     {\\parindent \\z@ \\center\n </s> add     {\\parindent \\z@ %\\center </s> remove             _request_ctx_stack.pop()\n </s> add             self.pop() </s> add     def pop(self):\n        \"\"\"Pops the request context.\"\"\"\n        _request_ctx_stack.pop()\n\n    def __enter__(self):\n        self.push()\n        return self\n </s> remove     {\\parindent \\z@ \\center\n </s> add     {\\parindent \\z@ %\\center </s> remove \\pagenumbering{arabic}\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "docs/flaskstyle.sty"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \\renewcommand\\thepart{\\@Roman\\c@part}\n <mask> \\renewcommand\\part{%\n <mask>    \\if@noskipsec \\leavevmode \\fi\n <mask>    \\cleardoublepage\n <mask>    \\vspace*{8cm}%\n <mask>    \\@afterindentfalse\n <mask>    \\secdef\\@part\\@spart}\n <mask> \n <mask> \\def\\@part[#1]#2{%\n <mask>     \\ifnum \\c@secnumdepth >\\m@ne\n </s> Added interactive Python docs, fixed part style. </s> add    \\pagestyle{empty} </s> remove     {\\parindent \\z@ \\center\n </s> add     {\\parindent \\z@ %\\center </s> remove             _request_ctx_stack.pop()\n </s> add             self.pop() </s> add     def pop(self):\n        \"\"\"Pops the request context.\"\"\"\n        _request_ctx_stack.pop()\n\n    def __enter__(self):\n        self.push()\n        return self\n </s> remove     {\\parindent \\z@ \\center\n </s> add     {\\parindent \\z@ %\\center </s> remove \\pagenumbering{arabic}\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "docs/flaskstyle.sty"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \\addcontentsline{toc}{part}{\\thepart\\hspace{1em}#1}%\n <mask>     \\else\n <mask>       \\addcontentsline{toc}{part}{#1}%\n <mask>     \\fi\n <mask>     {\\parindent \\z@ \\center\n <mask>      \\interlinepenalty \\@M\n <mask>      \\normalfont\n <mask>      \\ifnum \\c@secnumdepth >\\m@ne\n <mask>        \\rm\\Large \\partname~\\thepart\n <mask>        \\par\\nobreak\n </s> Added interactive Python docs, fixed part style. </s> remove     {\\parindent \\z@ \\center\n </s> add     {\\parindent \\z@ %\\center </s> remove    \\vspace*{8cm}%\n </s> add    \\vspace*{6cm}% </s> add    \\pagestyle{empty} </s> remove             _request_ctx_stack.pop()\n </s> add             self.pop() </s> add     def pop(self):\n        \"\"\"Pops the request context.\"\"\"\n        _request_ctx_stack.pop()\n\n    def __enter__(self):\n        self.push()\n        return self\n </s> remove \\pagenumbering{arabic}\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "docs/flaskstyle.sty"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \\nobreak\n <mask>     \\vskip 8ex\n <mask>     \\@afterheading}\n <mask> \\def\\@spart#1{%\n <mask>     {\\parindent \\z@ \\center\n <mask>      \\interlinepenalty \\@M\n <mask>      \\normalfont\n <mask>      \\huge \\bfseries #1\\par}%\n <mask>      \\nobreak\n <mask>      \\vskip 3ex\n </s> Added interactive Python docs, fixed part style. </s> remove     {\\parindent \\z@ \\center\n </s> add     {\\parindent \\z@ %\\center </s> remove             _request_ctx_stack.pop()\n </s> add             self.pop() </s> add     def pop(self):\n        \"\"\"Pops the request context.\"\"\"\n        _request_ctx_stack.pop()\n\n    def __enter__(self):\n        self.push()\n        return self\n </s> remove    \\vspace*{8cm}%\n </s> add    \\vspace*{6cm}% </s> add    \\pagestyle{empty} </s> remove \\pagenumbering{arabic}\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "docs/flaskstyle.sty"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Binds the request context.\"\"\"\n <mask>         _request_ctx_stack.push(self)\n <mask> \n <mask>     def __exit__(self, exc_type, exc_value, tb):\n <mask>         # do not pop the request stack if we are in debug mode and an\n <mask>         # exception happened.  This will allow the debugger to still\n <mask>         # access the request object in the interactive shell.\n <mask>         if tb is None or not self.app.debug:\n <mask>             self.pop()\n </s> Added interactive Python docs, fixed part style. </s> remove             _request_ctx_stack.pop()\n </s> add             self.pop() </s> add - added support for context binding that does not require the use of\n  the with statement for playing in the console.\n- the request context is now available within the with statement making\n  it possible to further push the request context or pop it. </s> remove     {\\parindent \\z@ \\center\n </s> add     {\\parindent \\z@ %\\center </s> remove     {\\parindent \\z@ \\center\n </s> add     {\\parindent \\z@ %\\center </s> remove    \\vspace*{8cm}%\n </s> add    \\vspace*{6cm}% </s> add    \\pagestyle{empty}", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # do not pop the request stack if we are in debug mode and an\n <mask>         # exception happened.  This will allow the debugger to still\n <mask>         # access the request object in the interactive shell.\n <mask>         if tb is None or not self.app.debug:\n <mask>             _request_ctx_stack.pop()\n <mask> \n <mask> \n <mask> def url_for(endpoint, **values):\n <mask>     \"\"\"Generates a URL to the given endpoint with the method provided.\n <mask>     The endpoint is relative to the active module if modules are in use.\n </s> Added interactive Python docs, fixed part style. </s> add     def pop(self):\n        \"\"\"Pops the request context.\"\"\"\n        _request_ctx_stack.pop()\n\n    def __enter__(self):\n        self.push()\n        return self\n </s> add - added support for context binding that does not require the use of\n  the with statement for playing in the console.\n- the request context is now available within the with statement making\n  it possible to further push the request context or pop it. </s> remove     {\\parindent \\z@ \\center\n </s> add     {\\parindent \\z@ %\\center </s> remove     {\\parindent \\z@ \\center\n </s> add     {\\parindent \\z@ %\\center </s> remove    \\vspace*{8cm}%\n </s> add    \\vspace*{6cm}% </s> add    \\pagestyle{empty}", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> intersphinx_mapping = {\n <mask>     \"python\": (\"https://docs.python.org/3/\", None),\n <mask>     \"werkzeug\": (\"https://werkzeug.palletsprojects.com/\", None),\n <mask>     \"click\": (\"https://click.palletsprojects.com/\", None),\n <mask>     \"jinja\": (\"http://jinja.pocoo.org/docs/\", None),\n <mask>     \"itsdangerous\": (\"https://itsdangerous.palletsprojects.com/\", None),\n <mask>     \"sqlalchemy\": (\"https://docs.sqlalchemy.org/\", None),\n <mask>     \"wtforms\": (\"https://wtforms.readthedocs.io/en/stable/\", None),\n <mask>     \"blinker\": (\"https://pythonhosted.org/blinker/\", None),\n <mask> }\n </s> Replace old pocoo links everywhere\n\npocco.org -> palletsprojects.com </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text\n </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\")\n </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> remove     url=\"http://flask.pocoo.org/docs/tutorial/\",\n </s> add     url=\"https://flask.palletsprojects.com/tutorial/\", </s> remove .. _tutorial: http://flask.pocoo.org/docs/tutorial/\n </s> add .. _tutorial: https://flask.palletsprojects.com/tutorial/ </s> remove     url=\"http://flask.pocoo.org/docs/patterns/jquery/\",\n </s> add     url=\"https://flask.palletsprojects.com/patterns/jquery/\", </s> remove .. _Flask docs: http://flask.pocoo.org/docs/patterns/jquery/\n </s> add .. _Flask docs: https://flask.palletsprojects.com/patterns/jquery/", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "docs/conf.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Flask depends on the `Jinja`_ template engine and the `Werkzeug`_ WSGI\n <mask> toolkit. The documentation for these libraries can be found at:\n <mask> \n <mask> - `Jinja documentation <http://jinja.pocoo.org/docs>`_\n <mask> - `Werkzeug documentation <https://werkzeug.palletsprojects.com/>`_\n <mask> \n <mask> .. _Jinja: https://www.palletsprojects.com/p/jinja/\n <mask> .. _Werkzeug: https://www.palletsprojects.com/p/werkzeug/\n <mask> \n </s> Replace old pocoo links everywhere\n\npocco.org -> palletsprojects.com </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically.\n </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> remove .. _Jinja: http://jinja.pocoo.org/docs/templates/\n </s> add .. _Jinja: https://jinja.palletsprojects.com/templates/ </s> remove .. _tutorial: http://flask.pocoo.org/docs/tutorial/\n </s> add .. _tutorial: https://flask.palletsprojects.com/tutorial/ </s> remove .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for\n </s> add .. _Jinja for loops: https://jinja.palletsprojects.com/templates/#for </s> remove <http://jinja.pocoo.org/docs/templates/>`_ for more information.\n </s> add <http://jinja.palletsprojects.com/templates/>`_ for more information. </s> remove Documentation <http://jinja.pocoo.org/docs/templates/>`_ for\n </s> add Documentation <https://jinja.palletsprojects.com/templates/>`_ for", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "docs/index.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Generating HTML from within Python is not fun, and actually pretty\n <mask> cumbersome because you have to do the HTML escaping on your own to keep\n <mask> the application secure.  Because of that Flask configures the `Jinja2\n <mask> <http://jinja.pocoo.org/>`_ template engine for you automatically.\n <mask> \n <mask> To render a template you can use the :func:`~flask.render_template`\n <mask> method.  All you have to do is provide the name of the template and the\n <mask> variables you want to pass to the template engine as keyword arguments.\n <mask> Here's a simple example of how to render a template::\n </s> Replace old pocoo links everywhere\n\npocco.org -> palletsprojects.com </s> remove <http://jinja.pocoo.org/docs/templates/>`_ for more information.\n </s> add <http://jinja.palletsprojects.com/templates/>`_ for more information. </s> remove Documentation <http://jinja.pocoo.org/docs/templates/>`_ for\n </s> add Documentation <https://jinja.palletsprojects.com/templates/>`_ for </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\")\n </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_\n </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text\n </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text </s> remove .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for\n </s> add .. _Jinja for loops: https://jinja.palletsprojects.com/templates/#for", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             /hello.html\n <mask> \n <mask> For templates you can use the full power of Jinja2 templates.  Head over\n <mask> to the official `Jinja2 Template Documentation\n <mask> <http://jinja.pocoo.org/docs/templates/>`_ for more information.\n <mask> \n <mask> Here is an example template:\n <mask> \n <mask> .. sourcecode:: html+jinja\n <mask> \n </s> Replace old pocoo links everywhere\n\npocco.org -> palletsprojects.com </s> remove Documentation <http://jinja.pocoo.org/docs/templates/>`_ for\n </s> add Documentation <https://jinja.palletsprojects.com/templates/>`_ for </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically.\n </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\")\n </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_\n </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for\n </s> add .. _Jinja for loops: https://jinja.palletsprojects.com/templates/#for </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text\n </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> This section only gives a very quick introduction into how Jinja2\n <mask> is integrated into Flask.  If you want information on the template\n <mask> engine's syntax itself, head over to the official `Jinja2 Template\n <mask> Documentation <http://jinja.pocoo.org/docs/templates/>`_ for\n <mask> more information.\n <mask> \n <mask> Jinja Setup\n <mask> -----------\n <mask> \n </s> Replace old pocoo links everywhere\n\npocco.org -> palletsprojects.com </s> remove <http://jinja.pocoo.org/docs/templates/>`_ for more information.\n </s> add <http://jinja.palletsprojects.com/templates/>`_ for more information. </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically.\n </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\")\n </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_\n </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for\n </s> add .. _Jinja for loops: https://jinja.palletsprojects.com/templates/#for </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text\n </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "docs/templating.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> special variable available inside `Jinja for loops`_. It's used to\n <mask> display a line after each post except the last one, to visually separate\n <mask> them.\n <mask> \n <mask> .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for\n <mask> \n <mask> \n <mask> Create\n <mask> ------\n <mask> \n </s> Replace old pocoo links everywhere\n\npocco.org -> palletsprojects.com </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_\n </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically.\n </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> remove Documentation <http://jinja.pocoo.org/docs/templates/>`_ for\n </s> add Documentation <https://jinja.palletsprojects.com/templates/>`_ for </s> remove <http://jinja.pocoo.org/docs/templates/>`_ for more information.\n </s> add <http://jinja.palletsprojects.com/templates/>`_ for more information. </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\")\n </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> remove     url=\"http://flask.pocoo.org/docs/patterns/jquery/\",\n </s> add     url=\"https://flask.palletsprojects.com/patterns/jquery/\",", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "docs/tutorial/blog.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> statement like ``if`` and ``for``. Unlike Python, blocks are denoted\n <mask> by start and end tags rather than indentation since static text within\n <mask> a block could change indentation.\n <mask> \n <mask> .. _Jinja: http://jinja.pocoo.org/docs/templates/\n <mask> .. _HTML: https://developer.mozilla.org/docs/Web/HTML\n <mask> \n <mask> \n <mask> The Base Layout\n <mask> ---------------\n </s> Replace old pocoo links everywhere\n\npocco.org -> palletsprojects.com </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_\n </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text\n </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically.\n </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> remove .. _tutorial: http://flask.pocoo.org/docs/tutorial/\n </s> add .. _tutorial: https://flask.palletsprojects.com/tutorial/ </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\")\n </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> remove .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for\n </s> add .. _Jinja for loops: https://jinja.palletsprojects.com/templates/#for", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "docs/tutorial/templates.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. |jQuery.ajax| replace:: ``jQuery.ajax``\n <mask> .. _jQuery.ajax: https://api.jquery.com/jQuery.ajax/\n <mask> \n <mask> .. _Flask docs: http://flask.pocoo.org/docs/patterns/jquery/\n <mask> \n <mask> \n <mask> Install\n <mask> -------\n <mask> \n </s> Replace old pocoo links everywhere\n\npocco.org -> palletsprojects.com </s> remove .. _tutorial: http://flask.pocoo.org/docs/tutorial/\n </s> add .. _tutorial: https://flask.palletsprojects.com/tutorial/ </s> remove .. _Jinja: http://jinja.pocoo.org/docs/templates/\n </s> add .. _Jinja: https://jinja.palletsprojects.com/templates/ </s> remove .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for\n </s> add .. _Jinja for loops: https://jinja.palletsprojects.com/templates/#for </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_\n </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove <http://jinja.pocoo.org/docs/templates/>`_ for more information.\n </s> add <http://jinja.palletsprojects.com/templates/>`_ for more information. </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text\n </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "examples/javascript/README.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> setup(\n <mask>     name=\"js_example\",\n <mask>     version=\"1.0.0\",\n <mask>     url=\"http://flask.pocoo.org/docs/patterns/jquery/\",\n <mask>     license=\"BSD\",\n <mask>     maintainer=\"Pallets team\",\n <mask>     maintainer_email=\"contact@palletsprojects.com\",\n <mask>     description=\"Demonstrates making Ajax requests to Flask.\",\n <mask>     long_description=readme,\n </s> Replace old pocoo links everywhere\n\npocco.org -> palletsprojects.com </s> remove     url=\"http://flask.pocoo.org/docs/tutorial/\",\n </s> add     url=\"https://flask.palletsprojects.com/tutorial/\", </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically.\n </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> remove .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for\n </s> add .. _Jinja for loops: https://jinja.palletsprojects.com/templates/#for </s> remove <http://jinja.pocoo.org/docs/templates/>`_ for more information.\n </s> add <http://jinja.palletsprojects.com/templates/>`_ for more information. </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\")\n </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> remove Documentation <http://jinja.pocoo.org/docs/templates/>`_ for\n </s> add Documentation <https://jinja.palletsprojects.com/templates/>`_ for", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "examples/javascript/setup.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ======\n <mask> \n <mask> The basic blog app built in the Flask `tutorial`_.\n <mask> \n <mask> .. _tutorial: http://flask.pocoo.org/docs/tutorial/\n <mask> \n <mask> \n <mask> Install\n <mask> -------\n <mask> \n </s> Replace old pocoo links everywhere\n\npocco.org -> palletsprojects.com </s> remove     url=\"http://flask.pocoo.org/docs/tutorial/\",\n </s> add     url=\"https://flask.palletsprojects.com/tutorial/\", </s> remove .. _Flask docs: http://flask.pocoo.org/docs/patterns/jquery/\n </s> add .. _Flask docs: https://flask.palletsprojects.com/patterns/jquery/ </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_\n </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\")\n </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text\n </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically.\n </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically.", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "examples/tutorial/README.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> setup(\n <mask>     name=\"flaskr\",\n <mask>     version=\"1.0.0\",\n <mask>     url=\"http://flask.pocoo.org/docs/tutorial/\",\n <mask>     license=\"BSD\",\n <mask>     maintainer=\"Pallets team\",\n <mask>     maintainer_email=\"contact@palletsprojects.com\",\n <mask>     description=\"The basic blog app built in the Flask tutorial.\",\n <mask>     long_description=readme,\n </s> Replace old pocoo links everywhere\n\npocco.org -> palletsprojects.com </s> remove     url=\"http://flask.pocoo.org/docs/patterns/jquery/\",\n </s> add     url=\"https://flask.palletsprojects.com/patterns/jquery/\", </s> remove .. _tutorial: http://flask.pocoo.org/docs/tutorial/\n </s> add .. _tutorial: https://flask.palletsprojects.com/tutorial/ </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text\n </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_\n </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\")\n </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically.\n </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically.", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "examples/tutorial/setup.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             \"  The template was looked up from an endpoint that \"\n <mask>             'belongs to the blueprint \"%s\".' % blueprint\n <mask>         )\n <mask>         info.append(\"  Maybe you did not place a template in the right folder?\")\n <mask>         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\")\n <mask> \n <mask>     app.logger.info(\"\\n\".join(info))\n <mask> \n <mask> \n <mask> def explain_ignored_app_run():\n </s> Replace old pocoo links everywhere\n\npocco.org -> palletsprojects.com </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text\n </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically.\n </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> remove <http://jinja.pocoo.org/docs/templates/>`_ for more information.\n </s> add <http://jinja.palletsprojects.com/templates/>`_ for more information. </s> remove Documentation <http://jinja.pocoo.org/docs/templates/>`_ for\n </s> add Documentation <https://jinja.palletsprojects.com/templates/>`_ for </s> remove .. _tutorial: http://flask.pocoo.org/docs/tutorial/\n </s> add .. _tutorial: https://flask.palletsprojects.com/tutorial/ </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_\n </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "src/flask/debughelpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             assert \"Error: the template could not be found\" in text\n <mask>             assert (\n <mask>                 \"looked up from an endpoint that belongs to \" 'the blueprint \"frontend\"'\n <mask>             ) in text\n <mask>             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text\n <mask> \n <mask>     with app.test_client() as c:\n <mask>         monkeypatch.setitem(app.config, \"EXPLAIN_TEMPLATE_LOADING\", True)\n <mask>         monkeypatch.setattr(\n <mask>             logging.getLogger(\"blueprintapp\"), \"handlers\", [_TestHandler()]\n </s> Replace old pocoo links everywhere\n\npocco.org -> palletsprojects.com </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\")\n </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> remove .. _Jinja: http://jinja.pocoo.org/docs/templates/\n </s> add .. _Jinja: https://jinja.palletsprojects.com/templates/ </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically.\n </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> remove .. _tutorial: http://flask.pocoo.org/docs/tutorial/\n </s> add .. _tutorial: https://flask.palletsprojects.com/tutorial/ </s> remove     url=\"http://flask.pocoo.org/docs/tutorial/\",\n </s> add     url=\"https://flask.palletsprojects.com/tutorial/\", </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_\n </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "tests/test_templating.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>    is for example very helpful if you try to generate JavaScript on the\n <mask>    fly.\n <mask> \n <mask>    Note that inside `script` tags no escaping must take place, so make\n <mask>    sure to disable escaping with ``|safe`` if you intend to use it inside\n <mask>    `script` tags:\n <mask> \n <mask>    .. sourcecode:: html+jinja\n <mask> \n <mask>        <script type=text/javascript>\n <mask>            doSomethingWith({{ user.username|tojson|safe }});\n </s> Imply the |safe on tojson in templates and change escaping logic </s> remove    That the ``|tojson`` filter escapes forward slashes properly for you.\n\n </s> add  </s> remove     this is available in templates through the ``|tojson`` filter but it will\n    have to be wrapped in ``|safe`` unless **true** XHTML is being used.\n </s> add     this is available in templates through the ``|tojson`` filter which will\n    also mark the result as safe.  Due to how this function escapes certain\n    characters this is safe even if used outside of ``<script>`` tags.\n\n    .. versionchanged:: 0.10\n       This function's return value is now always safe for HTML usage, even\n       if outside of script tags or if used in XHTML. </s> remove     rv = dumps(obj, **kwargs)\n    if _slash_escape:\n        rv = rv.replace('/', '\\\\/')\n    return rv.replace('<!', '<\\\\u0021')\n </s> add     rv = dumps(obj, **kwargs) \\\n        .replace(u'<', u'\\\\u003c') \\\n        .replace(u'>', u'\\\\u003e') \\\n        .replace(u'&', u'\\\\u0026')\n    if not _slash_escape:\n        rv = rv.replace('\\\\/', '/')\n    return rv </s> remove         # If this interpreter supports clearing the exception information\n        # we do that now.  This will only go into effect on Python 2.x,\n        # on 3.x it disappears automatically at the end of the exception\n        # stack.\n        if hasattr(sys, 'exc_clear'):\n            sys.exc_clear()\n\n </s> add  </s> remove         rv.filters['tojson'] = json.htmlsafe_dumps\n </s> add         rv.filters['tojson'] = json.tojson_filter </s> remove     fp.write(htmlsafe_dumps(obj, **kwargs))\n </s> add     fp.write(unicode(htmlsafe_dumps(obj, **kwargs)))", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "docs/templating.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>        <script type=text/javascript>\n <mask>            doSomethingWith({{ user.username|tojson|safe }});\n <mask>        </script>\n <mask> \n <mask>    That the ``|tojson`` filter escapes forward slashes properly for you.\n <mask> \n <mask> Controlling Autoescaping\n <mask> ------------------------\n <mask> \n <mask> Autoescaping is the concept of automatically escaping special characters\n <mask> of you.  Special characters in the sense of HTML (or XML, and thus XHTML)\n </s> Imply the |safe on tojson in templates and change escaping logic </s> remove    sure to disable escaping with ``|safe`` if you intend to use it inside\n   `script` tags:\n </s> add    sure to disable escaping with ``|safe`` before Flask 0.10 if you intend\n   to use it inside `script` tags: </s> remove     this is available in templates through the ``|tojson`` filter but it will\n    have to be wrapped in ``|safe`` unless **true** XHTML is being used.\n </s> add     this is available in templates through the ``|tojson`` filter which will\n    also mark the result as safe.  Due to how this function escapes certain\n    characters this is safe even if used outside of ``<script>`` tags.\n\n    .. versionchanged:: 0.10\n       This function's return value is now always safe for HTML usage, even\n       if outside of script tags or if used in XHTML. </s> remove         # If this interpreter supports clearing the exception information\n        # we do that now.  This will only go into effect on Python 2.x,\n        # on 3.x it disappears automatically at the end of the exception\n        # stack.\n        if hasattr(sys, 'exc_clear'):\n            sys.exc_clear()\n\n </s> add  </s> remove     rv = dumps(obj, **kwargs)\n    if _slash_escape:\n        rv = rv.replace('/', '\\\\/')\n    return rv.replace('<!', '<\\\\u0021')\n </s> add     rv = dumps(obj, **kwargs) \\\n        .replace(u'<', u'\\\\u003c') \\\n        .replace(u'>', u'\\\\u003e') \\\n        .replace(u'&', u'\\\\u0026')\n    if not _slash_escape:\n        rv = rv.replace('\\\\/', '/')\n    return rv </s> remove         rv.filters['tojson'] = json.htmlsafe_dumps\n </s> add         rv.filters['tojson'] = json.tojson_filter </s> remove     fp.write(htmlsafe_dumps(obj, **kwargs))\n </s> add     fp.write(unicode(htmlsafe_dumps(obj, **kwargs)))", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "docs/templating.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             request=request,\n <mask>             session=session,\n <mask>             g=g\n <mask>         )\n <mask>         rv.filters['tojson'] = json.htmlsafe_dumps\n <mask>         return rv\n <mask> \n <mask>     def create_global_jinja_loader(self):\n <mask>         \"\"\"Creates the loader for the Jinja2 environment.  Can be used to\n <mask>         override just the loader and keeping the rest unchanged.  It's\n </s> Imply the |safe on tojson in templates and change escaping logic </s> remove     this is available in templates through the ``|tojson`` filter but it will\n    have to be wrapped in ``|safe`` unless **true** XHTML is being used.\n </s> add     this is available in templates through the ``|tojson`` filter which will\n    also mark the result as safe.  Due to how this function escapes certain\n    characters this is safe even if used outside of ``<script>`` tags.\n\n    .. versionchanged:: 0.10\n       This function's return value is now always safe for HTML usage, even\n       if outside of script tags or if used in XHTML. </s> remove     rv = dumps(obj, **kwargs)\n    if _slash_escape:\n        rv = rv.replace('/', '\\\\/')\n    return rv.replace('<!', '<\\\\u0021')\n </s> add     rv = dumps(obj, **kwargs) \\\n        .replace(u'<', u'\\\\u003c') \\\n        .replace(u'>', u'\\\\u003e') \\\n        .replace(u'&', u'\\\\u0026')\n    if not _slash_escape:\n        rv = rv.replace('\\\\/', '/')\n    return rv </s> remove     fp.write(htmlsafe_dumps(obj, **kwargs))\n </s> add     fp.write(unicode(htmlsafe_dumps(obj, **kwargs))) </s> remove         # If this interpreter supports clearing the exception information\n        # we do that now.  This will only go into effect on Python 2.x,\n        # on 3.x it disappears automatically at the end of the exception\n        # stack.\n        if hasattr(sys, 'exc_clear'):\n            sys.exc_clear()\n\n </s> add  </s> remove    That the ``|tojson`` filter escapes forward slashes properly for you.\n\n </s> add  </s> remove    sure to disable escaping with ``|safe`` if you intend to use it inside\n   `script` tags:\n </s> add    sure to disable escaping with ``|safe`` before Flask 0.10 if you intend\n   to use it inside `script` tags:", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         for func in funcs:\n <mask>             rv = func(exc)\n <mask>         request_tearing_down.send(self, exc=exc)\n <mask> \n <mask>         # If this interpreter supports clearing the exception information\n <mask>         # we do that now.  This will only go into effect on Python 2.x,\n <mask>         # on 3.x it disappears automatically at the end of the exception\n <mask>         # stack.\n <mask>         if hasattr(sys, 'exc_clear'):\n <mask>             sys.exc_clear()\n <mask> \n <mask>     def do_teardown_appcontext(self, exc=None):\n <mask>         \"\"\"Called when an application context is popped.  This works pretty\n <mask>         much the same as :meth:`do_teardown_request` but for the application\n <mask>         context.\n <mask> \n </s> Imply the |safe on tojson in templates and change escaping logic </s> add from jinja2 import Markup </s> remove     this is available in templates through the ``|tojson`` filter but it will\n    have to be wrapped in ``|safe`` unless **true** XHTML is being used.\n </s> add     this is available in templates through the ``|tojson`` filter which will\n    also mark the result as safe.  Due to how this function escapes certain\n    characters this is safe even if used outside of ``<script>`` tags.\n\n    .. versionchanged:: 0.10\n       This function's return value is now always safe for HTML usage, even\n       if outside of script tags or if used in XHTML. </s> remove     rv = dumps(obj, **kwargs)\n    if _slash_escape:\n        rv = rv.replace('/', '\\\\/')\n    return rv.replace('<!', '<\\\\u0021')\n </s> add     rv = dumps(obj, **kwargs) \\\n        .replace(u'<', u'\\\\u003c') \\\n        .replace(u'>', u'\\\\u003e') \\\n        .replace(u'&', u'\\\\u0026')\n    if not _slash_escape:\n        rv = rv.replace('\\\\/', '/')\n    return rv </s> remove    That the ``|tojson`` filter escapes forward slashes properly for you.\n\n </s> add  </s> remove     fp.write(htmlsafe_dumps(obj, **kwargs))\n </s> add     fp.write(unicode(htmlsafe_dumps(obj, **kwargs))) </s> remove         rv.filters['tojson'] = json.htmlsafe_dumps\n </s> add         rv.filters['tojson'] = json.tojson_filter", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "flask/app.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> from werkzeug.http import http_date\n <mask> \n <mask> # Use the same json implementation as itsdangerous on which we\n <mask> # depend anyways.\n <mask> try:\n </s> Imply the |safe on tojson in templates and change escaping logic </s> remove         # If this interpreter supports clearing the exception information\n        # we do that now.  This will only go into effect on Python 2.x,\n        # on 3.x it disappears automatically at the end of the exception\n        # stack.\n        if hasattr(sys, 'exc_clear'):\n            sys.exc_clear()\n\n </s> add  </s> remove     this is available in templates through the ``|tojson`` filter but it will\n    have to be wrapped in ``|safe`` unless **true** XHTML is being used.\n </s> add     this is available in templates through the ``|tojson`` filter which will\n    also mark the result as safe.  Due to how this function escapes certain\n    characters this is safe even if used outside of ``<script>`` tags.\n\n    .. versionchanged:: 0.10\n       This function's return value is now always safe for HTML usage, even\n       if outside of script tags or if used in XHTML. </s> remove    sure to disable escaping with ``|safe`` if you intend to use it inside\n   `script` tags:\n </s> add    sure to disable escaping with ``|safe`` before Flask 0.10 if you intend\n   to use it inside `script` tags: </s> remove         rv.filters['tojson'] = json.htmlsafe_dumps\n </s> add         rv.filters['tojson'] = json.tojson_filter </s> remove    That the ``|tojson`` filter escapes forward slashes properly for you.\n\n </s> add  </s> remove     rv = dumps(obj, **kwargs)\n    if _slash_escape:\n        rv = rv.replace('/', '\\\\/')\n    return rv.replace('<!', '<\\\\u0021')\n </s> add     rv = dumps(obj, **kwargs) \\\n        .replace(u'<', u'\\\\u003c') \\\n        .replace(u'>', u'\\\\u003e') \\\n        .replace(u'&', u'\\\\u0026')\n    if not _slash_escape:\n        rv = rv.replace('\\\\/', '/')\n    return rv", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "flask/json.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace replace replace replace", "code_tokens": " <mask> def htmlsafe_dumps(obj, **kwargs):\n <mask>     \"\"\"Works exactly like :func:`dumps` but is safe for use in ``<script>``\n <mask>     tags.  It accepts the same arguments and returns a JSON string.  Note that\n <mask>     this is available in templates through the ``|tojson`` filter but it will\n <mask>     have to be wrapped in ``|safe`` unless **true** XHTML is being used.\n <mask>     \"\"\"\n <mask>     rv = dumps(obj, **kwargs)\n <mask>     if _slash_escape:\n <mask>         rv = rv.replace('/', '\\\\/')\n <mask>     return rv.replace('<!', '<\\\\u0021')\n </s> Imply the |safe on tojson in templates and change escaping logic </s> remove         # If this interpreter supports clearing the exception information\n        # we do that now.  This will only go into effect on Python 2.x,\n        # on 3.x it disappears automatically at the end of the exception\n        # stack.\n        if hasattr(sys, 'exc_clear'):\n            sys.exc_clear()\n\n </s> add  </s> remove         rv.filters['tojson'] = json.htmlsafe_dumps\n </s> add         rv.filters['tojson'] = json.tojson_filter </s> remove    sure to disable escaping with ``|safe`` if you intend to use it inside\n   `script` tags:\n </s> add    sure to disable escaping with ``|safe`` before Flask 0.10 if you intend\n   to use it inside `script` tags: </s> remove     fp.write(htmlsafe_dumps(obj, **kwargs))\n </s> add     fp.write(unicode(htmlsafe_dumps(obj, **kwargs))) </s> remove    That the ``|tojson`` filter escapes forward slashes properly for you.\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "flask/json.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def htmlsafe_dump(obj, fp, **kwargs):\n <mask>     \"\"\"Like :func:`htmlsafe_dumps` but writes into a file object.\"\"\"\n <mask>     fp.write(htmlsafe_dumps(obj, **kwargs))\n <mask> \n <mask> \n <mask> def jsonify(*args, **kwargs):\n <mask>     \"\"\"Creates a :class:`~flask.Response` with the JSON representation of\n <mask>     the given arguments with an `application/json` mimetype.  The arguments\n </s> Imply the |safe on tojson in templates and change escaping logic </s> remove     rv = dumps(obj, **kwargs)\n    if _slash_escape:\n        rv = rv.replace('/', '\\\\/')\n    return rv.replace('<!', '<\\\\u0021')\n </s> add     rv = dumps(obj, **kwargs) \\\n        .replace(u'<', u'\\\\u003c') \\\n        .replace(u'>', u'\\\\u003e') \\\n        .replace(u'&', u'\\\\u0026')\n    if not _slash_escape:\n        rv = rv.replace('\\\\/', '/')\n    return rv </s> remove     this is available in templates through the ``|tojson`` filter but it will\n    have to be wrapped in ``|safe`` unless **true** XHTML is being used.\n </s> add     this is available in templates through the ``|tojson`` filter which will\n    also mark the result as safe.  Due to how this function escapes certain\n    characters this is safe even if used outside of ``<script>`` tags.\n\n    .. versionchanged:: 0.10\n       This function's return value is now always safe for HTML usage, even\n       if outside of script tags or if used in XHTML. </s> remove         # If this interpreter supports clearing the exception information\n        # we do that now.  This will only go into effect on Python 2.x,\n        # on 3.x it disappears automatically at the end of the exception\n        # stack.\n        if hasattr(sys, 'exc_clear'):\n            sys.exc_clear()\n\n </s> add  </s> remove         rv.filters['tojson'] = json.htmlsafe_dumps\n </s> add         rv.filters['tojson'] = json.tojson_filter </s> remove    sure to disable escaping with ``|safe`` if you intend to use it inside\n   `script` tags:\n </s> add    sure to disable escaping with ``|safe`` before Flask 0.10 if you intend\n   to use it inside `script` tags: </s> remove             rv = render('{{ \"</script>\"|tojson|safe }}')\n            self.assert_equal(rv, '\"<\\\\/script>\"')\n            rv = render('{{ \"<\\0/script>\"|tojson|safe }}')\n            self.assert_equal(rv, '\"<\\\\u0000\\\\/script>\"')\n            rv = render('{{ \"<!--<script>\"|tojson|safe }}')\n            self.assert_equal(rv, '\"<\\\\u0021--<script>\"')\n </s> add             rv = flask.json.htmlsafe_dumps('</script>')\n            self.assert_equal(rv, u'\"\\\\u003c/script\\\\u003e\"')\n            self.assert_equal(type(rv), text_type)\n            rv = render('{{ \"</script>\"|tojson }}')\n            self.assert_equal(rv, '\"\\\\u003c/script\\\\u003e\"')\n            rv = render('{{ \"<\\0/script>\"|tojson }}')\n            self.assert_equal(rv, '\"\\\\u003c\\\\u0000/script\\\\u003e\"')\n            rv = render('{{ \"<!--<script>\"|tojson }}')\n            self.assert_equal(rv, '\"\\\\u003c!--\\\\u003cscript\\\\u003e\"')\n            rv = render('{{ \"&\"|tojson }}')\n            self.assert_equal(rv, '\"\\\\u0026\"')", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "flask/json.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     def test_template_escaping(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         render = flask.render_template_string\n <mask>         with app.test_request_context():\n <mask>             rv = render('{{ \"</script>\"|tojson|safe }}')\n <mask>             self.assert_equal(rv, '\"<\\\\/script>\"')\n <mask>             rv = render('{{ \"<\\0/script>\"|tojson|safe }}')\n <mask>             self.assert_equal(rv, '\"<\\\\u0000\\\\/script>\"')\n <mask>             rv = render('{{ \"<!--<script>\"|tojson|safe }}')\n <mask>             self.assert_equal(rv, '\"<\\\\u0021--<script>\"')\n <mask> \n <mask>     def test_json_customization(self):\n <mask>         class X(object):\n <mask>             def __init__(self, val):\n <mask>                 self.val = val\n </s> Imply the |safe on tojson in templates and change escaping logic </s> remove     rv = dumps(obj, **kwargs)\n    if _slash_escape:\n        rv = rv.replace('/', '\\\\/')\n    return rv.replace('<!', '<\\\\u0021')\n </s> add     rv = dumps(obj, **kwargs) \\\n        .replace(u'<', u'\\\\u003c') \\\n        .replace(u'>', u'\\\\u003e') \\\n        .replace(u'&', u'\\\\u0026')\n    if not _slash_escape:\n        rv = rv.replace('\\\\/', '/')\n    return rv </s> remove         rv.filters['tojson'] = json.htmlsafe_dumps\n </s> add         rv.filters['tojson'] = json.tojson_filter </s> remove     this is available in templates through the ``|tojson`` filter but it will\n    have to be wrapped in ``|safe`` unless **true** XHTML is being used.\n </s> add     this is available in templates through the ``|tojson`` filter which will\n    also mark the result as safe.  Due to how this function escapes certain\n    characters this is safe even if used outside of ``<script>`` tags.\n\n    .. versionchanged:: 0.10\n       This function's return value is now always safe for HTML usage, even\n       if outside of script tags or if used in XHTML. </s> remove         # If this interpreter supports clearing the exception information\n        # we do that now.  This will only go into effect on Python 2.x,\n        # on 3.x it disappears automatically at the end of the exception\n        # stack.\n        if hasattr(sys, 'exc_clear'):\n            sys.exc_clear()\n\n </s> add  </s> remove     fp.write(htmlsafe_dumps(obj, **kwargs))\n </s> add     fp.write(unicode(htmlsafe_dumps(obj, **kwargs))) </s> remove    sure to disable escaping with ``|safe`` if you intend to use it inside\n   `script` tags:\n </s> add    sure to disable escaping with ``|safe`` before Flask 0.10 if you intend\n   to use it inside `script` tags:", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>   - \"3.5\"\n <mask> \n <mask> env:\n <mask>   - REQUIREMENTS=lowest\n <mask>   - REQUIREMENTS=release\n <mask>   - REQUIREMENTS=release-simplejson\n <mask>   - REQUIREMENTS=devel\n <mask>   - REQUIREMENTS=devel-simplejson\n <mask> \n <mask> matrix:\n </s> Tests with and without simplejson for every existing testenv (#1869) </s> add   - REQUIREMENTS=devel-simplejson </s> add   - REQUIREMENTS=release-simplejson", "html_url": "https://github.com/pallets/flask/commit/f034d2e271403c7b3b8a1c2728b2320ed157a037", "file_name": ".travis.yml"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>   - REQUIREMENTS=lowest-simplejson\n <mask>   - REQUIREMENTS=release\n <mask>   - REQUIREMENTS=devel\n <mask>   - REQUIREMENTS=devel-simplejson\n <mask> \n <mask> matrix:\n <mask>   exclude:\n </s> Tests with and without simplejson for every existing testenv (#1869) </s> add   - REQUIREMENTS=devel-simplejson </s> add   - REQUIREMENTS=lowest-simplejson", "html_url": "https://github.com/pallets/flask/commit/f034d2e271403c7b3b8a1c2728b2320ed157a037", "file_name": ".travis.yml"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>   - REQUIREMENTS=lowest-simplejson\n <mask>   - REQUIREMENTS=release\n <mask>   - REQUIREMENTS=release-simplejson\n <mask>   - REQUIREMENTS=devel\n <mask> \n <mask> matrix:\n <mask>   exclude:\n <mask>     # Python 3 support currently does not work with lowest requirements\n </s> Tests with and without simplejson for every existing testenv (#1869) </s> add   - REQUIREMENTS=lowest-simplejson </s> add   - REQUIREMENTS=release-simplejson", "html_url": "https://github.com/pallets/flask/commit/f034d2e271403c7b3b8a1c2728b2320ed157a037", "file_name": ".travis.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         app = flask.Flask(__name__)\n <mask>         app.register_blueprint(bp, url_prefix='/py')\n <mask>         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse']('abcd'), 'dcba')\n <mask> \n <mask>     def test_add_template_filter(self):\n <mask>         bp = flask.Blueprint('bp', __name__)\n </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return s[::-1]\n <mask>         bp.add_app_template_filter(my_reverse)\n <mask>         app = flask.Flask(__name__)\n <mask>         app.register_blueprint(bp, url_prefix='/py')\n <mask>         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse']('abcd'), 'dcba')\n <mask> \n <mask>     def test_template_filter_with_name(self):\n <mask>         bp = flask.Blueprint('bp', __name__)\n </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         app = flask.Flask(__name__)\n <mask>         app.register_blueprint(bp, url_prefix='/py')\n <mask>         self.assert_('strrev' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['strrev'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['strrev']('abcd'), 'dcba')\n <mask> \n <mask>     def test_add_template_filter_with_name(self):\n <mask>         bp = flask.Blueprint('bp', __name__)\n </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return s[::-1]\n <mask>         bp.add_app_template_filter(my_reverse, 'strrev')\n <mask>         app = flask.Flask(__name__)\n <mask>         app.register_blueprint(bp, url_prefix='/py')\n <mask>         self.assert_('strrev' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['strrev'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['strrev']('abcd'), 'dcba')\n <mask> \n <mask>     def test_template_filter_with_template(self):\n <mask>         bp = flask.Blueprint('bp', __name__)\n </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app = flask.Flask(__name__)\n <mask>         @app.template_filter()\n <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse']('abcd'), 'dcba')\n <mask> \n <mask>     def test_add_template_filter(self):\n <mask>         app = flask.Flask(__name__)\n </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app = flask.Flask(__name__)\n <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         app.add_template_filter(my_reverse)\n <mask>         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse']('abcd'), 'dcba')\n <mask> \n <mask>     def test_template_filter_with_name(self):\n <mask>         app = flask.Flask(__name__)\n </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app = flask.Flask(__name__)\n <mask>         @app.template_filter('strrev')\n <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         self.assert_('strrev' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['strrev'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['strrev']('abcd'), 'dcba')\n <mask> \n <mask>     def test_add_template_filter_with_name(self):\n <mask>         app = flask.Flask(__name__)\n </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app = flask.Flask(__name__)\n <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         app.add_template_filter(my_reverse, 'strrev')\n <mask>         self.assert_('strrev' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['strrev'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['strrev']('abcd'), 'dcba')\n <mask> \n <mask>     def test_template_filter_with_template(self):\n <mask>         app = flask.Flask(__name__)\n </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return update_wrapper(new_f, f)\n <mask> \n <mask> \n <mask> class FlaskTestCase(unittest.TestCase):\n <mask>     pass\n <mask> \n <mask> \n <mask> class ContextTestCase(FlaskTestCase):\n <mask> \n <mask>     def test_context_binding(self):\n </s> Test that we're not leaking a request context in the testsuite, fixed a leak </s> remove         with catch_stderr() as err:\n            c.get('/')\n            out = err.getvalue()\n            assert 'WARNING in flask_tests [' in out\n            assert 'flask_tests.py' in out\n            assert 'the standard library is dead' in out\n            assert 'this is a debug statement' in out\n\n        with catch_stderr() as err:\n            try:\n                c.get('/exc')\n            except ZeroDivisionError:\n                pass\n            else:\n                assert False, 'debug log ate the exception'\n </s> add         with app.test_client() as c:\n            with catch_stderr() as err:\n                c.get('/')\n                out = err.getvalue()\n                assert 'WARNING in flask_tests [' in out\n                assert 'flask_tests.py' in out\n                assert 'the standard library is dead' in out\n                assert 'this is a debug statement' in out\n\n            with catch_stderr() as err:\n                try:\n                    c.get('/exc')\n                except ZeroDivisionError:\n                    pass\n                else:\n                    assert False, 'debug log ate the exception' </s> remove         c = app.test_client()\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f051939d8ba1c5ec585fd4db1f83237a66020c0a", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep replace keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep", "code_tokens": " <mask>         def exc():\n <mask>             1/0\n <mask>         c = app.test_client()\n <mask> \n <mask>         with catch_stderr() as err:\n <mask>             c.get('/')\n <mask>             out = err.getvalue()\n <mask>             assert 'WARNING in flask_tests [' in out\n <mask>             assert 'flask_tests.py' in out\n <mask>             assert 'the standard library is dead' in out\n <mask>             assert 'this is a debug statement' in out\n <mask> \n <mask>         with catch_stderr() as err:\n <mask>             try:\n <mask>                 c.get('/exc')\n <mask>             except ZeroDivisionError:\n <mask>                 pass\n <mask>             else:\n <mask>                 assert False, 'debug log ate the exception'\n <mask> \n </s> Test that we're not leaking a request context in the testsuite, fixed a leak </s> remove     pass\n </s> add     def ensure_clean_request_context(self):\n        # make sure we're not leaking a request context since we are\n        # testing flask internally in debug mode in a few cases\n        self.assertEqual(flask._request_ctx_stack.top, None)\n\n    def tearDown(self):\n        unittest.TestCase.tearDown(self)\n        self.ensure_clean_request_context()", "html_url": "https://github.com/pallets/flask/commit/f051939d8ba1c5ec585fd4db1f83237a66020c0a", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     make html\n <mask> \n <mask> Open ``_build/html/index.html`` in your browser to view the docs.\n <mask> \n <mask> Read more about `Sphinx <http://www.sphinx-doc.org>`_.\n <mask> \n <mask> \n <mask> make targets\n <mask> ~~~~~~~~~~~~\n <mask> \n </s> Use https for external links wherever possible </s> remove .. _fabric: http://www.fabfile.org/\n </s> add .. _fabric: https://www.fabfile.org/ </s> remove .. _Fabric: http://www.fabfile.org/\n </s> add .. _Fabric: https://www.fabfile.org/ </s> remove       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is\n </s> add       <https://tools.ietf.org/html/rfc3987>`_.  Imagine your application is </s> remove .. _jQuery: http://jquery.com/\n </s> add .. _jQuery: https://jquery.com/ </s> remove .. _Dive Into HTML5: http://diveintohtml5.info/\n </s> add .. _Dive Into HTML5: http://diveintohtml5.info/table-of-contents.html </s> remove `First Steps with Celery <http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html>`_\n </s> add `First Steps with Celery <https://celery.readthedocs.io/en/latest/getting-started/first-steps-with-celery.html>`_", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "CONTRIBUTING.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>    .. attribute:: base_url\n <mask>    .. attribute:: url_root\n <mask> \n <mask>       Provides different ways to look at the current `IRI\n <mask>       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is\n <mask>       listening on the following application root::\n <mask> \n <mask>           http://www.example.com/myapplication\n <mask> \n <mask>       And a user requests the following URI::\n </s> Use https for external links wherever possible </s> remove .. _Fabric: http://www.fabfile.org/\n </s> add .. _Fabric: https://www.fabfile.org/ </s> remove .. _jQuery: http://jquery.com/\n </s> add .. _jQuery: https://jquery.com/ </s> remove .. _fabric: http://www.fabfile.org/\n </s> add .. _fabric: https://www.fabfile.org/ </s> remove Read more about `Sphinx <http://www.sphinx-doc.org>`_.\n </s> add Read more about `Sphinx <https://www.sphinx-doc.org>`_. </s> remove .. _Dive Into HTML5: http://diveintohtml5.info/\n </s> add .. _Dive Into HTML5: http://diveintohtml5.info/table-of-contents.html </s> remove `First Steps with Celery <http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html>`_\n </s> add `First Steps with Celery <https://celery.readthedocs.io/en/latest/getting-started/first-steps-with-celery.html>`_", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/api.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     configurations separately to the production server(s).  For some\n <mask>     details about how to do that, head over to the\n <mask>     :ref:`fabric-deployment` pattern.\n <mask> \n <mask> .. _fabric: http://www.fabfile.org/\n <mask> \n <mask> \n <mask> .. _instance-folders:\n <mask> \n <mask> Instance Folders\n </s> Use https for external links wherever possible </s> remove Read more about `Sphinx <http://www.sphinx-doc.org>`_.\n </s> add Read more about `Sphinx <https://www.sphinx-doc.org>`_. </s> remove .. _Fabric: http://www.fabfile.org/\n </s> add .. _Fabric: https://www.fabfile.org/ </s> remove       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is\n </s> add       <https://tools.ietf.org/html/rfc3987>`_.  Imagine your application is </s> remove .. _jQuery: http://jquery.com/\n </s> add .. _jQuery: https://jquery.com/ </s> remove `First Steps with Celery <http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html>`_\n </s> add `First Steps with Celery <https://celery.readthedocs.io/en/latest/getting-started/first-steps-with-celery.html>`_ </s> remove .. _Dive Into HTML5: http://diveintohtml5.info/\n </s> add .. _Dive Into HTML5: http://diveintohtml5.info/table-of-contents.html", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/config.rst"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask> \n <mask> .. _nginx: https://nginx.org/\n <mask> .. _lighttpd: https://www.lighttpd.net/\n <mask> .. _cherokee: http://cherokee-project.com/\n <mask> .. _uwsgi: http://projects.unbit.it/uwsgi/\n </s> Use https for external links wherever possible </s> remove .. _Gunicorn: http://gunicorn.org/\n.. _eventlet: http://eventlet.net/\n </s> add .. _Gunicorn: https://gunicorn.org/\n.. _eventlet: https://eventlet.net/ </s> remove .. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router\n </s> add .. _uWSGI: https://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: https://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router </s> remove .. _fabric: http://www.fabfile.org/\n </s> add .. _fabric: https://www.fabfile.org/ </s> remove .. _MongoKit: http://bytebucket.org/namlook/mongokit/\n </s> add .. _MongoKit: https://github.com/namlook/mongokit </s> remove .. _Fabric: http://www.fabfile.org/\n </s> add .. _Fabric: https://www.fabfile.org/ </s> remove       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is\n </s> add       <https://tools.ietf.org/html/rfc3987>`_.  Imagine your application is", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/deploying/uwsgi.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> 4``) binding to localhost port 4000 (``-b 127.0.0.1:4000``)::\n <mask> \n <mask>     $ gunicorn -w 4 -b 127.0.0.1:4000 myproject:app\n <mask> \n <mask> .. _Gunicorn: http://gunicorn.org/\n <mask> .. _eventlet: http://eventlet.net/\n <mask> .. _greenlet: https://greenlet.readthedocs.io/en/latest/\n <mask> \n <mask> uWSGI\n <mask> --------\n <mask> \n </s> Use https for external links wherever possible </s> remove .. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router\n </s> add .. _uWSGI: https://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: https://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router </s> remove .. _fabric: http://www.fabfile.org/\n </s> add .. _fabric: https://www.fabfile.org/ </s> remove .. _uwsgi: http://projects.unbit.it/uwsgi/\n </s> add .. _uwsgi: https://uwsgi-docs.readthedocs.io/ </s> remove .. _Fabric: http://www.fabfile.org/\n </s> add .. _Fabric: https://www.fabfile.org/ </s> remove       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is\n </s> add       <https://tools.ietf.org/html/rfc3987>`_.  Imagine your application is </s> remove .. _MongoKit: http://bytebucket.org/namlook/mongokit/\n </s> add .. _MongoKit: https://github.com/namlook/mongokit", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/deploying/wsgi-standalone.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     $ uwsgi --http 127.0.0.1:5000 --module myproject:app\n <mask> \n <mask> For a more optimized setup, see :doc:`configuring uWSGI and NGINX <uwsgi>`.\n <mask> \n <mask> .. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n <mask> .. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router\n <mask> \n <mask> Gevent\n <mask> -------\n <mask> \n <mask> `Gevent`_ is a coroutine-based Python networking library that uses\n </s> Use https for external links wherever possible </s> remove .. _Gunicorn: http://gunicorn.org/\n.. _eventlet: http://eventlet.net/\n </s> add .. _Gunicorn: https://gunicorn.org/\n.. _eventlet: https://eventlet.net/ </s> remove .. _Fabric: http://www.fabfile.org/\n </s> add .. _Fabric: https://www.fabfile.org/ </s> remove .. _jQuery: http://jquery.com/\n </s> add .. _jQuery: https://jquery.com/ </s> remove `First Steps with Celery <http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html>`_\n </s> add `First Steps with Celery <https://celery.readthedocs.io/en/latest/getting-started/first-steps-with-celery.html>`_ </s> remove .. _fabric: http://www.fabfile.org/\n </s> add .. _fabric: https://www.fabfile.org/ </s> remove <http://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the\n </s> add <https://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/deploying/wsgi-standalone.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Many other features have been added, as well. A good guide to new features\n <mask> in HTML5 is Mark Pilgrim's soon-to-be-published book, `Dive Into HTML5`_.\n <mask> Not all of them are supported in browsers yet, however, so use caution.\n <mask> \n <mask> .. _Dive Into HTML5: http://diveintohtml5.info/\n <mask> \n <mask> What should be used?\n <mask> --------------------\n <mask> \n <mask> Currently, the answer is HTML5.  There are very few reasons to use XHTML\n </s> Use https for external links wherever possible </s> remove .. _jQuery: http://jquery.com/\n </s> add .. _jQuery: https://jquery.com/ </s> remove <http://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the\n </s> add <https://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the </s> remove `First Steps with Celery <http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html>`_\n </s> add `First Steps with Celery <https://celery.readthedocs.io/en/latest/getting-started/first-steps-with-celery.html>`_ </s> remove       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is\n </s> add       <https://tools.ietf.org/html/rfc3987>`_.  Imagine your application is </s> remove Read more about `Sphinx <http://www.sphinx-doc.org>`_.\n </s> add Read more about `Sphinx <https://www.sphinx-doc.org>`_. </s> remove \techo.http://sphinx-doc.org/\n </s> add \techo.https://www.sphinx-doc.org/\r", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/htmlfaq.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \techo.to the full path of the 'sphinx-build' executable. Alternatively you\n <mask> \techo.may add the Sphinx directory to PATH.\n <mask> \techo.\n <mask> \techo.If you don't have Sphinx installed, grab it from\n <mask> \techo.http://sphinx-doc.org/\n <mask> \texit /b 1\n <mask> )\n <mask> \n <mask> %SPHINXBUILD% -M %1 %SOURCEDIR% %BUILDDIR% %SPHINXOPTS%\n <mask> goto end\n </s> Use https for external links wherever possible </s> remove <http://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the\n </s> add <https://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the </s> remove .. _jQuery: http://jquery.com/\n </s> add .. _jQuery: https://jquery.com/ </s> remove `First Steps with Celery <http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html>`_\n </s> add `First Steps with Celery <https://celery.readthedocs.io/en/latest/getting-started/first-steps-with-celery.html>`_ </s> remove .. _fabric: http://www.fabfile.org/\n </s> add .. _fabric: https://www.fabfile.org/ </s> remove .. _Dive Into HTML5: http://diveintohtml5.info/\n </s> add .. _Dive Into HTML5: http://diveintohtml5.info/table-of-contents.html </s> remove       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is\n </s> add       <https://tools.ietf.org/html/rfc3987>`_.  Imagine your application is", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/make.bat"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Celery is a powerful task queue that can be used for simple background tasks\n <mask> as well as complex multi-stage programs and schedules. This guide will show you\n <mask> how to configure Celery using Flask, but assumes you've already read the\n <mask> `First Steps with Celery <http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html>`_\n <mask> guide in the Celery documentation.\n <mask> \n <mask> Install\n <mask> -------\n <mask> \n </s> Use https for external links wherever possible </s> remove <http://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the\n </s> add <https://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the </s> remove .. _Dive Into HTML5: http://diveintohtml5.info/\n </s> add .. _Dive Into HTML5: http://diveintohtml5.info/table-of-contents.html </s> remove .. _jQuery: http://jquery.com/\n </s> add .. _jQuery: https://jquery.com/ </s> remove .. _fabric: http://www.fabfile.org/\n </s> add .. _fabric: https://www.fabfile.org/ </s> remove .. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router\n </s> add .. _uWSGI: https://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: https://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router </s> remove       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is\n </s> add       <https://tools.ietf.org/html/rfc3987>`_.  Imagine your application is", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/patterns/celery.rst"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask> type ``fab deploy`` and see your application being deployed automatically\n <mask> to one or more remote servers.\n <mask> \n <mask> \n <mask> .. _Fabric: http://www.fabfile.org/\n </s> Use https for external links wherever possible </s> remove       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is\n </s> add       <https://tools.ietf.org/html/rfc3987>`_.  Imagine your application is </s> remove .. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router\n </s> add .. _uWSGI: https://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: https://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router </s> remove Read more about `Sphinx <http://www.sphinx-doc.org>`_.\n </s> add Read more about `Sphinx <https://www.sphinx-doc.org>`_. </s> remove .. _fabric: http://www.fabfile.org/\n </s> add .. _fabric: https://www.fabfile.org/ </s> remove .. _jQuery: http://jquery.com/\n </s> add .. _jQuery: https://jquery.com/ </s> remove .. _Gunicorn: http://gunicorn.org/\n.. _eventlet: http://eventlet.net/\n </s> add .. _Gunicorn: https://gunicorn.org/\n.. _eventlet: https://eventlet.net/", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/patterns/fabric.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Python primitives (numbers, strings, dicts and lists) look like which is\n <mask> widely supported and very easy to parse.  It became popular a few years\n <mask> ago and quickly replaced XML as transport format in web applications.\n <mask> \n <mask> .. _jQuery: http://jquery.com/\n <mask> \n <mask> Loading jQuery\n <mask> --------------\n <mask> \n <mask> In order to use jQuery, you have to download it first and place it in the\n </s> Use https for external links wherever possible </s> remove .. _Dive Into HTML5: http://diveintohtml5.info/\n </s> add .. _Dive Into HTML5: http://diveintohtml5.info/table-of-contents.html </s> remove <http://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the\n </s> add <https://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the </s> remove `First Steps with Celery <http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html>`_\n </s> add `First Steps with Celery <https://celery.readthedocs.io/en/latest/getting-started/first-steps-with-celery.html>`_ </s> remove \techo.http://sphinx-doc.org/\n </s> add \techo.https://www.sphinx-doc.org/\r </s> remove       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is\n </s> add       <https://tools.ietf.org/html/rfc3987>`_.  Imagine your application is </s> remove .. _Fabric: http://www.fabfile.org/\n </s> add .. _Fabric: https://www.fabfile.org/", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/patterns/jquery.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> [<User u'admin'>]\n <mask> >>> collection.User.find_one({'name': u'admin'})\n <mask> <User u'admin'>\n <mask> \n <mask> .. _MongoKit: http://bytebucket.org/namlook/mongokit/\n <mask> \n <mask> \n <mask> PyMongo Compatibility Layer\n <mask> ---------------------------\n <mask> \n </s> Use https for external links wherever possible </s> remove .. _uwsgi: http://projects.unbit.it/uwsgi/\n </s> add .. _uwsgi: https://uwsgi-docs.readthedocs.io/ </s> remove .. _Gunicorn: http://gunicorn.org/\n.. _eventlet: http://eventlet.net/\n </s> add .. _Gunicorn: https://gunicorn.org/\n.. _eventlet: https://eventlet.net/ </s> remove .. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router\n </s> add .. _uWSGI: https://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: https://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router </s> remove .. _fabric: http://www.fabfile.org/\n </s> add .. _fabric: https://www.fabfile.org/ </s> remove .. _Fabric: http://www.fabfile.org/\n </s> add .. _Fabric: https://www.fabfile.org/ </s> remove       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is\n </s> add       <https://tools.ietf.org/html/rfc3987>`_.  Imagine your application is", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/patterns/mongokit.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> text.  Not only these libraries, also the majority of web related Python\n <mask> libraries that deal with text.  If you don't know Unicode so far, you\n <mask> should probably read `The Absolute Minimum Every Software Developer\n <mask> Absolutely, Positively Must Know About Unicode and Character Sets\n <mask> <http://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the\n <mask> documentation just tries to cover the very basics so that you have a\n <mask> pleasant experience with Unicode related things.\n <mask> \n <mask> Automatic Conversion\n <mask> --------------------\n </s> Use https for external links wherever possible </s> remove `First Steps with Celery <http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html>`_\n </s> add `First Steps with Celery <https://celery.readthedocs.io/en/latest/getting-started/first-steps-with-celery.html>`_ </s> remove .. _Dive Into HTML5: http://diveintohtml5.info/\n </s> add .. _Dive Into HTML5: http://diveintohtml5.info/table-of-contents.html </s> remove \techo.http://sphinx-doc.org/\n </s> add \techo.https://www.sphinx-doc.org/\r </s> remove .. _jQuery: http://jquery.com/\n </s> add .. _jQuery: https://jquery.com/ </s> remove .. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router\n </s> add .. _uWSGI: https://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: https://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router </s> remove       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is\n </s> add       <https://tools.ietf.org/html/rfc3987>`_.  Imagine your application is", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> _missing = object()\n <mask> \n <mask> \n <mask> def _get_data(req):\n <mask>     getter = getattr(req, 'get_data', None)\n <mask>     if getter is not None:\n <mask>         return getter()\n <mask>     return req.data\n <mask> \n <mask> \n <mask> class JSONMixin(object):\n <mask>     \"\"\"Mixin for both request and response classes to provide JSON parsing\n <mask>     capabilities.\n <mask> \n <mask>     .. versionadded:: 0.12\n </s> Alternative solution for lack of response caching </s> add     def _get_data_for_json(req, cache):\n        getter = getattr(req, 'get_data', None)\n        if getter is not None:\n            return getter(cache=cache)\n        return req.data\n </s> remove             data = _get_data(self)\n </s> add             data = self._get_data_for_json(cache)", "html_url": "https://github.com/pallets/flask/commit/f0f458e0c5c4610cc210ef80a89b2b0870baa1b6", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         warn(DeprecationWarning('json is deprecated.  '\n <mask>                                 'Use get_json() instead.'), stacklevel=2)\n <mask>         return self.get_json()\n <mask> \n <mask>     def get_json(self, force=False, silent=False, cache=True):\n <mask>         \"\"\"Parses the incoming JSON request data and returns it.  By default\n <mask>         this function will return ``None`` if the mimetype is not\n <mask>         :mimetype:`application/json` but this can be overridden by the\n </s> Alternative solution for lack of response caching </s> remove def _get_data(req):\n    getter = getattr(req, 'get_data', None)\n    if getter is not None:\n        return getter()\n    return req.data\n\n\n </s> add  </s> remove             data = _get_data(self)\n </s> add             data = self._get_data_for_json(cache)", "html_url": "https://github.com/pallets/flask/commit/f0f458e0c5c4610cc210ef80a89b2b0870baa1b6", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # that if the response charset was set explicitly then the data had\n <mask>         # been encoded correctly as well.\n <mask>         charset = self.mimetype_params.get('charset')\n <mask>         try:\n <mask>             data = _get_data(self)\n <mask>             if charset is not None:\n <mask>                 rv = json.loads(data, encoding=charset)\n <mask>             else:\n <mask>                 rv = json.loads(data)\n <mask>         except ValueError as e:\n </s> Alternative solution for lack of response caching </s> add     def _get_data_for_json(req, cache):\n        getter = getattr(req, 'get_data', None)\n        if getter is not None:\n            return getter(cache=cache)\n        return req.data\n </s> remove def _get_data(req):\n    getter = getattr(req, 'get_data', None)\n    if getter is not None:\n        return getter()\n    return req.data\n\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f0f458e0c5c4610cc210ef80a89b2b0870baa1b6", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> `float`     like `int` but for floating point values\n <mask> `path`      like the default but also accepts slashes\n <mask> =========== ===========================================\n <mask> \n <mask> URL Building\n <mask> ````````````\n <mask> \n <mask> If it can match URLs, can it also generate them?  Of course you can.  To\n <mask> build a URL to a specific function you can use the :func:`~flask.url_for`\n <mask> function.  It accepts the name of the function as first argument and a\n </s> Docs mention query args now.  This fixes #20 </s> remove the URL rule.  Here some examples:\n </s> add the URL rule.  Unknown variable parts are appended to the URL as query\nparameter.  Here some examples: </s> add     Variable arguments that are unknown to the target endpoint are appended\n    to the generated URL as query arguments.\n\n    For more information, head over to the :ref:`Quickstart <url-building>`. </s> add /login?next=/ </s> add ...  print url_for('login', next='/')", "html_url": "https://github.com/pallets/flask/commit/f1603d33f266ab24eda604f76632fa604b91e3f9", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> If it can match URLs, can it also generate them?  Of course you can.  To\n <mask> build a URL to a specific function you can use the :func:`~flask.url_for`\n <mask> function.  It accepts the name of the function as first argument and a\n <mask> number of keyword arguments, each corresponding to the variable part of\n <mask> the URL rule.  Here some examples:\n <mask> \n <mask> >>> from flask import Flask, url_for\n <mask> >>> app = Flask(__name__)\n <mask> >>> @app.route('/')\n <mask> ... def index(): pass\n </s> Docs mention query args now.  This fixes #20 </s> add .. _url-building:\n </s> add     Variable arguments that are unknown to the target endpoint are appended\n    to the generated URL as query arguments.\n\n    For more information, head over to the :ref:`Quickstart <url-building>`. </s> add /login?next=/ </s> add ...  print url_for('login', next='/')", "html_url": "https://github.com/pallets/flask/commit/f1603d33f266ab24eda604f76632fa604b91e3f9", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> ...  print url_for('login')\n <mask> ...  print url_for('profile', username='John Doe')\n <mask> ... \n <mask> /\n <mask> /login\n <mask> /login?next=/\n <mask> /user/John%20Doe\n </s> Docs mention query args now.  This fixes #20 </s> add /login?next=/ </s> remove the URL rule.  Here some examples:\n </s> add the URL rule.  Unknown variable parts are appended to the URL as query\nparameter.  Here some examples: </s> add     Variable arguments that are unknown to the target endpoint are appended\n    to the generated URL as query arguments.\n\n    For more information, head over to the :ref:`Quickstart <url-building>`. </s> add .. _url-building:\n", "html_url": "https://github.com/pallets/flask/commit/f1603d33f266ab24eda604f76632fa604b91e3f9", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> ...  print url_for('login', next='/')\n <mask> ... \n <mask> /\n <mask> /login\n <mask> /user/John%20Doe\n <mask> \n <mask> (This also uses the :meth:`~flask.Flask.test_request_context` method\n <mask> explained below.  It basically tells flask to think we are handling a\n </s> Docs mention query args now.  This fixes #20 </s> add ...  print url_for('login', next='/') </s> remove the URL rule.  Here some examples:\n </s> add the URL rule.  Unknown variable parts are appended to the URL as query\nparameter.  Here some examples: </s> add     Variable arguments that are unknown to the target endpoint are appended\n    to the generated URL as query arguments.\n\n    For more information, head over to the :ref:`Quickstart <url-building>`. </s> add .. _url-building:\n", "html_url": "https://github.com/pallets/flask/commit/f1603d33f266ab24eda604f76632fa604b91e3f9", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> def url_for(endpoint, **values):\n <mask>     \"\"\"Generates a URL to the given endpoint with the method provided.\n <mask> \n <mask>     :param endpoint: the endpoint of the URL (name of the function)\n <mask>     :param values: the variable arguments of the URL rule\n <mask>     \"\"\"\n </s> Docs mention query args now.  This fixes #20 </s> remove the URL rule.  Here some examples:\n </s> add the URL rule.  Unknown variable parts are appended to the URL as query\nparameter.  Here some examples: </s> add .. _url-building:\n </s> add /login?next=/ </s> add ...  print url_for('login', next='/')", "html_url": "https://github.com/pallets/flask/commit/f1603d33f266ab24eda604f76632fa604b91e3f9", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> import pytest\n <mask> \n <mask> import os\n <mask> import datetime\n <mask> import flask\n <mask> from logging import StreamHandler\n <mask> from werkzeug.exceptions import BadRequest, NotFound\n <mask> from werkzeug.http import parse_cache_control_header, parse_options_header\n <mask> from werkzeug.http import http_date\n </s> Add tests for flask.json.dump() and test that jsonify correctly converts uuids. </s> add     def test_json_dump_to_file(self):\n        app = flask.Flask(__name__)\n\n        test_data = {'lol': 'wut'}\n\n        with app.app_context():\n            t_fh = open('test_json_dump_file', 'w')\n            flask.json.dump(test_data, t_fh)\n            t_fh.close()\n\n            t_fh = open('test_json_dump_file', 'r')\n            rv = flask.json.load(t_fh)\n            assert rv == test_data\n            t_fh.close()\n            os.remove('test_json_dump_file')\n </s> add     def test_jsonify_uuid_types(self):\n        \"\"\"Test jsonify with uuid.UUID types\"\"\"\n        test_uuid = uuid.UUID(bytes=b'\\xDE\\xAD\\xBE\\xEF'*4)\n\n        app = flask.Flask(__name__)\n        c = app.test_client()\n        url = '/uuid_test'\n        app.add_url_rule(url, 'uuid_test', lambda val=test_uuid: flask.jsonify(x=val))\n        rv = c.get(url)\n        assert rv.mimetype == 'application/json'\n        assert flask.json.loads(rv.data)['x'] == str(test_uuid)\n", "html_url": "https://github.com/pallets/flask/commit/f16e477b2a7329d249b5793a0dc4986503a48371", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>             assert rv == u'\"\\u2603\"'\n <mask> \n <mask>     def test_jsonify_basic_types(self):\n <mask>         \"\"\"Test jsonify with basic types.\"\"\"\n <mask>         # Should be able to use pytest parametrize on this, but I couldn't\n <mask>         # figure out the correct syntax\n <mask>         # https://pytest.org/latest/parametrize.html#pytest-mark-parametrize-parametrizing-test-functions\n <mask>         test_data = (0, 1, 23, 3.14, 's', \"longer string\", True, False,)\n </s> Add tests for flask.json.dump() and test that jsonify correctly converts uuids. </s> add     def test_jsonify_uuid_types(self):\n        \"\"\"Test jsonify with uuid.UUID types\"\"\"\n        test_uuid = uuid.UUID(bytes=b'\\xDE\\xAD\\xBE\\xEF'*4)\n\n        app = flask.Flask(__name__)\n        c = app.test_client()\n        url = '/uuid_test'\n        app.add_url_rule(url, 'uuid_test', lambda val=test_uuid: flask.jsonify(x=val))\n        rv = c.get(url)\n        assert rv.mimetype == 'application/json'\n        assert flask.json.loads(rv.data)['x'] == str(test_uuid)\n </s> add import uuid", "html_url": "https://github.com/pallets/flask/commit/f16e477b2a7329d249b5793a0dc4986503a48371", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>             assert rv.mimetype == 'application/json'\n <mask>             assert flask.json.loads(rv.data)['x'] == http_date(d.timetuple())\n <mask> \n <mask>     def test_json_attr(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         @app.route('/add', methods=['POST'])\n <mask>         def add():\n <mask>             json = flask.request.get_json()\n <mask>             return text_type(json['a'] + json['b'])\n </s> Add tests for flask.json.dump() and test that jsonify correctly converts uuids. </s> add     def test_json_dump_to_file(self):\n        app = flask.Flask(__name__)\n\n        test_data = {'lol': 'wut'}\n\n        with app.app_context():\n            t_fh = open('test_json_dump_file', 'w')\n            flask.json.dump(test_data, t_fh)\n            t_fh.close()\n\n            t_fh = open('test_json_dump_file', 'r')\n            rv = flask.json.load(t_fh)\n            assert rv == test_data\n            t_fh.close()\n            os.remove('test_json_dump_file')\n </s> add import uuid", "html_url": "https://github.com/pallets/flask/commit/f16e477b2a7329d249b5793a0dc4986503a48371", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>   you can reintroduce them again yourself trivially.  Using them however is\n <mask>   strongly discouraged as the interface was flawed.\n <mask> - Python requirements changed: requiring Python 2.6 or 2.7 now to prepare\n <mask>   for Python 3.3 port.\n <mask> \n <mask> Version 0.9\n <mask> -----------\n <mask> \n </s> Changed teardown error handling to be more reliable. </s> add     def should_ignore_error(self, error):\n        \"\"\"This is called to figure out if an error should be ignored\n        or not as far as the teardown system is concerned.  If this\n        function returns `True` then the teardown handlers will not be\n        passed the error.\n\n        .. versionadded:: 0.10\n        \"\"\"\n        return False\n </s> remove         if self.request.environ.get('flask._preserve_context') or \\\n           (tb is not None and self.app.preserve_context_on_exception):\n            self.preserved = True\n        else:\n            self.pop(exc_value)\n </s> add         self.auto_pop(exc_value) </s> remove         with self.request_context(environ):\n </s> add         ctx = self.request_context(environ)\n        ctx.push()\n        error = None\n        try:", "html_url": "https://github.com/pallets/flask/commit/f1918093ac70d589a4d67af0d77140734c06c13d", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         rv = self.response_class()\n <mask>         rv.allow.update(methods)\n <mask>         return rv\n <mask> \n <mask>     def make_response(self, rv):\n <mask>         \"\"\"Converts the return value from a view function to a real\n <mask>         response object that is an instance of :attr:`response_class`.\n <mask> \n </s> Changed teardown error handling to be more reliable. </s> remove         with self.request_context(environ):\n </s> add         ctx = self.request_context(environ)\n        ctx.push()\n        error = None\n        try: </s> remove         if self.request.environ.get('flask._preserve_context') or \\\n           (tb is not None and self.app.preserve_context_on_exception):\n            self.preserved = True\n        else:\n            self.pop(exc_value)\n </s> add         self.auto_pop(exc_value) </s> add - Changed how the teardown system is informed about exceptions.  This is now\n  more reliable in case something handles an exception halfway through\n  the error handling process.", "html_url": "https://github.com/pallets/flask/commit/f1918093ac70d589a4d67af0d77140734c06c13d", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         :param start_response: a callable accepting a status code,\n <mask>                                a list of headers and an optional\n <mask>                                exception context to start the response\n <mask>         \"\"\"\n <mask>         with self.request_context(environ):\n <mask>             try:\n <mask>                 response = self.full_dispatch_request()\n <mask>             except Exception as e:\n <mask>                 response = self.make_response(self.handle_exception(e))\n <mask>             return response(environ, start_response)\n </s> Changed teardown error handling to be more reliable. </s> add     def should_ignore_error(self, error):\n        \"\"\"This is called to figure out if an error should be ignored\n        or not as far as the teardown system is concerned.  If this\n        function returns `True` then the teardown handlers will not be\n        passed the error.\n\n        .. versionadded:: 0.10\n        \"\"\"\n        return False\n </s> remove         if self.request.environ.get('flask._preserve_context') or \\\n           (tb is not None and self.app.preserve_context_on_exception):\n            self.preserved = True\n        else:\n            self.pop(exc_value)\n </s> add         self.auto_pop(exc_value) </s> add - Changed how the teardown system is informed about exceptions.  This is now\n  more reliable in case something handles an exception halfway through\n  the error handling process.", "html_url": "https://github.com/pallets/flask/commit/f1918093ac70d589a4d67af0d77140734c06c13d", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         # exception happened.  This will allow the debugger to still\n <mask>         # access the request object in the interactive shell.  Furthermore\n <mask>         # the context can be force kept alive for the test client.\n <mask>         # See flask.testing for how this works.\n <mask>         if self.request.environ.get('flask._preserve_context') or \\\n <mask>            (tb is not None and self.app.preserve_context_on_exception):\n <mask>             self.preserved = True\n <mask>         else:\n <mask>             self.pop(exc_value)\n <mask> \n <mask>     def __repr__(self):\n <mask>         return '<%s \\'%s\\' [%s] of %s>' % (\n <mask>             self.__class__.__name__,\n <mask>             self.request.url,\n </s> Changed teardown error handling to be more reliable. </s> add     def should_ignore_error(self, error):\n        \"\"\"This is called to figure out if an error should be ignored\n        or not as far as the teardown system is concerned.  If this\n        function returns `True` then the teardown handlers will not be\n        passed the error.\n\n        .. versionadded:: 0.10\n        \"\"\"\n        return False\n </s> add - Changed how the teardown system is informed about exceptions.  This is now\n  more reliable in case something handles an exception halfway through\n  the error handling process. </s> remove         with self.request_context(environ):\n </s> add         ctx = self.request_context(environ)\n        ctx.push()\n        error = None\n        try:", "html_url": "https://github.com/pallets/flask/commit/f1918093ac70d589a4d67af0d77140734c06c13d", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep replace keep keep keep keep", "code_tokens": " <mask>     assert testapp.cli.name == testapp.name\n <mask> \n <mask> \n <mask> def test_find_best_app(test_apps):\n <mask>     \"\"\"Test of find_best_app.\"\"\"\n <mask>     class mod:\n <mask>         app = Flask('appname')\n <mask>     assert find_best_app(mod) == mod.app\n <mask> \n <mask>     class mod:\n <mask>         application = Flask('appname')\n <mask>     assert find_best_app(mod) == mod.application\n </s> Enhance tests.test_cli.test_find_best_app (#1882)\n\nThis commit adds a test case for `test_find_best_app` where\r\nModule object does not contain Flask application.\r\nAlso cleans the function little bit to provides more meaningful comment. </s> remove     class mod:\n </s> add     class Module: </s> remove     assert find_best_app(mod) == mod.application\n </s> add     assert find_best_app(Module) == Module.application </s> remove     class mod:\n </s> add     class Module: </s> remove     assert find_best_app(mod) == mod.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     class mod:\n        myapp = Flask('appname')\n        myapp2 = Flask('appname2')\n </s> add     class Module:\n        pass\n    pytest.raises(NoAppException, find_best_app, Module)", "html_url": "https://github.com/pallets/flask/commit/f19d3bd67e0d8213013cf06f47d951c8735515c8", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep keep", "code_tokens": " <mask>         app = Flask('appname')\n <mask>     assert find_best_app(mod) == mod.app\n <mask> \n <mask>     class mod:\n <mask>         application = Flask('appname')\n <mask>     assert find_best_app(mod) == mod.application\n <mask> \n <mask>     class mod:\n <mask>         myapp = Flask('appname')\n </s> Enhance tests.test_cli.test_find_best_app (#1882)\n\nThis commit adds a test case for `test_find_best_app` where\r\nModule object does not contain Flask application.\r\nAlso cleans the function little bit to provides more meaningful comment. </s> remove     class mod:\n </s> add     class Module: </s> remove     assert find_best_app(mod) == mod.app\n </s> add     assert find_best_app(Module) == Module.app </s> remove     assert find_best_app(mod) == mod.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     \"\"\"Test of find_best_app.\"\"\"\n    class mod:\n </s> add     \"\"\"Test if `find_best_app` behaves as expected with different combinations of input.\"\"\"\n    class Module: </s> remove     class mod:\n        myapp = Flask('appname')\n        myapp2 = Flask('appname2')\n </s> add     class Module:\n        pass\n    pytest.raises(NoAppException, find_best_app, Module)", "html_url": "https://github.com/pallets/flask/commit/f19d3bd67e0d8213013cf06f47d951c8735515c8", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep keep keep", "code_tokens": " <mask>         application = Flask('appname')\n <mask>     assert find_best_app(mod) == mod.application\n <mask> \n <mask>     class mod:\n <mask>         myapp = Flask('appname')\n <mask>     assert find_best_app(mod) == mod.myapp\n <mask> \n <mask>     class mod:\n <mask>         myapp = Flask('appname')\n <mask>         myapp2 = Flask('appname2')\n </s> Enhance tests.test_cli.test_find_best_app (#1882)\n\nThis commit adds a test case for `test_find_best_app` where\r\nModule object does not contain Flask application.\r\nAlso cleans the function little bit to provides more meaningful comment. </s> remove     class mod:\n </s> add     class Module: </s> remove     class mod:\n        myapp = Flask('appname')\n        myapp2 = Flask('appname2')\n </s> add     class Module:\n        pass\n    pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(mod) == mod.application\n </s> add     assert find_best_app(Module) == Module.application </s> remove     assert find_best_app(mod) == mod.app\n </s> add     assert find_best_app(Module) == Module.app </s> remove     \"\"\"Test of find_best_app.\"\"\"\n    class mod:\n </s> add     \"\"\"Test if `find_best_app` behaves as expected with different combinations of input.\"\"\"\n    class Module:", "html_url": "https://github.com/pallets/flask/commit/f19d3bd67e0d8213013cf06f47d951c8735515c8", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep replace keep keep", "code_tokens": " <mask>         myapp = Flask('appname')\n <mask>     assert find_best_app(mod) == mod.myapp\n <mask> \n <mask>     class mod:\n <mask>         myapp = Flask('appname')\n <mask>         myapp2 = Flask('appname2')\n <mask> \n <mask>     pytest.raises(NoAppException, find_best_app, mod)\n <mask> \n <mask> \n </s> Enhance tests.test_cli.test_find_best_app (#1882)\n\nThis commit adds a test case for `test_find_best_app` where\r\nModule object does not contain Flask application.\r\nAlso cleans the function little bit to provides more meaningful comment. </s> remove     assert find_best_app(mod) == mod.myapp\n </s> add     assert find_best_app(Module) == Module.myapp </s> remove     class mod:\n </s> add     class Module: </s> remove     class mod:\n </s> add     class Module: </s> remove     assert find_best_app(mod) == mod.application\n </s> add     assert find_best_app(Module) == Module.application </s> remove     assert find_best_app(mod) == mod.app\n </s> add     assert find_best_app(Module) == Module.app", "html_url": "https://github.com/pallets/flask/commit/f19d3bd67e0d8213013cf06f47d951c8735515c8", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep add", "code_tokens": " <mask> \n <mask>       3. now you can run the minitwit.py file with your\n <mask>          python interpreter and the application will\n <mask>          greet you on http://localhost:5000/\n </s> Added tests for minitwit.  Testing with Flask is awesome </s> remove     @cached_property\n    def test(self):\n        \"\"\"A test client for this application\"\"\"\n </s> add     def test_client(self):\n        \"\"\"Creates a test client for this application\"\"\" </s> remove             error = 'The two passwords to not match'\n </s> add             error = 'The two passwords do not match'", "html_url": "https://github.com/pallets/flask/commit/f2dc38cda61f76c64b97ab9f730accc986a4b188", "file_name": "examples/minitwit/README"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             error = 'You have to enter a valid email address'\n <mask>         elif not request.form['password']:\n <mask>             error = 'You have to enter a password'\n <mask>         elif request.form['password'] != request.form['password2']:\n <mask>             error = 'The two passwords to not match'\n <mask>         elif get_user_id(request.form['username']) is not None:\n <mask>             error = 'The username is already taken'\n <mask>         else:\n <mask>             g.db.execute('''insert into user (\n <mask>                 username, email, pw_hash) values (?, ?, ?)''',\n </s> Added tests for minitwit.  Testing with Flask is awesome </s> add \t\n    ~ Is it tested?\n\n      You betcha.  Run the `minitwit_tests.py` file to\n      see the tests pass. </s> remove     @cached_property\n    def test(self):\n        \"\"\"A test client for this application\"\"\"\n </s> add     def test_client(self):\n        \"\"\"Creates a test client for this application\"\"\"", "html_url": "https://github.com/pallets/flask/commit/f2dc38cda61f76c64b97ab9f730accc986a4b188", "file_name": "examples/minitwit/minitwit.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         options.setdefault('use_reloader', self.debug)\n <mask>         options.setdefault('use_debugger', self.debug)\n <mask>         return run_simple(host, port, self, **options)\n <mask> \n <mask>     @cached_property\n <mask>     def test(self):\n <mask>         \"\"\"A test client for this application\"\"\"\n <mask>         from werkzeug import Client\n <mask>         return Client(self, self.response_class, use_cookies=True)\n <mask> \n <mask>     def open_resource(self, resource):\n <mask>         \"\"\"Opens a resource from the application's resource folder.  To see\n </s> Added tests for minitwit.  Testing with Flask is awesome </s> add \t\n    ~ Is it tested?\n\n      You betcha.  Run the `minitwit_tests.py` file to\n      see the tests pass. </s> remove             error = 'The two passwords to not match'\n </s> add             error = 'The two passwords do not match'", "html_url": "https://github.com/pallets/flask/commit/f2dc38cda61f76c64b97ab9f730accc986a4b188", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     from sqlalchemy import create_engine\n <mask>     from sqlalchemy.orm import scoped_session, sessionmaker\n <mask>     from sqlalchemy.ext.declarative import declarative_base\n <mask> \n <mask>     engine = create_engine('sqlite:////tmp/test.db')\n <mask>     db_session = scoped_session(sessionmaker(autocommit=False,\n <mask>                                              autoflush=False,\n <mask>                                              bind=engine)) \n <mask>     Base = declarative_base()\n <mask>     Base.query = db_session.query_property()\n </s> Use unicode in SQLAlchemy pattern. </s> remove     engine = create_engine('sqlite:////tmp/test.db')\n </s> add     engine = create_engine('sqlite:////tmp/test.db', convert_unicode=True) </s> remove     engine = create_engine('sqlite:////tmp/test.db')\n </s> add     engine = create_engine('sqlite:////tmp/test.db', convert_unicode=True)", "html_url": "https://github.com/pallets/flask/commit/f345af8d9d33e6164747c865c29a72186a470c22", "file_name": "docs/patterns/sqlalchemy.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     from sqlalchemy import create_engine, MetaData\n <mask>     from sqlalchemy.orm import scoped_session, sessionmaker\n <mask> \n <mask>     engine = create_engine('sqlite:////tmp/test.db')\n <mask>     metadata = MetaData()\n <mask>     db_session = scoped_session(sessionmaker(autocommit=False,\n <mask>                                              autoflush=False,\n <mask>                                              bind=engine)) \n <mask>     def init_db():\n </s> Use unicode in SQLAlchemy pattern. </s> remove     engine = create_engine('sqlite:////tmp/test.db')\n </s> add     engine = create_engine('sqlite:////tmp/test.db', convert_unicode=True) </s> remove     engine = create_engine('sqlite:////tmp/test.db')\n </s> add     engine = create_engine('sqlite:////tmp/test.db', convert_unicode=True)", "html_url": "https://github.com/pallets/flask/commit/f345af8d9d33e6164747c865c29a72186a470c22", "file_name": "docs/patterns/sqlalchemy.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> you basically only need the engine::\n <mask> \n <mask>     from sqlalchemy import create_engine, MetaData\n <mask> \n <mask>     engine = create_engine('sqlite:////tmp/test.db')\n <mask>     metadata = MetaData(bind=engine)\n <mask> \n <mask> Then you can either declare the tables in your code like in the examples\n <mask> above, or automatically load them::\n <mask> \n </s> Use unicode in SQLAlchemy pattern. </s> remove     engine = create_engine('sqlite:////tmp/test.db')\n </s> add     engine = create_engine('sqlite:////tmp/test.db', convert_unicode=True) </s> remove     engine = create_engine('sqlite:////tmp/test.db')\n </s> add     engine = create_engine('sqlite:////tmp/test.db', convert_unicode=True)", "html_url": "https://github.com/pallets/flask/commit/f345af8d9d33e6164747c865c29a72186a470c22", "file_name": "docs/patterns/sqlalchemy.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>   JSON is handled by Flask or any Flask extension.\n <mask> - Removed deprecated internal ``flask.session`` module alias.  Use\n <mask>   ``flask.sessions`` instead to get the session module.  This is not to\n <mask>   be confused with ``flask.session`` the session proxy.\n <mask> \n <mask> Version 0.9\n <mask> -----------\n <mask> \n </s> Added template tests and made config a true global </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp])\n </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> remove    The current session object (:class:`flask.session`)\n </s> add    The current session object (:class:`flask.session`).  This variable\n   is unavailable if the template was rendered without an active request\n   context. </s> remove    The current request object (:class:`flask.request`)\n </s> add    The current request object (:class:`flask.request`).  This variable is\n   unavailable if the template was rendered without an active request\n   context. </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top </s> remove    The request-bound object for global variables (:data:`flask.g`)\n </s> add    The request-bound object for global variables (:data:`flask.g`).  This\n   variable is unavailable if the template was rendered without an active\n   request context.", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "CHANGES"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>    .. versionadded:: 0.6\n <mask> \n <mask> .. data:: request\n <mask>    :noindex:\n <mask> \n <mask>    The current request object (:class:`flask.request`).  This variable is\n </s> Added template tests and made config a true global </s> remove    The current request object (:class:`flask.request`)\n </s> add    The current request object (:class:`flask.request`).  This variable is\n   unavailable if the template was rendered without an active request\n   context. </s> remove    The current session object (:class:`flask.session`)\n </s> add    The current session object (:class:`flask.session`).  This variable\n   is unavailable if the template was rendered without an active request\n   context. </s> remove    The request-bound object for global variables (:data:`flask.g`)\n </s> add    The request-bound object for global variables (:data:`flask.g`).  This\n   variable is unavailable if the template was rendered without an active\n   request context. </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp])\n </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> add     if reqctx is None:\n        return {}", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "docs/templating.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. data:: request\n <mask>    :noindex:\n <mask> \n <mask>    The current request object (:class:`flask.request`)\n <mask> \n <mask> .. data:: session\n <mask>    :noindex:\n <mask> \n <mask>    The current session object (:class:`flask.session`)\n </s> Added template tests and made config a true global </s> remove    The current session object (:class:`flask.session`)\n </s> add    The current session object (:class:`flask.session`).  This variable\n   is unavailable if the template was rendered without an active request\n   context. </s> add    .. versionchanged:: 0.10\n      This is now always available, even in imported templates.\n </s> remove    The request-bound object for global variables (:data:`flask.g`)\n </s> add    The request-bound object for global variables (:data:`flask.g`).  This\n   variable is unavailable if the template was rendered without an active\n   request context. </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> add     def test_request_less_rendering(self):\n        app = flask.Flask(__name__)\n        app.config['WORLD_NAME'] = 'Special World'\n        @app.context_processor\n        def context_processor():\n            return dict(foo=42)\n\n        with app.app_context():\n            rv = flask.render_template_string('Hello {{ config.WORLD_NAME }} '\n                                              '{{ foo }}')\n            self.assert_equal(rv, 'Hello Special World 42')\n </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "docs/templating.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. data:: session\n <mask>    :noindex:\n <mask> \n <mask>    The current session object (:class:`flask.session`)\n <mask> \n <mask> .. data:: g\n <mask>    :noindex:\n <mask> \n <mask>    The request-bound object for global variables (:data:`flask.g`)\n </s> Added template tests and made config a true global </s> remove    The request-bound object for global variables (:data:`flask.g`)\n </s> add    The request-bound object for global variables (:data:`flask.g`).  This\n   variable is unavailable if the template was rendered without an active\n   request context. </s> remove    The current request object (:class:`flask.request`)\n </s> add    The current request object (:class:`flask.request`).  This variable is\n   unavailable if the template was rendered without an active request\n   context. </s> add    .. versionchanged:: 0.10\n      This is now always available, even in imported templates.\n </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp])\n </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "docs/templating.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. data:: g\n <mask>    :noindex:\n <mask> \n <mask>    The request-bound object for global variables (:data:`flask.g`)\n <mask> \n <mask> .. function:: url_for\n <mask>    :noindex:\n <mask> \n <mask>    The :func:`flask.url_for` function.\n </s> Added template tests and made config a true global </s> remove    The current session object (:class:`flask.session`)\n </s> add    The current session object (:class:`flask.session`).  This variable\n   is unavailable if the template was rendered without an active request\n   context. </s> remove    The current request object (:class:`flask.request`)\n </s> add    The current request object (:class:`flask.request`).  This variable is\n   unavailable if the template was rendered without an active request\n   context. </s> add    .. versionchanged:: 0.10\n      This is now always available, even in imported templates.\n </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp])\n </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "docs/templating.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             options['autoescape'] = self.select_jinja_autoescape\n <mask>         rv = Environment(self, **options)\n <mask>         rv.globals.update(\n <mask>             url_for=url_for,\n <mask>             get_flashed_messages=get_flashed_messages\n <mask>         )\n <mask>         rv.filters['tojson'] = json.htmlsafe_dumps\n <mask>         return rv\n <mask> \n <mask>     def create_global_jinja_loader(self):\n </s> Added template tests and made config a true global </s> add     def test_request_less_rendering(self):\n        app = flask.Flask(__name__)\n        app.config['WORLD_NAME'] = 'Special World'\n        @app.context_processor\n        def context_processor():\n            return dict(foo=42)\n\n        with app.app_context():\n            rv = flask.render_template_string('Hello {{ config.WORLD_NAME }} '\n                                              '{{ foo }}')\n            self.assert_equal(rv, 'Hello Special World 42')\n </s> remove         config=reqctx.app.config,\n </s> add  </s> add     if reqctx is None:\n        return {} </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp])\n </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         :param context: the context as a dictionary that is updated in place\n <mask>                         to add extra variables.\n <mask>         \"\"\"\n <mask>         funcs = self.template_context_processors[None]\n <mask>         bp = _request_ctx_stack.top.request.blueprint\n <mask>         if bp is not None and bp in self.template_context_processors:\n <mask>             funcs = chain(funcs, self.template_context_processors[bp])\n <mask>         orig_ctx = context.copy()\n <mask>         for func in funcs:\n <mask>             context.update(func())\n <mask>         # make sure the original values win.  This makes it possible to\n <mask>         # easier add new variables in context processors without breaking\n </s> Added template tests and made config a true global </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top </s> add     if reqctx is None:\n        return {} </s> remove    The request-bound object for global variables (:data:`flask.g`)\n </s> add    The request-bound object for global variables (:data:`flask.g`).  This\n   variable is unavailable if the template was rendered without an active\n   request context. </s> remove    The current session object (:class:`flask.session`)\n </s> add    The current session object (:class:`flask.session`).  This variable\n   is unavailable if the template was rendered without an active request\n   context.", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import posixpath\n <mask> from jinja2 import BaseLoader, Environment as BaseEnvironment, \\\n <mask>      TemplateNotFound\n <mask> \n <mask> from .globals import _request_ctx_stack\n <mask> from .signals import template_rendered\n <mask> from .module import blueprint_is_module\n <mask> \n <mask> \n <mask> def _default_template_ctx_processor():\n </s> Added template tests and made config a true global </s> add     def test_request_less_rendering(self):\n        app = flask.Flask(__name__)\n        app.config['WORLD_NAME'] = 'Special World'\n        @app.context_processor\n        def context_processor():\n            return dict(foo=42)\n\n        with app.app_context():\n            rv = flask.render_template_string('Hello {{ config.WORLD_NAME }} '\n                                              '{{ foo }}')\n            self.assert_equal(rv, 'Hello Special World 42')\n </s> remove             get_flashed_messages=get_flashed_messages\n </s> add             get_flashed_messages=get_flashed_messages,\n            config=self.config </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp])\n </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/templating.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     `session` and `g`.\n <mask>     \"\"\"\n <mask>     reqctx = _request_ctx_stack.top\n <mask>     return dict(\n <mask>         request=reqctx.request,\n <mask>         session=reqctx.session,\n <mask>         g=reqctx.g\n <mask>     )\n <mask> \n </s> Added template tests and made config a true global </s> remove         config=reqctx.app.config,\n </s> add  </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp])\n </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> remove             get_flashed_messages=get_flashed_messages\n </s> add             get_flashed_messages=get_flashed_messages,\n            config=self.config </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top </s> add     def test_request_less_rendering(self):\n        app = flask.Flask(__name__)\n        app.config['WORLD_NAME'] = 'Special World'\n        @app.context_processor\n        def context_processor():\n            return dict(foo=42)\n\n        with app.app_context():\n            rv = flask.render_template_string('Hello {{ config.WORLD_NAME }} '\n                                              '{{ foo }}')\n            self.assert_equal(rv, 'Hello Special World 42')\n", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     `session` and `g`.\n <mask>     \"\"\"\n <mask>     reqctx = _request_ctx_stack.top\n <mask>     return dict(\n <mask>         config=reqctx.app.config,\n <mask>         request=reqctx.request,\n <mask>         session=reqctx.session,\n <mask>         g=reqctx.g\n <mask>     )\n <mask> \n </s> Added template tests and made config a true global </s> add     if reqctx is None:\n        return {} </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp])\n </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> remove             get_flashed_messages=get_flashed_messages\n </s> add             get_flashed_messages=get_flashed_messages,\n            config=self.config </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top </s> add     def test_request_less_rendering(self):\n        app = flask.Flask(__name__)\n        app.config['WORLD_NAME'] = 'Special World'\n        @app.context_processor\n        def context_processor():\n            return dict(foo=42)\n\n        with app.app_context():\n            rv = flask.render_template_string('Hello {{ config.WORLD_NAME }} '\n                                              '{{ foo }}')\n            self.assert_equal(rv, 'Hello Special World 42')\n", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                                   the first one existing will be rendered\n <mask>     :param context: the variables that should be available in the\n <mask>                     context of the template.\n <mask>     \"\"\"\n <mask>     ctx = _request_ctx_stack.top\n <mask>     ctx.app.update_template_context(context)\n <mask>     return _render(ctx.app.jinja_env.get_or_select_template(template_name_or_list),\n <mask>                    context, ctx.app)\n <mask> \n <mask> \n </s> Added template tests and made config a true global </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp])\n </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> remove    The request-bound object for global variables (:data:`flask.g`)\n </s> add    The request-bound object for global variables (:data:`flask.g`).  This\n   variable is unavailable if the template was rendered without an active\n   request context. </s> remove    The current session object (:class:`flask.session`)\n </s> add    The current session object (:class:`flask.session`).  This variable\n   is unavailable if the template was rendered without an active request\n   context. </s> remove         config=reqctx.app.config,\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep", "code_tokens": " <mask>                    rendered\n <mask>     :param context: the variables that should be available in the\n <mask>                     context of the template.\n <mask>     \"\"\"\n <mask>     ctx = _request_ctx_stack.top\n <mask>     ctx.app.update_template_context(context)\n <mask>     return _render(ctx.app.jinja_env.from_string(source),\n <mask>                    context, ctx.app)\n </s> Added template tests and made config a true global </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp])\n </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> remove    The request-bound object for global variables (:data:`flask.g`)\n </s> add    The request-bound object for global variables (:data:`flask.g`).  This\n   variable is unavailable if the template was rendered without an active\n   request context. </s> remove         config=reqctx.app.config,\n </s> add  </s> add     if reqctx is None:\n        return {}", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/templating.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>         self.assert_equal(rv.data, '42')\n <mask> \n <mask>     def test_standard_context(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.secret_key = 'development key'\n <mask>         @app.route('/')\n <mask>         def index():\n <mask>             flask.g.foo = 23\n </s> Added template tests and made config a true global </s> remove             get_flashed_messages=get_flashed_messages\n </s> add             get_flashed_messages=get_flashed_messages,\n            config=self.config </s> remove from .globals import _request_ctx_stack\n </s> add from .globals import _request_ctx_stack, _app_ctx_stack </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp])\n </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top </s> remove     ctx = _request_ctx_stack.top\n </s> add     ctx = _app_ctx_stack.top </s> remove         config=reqctx.app.config,\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> -   Python 3.12 compatibility.\n <mask> -   Require Werkzeug >= 2.3.6.\n <mask> -   Refactor how an app's root and instance paths are determined. :issue:`5160`\n <mask> \n <mask> \n <mask> Version 2.3.2\n </s> switch to flit build backend </s> remove [tool.setuptools.dynamic]\nversion = {attr = \"flask.__version__\"}\n </s> add [tool.flit.module]\nname = \"flask\"\n\n[tool.flit.sdist]\ninclude = [\n    \"docs/\",\n    \"examples/\",\n    \"requirements/\",\n    \"tests/\",\n    \"CHANGES.rst\",\n    \"CONTRIBUTING.rst\",\n    \"tox.ini\",\n]\nexclude = [\n    \"docs/_build/\",\n] </s> remove requires = [\"setuptools\"]\nbuild-backend = \"setuptools.build_meta\"\n </s> add requires = [\"flit_core<4\"]\nbuild-backend = \"flit_core.buildapi\" </s> remove license = {text = \"BSD-3-Clause\"}\n </s> add license = {file = \"LICENSE.rst\"}", "html_url": "https://github.com/pallets/flask/commit/f38f3a745ab2f90084f495403ed28d4fc27e4b50", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> [project]\n <mask> name = \"Flask\"\n <mask> description = \"A simple framework for building complex web applications.\"\n <mask> readme = \"README.rst\"\n <mask> license = {text = \"BSD-3-Clause\"}\n <mask> maintainers = [{name = \"Pallets\", email = \"contact@palletsprojects.com\"}]\n <mask> classifiers = [\n <mask>     \"Development Status :: 5 - Production/Stable\",\n <mask>     \"Environment :: Web Environment\",\n <mask>     \"Framework :: Flask\",\n </s> switch to flit build backend </s> remove requires = [\"setuptools\"]\nbuild-backend = \"setuptools.build_meta\"\n </s> add requires = [\"flit_core<4\"]\nbuild-backend = \"flit_core.buildapi\" </s> remove [tool.setuptools.dynamic]\nversion = {attr = \"flask.__version__\"}\n </s> add [tool.flit.module]\nname = \"flask\"\n\n[tool.flit.sdist]\ninclude = [\n    \"docs/\",\n    \"examples/\",\n    \"requirements/\",\n    \"tests/\",\n    \"CHANGES.rst\",\n    \"CONTRIBUTING.rst\",\n    \"tox.ini\",\n]\nexclude = [\n    \"docs/_build/\",\n] </s> add -   Use ``flit_core`` instead of ``setuptools`` as build backend.", "html_url": "https://github.com/pallets/flask/commit/f38f3a745ab2f90084f495403ed28d4fc27e4b50", "file_name": "pyproject.toml"}
{"docstring_tokens": "keep keep keep keep replace replace keep replace replace keep keep keep keep", "code_tokens": " <mask> [project.scripts]\n <mask> flask = \"flask.cli:main\"\n <mask> \n <mask> [build-system]\n <mask> requires = [\"setuptools\"]\n <mask> build-backend = \"setuptools.build_meta\"\n <mask> \n <mask> [tool.setuptools.dynamic]\n <mask> version = {attr = \"flask.__version__\"}\n <mask> \n <mask> [tool.pytest.ini_options]\n <mask> testpaths = [\"tests\"]\n <mask> filterwarnings = [\n </s> switch to flit build backend </s> remove license = {text = \"BSD-3-Clause\"}\n </s> add license = {file = \"LICENSE.rst\"} </s> add -   Use ``flit_core`` instead of ``setuptools`` as build backend.", "html_url": "https://github.com/pallets/flask/commit/f38f3a745ab2f90084f495403ed28d4fc27e4b50", "file_name": "pyproject.toml"}
{"docstring_tokens": "keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> User's Guide\n <mask> ------------\n <mask> \n <mask> This part of the documentation is written text and should give you an idea\n <mask> how to work with Flask.  It's a series of step-by-step instructions for\n <mask> web development.\n <mask> \n <mask> .. toctree::\n <mask>    :maxdepth: 2\n <mask> \n <mask>    foreword\n </s> Copy edited and partially rewrote the foreword. </s> remove What does Micro Mean?\n---------------------\n </s> add What does \"micro\" mean?\n----------------------- </s> remove questions about the intention of the project, what it aims at and when you\n </s> add questions about the purpose and goals of the project, and when you </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements.\n </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like. </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need\n </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove For example Flask uses thread local objects internally so that you don't\n </s> add For example, Flask uses thread-local objects internally so that you don't </s> remove A Framework and An Example\n </s> add A Framework and an Example", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/contents.rst.inc"}
{"docstring_tokens": "keep keep keep replace keep keep replace replace keep keep keep", "code_tokens": " <mask> ========\n <mask> \n <mask> Read this before you get started with Flask.  This hopefully answers some\n <mask> questions about the intention of the project, what it aims at and when you\n <mask> should or should not be using it.\n <mask> \n <mask> What does Micro Mean?\n <mask> ---------------------\n <mask> \n <mask> The micro in microframework for me means on the one hand being small in\n <mask> size and complexity but on the other hand also that the complexity of the\n </s> Copy edited and partially rewrote the foreword. </s> remove The micro in microframework for me means on the one hand being small in\nsize and complexity but on the other hand also that the complexity of the\napplications that are written with these frameworks do not exceed a\ncertain size.  A microframework like Flask sacrifices a few things in\norder to be approachable and to be as concise as possible.\n </s> add To me, the \"micro\" in microframework refers not only to the simplicity and\nsmall size of the framework, but also to the typically limited complexity\nand size of applications that are written with the framework.  To be\napproachable and concise, a microframework sacrifices a few features that\nmay be necessary in larger or more complex applications. </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need\n </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove This part of the documentation is written text and should give you an idea\nhow to work with Flask.  It's a series of step-by-step instructions for\nweb development.\n </s> add This part of the documentation, which is mostly prose, begins with some\nbackground information about Flask, then focuses on step-by-step\ninstructions for web development with Flask. </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements.\n </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like. </s> remove For example Flask uses thread local objects internally so that you don't\n </s> add For example, Flask uses thread-local objects internally so that you don't", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep replace replace replace replace replace keep replace keep keep", "code_tokens": " <mask> \n <mask> The micro in microframework for me means on the one hand being small in\n <mask> size and complexity but on the other hand also that the complexity of the\n <mask> applications that are written with these frameworks do not exceed a\n <mask> certain size.  A microframework like Flask sacrifices a few things in\n <mask> order to be approachable and to be as concise as possible.\n <mask> \n <mask> For example Flask uses thread local objects internally so that you don't\n <mask> have to pass objects around from function to function within a request in\n <mask> order to stay threadsafe.  While this is a really easy approach and saves\n </s> Copy edited and partially rewrote the foreword. </s> remove What does Micro Mean?\n---------------------\n </s> add What does \"micro\" mean?\n----------------------- </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need\n </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements.\n </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like. </s> remove A Framework and An Example\n </s> add A Framework and an Example </s> remove Is Flask for you?  If your application small-ish and does not depend on\ntoo complex database structures, Flask is the Framework for you.  It was\ndesigned from the ground up to be easy to use, based on established\nprinciples, good intentions and on top of two established libraries in\nwidespread usage.  Recent versions of Flask scale nicely within reasonable\nbounds and if you grow larger, you won't have any troubles adjusting Flask\n </s> add Is Flask for you?  If your application is small-ish and does not depend on\nvery complex database structures, Flask is the Framework for you.  It was\ndesigned from the ground up to be easy to use, and built on the firm\nfoundation of established principles, good intentions, and mature, widely\nused libraries.  Recent versions of Flask scale nicely within reasonable\nbounds, and if you grow larger, you won't have any trouble adjusting Flask", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> For example Flask uses thread local objects internally so that you don't\n <mask> have to pass objects around from function to function within a request in\n <mask> order to stay threadsafe.  While this is a really easy approach and saves\n <mask> you a lot of time, it also does not scale well to large applications.\n <mask> It's especially painful for more complex unittests and when you suddenly\n <mask> have to deal with code being executed outside of the context of a request\n <mask> (for example if you have cronjobs).\n <mask> \n <mask> Flask provides some tools to deal with the downsides of this approach but\n <mask> the core problem of this approach obviously stays.  It is also based on\n <mask> convention over configuration which means that a lot of things are\n <mask> preconfigured in Flask and will work well for smaller applications but not\n <mask> so much for larger ones (where and how it looks for templates, static\n <mask> files etc.)\n <mask> \n <mask> But don't worry if your application suddenly grows larger than it was\n <mask> initially and you're afraid Flask might not grow with it.  Even with\n <mask> larger frameworks you sooner or later will find out that you need\n <mask> something the framework just cannot do for you without modification.\n <mask> If you are ever in that situation, check out the :ref:`becomingbig`\n <mask> chapter.\n <mask> \n <mask> A Framework and An Example\n <mask> --------------------------\n <mask> \n <mask> Flask is not only a microframework, it is also an example.  Based on\n <mask> Flask, there will be a series of blog posts that explain how to create a\n </s> Copy edited and partially rewrote the foreword. </s> remove For example Flask uses thread local objects internally so that you don't\n </s> add For example, Flask uses thread-local objects internally so that you don't </s> remove The micro in microframework for me means on the one hand being small in\nsize and complexity but on the other hand also that the complexity of the\napplications that are written with these frameworks do not exceed a\ncertain size.  A microframework like Flask sacrifices a few things in\norder to be approachable and to be as concise as possible.\n </s> add To me, the \"micro\" in microframework refers not only to the simplicity and\nsmall size of the framework, but also to the typically limited complexity\nand size of applications that are written with the framework.  To be\napproachable and concise, a microframework sacrifices a few features that\nmay be necessary in larger or more complex applications. </s> remove Is Flask for you?  If your application small-ish and does not depend on\ntoo complex database structures, Flask is the Framework for you.  It was\ndesigned from the ground up to be easy to use, based on established\nprinciples, good intentions and on top of two established libraries in\nwidespread usage.  Recent versions of Flask scale nicely within reasonable\nbounds and if you grow larger, you won't have any troubles adjusting Flask\n </s> add Is Flask for you?  If your application is small-ish and does not depend on\nvery complex database structures, Flask is the Framework for you.  It was\ndesigned from the ground up to be easy to use, and built on the firm\nfoundation of established principles, good intentions, and mature, widely\nused libraries.  Recent versions of Flask scale nicely within reasonable\nbounds, and if you grow larger, you won't have any trouble adjusting Flask </s> remove Flask is not only a microframework, it is also an example.  Based on\n </s> add Flask is not only a microframework; it is also an example.  Based on </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements.\n </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like.", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep keep keep keep keep replace replace keep keep keep", "code_tokens": " <mask> A Framework and An Example\n <mask> --------------------------\n <mask> \n <mask> Flask is not only a microframework, it is also an example.  Based on\n <mask> Flask, there will be a series of blog posts that explain how to create a\n <mask> framework.  Flask itself is just one way to implement a framework on top\n <mask> of existing libraries.  Unlike many other microframeworks Flask does not\n <mask> try to implement anything on its own, it reuses existing code.\n <mask> \n <mask> Flask is not only a microframework, it is also an example.  Based on\n <mask> Flask, there will be a series of blog posts that explain how to create a\n <mask> framework.  Flask itself is just one way to implement a framework on top\n <mask> of existing libraries.  Unlike many other microframeworks Flask does not\n <mask> try to implement anything on its own, it reuses existing code.\n <mask> \n <mask> Web Development is Dangerous\n <mask> ----------------------------\n </s> Copy edited and partially rewrote the foreword. </s> remove A Framework and An Example\n </s> add A Framework and an Example </s> remove The micro in microframework for me means on the one hand being small in\nsize and complexity but on the other hand also that the complexity of the\napplications that are written with these frameworks do not exceed a\ncertain size.  A microframework like Flask sacrifices a few things in\norder to be approachable and to be as concise as possible.\n </s> add To me, the \"micro\" in microframework refers not only to the simplicity and\nsmall size of the framework, but also to the typically limited complexity\nand size of applications that are written with the framework.  To be\napproachable and concise, a microframework sacrifices a few features that\nmay be necessary in larger or more complex applications. </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements.\n </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like. </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need\n </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove I'm not even joking.  Well, maybe a little.  If you write a web\napplication you are probably allowing users to register and leave their\n </s> add I'm not joking.  Well, maybe a little.  If you write a web\napplication, you are probably allowing users to register and leave their", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep replace", "code_tokens": " <mask> \n <mask> Web Development is Dangerous\n <mask> ----------------------------\n <mask> \n <mask> I'm not even joking.  Well, maybe a little.  If you write a web\n <mask> application you are probably allowing users to register and leave their\n <mask> data on your server.  The users are entrusting you with data.  And even if\n <mask> you are the only user that might leave data in your application, you still\n <mask> want that data to be stored in a secure manner.\n </s> Copy edited and partially rewrote the foreword. </s> remove Unfortunately there are many ways security of a web application can be\n </s> add Unfortunately, there are many ways the security of a web application can be </s> remove of existing libraries.  Unlike many other microframeworks Flask does not\ntry to implement anything on its own, it reuses existing code.\n </s> add of existing libraries.  Unlike many other microframeworks, Flask does not\ntry to implement everything on its own; it reuses existing code. </s> remove problems of modern web applications: cross site scripting (XSS).  Unless\nyou deliberately mark insecure HTML as secure Flask (and the underlying\nJinja2 template engine) have you covered.  But there are many more ways to\n </s> add problems of modern web applications: cross-site scripting (XSS).  Unless\nyou deliberately mark insecure HTML as secure, Flask and the underlying\nJinja2 template engine have you covered.  But there are many more ways to </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements.\n </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like. </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need\n </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep keep replace keep replace replace replace keep", "code_tokens": " <mask> you are the only user that might leave data in your application, you still\n <mask> want that data to be stored in a secure manner.\n <mask> \n <mask> Unfortunately there are many ways security of a web application can be\n <mask> compromised.  Flask protects you against one of the most common security\n <mask> problems of modern web applications: cross site scripting (XSS).  Unless\n <mask> you deliberately mark insecure HTML as secure Flask (and the underlying\n <mask> Jinja2 template engine) have you covered.  But there are many more ways to\n <mask> cause security problems.\n </s> Copy edited and partially rewrote the foreword. </s> remove want that data to be stored in a secure manner.\n </s> add want that data to be stored securely. </s> remove I'm not even joking.  Well, maybe a little.  If you write a web\napplication you are probably allowing users to register and leave their\n </s> add I'm not joking.  Well, maybe a little.  If you write a web\napplication, you are probably allowing users to register and leave their </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements.\n </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like. </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need\n </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove The micro in microframework for me means on the one hand being small in\nsize and complexity but on the other hand also that the complexity of the\napplications that are written with these frameworks do not exceed a\ncertain size.  A microframework like Flask sacrifices a few things in\norder to be approachable and to be as concise as possible.\n </s> add To me, the \"micro\" in microframework refers not only to the simplicity and\nsmall size of the framework, but also to the typically limited complexity\nand size of applications that are written with the framework.  To be\napproachable and concise, a microframework sacrifices a few features that\nmay be necessary in larger or more complex applications.", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace replace replace replace keep replace keep keep", "code_tokens": " <mask> cause security problems.\n <mask> \n <mask> Whenever something is dangerous where you have to watch out, the\n <mask> documentation will tell you so.  Some of the security concerns of web\n <mask> development are far more complex than one might think and often we all end\n <mask> up in situations where we think \"well, this is just far fetched, how could\n <mask> that possibly be exploited\" and then an intelligent guy comes along and\n <mask> figures a way out to exploit that application.  And don't think, your\n <mask> application is not important enough for hackers to take notice.  Depending\n <mask> on the kind of attack, chances are there are automated botnets out there\n <mask> trying to figure out how to fill your database with viagra advertisements.\n <mask> \n <mask> So always keep that in mind when doing web development.\n <mask> \n <mask> Target Audience\n </s> Copy edited and partially rewrote the foreword. </s> remove problems of modern web applications: cross site scripting (XSS).  Unless\nyou deliberately mark insecure HTML as secure Flask (and the underlying\nJinja2 template engine) have you covered.  But there are many more ways to\n </s> add problems of modern web applications: cross-site scripting (XSS).  Unless\nyou deliberately mark insecure HTML as secure, Flask and the underlying\nJinja2 template engine have you covered.  But there are many more ways to </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need\n </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove A Framework and An Example\n </s> add A Framework and an Example </s> remove Unfortunately there are many ways security of a web application can be\n </s> add Unfortunately, there are many ways the security of a web application can be </s> remove Is Flask for you?  If your application small-ish and does not depend on\ntoo complex database structures, Flask is the Framework for you.  It was\ndesigned from the ground up to be easy to use, based on established\nprinciples, good intentions and on top of two established libraries in\nwidespread usage.  Recent versions of Flask scale nicely within reasonable\nbounds and if you grow larger, you won't have any troubles adjusting Flask\n </s> add Is Flask for you?  If your application is small-ish and does not depend on\nvery complex database structures, Flask is the Framework for you.  It was\ndesigned from the ground up to be easy to use, and built on the firm\nfoundation of established principles, good intentions, and mature, widely\nused libraries.  Recent versions of Flask scale nicely within reasonable\nbounds, and if you grow larger, you won't have any trouble adjusting Flask", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Target Audience\n <mask> ---------------\n <mask> \n <mask> Is Flask for you?  If your application small-ish and does not depend on\n <mask> too complex database structures, Flask is the Framework for you.  It was\n <mask> designed from the ground up to be easy to use, based on established\n <mask> principles, good intentions and on top of two established libraries in\n <mask> widespread usage.  Recent versions of Flask scale nicely within reasonable\n <mask> bounds and if you grow larger, you won't have any troubles adjusting Flask\n <mask> for your new application size.\n <mask> \n <mask> If you suddenly discover that your application grows larger than\n <mask> originally intended, head over to the :ref:`becomingbig` section to see\n <mask> some possible solutions for larger applications.\n </s> Copy edited and partially rewrote the foreword. </s> remove Satisfied?  Then head over to the :ref:`installation`.\n </s> add Satisfied?  Then let's proceed with :ref:`installation`. </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need\n </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove So always keep that in mind when doing web development.\n </s> add So always keep security in mind when doing web development. </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements.\n </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like. </s> remove The micro in microframework for me means on the one hand being small in\nsize and complexity but on the other hand also that the complexity of the\napplications that are written with these frameworks do not exceed a\ncertain size.  A microframework like Flask sacrifices a few things in\norder to be approachable and to be as concise as possible.\n </s> add To me, the \"micro\" in microframework refers not only to the simplicity and\nsmall size of the framework, but also to the typically limited complexity\nand size of applications that are written with the framework.  To be\napproachable and concise, a microframework sacrifices a few features that\nmay be necessary in larger or more complex applications. </s> remove For example Flask uses thread local objects internally so that you don't\n </s> add For example, Flask uses thread-local objects internally so that you don't", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask> If you suddenly discover that your application grows larger than\n <mask> originally intended, head over to the :ref:`becomingbig` section to see\n <mask> some possible solutions for larger applications.\n <mask> \n <mask> Satisfied?  Then head over to the :ref:`installation`.\n </s> Copy edited and partially rewrote the foreword. </s> remove Is Flask for you?  If your application small-ish and does not depend on\ntoo complex database structures, Flask is the Framework for you.  It was\ndesigned from the ground up to be easy to use, based on established\nprinciples, good intentions and on top of two established libraries in\nwidespread usage.  Recent versions of Flask scale nicely within reasonable\nbounds and if you grow larger, you won't have any troubles adjusting Flask\n </s> add Is Flask for you?  If your application is small-ish and does not depend on\nvery complex database structures, Flask is the Framework for you.  It was\ndesigned from the ground up to be easy to use, and built on the firm\nfoundation of established principles, good intentions, and mature, widely\nused libraries.  Recent versions of Flask scale nicely within reasonable\nbounds, and if you grow larger, you won't have any trouble adjusting Flask </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need\n </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove The micro in microframework for me means on the one hand being small in\nsize and complexity but on the other hand also that the complexity of the\napplications that are written with these frameworks do not exceed a\ncertain size.  A microframework like Flask sacrifices a few things in\norder to be approachable and to be as concise as possible.\n </s> add To me, the \"micro\" in microframework refers not only to the simplicity and\nsmall size of the framework, but also to the typically limited complexity\nand size of applications that are written with the framework.  To be\napproachable and concise, a microframework sacrifices a few features that\nmay be necessary in larger or more complex applications. </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements.\n </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like. </s> remove For example Flask uses thread local objects internally so that you don't\n </s> add For example, Flask uses thread-local objects internally so that you don't </s> remove A Framework and An Example\n </s> add A Framework and an Example", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>           - {name: '3.6', python: '3.6', os: ubuntu-latest, tox: py36}\n <mask>           - {name: 'PyPy', python: pypy3, os: ubuntu-latest, tox: pypy3}\n <mask>     steps:\n <mask>       - uses: actions/checkout@v2\n <mask>       - uses: actions/setup-python@v2\n <mask>         with:\n </s> Initial typing support\n\nThis enables type checking in CI and marks the project as typed. </s> add [testenv:typing]\ndeps = -r requirements/typing.txt\ncommands = mypy\n </s> add     typing </s> add include src/flask/py.typed", "html_url": "https://github.com/pallets/flask/commit/f405c6f19e002ae13708cb33f6d48257cc1ea37a", "file_name": ".github/workflows/tests.yaml"}
{"docstring_tokens": "keep keep keep add keep", "code_tokens": " <mask> graft docs\n <mask> prune docs/_build\n <mask> graft examples\n <mask> graft tests\n <mask> global-exclude *.pyc\n </s> Initial typing support\n\nThis enables type checking in CI and marks the project as typed. </s> add [testenv:typing]\ndeps = -r requirements/typing.txt\ncommands = mypy\n </s> add     typing </s> add           - {name: Typing, python: '3.9', os: ubuntu-latest, tox: typing}", "html_url": "https://github.com/pallets/flask/commit/f405c6f19e002ae13708cb33f6d48257cc1ea37a", "file_name": "MANIFEST.in"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> envlist =\n <mask>     py{39,38,37,36,py3}\n <mask>     style\n <mask>     docs\n <mask> skip_missing_interpreters = true\n <mask> \n <mask> [testenv]\n <mask> deps =\n </s> Initial typing support\n\nThis enables type checking in CI and marks the project as typed. </s> add [testenv:typing]\ndeps = -r requirements/typing.txt\ncommands = mypy\n </s> add include src/flask/py.typed </s> add           - {name: Typing, python: '3.9', os: ubuntu-latest, tox: typing}", "html_url": "https://github.com/pallets/flask/commit/f405c6f19e002ae13708cb33f6d48257cc1ea37a", "file_name": "tox.ini"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> skip_install = true\n <mask> commands = pre-commit run --all-files --show-diff-on-failure\n <mask> \n <mask> [testenv:docs]\n <mask> deps =\n <mask>     -r requirements/docs.txt\n <mask> \n <mask>     https://github.com/pallets/werkzeug/archive/master.tar.gz\n </s> Initial typing support\n\nThis enables type checking in CI and marks the project as typed. </s> add     typing </s> add include src/flask/py.typed </s> add           - {name: Typing, python: '3.9', os: ubuntu-latest, tox: typing}", "html_url": "https://github.com/pallets/flask/commit/f405c6f19e002ae13708cb33f6d48257cc1ea37a", "file_name": "tox.ini"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> - The :func:`flask.url_for` function now can generate anchors to the\n <mask>   generated links.\n <mask> - Logger now only returns the debug log setting if it was not set\n <mask>   explicitly.\n <mask> \n <mask> Version 0.8.1\n <mask> -------------\n </s> Added support for _method to url_for() </s> remove        The `_anchor` parameter was added.\n </s> add        The `_anchor` and `_method` parameters were added. </s> add     :param _method: if provided this explicitly specifies an HTTP method. </s> remove     rv = ctx.url_adapter.build(endpoint, values, force_external=external)\n </s> add     rv = ctx.url_adapter.build(endpoint, values, method=method,\n                               force_external=external) </s> add     method = values.pop('_method', None)", "html_url": "https://github.com/pallets/flask/commit/f52e7a9dc944f425c2f2a77706bc2af98b23295c", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     For more information, head over to the :ref:`Quickstart <url-building>`.\n <mask> \n <mask>     .. versionadded:: 0.9\n <mask>        The `_anchor` parameter was added.\n <mask> \n <mask>     :param endpoint: the endpoint of the URL (name of the function)\n <mask>     :param values: the variable arguments of the URL rule\n <mask>     :param _external: if set to `True`, an absolute URL is generated.\n <mask>     :param _anchor: if provided this is added as anchor to the URL.\n </s> Added support for _method to url_for() </s> add     :param _method: if provided this explicitly specifies an HTTP method. </s> add - The :func:`flask.url_for` function now can also explicitly generate\n  URL rules specific to a given HTTP method. </s> remove     rv = ctx.url_adapter.build(endpoint, values, force_external=external)\n </s> add     rv = ctx.url_adapter.build(endpoint, values, method=method,\n                               force_external=external) </s> add     method = values.pop('_method', None)", "html_url": "https://github.com/pallets/flask/commit/f52e7a9dc944f425c2f2a77706bc2af98b23295c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     :param _external: if set to `True`, an absolute URL is generated.\n <mask>     :param _anchor: if provided this is added as anchor to the URL.\n <mask>     \"\"\"\n <mask>     ctx = _request_ctx_stack.top\n <mask>     blueprint_name = request.blueprint\n <mask>     if not ctx.request._is_old_module:\n <mask>         if endpoint[:1] == '.':\n </s> Added support for _method to url_for() </s> remove        The `_anchor` parameter was added.\n </s> add        The `_anchor` and `_method` parameters were added. </s> remove     rv = ctx.url_adapter.build(endpoint, values, force_external=external)\n </s> add     rv = ctx.url_adapter.build(endpoint, values, method=method,\n                               force_external=external) </s> add     method = values.pop('_method', None) </s> add - The :func:`flask.url_for` function now can also explicitly generate\n  URL rules specific to a given HTTP method.", "html_url": "https://github.com/pallets/flask/commit/f52e7a9dc944f425c2f2a77706bc2af98b23295c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         elif endpoint.startswith('.'):\n <mask>             endpoint = endpoint[1:]\n <mask>     external = values.pop('_external', False)\n <mask>     anchor = values.pop('_anchor', None)\n <mask>     ctx.app.inject_url_defaults(endpoint, values)\n <mask>     rv = ctx.url_adapter.build(endpoint, values, method=method,\n <mask>                                force_external=external)\n <mask>     if anchor is not None:\n <mask>         rv += '#' + url_quote(anchor)\n <mask>     return rv\n </s> Added support for _method to url_for() </s> remove     rv = ctx.url_adapter.build(endpoint, values, force_external=external)\n </s> add     rv = ctx.url_adapter.build(endpoint, values, method=method,\n                               force_external=external) </s> add     :param _method: if provided this explicitly specifies an HTTP method. </s> remove        The `_anchor` parameter was added.\n </s> add        The `_anchor` and `_method` parameters were added. </s> add - The :func:`flask.url_for` function now can also explicitly generate\n  URL rules specific to a given HTTP method.", "html_url": "https://github.com/pallets/flask/commit/f52e7a9dc944f425c2f2a77706bc2af98b23295c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             endpoint = endpoint[1:]\n <mask>     external = values.pop('_external', False)\n <mask>     anchor = values.pop('_anchor', None)\n <mask>     ctx.app.inject_url_defaults(endpoint, values)\n <mask>     rv = ctx.url_adapter.build(endpoint, values, force_external=external)\n <mask>     if anchor is not None:\n <mask>         rv += '#' + url_quote(anchor)\n <mask>     return rv\n <mask> \n <mask> \n </s> Added support for _method to url_for() </s> add     method = values.pop('_method', None) </s> add     :param _method: if provided this explicitly specifies an HTTP method. </s> remove        The `_anchor` parameter was added.\n </s> add        The `_anchor` and `_method` parameters were added. </s> add - The :func:`flask.url_for` function now can also explicitly generate\n  URL rules specific to a given HTTP method.", "html_url": "https://github.com/pallets/flask/commit/f52e7a9dc944f425c2f2a77706bc2af98b23295c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep replace replace keep keep replace replace", "code_tokens": " <mask>    **Something that is untested is broken.**\n <mask> \n <mask> Not sure where that is coming from, and it's not entirely correct, but\n <mask> also not that far from the truth.  Untested applications make it hard to\n <mask> improve existing code and developers of untested applications tend to\n <mask> become pretty paranoid.  If an application has automated tests, you can\n <mask> safely change things, and you will instantly know if your change broke\n <mask> something.\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove Flask gives you a couple of ways to test applications.  It mainly does\nthat by exposing the Werkzeug test :class:`~werkzeug.test.Client` class to your\ncode and handling the context locals for you.  You can then use that with\nyour favourite testing solution.  In this documentation we will use the\n:mod:`unittest` package that comes preinstalled with each Python\ninstallation.\n </s> add Flask provides a way to test your application by exposing the Werkzeug \ntest :class:`~werkzeug.test.Client` and handling the context locals for you.\nYou can then use that with your favourite testing solution.  In this documentation\nwe will use the :mod:`unittest` package that comes pre-installed with Python. </s> remove Even though it did not run any tests, we already know that our flaskr\n </s> add Even though it did not run any actual tests, we already know that our flaskr </s> remove All the other objects that are context bound can be used the same.\n </s> add All the other objects that are context bound can be used in the same\nway. </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us.\n </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove Besides using the test client we used above, there is also the\n:meth:`~flask.Flask.test_request_context` method that in combination with\nthe `with` statement can be used to activate a request context\ntemporarily.  With that you can access the :class:`~flask.request`,\n </s> add Besides using the test client as shown above, there is also the\n:meth:`~flask.Flask.test_request_context` method that can be used\nin combination with the `with` statement to activate a request context\ntemporarily.  With this you can access the :class:`~flask.request`,", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> become pretty paranoid.  If an application has automated tests, you can\n <mask> safely change things, and you will instantly know if your change broke\n <mask> something.\n <mask> \n <mask> Flask gives you a couple of ways to test applications.  It mainly does\n <mask> that by exposing the Werkzeug test :class:`~werkzeug.test.Client` class to your\n <mask> code and handling the context locals for you.  You can then use that with\n <mask> your favourite testing solution.  In this documentation we will use the\n <mask> :mod:`unittest` package that comes preinstalled with each Python\n <mask> installation.\n <mask> \n <mask> The Application\n <mask> ---------------\n <mask> \n <mask> First we need an application to test for functionality.  For the testing\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove safely change things, and you will instantly know if your change broke\nsomething.\n </s> add safely make changes and instantly know if anything breaks. </s> remove Not sure where that is coming from, and it's not entirely correct, but\nalso not that far from the truth.  Untested applications make it hard to\n </s> add The origin of this quote is unknown and while it is not entirely correct, it is also\nnot far from the truth.  Untested applications make it hard to </s> remove First we need an application to test for functionality.  For the testing\nwe will use the application from the :ref:`tutorial`.  If you don't have\nthat application yet, get the sources from `the examples`_.\n </s> add First, we need an application to test; we will use the application from \nthe :ref:`tutorial`.  If you don't have that application yet, get the \nsources from `the examples`_. </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output.\n </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output. </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us.\n </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove Of course you can submit forms with the test client as well, which we will\nuse now to log our user in.\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> The Application\n <mask> ---------------\n <mask> \n <mask> First we need an application to test for functionality.  For the testing\n <mask> we will use the application from the :ref:`tutorial`.  If you don't have\n <mask> that application yet, get the sources from `the examples`_.\n <mask> \n <mask> .. _the examples:\n <mask>    http://github.com/mitsuhiko/flask/tree/master/examples/flaskr/\n <mask> \n <mask> The Testing Skeleton\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove Flask gives you a couple of ways to test applications.  It mainly does\nthat by exposing the Werkzeug test :class:`~werkzeug.test.Client` class to your\ncode and handling the context locals for you.  You can then use that with\nyour favourite testing solution.  In this documentation we will use the\n:mod:`unittest` package that comes preinstalled with each Python\ninstallation.\n </s> add Flask provides a way to test your application by exposing the Werkzeug \ntest :class:`~werkzeug.test.Client` and handling the context locals for you.\nYou can then use that with your favourite testing solution.  In this documentation\nwe will use the :mod:`unittest` package that comes pre-installed with Python. </s> remove `MiniTwit Example`_ from the sources.  That one contains a larger test\n </s> add `MiniTwit Example`_ from the sources which contains a larger test </s> remove safely change things, and you will instantly know if your change broke\nsomething.\n </s> add safely make changes and instantly know if anything breaks. </s> remove Now we can add the first test.  Let's check that the application shows\n\"No entries here so far\" if we access the root of the application (``/``).\nFor that we modify our created test case class so that it looks like\nthis::\n </s> add Now it's time to start testing the functionality of the application.  \nLet's check that the application shows \"No entries here so far\" if we \naccess the root of the application (``/``). To do this, we add a new\ntest method to our class, like this:: </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output.\n </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output. </s> remove Of course you can submit forms with the test client as well, which we will\nuse now to log our user in.\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> The Testing Skeleton\n <mask> --------------------\n <mask> \n <mask> In order to test that, we add a second module (\n <mask> `flaskr_tests.py`) and create a unittest skeleton there::\n <mask> \n <mask>     import os\n <mask>     import flaskr\n <mask>     import unittest\n <mask>     import tempfile\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove Even though it did not run any tests, we already know that our flaskr\n </s> add Even though it did not run any actual tests, we already know that our flaskr </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us.\n </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove Besides using the test client we used above, there is also the\n:meth:`~flask.Flask.test_request_context` method that in combination with\nthe `with` statement can be used to activate a request context\ntemporarily.  With that you can access the :class:`~flask.request`,\n </s> add Besides using the test client as shown above, there is also the\n:meth:`~flask.Flask.test_request_context` method that can be used\nin combination with the `with` statement to activate a request context\ntemporarily.  With this you can access the :class:`~flask.request`, </s> remove First we need an application to test for functionality.  For the testing\nwe will use the application from the :ref:`tutorial`.  If you don't have\nthat application yet, get the sources from `the examples`_.\n </s> add First, we need an application to test; we will use the application from \nthe :ref:`tutorial`.  If you don't have that application yet, get the \nsources from `the examples`_. </s> remove Now we can add the first test.  Let's check that the application shows\n\"No entries here so far\" if we access the root of the application (``/``).\nFor that we modify our created test case class so that it looks like\nthis::\n </s> add Now it's time to start testing the functionality of the application.  \nLet's check that the application shows \"No entries here so far\" if we \naccess the root of the application (``/``). To do this, we add a new\ntest method to our class, like this:: </s> remove Now we can also test that adding messages works.  Add a new test method\n </s> add We should also test that adding messages works.  Add a new test method", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     if __name__ == '__main__':\n <mask>         unittest.main()\n <mask> \n <mask> The code in the :meth:`~unittest.TestCase.setUp` method creates a new test\n <mask> client and initializes a new database.  That function is called before\n <mask> each individual test function.  To delete the database after the test, we\n <mask> close the file and remove it from the filesystem in the\n <mask> :meth:`~unittest.TestCase.tearDown` method.  What the test client does is\n <mask> give us a simple interface to the application.  We can trigger test\n <mask> requests to the application, and the client will also keep track of cookies\n <mask> for us.\n <mask> \n <mask> Because SQLite3 is filesystem-based we can easily use the tempfile module\n <mask> to create a temporary database and initialize it.  The\n <mask> :func:`~tempfile.mkstemp` function does two things for us: it returns a\n <mask> low-level file handle and a random file name, the latter we use as\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove If we now run that test suite, we should see the following output::\n </s> add If we now run the test suite, we should see the following output:: </s> remove the administrative user, so we need a way to log our test client in to the\napplication and out of it again.  For that we fire some requests to the\nlogin and logout pages with the required form data (username and\npassword).  Because the login and logout pages redirect, we tell the\nclient to `follow_redirects`.\n </s> add the administrative user, so we need a way to log our test client in and out\nof the application.  To do this, we fire some requests to the login and logout \npages with the required form data (username and password).  And because the \nlogin and logout pages redirect, we tell the client to `follow_redirects`. </s> remove Of course you can submit forms with the test client as well, which we will\nuse now to log our user in.\n\n </s> add  </s> remove Besides using the test client we used above, there is also the\n:meth:`~flask.Flask.test_request_context` method that in combination with\nthe `with` statement can be used to activate a request context\ntemporarily.  With that you can access the :class:`~flask.request`,\n </s> add Besides using the test client as shown above, there is also the\n:meth:`~flask.Flask.test_request_context` method that can be used\nin combination with the `with` statement to activate a request context\ntemporarily.  With this you can access the :class:`~flask.request`, </s> remove In order to test that, we add a second module (\n`flaskr_tests.py`) and create a unittest skeleton there::\n </s> add In order to test the application, we add a second module \n(`flaskr_tests.py`) and create a unittest skeleton there:: </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output.\n </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output.", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> low-level file handle and a random file name, the latter we use as\n <mask> database name.  We just have to keep the `db_fd` around so that we can use\n <mask> the :func:`os.close` function to close the file.\n <mask> \n <mask> If we now run that test suite, we should see the following output::\n <mask> \n <mask>     $ python flaskr_tests.py\n <mask> \n <mask>     ----------------------------------------------------------------------\n <mask>     Ran 0 tests in 0.000s\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us.\n </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output.\n </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output. </s> remove Even though it did not run any tests, we already know that our flaskr\n </s> add Even though it did not run any actual tests, we already know that our flaskr </s> remove Of course you can submit forms with the test client as well, which we will\nuse now to log our user in.\n\n </s> add  </s> remove the administrative user, so we need a way to log our test client in to the\napplication and out of it again.  For that we fire some requests to the\nlogin and logout pages with the required form data (username and\npassword).  Because the login and logout pages redirect, we tell the\nclient to `follow_redirects`.\n </s> add the administrative user, so we need a way to log our test client in and out\nof the application.  To do this, we fire some requests to the login and logout \npages with the required form data (username and password).  And because the \nlogin and logout pages redirect, we tell the client to `follow_redirects`. </s> remove First we need an application to test for functionality.  For the testing\nwe will use the application from the :ref:`tutorial`.  If you don't have\nthat application yet, get the sources from `the examples`_.\n </s> add First, we need an application to test; we will use the application from \nthe :ref:`tutorial`.  If you don't have that application yet, get the \nsources from `the examples`_.", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     Ran 0 tests in 0.000s\n <mask> \n <mask>     OK\n <mask> \n <mask> Even though it did not run any tests, we already know that our flaskr\n <mask> application is syntactically valid, otherwise the import would have died\n <mask> with an exception.\n <mask> \n <mask> The First Test\n <mask> --------------\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove If we now run that test suite, we should see the following output::\n </s> add If we now run the test suite, we should see the following output:: </s> remove is no longer available (because used outside of an actual request).\nKeep in mind however that :meth:`~flask.Flask.after_request` functions\nare already called at that point so your database connection and\n </s> add is no longer available (because you are trying to use it outside of the actual request).\nHowever, keep in mind that any :meth:`~flask.Flask.after_request` functions\nare already called at this point so your database connection and </s> remove Of course you can submit forms with the test client as well, which we will\nuse now to log our user in.\n\n </s> add  </s> remove If you would just be using the :meth:`~flask.Flask.test_client` without\n </s> add If you were to use just the :meth:`~flask.Flask.test_client` without </s> remove Now we can add the first test.  Let's check that the application shows\n\"No entries here so far\" if we access the root of the application (``/``).\nFor that we modify our created test case class so that it looks like\nthis::\n </s> add Now it's time to start testing the functionality of the application.  \nLet's check that the application shows \"No entries here so far\" if we \naccess the root of the application (``/``). To do this, we add a new\ntest method to our class, like this:: </s> remove Not sure where that is coming from, and it's not entirely correct, but\nalso not that far from the truth.  Untested applications make it hard to\n </s> add The origin of this quote is unknown and while it is not entirely correct, it is also\nnot far from the truth.  Untested applications make it hard to", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> The First Test\n <mask> --------------\n <mask> \n <mask> Now we can add the first test.  Let's check that the application shows\n <mask> \"No entries here so far\" if we access the root of the application (``/``).\n <mask> For that we modify our created test case class so that it looks like\n <mask> this::\n <mask> \n <mask>     class FlaskrTestCase(unittest.TestCase):\n <mask> \n <mask>         def setUp(self):\n <mask>             self.db_fd, flaskr.app.config['DATABASE'] = tempfile.mkstemp()\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output.\n </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output. </s> remove Flask gives you a couple of ways to test applications.  It mainly does\nthat by exposing the Werkzeug test :class:`~werkzeug.test.Client` class to your\ncode and handling the context locals for you.  You can then use that with\nyour favourite testing solution.  In this documentation we will use the\n:mod:`unittest` package that comes preinstalled with each Python\ninstallation.\n </s> add Flask provides a way to test your application by exposing the Werkzeug \ntest :class:`~werkzeug.test.Client` and handling the context locals for you.\nYou can then use that with your favourite testing solution.  In this documentation\nwe will use the :mod:`unittest` package that comes pre-installed with Python. </s> remove Even though it did not run any tests, we already know that our flaskr\n </s> add Even though it did not run any actual tests, we already know that our flaskr </s> remove Now we can also test that adding messages works.  Add a new test method\n </s> add We should also test that adding messages works.  Add a new test method </s> remove Now we can easily test if logging in and out works and that it fails with\n </s> add Now we can easily test that logging in and out works and that it fails with </s> remove Besides using the test client we used above, there is also the\n:meth:`~flask.Flask.test_request_context` method that in combination with\nthe `with` statement can be used to activate a request context\ntemporarily.  With that you can access the :class:`~flask.request`,\n </s> add Besides using the test client as shown above, there is also the\n:meth:`~flask.Flask.test_request_context` method that can be used\nin combination with the `with` statement to activate a request context\ntemporarily.  With this you can access the :class:`~flask.request`,", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         def test_empty_db(self):\n <mask>             rv = self.app.get('/')\n <mask>             assert 'No entries here so far' in rv.data\n <mask> \n <mask> Test functions begin with the word `test`.  Every function named like that\n <mask> will be picked up automatically.  By using `self.app.get` we can send an\n <mask> HTTP `GET` request to the application with the given path.  The return\n <mask> value will be a :class:`~flask.Flask.response_class` object.  We can now\n <mask> use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\n <mask> return value (as string) from the application.  In this case, we ensure\n <mask> that ``'No entries here so far'`` is part of the output.\n <mask> \n <mask> Run it again and you should see one passing test::\n <mask> \n <mask>     $ python flaskr_tests.py\n <mask>     .\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove If we now run that test suite, we should see the following output::\n </s> add If we now run the test suite, we should see the following output:: </s> remove Now we can add the first test.  Let's check that the application shows\n\"No entries here so far\" if we access the root of the application (``/``).\nFor that we modify our created test case class so that it looks like\nthis::\n </s> add Now it's time to start testing the functionality of the application.  \nLet's check that the application shows \"No entries here so far\" if we \naccess the root of the application (``/``). To do this, we add a new\ntest method to our class, like this:: </s> remove Now we can easily test if logging in and out works and that it fails with\n </s> add Now we can easily test that logging in and out works and that it fails with </s> remove Besides using the test client we used above, there is also the\n:meth:`~flask.Flask.test_request_context` method that in combination with\nthe `with` statement can be used to activate a request context\ntemporarily.  With that you can access the :class:`~flask.request`,\n </s> add Besides using the test client as shown above, there is also the\n:meth:`~flask.Flask.test_request_context` method that can be used\nin combination with the `with` statement to activate a request context\ntemporarily.  With this you can access the :class:`~flask.request`, </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us.\n </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove the administrative user, so we need a way to log our test client in to the\napplication and out of it again.  For that we fire some requests to the\nlogin and logout pages with the required form data (username and\npassword).  Because the login and logout pages redirect, we tell the\nclient to `follow_redirects`.\n </s> add the administrative user, so we need a way to log our test client in and out\nof the application.  To do this, we fire some requests to the login and logout \npages with the required form data (username and password).  And because the \nlogin and logout pages redirect, we tell the client to `follow_redirects`.", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask>     Ran 1 test in 0.034s\n <mask> \n <mask>     OK\n <mask> \n <mask> Of course you can submit forms with the test client as well, which we will\n <mask> use now to log our user in.\n <mask> \n <mask> Logging In and Out\n <mask> ------------------\n <mask> \n <mask> The majority of the functionality of our application is only available for\n <mask> the administrative user, so we need a way to log our test client in to the\n <mask> application and out of it again.  For that we fire some requests to the\n <mask> login and logout pages with the required form data (username and\n <mask> password).  Because the login and logout pages redirect, we tell the\n <mask> client to `follow_redirects`.\n <mask> \n <mask> Add the following two methods to your `FlaskrTestCase` class::\n <mask> \n <mask>    def login(self, username, password):\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us.\n </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove If we now run that test suite, we should see the following output::\n </s> add If we now run the test suite, we should see the following output:: </s> remove Flask gives you a couple of ways to test applications.  It mainly does\nthat by exposing the Werkzeug test :class:`~werkzeug.test.Client` class to your\ncode and handling the context locals for you.  You can then use that with\nyour favourite testing solution.  In this documentation we will use the\n:mod:`unittest` package that comes preinstalled with each Python\ninstallation.\n </s> add Flask provides a way to test your application by exposing the Werkzeug \ntest :class:`~werkzeug.test.Client` and handling the context locals for you.\nYou can then use that with your favourite testing solution.  In this documentation\nwe will use the :mod:`unittest` package that comes pre-installed with Python. </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output.\n </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output. </s> remove Now we can easily test if logging in and out works and that it fails with\n </s> add Now we can easily test that logging in and out works and that it fails with", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>    def logout(self):\n <mask>        return self.app.get('/logout', follow_redirects=True)\n <mask> \n <mask> Now we can easily test if logging in and out works and that it fails with\n <mask> invalid credentials.  Add this new test to the class::\n <mask> \n <mask>    def test_login_logout(self):\n <mask>        rv = self.login('admin', 'default')\n <mask>        assert 'You were logged in' in rv.data\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove Now we can also test that adding messages works.  Add a new test method\n </s> add We should also test that adding messages works.  Add a new test method </s> remove the administrative user, so we need a way to log our test client in to the\napplication and out of it again.  For that we fire some requests to the\nlogin and logout pages with the required form data (username and\npassword).  Because the login and logout pages redirect, we tell the\nclient to `follow_redirects`.\n </s> add the administrative user, so we need a way to log our test client in and out\nof the application.  To do this, we fire some requests to the login and logout \npages with the required form data (username and password).  And because the \nlogin and logout pages redirect, we tell the client to `follow_redirects`. </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output.\n </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output. </s> remove Now we can add the first test.  Let's check that the application shows\n\"No entries here so far\" if we access the root of the application (``/``).\nFor that we modify our created test case class so that it looks like\nthis::\n </s> add Now it's time to start testing the functionality of the application.  \nLet's check that the application shows \"No entries here so far\" if we \naccess the root of the application (``/``). To do this, we add a new\ntest method to our class, like this:: </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us.\n </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove If you would just be using the :meth:`~flask.Flask.test_client` without\n </s> add If you were to use just the :meth:`~flask.Flask.test_client` without", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Test Adding Messages\n <mask> --------------------\n <mask> \n <mask> Now we can also test that adding messages works.  Add a new test method\n <mask> like this::\n <mask> \n <mask>     def test_messages(self):\n <mask>         self.login('admin', 'default')\n <mask>         rv = self.app.post('/add', data=dict(\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove Now we can easily test if logging in and out works and that it fails with\n </s> add Now we can easily test that logging in and out works and that it fails with </s> remove Now we can add the first test.  Let's check that the application shows\n\"No entries here so far\" if we access the root of the application (``/``).\nFor that we modify our created test case class so that it looks like\nthis::\n </s> add Now it's time to start testing the functionality of the application.  \nLet's check that the application shows \"No entries here so far\" if we \naccess the root of the application (``/``). To do this, we add a new\ntest method to our class, like this:: </s> remove Besides using the test client we used above, there is also the\n:meth:`~flask.Flask.test_request_context` method that in combination with\nthe `with` statement can be used to activate a request context\ntemporarily.  With that you can access the :class:`~flask.request`,\n </s> add Besides using the test client as shown above, there is also the\n:meth:`~flask.Flask.test_request_context` method that can be used\nin combination with the `with` statement to activate a request context\ntemporarily.  With this you can access the :class:`~flask.request`, </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output.\n </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output. </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us.\n </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove functions.  Here's a full example that showcases this::\n </s> add functions.  Here is a full example that demonstrates this approach::", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     OK\n <mask> \n <mask> For more complex tests with headers and status codes, check out the\n <mask> `MiniTwit Example`_ from the sources.  That one contains a larger test\n <mask> suite.\n <mask> \n <mask> \n <mask> .. _MiniTwit Example:\n <mask>    http://github.com/mitsuhiko/flask/tree/master/examples/minitwit/\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove the administrative user, so we need a way to log our test client in to the\napplication and out of it again.  For that we fire some requests to the\nlogin and logout pages with the required form data (username and\npassword).  Because the login and logout pages redirect, we tell the\nclient to `follow_redirects`.\n </s> add the administrative user, so we need a way to log our test client in and out\nof the application.  To do this, we fire some requests to the login and logout \npages with the required form data (username and password).  And because the \nlogin and logout pages redirect, we tell the client to `follow_redirects`. </s> remove First we need an application to test for functionality.  For the testing\nwe will use the application from the :ref:`tutorial`.  If you don't have\nthat application yet, get the sources from `the examples`_.\n </s> add First, we need an application to test; we will use the application from \nthe :ref:`tutorial`.  If you don't have that application yet, get the \nsources from `the examples`_. </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us.\n </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove Now we can add the first test.  Let's check that the application shows\n\"No entries here so far\" if we access the root of the application (``/``).\nFor that we modify our created test case class so that it looks like\nthis::\n </s> add Now it's time to start testing the functionality of the application.  \nLet's check that the application shows \"No entries here so far\" if we \naccess the root of the application (``/``). To do this, we add a new\ntest method to our class, like this:: </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output.\n </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output. </s> remove Of course you can submit forms with the test client as well, which we will\nuse now to log our user in.\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep replace", "code_tokens": " <mask> \n <mask> Other Testing Tricks\n <mask> --------------------\n <mask> \n <mask> Besides using the test client we used above, there is also the\n <mask> :meth:`~flask.Flask.test_request_context` method that in combination with\n <mask> the `with` statement can be used to activate a request context\n <mask> temporarily.  With that you can access the :class:`~flask.request`,\n <mask> :class:`~flask.g` and :class:`~flask.session` objects like in view\n <mask> functions.  Here's a full example that showcases this::\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove All the other objects that are context bound can be used the same.\n </s> add All the other objects that are context bound can be used in the same\nway. </s> remove Sometimes it can be helpful to trigger a regular request but keep the\n </s> add Sometimes it is helpful to trigger a regular request but still keep the </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output.\n </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output. </s> remove Now we can add the first test.  Let's check that the application shows\n\"No entries here so far\" if we access the root of the application (``/``).\nFor that we modify our created test case class so that it looks like\nthis::\n </s> add Now it's time to start testing the functionality of the application.  \nLet's check that the application shows \"No entries here so far\" if we \naccess the root of the application (``/``). To do this, we add a new\ntest method to our class, like this:: </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us.\n </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us.", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     with app.test_request_context('/?name=Peter'):\n <mask>         assert flask.request.path == '/'\n <mask>         assert flask.request.args['name'] == 'Peter'\n <mask> \n <mask> All the other objects that are context bound can be used the same.\n <mask> \n <mask> If you want to test your application with different configurations and\n <mask> there does not seem to be a good way to do that, consider switching to\n <mask> application factories (see :ref:`app-factories`).\n <mask> \n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove functions.  Here's a full example that showcases this::\n </s> add functions.  Here is a full example that demonstrates this approach:: </s> remove Besides using the test client we used above, there is also the\n:meth:`~flask.Flask.test_request_context` method that in combination with\nthe `with` statement can be used to activate a request context\ntemporarily.  With that you can access the :class:`~flask.request`,\n </s> add Besides using the test client as shown above, there is also the\n:meth:`~flask.Flask.test_request_context` method that can be used\nin combination with the `with` statement to activate a request context\ntemporarily.  With this you can access the :class:`~flask.request`, </s> remove If you would just be using the :meth:`~flask.Flask.test_client` without\n </s> add If you were to use just the :meth:`~flask.Flask.test_client` without </s> remove is no longer available (because used outside of an actual request).\nKeep in mind however that :meth:`~flask.Flask.after_request` functions\nare already called at that point so your database connection and\n </s> add is no longer available (because you are trying to use it outside of the actual request).\nHowever, keep in mind that any :meth:`~flask.Flask.after_request` functions\nare already called at this point so your database connection and </s> remove Flask gives you a couple of ways to test applications.  It mainly does\nthat by exposing the Werkzeug test :class:`~werkzeug.test.Client` class to your\ncode and handling the context locals for you.  You can then use that with\nyour favourite testing solution.  In this documentation we will use the\n:mod:`unittest` package that comes preinstalled with each Python\ninstallation.\n </s> add Flask provides a way to test your application by exposing the Werkzeug \ntest :class:`~werkzeug.test.Client` and handling the context locals for you.\nYou can then use that with your favourite testing solution.  In this documentation\nwe will use the :mod:`unittest` package that comes pre-installed with Python. </s> remove safely change things, and you will instantly know if your change broke\nsomething.\n </s> add safely make changes and instantly know if anything breaks.", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> --------------------------\n <mask> \n <mask> .. versionadded:: 0.4\n <mask> \n <mask> Sometimes it can be helpful to trigger a regular request but keep the\n <mask> context around for a little longer so that additional introspection can\n <mask> happen.  With Flask 0.4 this is possible by using the\n <mask> :meth:`~flask.Flask.test_client` with a `with` block::\n <mask> \n <mask>     app = flask.Flask(__name__)\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove Besides using the test client we used above, there is also the\n:meth:`~flask.Flask.test_request_context` method that in combination with\nthe `with` statement can be used to activate a request context\ntemporarily.  With that you can access the :class:`~flask.request`,\n </s> add Besides using the test client as shown above, there is also the\n:meth:`~flask.Flask.test_request_context` method that can be used\nin combination with the `with` statement to activate a request context\ntemporarily.  With this you can access the :class:`~flask.request`, </s> remove functions.  Here's a full example that showcases this::\n </s> add functions.  Here is a full example that demonstrates this approach:: </s> remove Flask gives you a couple of ways to test applications.  It mainly does\nthat by exposing the Werkzeug test :class:`~werkzeug.test.Client` class to your\ncode and handling the context locals for you.  You can then use that with\nyour favourite testing solution.  In this documentation we will use the\n:mod:`unittest` package that comes preinstalled with each Python\ninstallation.\n </s> add Flask provides a way to test your application by exposing the Werkzeug \ntest :class:`~werkzeug.test.Client` and handling the context locals for you.\nYou can then use that with your favourite testing solution.  In this documentation\nwe will use the :mod:`unittest` package that comes pre-installed with Python. </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output.\n </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output. </s> remove is no longer available (because used outside of an actual request).\nKeep in mind however that :meth:`~flask.Flask.after_request` functions\nare already called at that point so your database connection and\n </s> add is no longer available (because you are trying to use it outside of the actual request).\nHowever, keep in mind that any :meth:`~flask.Flask.after_request` functions\nare already called at this point so your database connection and </s> remove safely change things, and you will instantly know if your change broke\nsomething.\n </s> add safely make changes and instantly know if anything breaks.", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep replace keep replace replace replace", "code_tokens": " <mask>         assert request.args['tequila'] == '42'\n <mask> \n <mask> If you would just be using the :meth:`~flask.Flask.test_client` without\n <mask> the `with` block, the `assert` would fail with an error because `request`\n <mask> is no longer available (because used outside of an actual request).\n <mask> Keep in mind however that :meth:`~flask.Flask.after_request` functions\n <mask> are already called at that point so your database connection and\n </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove All the other objects that are context bound can be used the same.\n </s> add All the other objects that are context bound can be used in the same\nway. </s> remove Even though it did not run any tests, we already know that our flaskr\n </s> add Even though it did not run any actual tests, we already know that our flaskr </s> remove Besides using the test client we used above, there is also the\n:meth:`~flask.Flask.test_request_context` method that in combination with\nthe `with` statement can be used to activate a request context\ntemporarily.  With that you can access the :class:`~flask.request`,\n </s> add Besides using the test client as shown above, there is also the\n:meth:`~flask.Flask.test_request_context` method that can be used\nin combination with the `with` statement to activate a request context\ntemporarily.  With this you can access the :class:`~flask.request`, </s> remove functions.  Here's a full example that showcases this::\n </s> add functions.  Here is a full example that demonstrates this approach:: </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output.\n </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output.", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> # The scheme of the identifier. Typical schemes are ISBN or URL.\n <mask> #epub_scheme = ''\n <mask> \n <mask> # The unique identifier of the text. This can be a ISBN number\n <mask> # or the project homepage.\n <mask> #epub_identifier = ''\n <mask> \n <mask> # A unique identification for the text.\n <mask> #epub_uid = ''\n </s> Fix typos/grammar in docs (#2201) </s> remove The reason for this is that some file-like objects have a invalid or even\n </s> add The reason for this is that some file-like objects have an invalid or even </s> remove         #: To register a error handler, use the :meth:`errorhandler`\n </s> add         #: To register an error handler, use the :meth:`errorhandler` </s> remove The script scans your whole application and generates an unified diff with\n </s> add The script scans your whole application and generates a unified diff with </s> remove     output an unified diff with all the changes that are necessary to easily\n </s> add     output a unified diff with all the changes that are necessary to easily </s> remove   The module header consists of an utf-8 encoding declaration (if non\n </s> add   The module header consists of a utf-8 encoding declaration (if non </s> remove         When a teardown function was called because of a exception it will\n </s> add         When a teardown function was called because of an exception it will", "html_url": "https://github.com/pallets/flask/commit/f5adb61b28f240effbba5a4686647c2af6e85b94", "file_name": "docs/conf.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 flash('No file part')\n <mask>                 return redirect(request.url)\n <mask>             file = request.files['file']\n <mask>             # if user does not select file, browser also\n <mask>             # submit a empty part without filename\n <mask>             if file.filename == '':\n <mask>                 flash('No selected file')\n <mask>                 return redirect(request.url)\n <mask>             if file and allowed_file(file.filename):\n <mask>                 filename = secure_filename(file.filename)\n </s> Fix typos/grammar in docs (#2201) </s> remove         When a teardown function was called because of a exception it will\n </s> add         When a teardown function was called because of an exception it will </s> remove     output an unified diff with all the changes that are necessary to easily\n </s> add     output a unified diff with all the changes that are necessary to easily </s> remove The reason for this is that some file-like objects have a invalid or even\n </s> add The reason for this is that some file-like objects have an invalid or even </s> remove The script scans your whole application and generates an unified diff with\n </s> add The script scans your whole application and generates a unified diff with </s> remove   The module header consists of an utf-8 encoding declaration (if non\n </s> add   The module header consists of a utf-8 encoding declaration (if non </s> remove         #: To register a error handler, use the :meth:`errorhandler`\n </s> add         #: To register an error handler, use the :meth:`errorhandler`", "html_url": "https://github.com/pallets/flask/commit/f5adb61b28f240effbba5a4686647c2af6e85b94", "file_name": "docs/patterns/fileuploads.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         is on its own line.\n <mask>         \"\"\"\n <mask> \n <mask> Module header:\n <mask>   The module header consists of an utf-8 encoding declaration (if non\n <mask>   ASCII letters are used, but it is recommended all the time) and a\n <mask>   standard docstring::\n <mask> \n <mask>     # -*- coding: utf-8 -*-\n <mask>     \"\"\"\n </s> Fix typos/grammar in docs (#2201) </s> remove The script scans your whole application and generates an unified diff with\n </s> add The script scans your whole application and generates a unified diff with </s> remove         When a teardown function was called because of a exception it will\n </s> add         When a teardown function was called because of an exception it will </s> remove     output an unified diff with all the changes that are necessary to easily\n </s> add     output a unified diff with all the changes that are necessary to easily </s> remove # The unique identifier of the text. This can be a ISBN number\n </s> add # The unique identifier of the text. This can be an ISBN number </s> remove         #: To register a error handler, use the :meth:`errorhandler`\n </s> add         #: To register an error handler, use the :meth:`errorhandler` </s> remove The reason for this is that some file-like objects have a invalid or even\n </s> add The reason for this is that some file-like objects have an invalid or even", "html_url": "https://github.com/pallets/flask/commit/f5adb61b28f240effbba5a4686647c2af6e85b94", "file_name": "docs/styleguide.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     # ETag still needs to be manually set\n <mask>     response = send_file(open(fname), attachment_filename=fname)\n <mask>     response.set_etag(...)\n <mask> \n <mask> The reason for this is that some file-like objects have a invalid or even\n <mask> misleading ``name`` attribute. Silently swallowing errors in such cases was not\n <mask> a satisfying solution.\n <mask> \n <mask> Additionally the default of falling back to ``application/octet-stream`` has\n <mask> been restricted. If Flask can't guess one or the user didn't provide one, the\n </s> Fix typos/grammar in docs (#2201) </s> remove # The unique identifier of the text. This can be a ISBN number\n </s> add # The unique identifier of the text. This can be an ISBN number </s> remove         When a teardown function was called because of a exception it will\n </s> add         When a teardown function was called because of an exception it will </s> remove The script scans your whole application and generates an unified diff with\n </s> add The script scans your whole application and generates a unified diff with </s> remove     output an unified diff with all the changes that are necessary to easily\n </s> add     output a unified diff with all the changes that are necessary to easily </s> remove         #: To register a error handler, use the :meth:`errorhandler`\n </s> add         #: To register an error handler, use the :meth:`errorhandler` </s> remove   The module header consists of an utf-8 encoding declaration (if non\n </s> add   The module header consists of a utf-8 encoding declaration (if non", "html_url": "https://github.com/pallets/flask/commit/f5adb61b28f240effbba5a4686647c2af6e85b94", "file_name": "docs/upgrading.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> applications with Flask.  Because we want to make upgrading as easy as\n <mask> possible we tried to counter the problems arising from these changes by\n <mask> providing a script that can ease the transition.\n <mask> \n <mask> The script scans your whole application and generates an unified diff with\n <mask> changes it assumes are safe to apply.  However as this is an automated\n <mask> tool it won't be able to find all use cases and it might miss some.  We\n <mask> internally spread a lot of deprecation warnings all over the place to make\n <mask> it easy to find pieces of code that it was unable to upgrade.\n <mask> \n </s> Fix typos/grammar in docs (#2201) </s> remove     output an unified diff with all the changes that are necessary to easily\n </s> add     output a unified diff with all the changes that are necessary to easily </s> remove         When a teardown function was called because of a exception it will\n </s> add         When a teardown function was called because of an exception it will </s> remove The reason for this is that some file-like objects have a invalid or even\n </s> add The reason for this is that some file-like objects have an invalid or even </s> remove         #: To register a error handler, use the :meth:`errorhandler`\n </s> add         #: To register an error handler, use the :meth:`errorhandler` </s> remove   The module header consists of an utf-8 encoding declaration (if non\n </s> add   The module header consists of a utf-8 encoding declaration (if non </s> remove # The unique identifier of the text. This can be a ISBN number\n </s> add # The unique identifier of the text. This can be an ISBN number", "html_url": "https://github.com/pallets/flask/commit/f5adb61b28f240effbba5a4686647c2af6e85b94", "file_name": "docs/upgrading.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: special key ``None`` points to a list of tuples where the first item\n <mask>         #: is the class for the instance check and the second the error handler\n <mask>         #: function.\n <mask>         #:\n <mask>         #: To register a error handler, use the :meth:`errorhandler`\n <mask>         #: decorator.\n <mask>         self.error_handler_spec = {None: self._error_handlers}\n <mask> \n <mask>         #: A list of functions that are called when :meth:`url_for` raises a\n <mask>         #: :exc:`~werkzeug.routing.BuildError`.  Each function registered here\n </s> Fix typos/grammar in docs (#2201) </s> remove         When a teardown function was called because of a exception it will\n </s> add         When a teardown function was called because of an exception it will </s> remove     output an unified diff with all the changes that are necessary to easily\n </s> add     output a unified diff with all the changes that are necessary to easily </s> remove The script scans your whole application and generates an unified diff with\n </s> add The script scans your whole application and generates a unified diff with </s> remove # The unique identifier of the text. This can be a ISBN number\n </s> add # The unique identifier of the text. This can be an ISBN number </s> remove The reason for this is that some file-like objects have a invalid or even\n </s> add The reason for this is that some file-like objects have an invalid or even </s> remove   The module header consists of an utf-8 encoding declaration (if non\n </s> add   The module header consists of a utf-8 encoding declaration (if non", "html_url": "https://github.com/pallets/flask/commit/f5adb61b28f240effbba5a4686647c2af6e85b94", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         that they will fail.  If they do execute code that might fail they\n <mask>         will have to surround the execution of these code by try/except\n <mask>         statements and log occurring errors.\n <mask> \n <mask>         When a teardown function was called because of a exception it will\n <mask>         be passed an error object.\n <mask> \n <mask>         The return values of teardown functions are ignored.\n <mask> \n <mask>         .. admonition:: Debug Note\n </s> Fix typos/grammar in docs (#2201) </s> remove The script scans your whole application and generates an unified diff with\n </s> add The script scans your whole application and generates a unified diff with </s> remove         #: To register a error handler, use the :meth:`errorhandler`\n </s> add         #: To register an error handler, use the :meth:`errorhandler` </s> remove     output an unified diff with all the changes that are necessary to easily\n </s> add     output a unified diff with all the changes that are necessary to easily </s> remove The reason for this is that some file-like objects have a invalid or even\n </s> add The reason for this is that some file-like objects have an invalid or even </s> remove   The module header consists of an utf-8 encoding declaration (if non\n </s> add   The module header consists of a utf-8 encoding declaration (if non </s> remove # The unique identifier of the text. This can be a ISBN number\n </s> add # The unique identifier of the text. This can be an ISBN number", "html_url": "https://github.com/pallets/flask/commit/f5adb61b28f240effbba5a4686647c2af6e85b94", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     flask-07-upgrade\n <mask>     ~~~~~~~~~~~~~~~~\n <mask> \n <mask>     This command line script scans a whole application tree and attempts to\n <mask>     output an unified diff with all the changes that are necessary to easily\n <mask>     upgrade the application to 0.7 and to not yield deprecation warnings.\n <mask> \n <mask>     This will also attempt to find `after_request` functions that don't modify\n <mask>     the response and appear to be better suited for `teardown_request`.\n <mask> \n </s> Fix typos/grammar in docs (#2201) </s> remove The script scans your whole application and generates an unified diff with\n </s> add The script scans your whole application and generates a unified diff with </s> remove         When a teardown function was called because of a exception it will\n </s> add         When a teardown function was called because of an exception it will </s> remove The reason for this is that some file-like objects have a invalid or even\n </s> add The reason for this is that some file-like objects have an invalid or even </s> remove         #: To register a error handler, use the :meth:`errorhandler`\n </s> add         #: To register an error handler, use the :meth:`errorhandler` </s> remove # The unique identifier of the text. This can be a ISBN number\n </s> add # The unique identifier of the text. This can be an ISBN number </s> remove   The module header consists of an utf-8 encoding declaration (if non\n </s> add   The module header consists of a utf-8 encoding declaration (if non", "html_url": "https://github.com/pallets/flask/commit/f5adb61b28f240effbba5a4686647c2af6e85b94", "file_name": "scripts/flask-07-upgrade.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from werkzeug.routing import Map, Rule\n <mask> from werkzeug.exceptions import HTTPException, InternalServerError, NotFound\n <mask> \n <mask> from .helpers import _PackageBoundObject, url_for, get_flashed_messages, \\\n <mask>     _tojson_filter\n <mask> from .wrappers import Request, Response\n <mask> from .config import ConfigAttribute, Config\n <mask> from .ctx import _RequestContext\n <mask> from .globals import _request_ctx_stack, request\n <mask> from .session import Session, _NullSession\n </s> endpoint is optional for modules.  This fixes #86 </s> remove from .helpers import _PackageBoundObject\n </s> add from .helpers import _PackageBoundObject, _endpoint_from_view_func </s> remove             assert view_func is not None, 'expected view func if endpoint ' \\\n                                          'is not provided.'\n            endpoint = view_func.__name__\n </s> add             endpoint = _endpoint_from_view_func(view_func) </s> add def _endpoint_from_view_func(view_func):\n    \"\"\"Internal helper that returns the default endpoint for a given\n    function.  This always is the function name.\n    \"\"\"\n    assert view_func is not None, 'expected view func if endpoint ' \\\n                                  'is not provided.'\n    return view_func.__name__\n\n </s> add     def test_default_endpoint_name(self):\n        app = flask.Flask(__name__)\n        mod = flask.Module(__name__, 'frontend')\n        def index():\n            return 'Awesome'\n        mod.add_url_rule('/', view_func=index)\n        app.register_module(mod)\n        rv = app.test_client().get('/')\n        assert rv.data == 'Awesome'\n        with app.test_request_context():\n            assert flask.url_for('frontend.index') == '/'\n </s> remove             state.app.add_url_rule(the_rule, '%s.%s' % (self.name, endpoint),\n </s> add             the_endpoint = endpoint\n            if the_endpoint is None:\n                the_endpoint = _endpoint_from_view_func(view_func)\n            state.app.add_url_rule(the_rule, '%s.%s' % (self.name,\n                                                        the_endpoint), </s> add         .. versionchanged:: 0.6\n           The `endpoint` argument is now optional and will default to the\n           function name to consistent with the function of the same name\n           on the application object.", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                         Starting with Flask 0.6, `OPTIONS` is implicitly\n <mask>                         added and handled by the standard request handling.\n <mask>         \"\"\"\n <mask>         if endpoint is None:\n <mask>             assert view_func is not None, 'expected view func if endpoint ' \\\n <mask>                                           'is not provided.'\n <mask>             endpoint = view_func.__name__\n <mask>         options['endpoint'] = endpoint\n <mask>         methods = options.pop('methods', ('GET',))\n <mask>         provide_automatic_options = False\n <mask>         if 'OPTIONS' not in methods:\n <mask>             methods = tuple(methods) + ('OPTIONS',)\n </s> endpoint is optional for modules.  This fixes #86 </s> add def _endpoint_from_view_func(view_func):\n    \"\"\"Internal helper that returns the default endpoint for a given\n    function.  This always is the function name.\n    \"\"\"\n    assert view_func is not None, 'expected view func if endpoint ' \\\n                                  'is not provided.'\n    return view_func.__name__\n\n </s> add         .. versionchanged:: 0.6\n           The `endpoint` argument is now optional and will default to the\n           function name to consistent with the function of the same name\n           on the application object. </s> remove             state.app.add_url_rule(the_rule, '%s.%s' % (self.name, endpoint),\n </s> add             the_endpoint = endpoint\n            if the_endpoint is None:\n                the_endpoint = _endpoint_from_view_func(view_func)\n            state.app.add_url_rule(the_rule, '%s.%s' % (self.name,\n                                                        the_endpoint), </s> remove     def add_url_rule(self, rule, endpoint, view_func=None, **options):\n </s> add     def add_url_rule(self, rule, endpoint=None, view_func=None, **options): </s> add     def test_default_endpoint_name(self):\n        app = flask.Flask(__name__)\n        mod = flask.Module(__name__, 'frontend')\n        def index():\n            return 'Awesome'\n        mod.add_url_rule('/', view_func=index)\n        app.register_module(mod)\n        rv = app.test_client().get('/')\n        assert rv.data == 'Awesome'\n        with app.test_request_context():\n            assert flask.url_for('frontend.index') == '/'\n </s> remove from .helpers import _PackageBoundObject\n </s> add from .helpers import _PackageBoundObject, _endpoint_from_view_func", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> else:\n <mask>     _tojson_filter = json.dumps\n <mask> \n <mask> \n <mask> def jsonify(*args, **kwargs):\n <mask>     \"\"\"Creates a :class:`~flask.Response` with the JSON representation of\n <mask>     the given arguments with an `application/json` mimetype.  The arguments\n <mask>     to this function are the same as to the :class:`dict` constructor.\n <mask> \n <mask>     Example usage::\n </s> endpoint is optional for modules.  This fixes #86 </s> add         .. versionchanged:: 0.6\n           The `endpoint` argument is now optional and will default to the\n           function name to consistent with the function of the same name\n           on the application object. </s> remove     def add_url_rule(self, rule, endpoint, view_func=None, **options):\n </s> add     def add_url_rule(self, rule, endpoint=None, view_func=None, **options): </s> remove from .helpers import _PackageBoundObject\n </s> add from .helpers import _PackageBoundObject, _endpoint_from_view_func </s> remove             assert view_func is not None, 'expected view func if endpoint ' \\\n                                          'is not provided.'\n            endpoint = view_func.__name__\n </s> add             endpoint = _endpoint_from_view_func(view_func) </s> add     def test_default_endpoint_name(self):\n        app = flask.Flask(__name__)\n        mod = flask.Module(__name__, 'frontend')\n        def index():\n            return 'Awesome'\n        mod.add_url_rule('/', view_func=index)\n        app.register_module(mod)\n        rv = app.test_client().get('/')\n        assert rv.data == 'Awesome'\n        with app.test_request_context():\n            assert flask.url_for('frontend.index') == '/'\n </s> remove             state.app.add_url_rule(the_rule, '%s.%s' % (self.name, endpoint),\n </s> add             the_endpoint = endpoint\n            if the_endpoint is None:\n                the_endpoint = _endpoint_from_view_func(view_func)\n            state.app.add_url_rule(the_rule, '%s.%s' % (self.name,\n                                                        the_endpoint),", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from .helpers import _PackageBoundObject\n <mask> \n <mask> \n <mask> def _register_module(module, static_path):\n <mask>     \"\"\"Internal helper function that returns a function for recording\n <mask>     that registers the `send_static_file` function for the module on\n </s> endpoint is optional for modules.  This fixes #86 </s> add def _endpoint_from_view_func(view_func):\n    \"\"\"Internal helper that returns the default endpoint for a given\n    function.  This always is the function name.\n    \"\"\"\n    assert view_func is not None, 'expected view func if endpoint ' \\\n                                  'is not provided.'\n    return view_func.__name__\n\n </s> add         .. versionchanged:: 0.6\n           The `endpoint` argument is now optional and will default to the\n           function name to consistent with the function of the same name\n           on the application object. </s> remove     _tojson_filter\n </s> add     _tojson_filter, _endpoint_from_view_func </s> remove     def add_url_rule(self, rule, endpoint, view_func=None, **options):\n </s> add     def add_url_rule(self, rule, endpoint=None, view_func=None, **options): </s> remove             state.app.add_url_rule(the_rule, '%s.%s' % (self.name, endpoint),\n </s> add             the_endpoint = endpoint\n            if the_endpoint is None:\n                the_endpoint = _endpoint_from_view_func(view_func)\n            state.app.add_url_rule(the_rule, '%s.%s' % (self.name,\n                                                        the_endpoint), </s> remove             assert view_func is not None, 'expected view func if endpoint ' \\\n                                          'is not provided.'\n            endpoint = view_func.__name__\n </s> add             endpoint = _endpoint_from_view_func(view_func)", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "flask/module.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             self.add_url_rule(rule, f.__name__, f, **options)\n <mask>             return f\n <mask>         return decorator\n <mask> \n <mask>     def add_url_rule(self, rule, endpoint, view_func=None, **options):\n <mask>         \"\"\"Like :meth:`Flask.add_url_rule` but for a module.  The endpoint for\n <mask>         the :func:`url_for` function is prefixed with the name of the module.\n <mask>         \"\"\"\n <mask>         def register_rule(state):\n <mask>             the_rule = rule\n </s> endpoint is optional for modules.  This fixes #86 </s> add         .. versionchanged:: 0.6\n           The `endpoint` argument is now optional and will default to the\n           function name to consistent with the function of the same name\n           on the application object. </s> remove             state.app.add_url_rule(the_rule, '%s.%s' % (self.name, endpoint),\n </s> add             the_endpoint = endpoint\n            if the_endpoint is None:\n                the_endpoint = _endpoint_from_view_func(view_func)\n            state.app.add_url_rule(the_rule, '%s.%s' % (self.name,\n                                                        the_endpoint), </s> add def _endpoint_from_view_func(view_func):\n    \"\"\"Internal helper that returns the default endpoint for a given\n    function.  This always is the function name.\n    \"\"\"\n    assert view_func is not None, 'expected view func if endpoint ' \\\n                                  'is not provided.'\n    return view_func.__name__\n\n </s> remove from .helpers import _PackageBoundObject\n </s> add from .helpers import _PackageBoundObject, _endpoint_from_view_func </s> remove             assert view_func is not None, 'expected view func if endpoint ' \\\n                                          'is not provided.'\n            endpoint = view_func.__name__\n </s> add             endpoint = _endpoint_from_view_func(view_func) </s> add     def test_default_endpoint_name(self):\n        app = flask.Flask(__name__)\n        mod = flask.Module(__name__, 'frontend')\n        def index():\n            return 'Awesome'\n        mod.add_url_rule('/', view_func=index)\n        app.register_module(mod)\n        rv = app.test_client().get('/')\n        assert rv.data == 'Awesome'\n        with app.test_request_context():\n            assert flask.url_for('frontend.index') == '/'\n", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "flask/module.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Like :meth:`Flask.add_url_rule` but for a module.  The endpoint for\n <mask>         the :func:`url_for` function is prefixed with the name of the module.\n <mask>         \"\"\"\n <mask>         def register_rule(state):\n <mask>             the_rule = rule\n <mask>             if state.url_prefix:\n <mask>                 the_rule = state.url_prefix + rule\n <mask>             the_endpoint = endpoint\n </s> endpoint is optional for modules.  This fixes #86 </s> remove     def add_url_rule(self, rule, endpoint, view_func=None, **options):\n </s> add     def add_url_rule(self, rule, endpoint=None, view_func=None, **options): </s> remove             state.app.add_url_rule(the_rule, '%s.%s' % (self.name, endpoint),\n </s> add             the_endpoint = endpoint\n            if the_endpoint is None:\n                the_endpoint = _endpoint_from_view_func(view_func)\n            state.app.add_url_rule(the_rule, '%s.%s' % (self.name,\n                                                        the_endpoint), </s> add def _endpoint_from_view_func(view_func):\n    \"\"\"Internal helper that returns the default endpoint for a given\n    function.  This always is the function name.\n    \"\"\"\n    assert view_func is not None, 'expected view func if endpoint ' \\\n                                  'is not provided.'\n    return view_func.__name__\n\n </s> remove             assert view_func is not None, 'expected view func if endpoint ' \\\n                                          'is not provided.'\n            endpoint = view_func.__name__\n </s> add             endpoint = _endpoint_from_view_func(view_func) </s> remove from .helpers import _PackageBoundObject\n </s> add from .helpers import _PackageBoundObject, _endpoint_from_view_func </s> add     def test_default_endpoint_name(self):\n        app = flask.Flask(__name__)\n        mod = flask.Module(__name__, 'frontend')\n        def index():\n            return 'Awesome'\n        mod.add_url_rule('/', view_func=index)\n        app.register_module(mod)\n        rv = app.test_client().get('/')\n        assert rv.data == 'Awesome'\n        with app.test_request_context():\n            assert flask.url_for('frontend.index') == '/'\n", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "flask/module.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def register_rule(state):\n <mask>             the_rule = rule\n <mask>             if state.url_prefix:\n <mask>                 the_rule = state.url_prefix + rule\n <mask>             state.app.add_url_rule(the_rule, '%s.%s' % (self.name, endpoint),\n <mask>                                    view_func, **options)\n <mask>         self._record(register_rule)\n <mask> \n <mask>     def before_request(self, f):\n <mask>         \"\"\"Like :meth:`Flask.before_request` but for a module.  This function\n </s> endpoint is optional for modules.  This fixes #86 </s> add         .. versionchanged:: 0.6\n           The `endpoint` argument is now optional and will default to the\n           function name to consistent with the function of the same name\n           on the application object. </s> remove     def add_url_rule(self, rule, endpoint, view_func=None, **options):\n </s> add     def add_url_rule(self, rule, endpoint=None, view_func=None, **options): </s> add def _endpoint_from_view_func(view_func):\n    \"\"\"Internal helper that returns the default endpoint for a given\n    function.  This always is the function name.\n    \"\"\"\n    assert view_func is not None, 'expected view func if endpoint ' \\\n                                  'is not provided.'\n    return view_func.__name__\n\n </s> add     def test_default_endpoint_name(self):\n        app = flask.Flask(__name__)\n        mod = flask.Module(__name__, 'frontend')\n        def index():\n            return 'Awesome'\n        mod.add_url_rule('/', view_func=index)\n        app.register_module(mod)\n        rv = app.test_client().get('/')\n        assert rv.data == 'Awesome'\n        with app.test_request_context():\n            assert flask.url_for('frontend.index') == '/'\n </s> remove from .helpers import _PackageBoundObject\n </s> add from .helpers import _PackageBoundObject, _endpoint_from_view_func </s> remove             assert view_func is not None, 'expected view func if endpoint ' \\\n                                          'is not provided.'\n            endpoint = view_func.__name__\n </s> add             endpoint = _endpoint_from_view_func(view_func)", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "flask/module.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         assert c.get('/admin/login').data == 'admin login'\n <mask>         assert c.get('/admin/logout').data == 'admin logout'\n <mask> \n <mask>     def test_request_processing(self):\n <mask>         catched = []\n <mask>         app = flask.Flask(__name__)\n <mask>         admin = flask.Module(__name__, 'admin', url_prefix='/admin')\n </s> endpoint is optional for modules.  This fixes #86 </s> remove             assert view_func is not None, 'expected view func if endpoint ' \\\n                                          'is not provided.'\n            endpoint = view_func.__name__\n </s> add             endpoint = _endpoint_from_view_func(view_func) </s> remove             state.app.add_url_rule(the_rule, '%s.%s' % (self.name, endpoint),\n </s> add             the_endpoint = endpoint\n            if the_endpoint is None:\n                the_endpoint = _endpoint_from_view_func(view_func)\n            state.app.add_url_rule(the_rule, '%s.%s' % (self.name,\n                                                        the_endpoint), </s> add def _endpoint_from_view_func(view_func):\n    \"\"\"Internal helper that returns the default endpoint for a given\n    function.  This always is the function name.\n    \"\"\"\n    assert view_func is not None, 'expected view func if endpoint ' \\\n                                  'is not provided.'\n    return view_func.__name__\n\n </s> add         .. versionchanged:: 0.6\n           The `endpoint` argument is now optional and will default to the\n           function name to consistent with the function of the same name\n           on the application object. </s> remove     def add_url_rule(self, rule, endpoint, view_func=None, **options):\n </s> add     def add_url_rule(self, rule, endpoint=None, view_func=None, **options): </s> remove from .helpers import _PackageBoundObject\n </s> add from .helpers import _PackageBoundObject, _endpoint_from_view_func", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>   mimetype parameter.\n <mask> - Don't modify the session on :func:`flask.get_flashed_messages` if there\n <mask>   are no messages in the session.\n <mask> - `before_request` handlers are now able to abort requests with errors.\n <mask> \n <mask> Version 0.6.1\n <mask> -------------\n <mask> \n </s> Added blueprint specific error handling </s> remove         handler = self.error_handlers.get(500)\n </s> add         handler = self.error_handler_spec[None].get(500) </s> remove             app.error_handlers[404] = page_not_found\n </s> add             app.error_handler_spec[None][404] = page_not_found\n\n        Setting error handlers via assignments to :attr:`error_handler_spec`\n        however is discouraged as it requires fidling with nested dictionaries\n        and the special case for arbitrary exception types.\n\n        The first `None` refers to the active blueprint.  If the error\n        handler should be application wide `None` shall be used.\n\n        .. versionadded:: 0.7\n           One can now additionally also register custom exception types\n           that do not necessarily have to be a subclass of the\n           :class:~`werkzeug.exceptions.HTTPException` class. </s> remove         explicitly by the user of this method.\n </s> add         explicitly by the user of this method.  If the endpoint is prefixed\n        with a `.` it will be registered to the current blueprint, otherwise\n        it's an application independent endpoint. </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f))\n </s> remove         handler = self.error_handlers.get(e.code)\n </s> add         handlers = self.error_handler_spec.get(request.blueprint)\n        if handlers and e.code in handlers:\n            handler = handlers[e.code]\n        else:\n            handler = self.error_handler_spec[None].get(e.code) </s> add         You can also register handlers for arbitrary exceptions::\n\n            @app.errorhandler(DatabaseError)\n            def special_exception_handler(error):\n                return 'Database connection failed', 500\n", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "CHANGES"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>                 return 'This page does not exist', 404\n <mask> \n <mask>         You can also register a function as error handler without using\n <mask>         the :meth:`errorhandler` decorator.  The following example is\n <mask>         equivalent to the one above::\n <mask> \n <mask>             def page_not_found(error):\n </s> Added blueprint specific error handling </s> remove             app.error_handlers[404] = page_not_found\n </s> add             app.error_handler_spec[None][404] = page_not_found\n\n        Setting error handlers via assignments to :attr:`error_handler_spec`\n        however is discouraged as it requires fidling with nested dictionaries\n        and the special case for arbitrary exception types.\n\n        The first `None` refers to the active blueprint.  If the error\n        handler should be application wide `None` shall be used.\n\n        .. versionadded:: 0.7\n           One can now additionally also register custom exception types\n           that do not necessarily have to be a subclass of the\n           :class:~`werkzeug.exceptions.HTTPException` class. </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f))\n </s> remove             self.error_handlers[code] = f\n </s> add             self._register_error_handler(None, code_or_exception, f) </s> remove         explicitly by the user of this method.\n </s> add         explicitly by the user of this method.  If the endpoint is prefixed\n        with a `.` it will be registered to the current blueprint, otherwise\n        it's an application independent endpoint. </s> remove         handler = self.error_handlers.get(500)\n </s> add         handler = self.error_handler_spec[None].get(500) </s> add - it is not possible to define user exception handlers.  That way you can\n  provide custom error messages from a central hub for certain errors that\n  might occur during request processing (for instance database connection\n  errors, timeouts from remote resources etc.).\n- Blueprints can provide blueprint specific error handlers.", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/app.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace keep", "code_tokens": " <mask>                 return 'This page does not exist', 404\n <mask>             app.error_handlers[404] = page_not_found\n <mask> \n <mask>         :param code: the code as integer for the handler\n <mask>         \"\"\"\n <mask>         def decorator(f):\n <mask>             self.error_handlers[code] = f\n <mask>             return f\n </s> Added blueprint specific error handling </s> add         You can also register handlers for arbitrary exceptions::\n\n            @app.errorhandler(DatabaseError)\n            def special_exception_handler(error):\n                return 'Database connection failed', 500\n </s> remove         explicitly by the user of this method.\n </s> add         explicitly by the user of this method.  If the endpoint is prefixed\n        with a `.` it will be registered to the current blueprint, otherwise\n        it's an application independent endpoint. </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f))\n </s> remove         handler = self.error_handlers.get(e.code)\n </s> add         handlers = self.error_handler_spec.get(request.blueprint)\n        if handlers and e.code in handlers:\n            handler = handlers[e.code]\n        else:\n            handler = self.error_handler_spec[None].get(e.code) </s> remove         handler = self.error_handlers.get(500)\n </s> add         handler = self.error_handler_spec[None].get(500)", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>             self._register_error_handler(None, code_or_exception, f)\n <mask>             return f\n <mask>         return decorator\n <mask> \n <mask>     def template_filter(self, name=None):\n <mask>         \"\"\"A decorator that is used to register custom template filter.\n <mask>         You can specify a name for the filter, otherwise the function\n <mask>         name will be used. Example::\n </s> Added blueprint specific error handling </s> remove             self.error_handlers[code] = f\n </s> add             self._register_error_handler(None, code_or_exception, f) </s> add         You can also register handlers for arbitrary exceptions::\n\n            @app.errorhandler(DatabaseError)\n            def special_exception_handler(error):\n                return 'Database connection failed', 500\n </s> remove         explicitly by the user of this method.\n </s> add         explicitly by the user of this method.  If the endpoint is prefixed\n        with a `.` it will be registered to the current blueprint, otherwise\n        it's an application independent endpoint. </s> remove             app.error_handlers[404] = page_not_found\n </s> add             app.error_handler_spec[None][404] = page_not_found\n\n        Setting error handlers via assignments to :attr:`error_handler_spec`\n        however is discouraged as it requires fidling with nested dictionaries\n        and the special case for arbitrary exception types.\n\n        The first `None` refers to the active blueprint.  If the error\n        handler should be application wide `None` shall be used.\n\n        .. versionadded:: 0.7\n           One can now additionally also register custom exception types\n           that do not necessarily have to be a subclass of the\n           :class:~`werkzeug.exceptions.HTTPException` class. </s> remove         handler = self.error_handlers.get(500)\n </s> add         handler = self.error_handler_spec[None].get(500) </s> add - it is not possible to define user exception handlers.  That way you can\n  provide custom error messages from a central hub for certain errors that\n  might occur during request processing (for instance database connection\n  errors, timeouts from remote resources etc.).\n- Blueprints can provide blueprint specific error handlers.", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         exception as response.\n <mask> \n <mask>         .. versionadded: 0.3\n <mask>         \"\"\"\n <mask>         handler = self.error_handlers.get(e.code)\n <mask>         if handler is None:\n <mask>             return e\n <mask>         return handler(e)\n <mask> \n <mask>     def handle_exception(self, e):\n </s> Added blueprint specific error handling </s> remove             app.error_handlers[404] = page_not_found\n </s> add             app.error_handler_spec[None][404] = page_not_found\n\n        Setting error handlers via assignments to :attr:`error_handler_spec`\n        however is discouraged as it requires fidling with nested dictionaries\n        and the special case for arbitrary exception types.\n\n        The first `None` refers to the active blueprint.  If the error\n        handler should be application wide `None` shall be used.\n\n        .. versionadded:: 0.7\n           One can now additionally also register custom exception types\n           that do not necessarily have to be a subclass of the\n           :class:~`werkzeug.exceptions.HTTPException` class. </s> remove             self.error_handlers[code] = f\n </s> add             self._register_error_handler(None, code_or_exception, f) </s> remove         except HTTPException, e:\n            rv = self.handle_http_exception(e)\n </s> add         except Exception, e:\n            rv = self.handle_user_exception(e) </s> add         You can also register handlers for arbitrary exceptions::\n\n            @app.errorhandler(DatabaseError)\n            def special_exception_handler(error):\n                return 'Database connection failed', 500\n </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f))\n </s> add     def test_user_error_handling(self):\n        class MyException(Exception):\n            pass\n\n        app = flask.Flask(__name__)\n        @app.errorhandler(MyException)\n        def handle_my_exception(e):\n            assert isinstance(e, MyException)\n            return '42'\n        @app.route('/')\n        def index():\n            raise MyException()\n\n        c = app.test_client()\n        assert c.get('/').data == '42'\n", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         exc_type, exc_value, tb = sys.exc_info()\n <mask> \n <mask>         got_request_exception.send(self, exception=e)\n <mask>         handler = self.error_handlers.get(500)\n <mask> \n <mask>         if self.propagate_exceptions:\n <mask>             # if we want to repropagate the exception, we can attempt to\n <mask>             # raise it with the whole traceback in case we can do that\n <mask>             # (the function was actually called from the except part)\n </s> Added blueprint specific error handling </s> remove             app.error_handlers[404] = page_not_found\n </s> add             app.error_handler_spec[None][404] = page_not_found\n\n        Setting error handlers via assignments to :attr:`error_handler_spec`\n        however is discouraged as it requires fidling with nested dictionaries\n        and the special case for arbitrary exception types.\n\n        The first `None` refers to the active blueprint.  If the error\n        handler should be application wide `None` shall be used.\n\n        .. versionadded:: 0.7\n           One can now additionally also register custom exception types\n           that do not necessarily have to be a subclass of the\n           :class:~`werkzeug.exceptions.HTTPException` class. </s> add - it is not possible to define user exception handlers.  That way you can\n  provide custom error messages from a central hub for certain errors that\n  might occur during request processing (for instance database connection\n  errors, timeouts from remote resources etc.).\n- Blueprints can provide blueprint specific error handlers. </s> remove         explicitly by the user of this method.\n </s> add         explicitly by the user of this method.  If the endpoint is prefixed\n        with a `.` it will be registered to the current blueprint, otherwise\n        it's an application independent endpoint. </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f))\n </s> remove             self.error_handlers[code] = f\n </s> add             self._register_error_handler(None, code_or_exception, f) </s> add         You can also register handlers for arbitrary exceptions::\n\n            @app.errorhandler(DatabaseError)\n            def special_exception_handler(error):\n                return 'Database connection failed', 500\n", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             request_started.send(self)\n <mask>             rv = self.preprocess_request()\n <mask>             if rv is None:\n <mask>                 rv = self.dispatch_request()\n <mask>         except HTTPException, e:\n <mask>             rv = self.handle_http_exception(e)\n <mask>         response = self.make_response(rv)\n <mask>         response = self.process_response(response)\n <mask>         request_finished.send(self, response=response)\n <mask>         return response\n <mask> \n </s> Added blueprint specific error handling </s> remove         handler = self.error_handlers.get(e.code)\n </s> add         handlers = self.error_handler_spec.get(request.blueprint)\n        if handlers and e.code in handlers:\n            handler = handlers[e.code]\n        else:\n            handler = self.error_handler_spec[None].get(e.code) </s> remove         handler = self.error_handlers.get(500)\n </s> add         handler = self.error_handler_spec[None].get(500) </s> add     def test_user_error_handling(self):\n        class MyException(Exception):\n            pass\n\n        app = flask.Flask(__name__)\n        @app.errorhandler(MyException)\n        def handle_my_exception(e):\n            assert isinstance(e, MyException)\n            return '42'\n        @app.route('/')\n        def index():\n            raise MyException()\n\n        c = app.test_client()\n        assert c.get('/').data == '42'\n </s> add         self.view_functions = {} </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f))\n </s> remove             self.error_handlers[code] = f\n </s> add             self._register_error_handler(None, code_or_exception, f)", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/app.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         self.static_url_path = static_url_path\n <mask>         self.deferred_functions = []\n <mask> \n <mask>     def _record(self, func):\n <mask>         self.deferred_functions.append(func)\n <mask> \n <mask>     def _record_once(self, func):\n </s> Added blueprint specific error handling </s> add     def test_user_error_handling(self):\n        class MyException(Exception):\n            pass\n\n        app = flask.Flask(__name__)\n        @app.errorhandler(MyException)\n        def handle_my_exception(e):\n            assert isinstance(e, MyException)\n            return '42'\n        @app.route('/')\n        def index():\n            raise MyException()\n\n        c = app.test_client()\n        assert c.get('/').data == '42'\n </s> remove         handler = self.error_handlers.get(e.code)\n </s> add         handlers = self.error_handler_spec.get(request.blueprint)\n        if handlers and e.code in handlers:\n            handler = handlers[e.code]\n        else:\n            handler = self.error_handler_spec[None].get(e.code) </s> remove             self.error_handlers[code] = f\n </s> add             self._register_error_handler(None, code_or_exception, f) </s> remove         explicitly by the user of this method.\n </s> add         explicitly by the user of this method.  If the endpoint is prefixed\n        with a `.` it will be registered to the current blueprint, otherwise\n        it's an application independent endpoint. </s> remove             app.error_handlers[404] = page_not_found\n </s> add             app.error_handler_spec[None][404] = page_not_found\n\n        Setting error handlers via assignments to :attr:`error_handler_spec`\n        however is discouraged as it requires fidling with nested dictionaries\n        and the special case for arbitrary exception types.\n\n        The first `None` refers to the active blueprint.  If the error\n        handler should be application wide `None` shall be used.\n\n        .. versionadded:: 0.7\n           One can now additionally also register custom exception types\n           that do not necessarily have to be a subclass of the\n           :class:~`werkzeug.exceptions.HTTPException` class. </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f))\n", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def endpoint(self, endpoint):\n <mask>         \"\"\"Like :meth:`Flask.endpoint` but for a module.  This does not\n <mask>         prefix the endpoint with the module name, this has to be done\n <mask>         explicitly by the user of this method.\n <mask>         \"\"\"\n <mask>         def decorator(f):\n <mask>             def register_endpoint(state):\n <mask>                 state.app.view_functions[endpoint] = f\n <mask>             self._record_once(register_endpoint)\n </s> Added blueprint specific error handling </s> remove             app.error_handlers[404] = page_not_found\n </s> add             app.error_handler_spec[None][404] = page_not_found\n\n        Setting error handlers via assignments to :attr:`error_handler_spec`\n        however is discouraged as it requires fidling with nested dictionaries\n        and the special case for arbitrary exception types.\n\n        The first `None` refers to the active blueprint.  If the error\n        handler should be application wide `None` shall be used.\n\n        .. versionadded:: 0.7\n           One can now additionally also register custom exception types\n           that do not necessarily have to be a subclass of the\n           :class:~`werkzeug.exceptions.HTTPException` class. </s> remove             self.error_handlers[code] = f\n </s> add             self._register_error_handler(None, code_or_exception, f) </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f))\n </s> add         You can also register handlers for arbitrary exceptions::\n\n            @app.errorhandler(DatabaseError)\n            def special_exception_handler(error):\n                return 'Database connection failed', 500\n </s> remove         handler = self.error_handlers.get(500)\n </s> add         handler = self.error_handler_spec[None].get(500) </s> add - it is not possible to define user exception handlers.  That way you can\n  provide custom error messages from a central hub for certain errors that\n  might occur during request processing (for instance database connection\n  errors, timeouts from remote resources etc.).\n- Blueprints can provide blueprint specific error handlers.", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         assert rv.status_code == 500\n <mask>         assert 'internal server error' == rv.data\n <mask> \n <mask>     def test_teardown_on_pop(self):\n <mask>         buffer = []\n <mask>         app = flask.Flask(__name__)\n <mask>         @app.teardown_request\n </s> Added blueprint specific error handling </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f))\n </s> add         self.view_functions = {} </s> remove         handler = self.error_handlers.get(e.code)\n </s> add         handlers = self.error_handler_spec.get(request.blueprint)\n        if handlers and e.code in handlers:\n            handler = handlers[e.code]\n        else:\n            handler = self.error_handler_spec[None].get(e.code) </s> remove         except HTTPException, e:\n            rv = self.handle_http_exception(e)\n </s> add         except Exception, e:\n            rv = self.handle_user_exception(e) </s> remove             self.error_handlers[code] = f\n </s> add             self._register_error_handler(None, code_or_exception, f) </s> add         You can also register handlers for arbitrary exceptions::\n\n            @app.errorhandler(DatabaseError)\n            def special_exception_handler(error):\n                return 'Database connection failed', 500\n", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     suite.addTest(unittest.makeSuite(BasicFunctionalityTestCase))\n <mask>     suite.addTest(unittest.makeSuite(TemplatingTestCase))\n <mask>     suite.addTest(unittest.makeSuite(ModuleTestCase))\n <mask>     suite.addTest(unittest.makeSuite(SendfileTestCase))\n <mask>     suite.addTest(unittest.makeSuite(LoggingTestCase))\n <mask>     suite.addTest(unittest.makeSuite(ConfigTestCase))\n <mask>     suite.addTest(unittest.makeSuite(SubdomainTestCase))\n <mask>     suite.addTest(unittest.makeSuite(DeprecationsTestCase))\n </s> Added blueprint specific error handling </s> add     def test_user_error_handling(self):\n        class MyException(Exception):\n            pass\n\n        app = flask.Flask(__name__)\n        @app.errorhandler(MyException)\n        def handle_my_exception(e):\n            assert isinstance(e, MyException)\n            return '42'\n        @app.route('/')\n        def index():\n            raise MyException()\n\n        c = app.test_client()\n        assert c.get('/').data == '42'\n </s> remove         explicitly by the user of this method.\n </s> add         explicitly by the user of this method.  If the endpoint is prefixed\n        with a `.` it will be registered to the current blueprint, otherwise\n        it's an application independent endpoint. </s> add         self.view_functions = {} </s> remove         except HTTPException, e:\n            rv = self.handle_http_exception(e)\n </s> add         except Exception, e:\n            rv = self.handle_user_exception(e) </s> remove         handler = self.error_handlers.get(500)\n </s> add         handler = self.error_handler_spec[None].get(500) </s> remove         handler = self.error_handlers.get(e.code)\n </s> add         handlers = self.error_handler_spec.get(request.blueprint)\n        if handlers and e.code in handlers:\n            handler = handlers[e.code]\n        else:\n            handler = self.error_handler_spec[None].get(e.code)", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>   requests that do not pop the request stack for testing.\n <mask> - because the Python standard library caches loggers, the name of\n <mask>   the logger is configurable now to better support unittests.\n <mask> \n <mask> Version 0.3.1\n <mask> -------------\n <mask> \n </s> Added TESTING flag.  This fixes #58. </s> add ``TESTING``                     enable/disable testing mode </s> add     #: The testing flask.  Set this to `True` to enable the test mode of\n    #: Flask extensions (and in the future probably also Flask itself).\n    #: For example this might activate unittest helpers that have an\n    #: additional runtime cost which should not be enabled by default.\n    #:\n    #: This attribute can also be configured from the config with the\n    #: `TESTING` configuration key.  Defaults to `False`.\n    testing = ConfigAttribute('TESTING')\n </s> add         'TESTING':                              False,", "html_url": "https://github.com/pallets/flask/commit/f5fb4576577cbedcedba9eb16d9fdace18c9292c", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> =============================== =========================================\n <mask> ``DEBUG``                       enable/disable debug mode\n <mask> ``SECRET_KEY``                  the secret key\n <mask> ``SESSION_COOKIE_NAME``         the name of the session cookie\n <mask> ``PERMANENT_SESSION_LIFETIME``  the lifetime of a permanent session as\n <mask>                                 :class:`datetime.timedelta` object.\n <mask> ``USE_X_SENDFILE``              enable/disable x-sendfile\n <mask> =============================== =========================================\n </s> Added TESTING flag.  This fixes #58. </s> add - added `TESTING` switch that can activate unittesting helpers. </s> add     #: The testing flask.  Set this to `True` to enable the test mode of\n    #: Flask extensions (and in the future probably also Flask itself).\n    #: For example this might activate unittest helpers that have an\n    #: additional runtime cost which should not be enabled by default.\n    #:\n    #: This attribute can also be configured from the config with the\n    #: `TESTING` configuration key.  Defaults to `False`.\n    testing = ConfigAttribute('TESTING')\n </s> add         'TESTING':                              False,", "html_url": "https://github.com/pallets/flask/commit/f5fb4576577cbedcedba9eb16d9fdace18c9292c", "file_name": "docs/config.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     #: This attribute can also be configured from the config with the `DEBUG`\n <mask>     #: configuration key.  Defaults to `False`.\n <mask>     debug = ConfigAttribute('DEBUG')\n <mask> \n <mask>     #: If a secret key is set, cryptographic components can use this to\n <mask>     #: sign cookies and other things.  Set this to a complex random value\n <mask>     #: when you want to use the secure cookie for instance.\n <mask>     #:\n </s> Added TESTING flag.  This fixes #58. </s> add ``TESTING``                     enable/disable testing mode </s> add - added `TESTING` switch that can activate unittesting helpers. </s> add         'TESTING':                              False,", "html_url": "https://github.com/pallets/flask/commit/f5fb4576577cbedcedba9eb16d9fdace18c9292c", "file_name": "flask.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     default_config = ImmutableDict({\n <mask>         'DEBUG':                                False,\n <mask>         'SECRET_KEY':                           None,\n <mask>         'SESSION_COOKIE_NAME':                  'session',\n <mask>         'PERMANENT_SESSION_LIFETIME':           timedelta(days=31),\n <mask>         'USE_X_SENDFILE':                       False,\n </s> Added TESTING flag.  This fixes #58. </s> add     #: The testing flask.  Set this to `True` to enable the test mode of\n    #: Flask extensions (and in the future probably also Flask itself).\n    #: For example this might activate unittest helpers that have an\n    #: additional runtime cost which should not be enabled by default.\n    #:\n    #: This attribute can also be configured from the config with the\n    #: `TESTING` configuration key.  Defaults to `False`.\n    testing = ConfigAttribute('TESTING')\n </s> add ``TESTING``                     enable/disable testing mode </s> add - added `TESTING` switch that can activate unittesting helpers.", "html_url": "https://github.com/pallets/flask/commit/f5fb4576577cbedcedba9eb16d9fdace18c9292c", "file_name": "flask.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     for x, node in enumerate(from_imports):\n <mask>         values = node.value\n <mask>         if (values[0].value == 'flask') and (values[1].value == 'ext'):\n <mask>             # Case 1\n <mask>             if len(node.value) == 3:\n <mask>                 package = values[2].value\n </s> Add skip to fix unnoticed bug with good imports\n\nFixes logic so that imports that should not be changed are skipped, which was not happening correctly before. </s> add def test_no_change_to_import():\n    red = RedBaron(\"from flask import Flask\")\n    output = migrate.fix_tester(red)\n    assert output == \"from flask import Flask\" </s> remove def test__named_from_import():\n </s> add def test_named_from_import():", "html_url": "https://github.com/pallets/flask/commit/f6c45afb6ffa9fc1bd3d3637f7d38e423798dce9", "file_name": "scripts/flaskext_migrate.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     output = migrate.fix_tester(red)\n <mask>     assert output == \"import flask_foo as foobar\"\n <mask> \n <mask> \n <mask> def test__named_from_import():\n <mask>     red = RedBaron(\"from flask.ext.foo import bar as baz\")\n <mask>     output = migrate.fix_tester(red)\n <mask>     assert output == \"from flask_foo import bar as baz\"\n <mask> \n <mask> \n </s> Add skip to fix unnoticed bug with good imports\n\nFixes logic so that imports that should not be changed are skipped, which was not happening correctly before. </s> add def test_no_change_to_import():\n    red = RedBaron(\"from flask import Flask\")\n    output = migrate.fix_tester(red)\n    assert output == \"from flask import Flask\" </s> add         if len(values) < 2:\n            continue", "html_url": "https://github.com/pallets/flask/commit/f6c45afb6ffa9fc1bd3d3637f7d38e423798dce9", "file_name": "scripts/test_import_migration.py"}
{"docstring_tokens": "keep keep keep add", "code_tokens": " <mask>                    \"flask.ext.foo.bar(var)\")\n <mask>     output = migrate.fix_tester(red)\n <mask>     assert output == (\"import flask_foo\\n\\n\"\n <mask>                       \"flask_foo.bar(var)\")\n </s> Add skip to fix unnoticed bug with good imports\n\nFixes logic so that imports that should not be changed are skipped, which was not happening correctly before. </s> remove def test__named_from_import():\n </s> add def test_named_from_import(): </s> add         if len(values) < 2:\n            continue", "html_url": "https://github.com/pallets/flask/commit/f6c45afb6ffa9fc1bd3d3637f7d38e423798dce9", "file_name": "scripts/test_import_migration.py"}
{"docstring_tokens": "keep keep replace keep keep keep replace keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def set_debug_value(ctx, value):\n <mask>     ctx.ensure_object(ScriptInfo).debug = value\n <mask> \n <mask> \n <mask> def set_app_value(ctx, value):\n <mask>     if value is not None:\n <mask>         if os.path.isfile(value):\n <mask>             value = prepare_exec_for_file(value)\n </s> Switch to newer click (2.0) </s> remove         'click>=0.6',\n </s> add         'click>=2.0',", "html_url": "https://github.com/pallets/flask/commit/f6d25bbc4f95112e9f5f85096d12a61ed43b38b8", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     install_requires=[\n <mask>         'Werkzeug>=0.7',\n <mask>         'Jinja2>=2.4',\n <mask>         'itsdangerous>=0.21',\n <mask>         'click>=0.6',\n <mask>     ],\n <mask>     classifiers=[\n <mask>         'Development Status :: 4 - Beta',\n <mask>         'Environment :: Web Environment',\n <mask>         'Intended Audience :: Developers',\n </s> Switch to newer click (2.0) </s> remove def set_app_value(ctx, value):\n </s> add def set_app_value(ctx, param, value): </s> remove def set_debug_value(ctx, value):\n </s> add def set_debug_value(ctx, param, value):", "html_url": "https://github.com/pallets/flask/commit/f6d25bbc4f95112e9f5f85096d12a61ed43b38b8", "file_name": "setup.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> - Add ``routes`` CLI command to output routes registered on the application.\n <mask>   (`#2259`_)\n <mask> \n <mask> .. _#1489: https://github.com/pallets/flask/pull/1489\n <mask> .. _#1898: https://github.com/pallets/flask/pull/1898\n <mask> .. _#1936: https://github.com/pallets/flask/pull/1936\n <mask> .. _#2017: https://github.com/pallets/flask/pull/2017\n <mask> .. _#2223: https://github.com/pallets/flask/pull/2223\n </s> refactor session cookie domain logic\ncache result of session cookie domain\nadd warnings for session cookie domain issues\nadd changelog </s> add .. _#2282: https://github.com/pallets/flask/pull/2282 </s> remove         \"\"\"Helpful helper method that returns the cookie domain that should\n        be used for the session cookie if session cookies are used.\n </s> add         \"\"\"Returns the domain that should be set for the session cookie.\n        \n        Uses ``SESSION_COOKIE_DOMAIN`` if it is configured, otherwise\n        falls back to detecting the domain based on ``SERVER_NAME``.\n        \n        Once detected (or if not set at all), ``SESSION_COOKIE_DOMAIN`` is\n        updated to avoid re-running the logic. </s> remove         if app.config['SESSION_COOKIE_DOMAIN'] is not None:\n            return app.config['SESSION_COOKIE_DOMAIN']\n        if app.config['SERVER_NAME'] is not None:\n            # chop off the port which is usually not supported by browsers\n            rv = '.' + app.config['SERVER_NAME'].rsplit(':', 1)[0]\n\n            # Google chrome does not like cookies set to .localhost, so\n            # we just go with no domain then.  Flask documents anyways that\n            # cross domain cookies need a fully qualified domain name\n            if rv == '.localhost':\n                rv = None\n\n            # If we infer the cookie domain from the server name we need\n            # to check if we are in a subpath.  In that case we can't\n            # set a cross domain cookie.\n            if rv is not None:\n                path = self.get_cookie_path(app)\n                if path != '/':\n                    rv = rv.lstrip('.')\n\n            return rv\n </s> add         rv = app.config['SESSION_COOKIE_DOMAIN']\n\n        # set explicitly, or cached from SERVER_NAME detection\n        # if False, return None\n        if rv is not None:\n            return rv if rv else None\n\n        rv = app.config['SERVER_NAME']\n\n        # server name not set, cache False to return none next time\n        if not rv:\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        # chop off the port which is usually not supported by browsers\n        # remove any leading '.' since we'll add that later\n        rv = rv.rsplit(':', 1)[0].lstrip('.')\n\n        if '.' not in rv:\n            # Chrome doesn't allow names without a '.'\n            # this should only come up with localhost\n            # hack around this by not setting the name, and show a warning\n            warnings.warn(\n                '\"{rv}\" is not a valid cookie domain, it must contain a \".\".'\n                ' Add an entry to your hosts file, for example'\n                ' \"{rv}.localdomain\", and use that instead.'.format(rv=rv)\n            )\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        ip = is_ip(rv)\n\n        if ip:\n            warnings.warn(\n                'The session cookie domain is an IP address. This may not work'\n                ' as intended in some browsers. Add an entry to your hosts'\n                ' file, for example \"localhost.localdomain\", and use that'\n                ' instead.'\n            )\n\n        # if this is not an ip and app is mounted at the root, allow subdomain\n        # matching by adding a '.' prefix\n        if self.get_cookie_path(app) == '/' and not ip:\n            rv = '.' + rv\n\n        app.config['SESSION_COOKIE_DOMAIN'] = rv\n        return rv </s> remove     :returns: True if string is an IP, False if not\n    :rtype: boolean\n </s> add     :param value: value to check\n    :type value: str\n\n    :return: True if string is an IP address\n    :rtype: bool </s> remove     :param string: the string to check if it an IP or not\n    :param var_name: the name of the string that is being checked\n </s> add def is_ip(value):\n    \"\"\"Determine if the given string is an IP address. </s> remove def is_ip(ip):\n    \"\"\"Returns the if the string received is an IP or not.\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> .. _#2254: https://github.com/pallets/flask/pull/2254\n <mask> .. _#2256: https://github.com/pallets/flask/pull/2256\n <mask> .. _#2259: https://github.com/pallets/flask/pull/2259\n <mask> \n <mask> Version 0.12.1\n <mask> --------------\n <mask> \n <mask> Bugfix release, released on March 31st 2017\n <mask> \n </s> refactor session cookie domain logic\ncache result of session cookie domain\nadd warnings for session cookie domain issues\nadd changelog </s> add - Show warning when session cookie domain is a bare hostname or an IP\n  address, as these may not behave properly in some browsers, such as Chrome.\n  (`#2282`_)\n- Allow IP address as exact session cookie domain. (`#2282`_)\n- ``SESSION_COOKIE_DOMAIN`` is set if it is detected through ``SERVER_NAME``.\n  (`#2282`_) </s> remove         \"\"\"Helpful helper method that returns the cookie domain that should\n        be used for the session cookie if session cookies are used.\n </s> add         \"\"\"Returns the domain that should be set for the session cookie.\n        \n        Uses ``SESSION_COOKIE_DOMAIN`` if it is configured, otherwise\n        falls back to detecting the domain based on ``SERVER_NAME``.\n        \n        Once detected (or if not set at all), ``SESSION_COOKIE_DOMAIN`` is\n        updated to avoid re-running the logic. </s> remove         if domain is not None:\n            if is_ip(domain):\n                warnings.warn(\"IP introduced in SESSION_COOKIE_DOMAIN\", RuntimeWarning)\n </s> add  </s> remove         if app.config['SESSION_COOKIE_DOMAIN'] is not None:\n            return app.config['SESSION_COOKIE_DOMAIN']\n        if app.config['SERVER_NAME'] is not None:\n            # chop off the port which is usually not supported by browsers\n            rv = '.' + app.config['SERVER_NAME'].rsplit(':', 1)[0]\n\n            # Google chrome does not like cookies set to .localhost, so\n            # we just go with no domain then.  Flask documents anyways that\n            # cross domain cookies need a fully qualified domain name\n            if rv == '.localhost':\n                rv = None\n\n            # If we infer the cookie domain from the server name we need\n            # to check if we are in a subpath.  In that case we can't\n            # set a cross domain cookie.\n            if rv is not None:\n                path = self.get_cookie_path(app)\n                if path != '/':\n                    rv = rv.lstrip('.')\n\n            return rv\n </s> add         rv = app.config['SESSION_COOKIE_DOMAIN']\n\n        # set explicitly, or cached from SERVER_NAME detection\n        # if False, return None\n        if rv is not None:\n            return rv if rv else None\n\n        rv = app.config['SERVER_NAME']\n\n        # server name not set, cache False to return none next time\n        if not rv:\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        # chop off the port which is usually not supported by browsers\n        # remove any leading '.' since we'll add that later\n        rv = rv.rsplit(':', 1)[0].lstrip('.')\n\n        if '.' not in rv:\n            # Chrome doesn't allow names without a '.'\n            # this should only come up with localhost\n            # hack around this by not setting the name, and show a warning\n            warnings.warn(\n                '\"{rv}\" is not a valid cookie domain, it must contain a \".\".'\n                ' Add an entry to your hosts file, for example'\n                ' \"{rv}.localdomain\", and use that instead.'.format(rv=rv)\n            )\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        ip = is_ip(rv)\n\n        if ip:\n            warnings.warn(\n                'The session cookie domain is an IP address. This may not work'\n                ' as intended in some browsers. Add an entry to your hosts'\n                ' file, for example \"localhost.localdomain\", and use that'\n                ' instead.'\n            )\n\n        # if this is not an ip and app is mounted at the root, allow subdomain\n        # matching by adding a '.' prefix\n        if self.get_cookie_path(app) == '/' and not ip:\n            rv = '.' + rv\n\n        app.config['SESSION_COOKIE_DOMAIN'] = rv\n        return rv </s> remove from warnings import warn\n </s> add import warnings </s> remove             socket.inet_pton(family, ip)\n </s> add             socket.inet_pton(family, value)", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "CHANGES"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> import os\n <mask> import sys\n <mask> import pkgutil\n <mask> import posixpath\n <mask> import mimetypes\n </s> refactor session cookie domain logic\ncache result of session cookie domain\nadd warnings for session cookie domain issues\nadd changelog </s> remove         if domain is not None:\n            if is_ip(domain):\n                warnings.warn(\"IP introduced in SESSION_COOKIE_DOMAIN\", RuntimeWarning)\n </s> add  </s> remove         if app.config['SESSION_COOKIE_DOMAIN'] is not None:\n            return app.config['SESSION_COOKIE_DOMAIN']\n        if app.config['SERVER_NAME'] is not None:\n            # chop off the port which is usually not supported by browsers\n            rv = '.' + app.config['SERVER_NAME'].rsplit(':', 1)[0]\n\n            # Google chrome does not like cookies set to .localhost, so\n            # we just go with no domain then.  Flask documents anyways that\n            # cross domain cookies need a fully qualified domain name\n            if rv == '.localhost':\n                rv = None\n\n            # If we infer the cookie domain from the server name we need\n            # to check if we are in a subpath.  In that case we can't\n            # set a cross domain cookie.\n            if rv is not None:\n                path = self.get_cookie_path(app)\n                if path != '/':\n                    rv = rv.lstrip('.')\n\n            return rv\n </s> add         rv = app.config['SESSION_COOKIE_DOMAIN']\n\n        # set explicitly, or cached from SERVER_NAME detection\n        # if False, return None\n        if rv is not None:\n            return rv if rv else None\n\n        rv = app.config['SERVER_NAME']\n\n        # server name not set, cache False to return none next time\n        if not rv:\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        # chop off the port which is usually not supported by browsers\n        # remove any leading '.' since we'll add that later\n        rv = rv.rsplit(':', 1)[0].lstrip('.')\n\n        if '.' not in rv:\n            # Chrome doesn't allow names without a '.'\n            # this should only come up with localhost\n            # hack around this by not setting the name, and show a warning\n            warnings.warn(\n                '\"{rv}\" is not a valid cookie domain, it must contain a \".\".'\n                ' Add an entry to your hosts file, for example'\n                ' \"{rv}.localdomain\", and use that instead.'.format(rv=rv)\n            )\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        ip = is_ip(rv)\n\n        if ip:\n            warnings.warn(\n                'The session cookie domain is an IP address. This may not work'\n                ' as intended in some browsers. Add an entry to your hosts'\n                ' file, for example \"localhost.localdomain\", and use that'\n                ' instead.'\n            )\n\n        # if this is not an ip and app is mounted at the root, allow subdomain\n        # matching by adding a '.' prefix\n        if self.get_cookie_path(app) == '/' and not ip:\n            rv = '.' + rv\n\n        app.config['SESSION_COOKIE_DOMAIN'] = rv\n        return rv </s> remove         \"\"\"Helpful helper method that returns the cookie domain that should\n        be used for the session cookie if session cookies are used.\n </s> add         \"\"\"Returns the domain that should be set for the session cookie.\n        \n        Uses ``SESSION_COOKIE_DOMAIN`` if it is configured, otherwise\n        falls back to detecting the domain based on ``SERVER_NAME``.\n        \n        Once detected (or if not set at all), ``SESSION_COOKIE_DOMAIN`` is\n        updated to avoid re-running the logic. </s> remove from warnings import warn\n </s> add import warnings </s> remove             socket.inet_pton(family, ip)\n </s> add             socket.inet_pton(family, value) </s> remove     import socket\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :rtype: int\n <mask>     \"\"\"\n <mask>     return td.days * 60 * 60 * 24 + td.seconds\n <mask> \n <mask> def is_ip(ip):\n <mask>     \"\"\"Returns the if the string received is an IP or not.\n <mask> \n <mask>     :param string: the string to check if it an IP or not\n <mask>     :param var_name: the name of the string that is being checked\n <mask> \n <mask>     :returns: True if string is an IP, False if not\n </s> refactor session cookie domain logic\ncache result of session cookie domain\nadd warnings for session cookie domain issues\nadd changelog </s> remove     :param string: the string to check if it an IP or not\n    :param var_name: the name of the string that is being checked\n </s> add def is_ip(value):\n    \"\"\"Determine if the given string is an IP address. </s> remove     :returns: True if string is an IP, False if not\n    :rtype: boolean\n </s> add     :param value: value to check\n    :type value: str\n\n    :return: True if string is an IP address\n    :rtype: bool </s> remove         \"\"\"Helpful helper method that returns the cookie domain that should\n        be used for the session cookie if session cookies are used.\n </s> add         \"\"\"Returns the domain that should be set for the session cookie.\n        \n        Uses ``SESSION_COOKIE_DOMAIN`` if it is configured, otherwise\n        falls back to detecting the domain based on ``SERVER_NAME``.\n        \n        Once detected (or if not set at all), ``SESSION_COOKIE_DOMAIN`` is\n        updated to avoid re-running the logic. </s> remove         if app.config['SESSION_COOKIE_DOMAIN'] is not None:\n            return app.config['SESSION_COOKIE_DOMAIN']\n        if app.config['SERVER_NAME'] is not None:\n            # chop off the port which is usually not supported by browsers\n            rv = '.' + app.config['SERVER_NAME'].rsplit(':', 1)[0]\n\n            # Google chrome does not like cookies set to .localhost, so\n            # we just go with no domain then.  Flask documents anyways that\n            # cross domain cookies need a fully qualified domain name\n            if rv == '.localhost':\n                rv = None\n\n            # If we infer the cookie domain from the server name we need\n            # to check if we are in a subpath.  In that case we can't\n            # set a cross domain cookie.\n            if rv is not None:\n                path = self.get_cookie_path(app)\n                if path != '/':\n                    rv = rv.lstrip('.')\n\n            return rv\n </s> add         rv = app.config['SESSION_COOKIE_DOMAIN']\n\n        # set explicitly, or cached from SERVER_NAME detection\n        # if False, return None\n        if rv is not None:\n            return rv if rv else None\n\n        rv = app.config['SERVER_NAME']\n\n        # server name not set, cache False to return none next time\n        if not rv:\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        # chop off the port which is usually not supported by browsers\n        # remove any leading '.' since we'll add that later\n        rv = rv.rsplit(':', 1)[0].lstrip('.')\n\n        if '.' not in rv:\n            # Chrome doesn't allow names without a '.'\n            # this should only come up with localhost\n            # hack around this by not setting the name, and show a warning\n            warnings.warn(\n                '\"{rv}\" is not a valid cookie domain, it must contain a \".\".'\n                ' Add an entry to your hosts file, for example'\n                ' \"{rv}.localdomain\", and use that instead.'.format(rv=rv)\n            )\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        ip = is_ip(rv)\n\n        if ip:\n            warnings.warn(\n                'The session cookie domain is an IP address. This may not work'\n                ' as intended in some browsers. Add an entry to your hosts'\n                ' file, for example \"localhost.localdomain\", and use that'\n                ' instead.'\n            )\n\n        # if this is not an ip and app is mounted at the root, allow subdomain\n        # matching by adding a '.' prefix\n        if self.get_cookie_path(app) == '/' and not ip:\n            rv = '.' + rv\n\n        app.config['SESSION_COOKIE_DOMAIN'] = rv\n        return rv </s> remove     import socket\n </s> add  </s> remove         if domain is not None:\n            if is_ip(domain):\n                warnings.warn(\"IP introduced in SESSION_COOKIE_DOMAIN\", RuntimeWarning)\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def is_ip(ip):\n <mask>     \"\"\"Returns the if the string received is an IP or not.\n <mask> \n <mask>     :param string: the string to check if it an IP or not\n <mask>     :param var_name: the name of the string that is being checked\n <mask> \n <mask>     :returns: True if string is an IP, False if not\n <mask>     :rtype: boolean\n <mask>     \"\"\"\n <mask>     import socket\n </s> refactor session cookie domain logic\ncache result of session cookie domain\nadd warnings for session cookie domain issues\nadd changelog </s> remove def is_ip(ip):\n    \"\"\"Returns the if the string received is an IP or not.\n </s> add  </s> remove     :returns: True if string is an IP, False if not\n    :rtype: boolean\n </s> add     :param value: value to check\n    :type value: str\n\n    :return: True if string is an IP address\n    :rtype: bool </s> remove     import socket\n </s> add  </s> remove         \"\"\"Helpful helper method that returns the cookie domain that should\n        be used for the session cookie if session cookies are used.\n </s> add         \"\"\"Returns the domain that should be set for the session cookie.\n        \n        Uses ``SESSION_COOKIE_DOMAIN`` if it is configured, otherwise\n        falls back to detecting the domain based on ``SERVER_NAME``.\n        \n        Once detected (or if not set at all), ``SESSION_COOKIE_DOMAIN`` is\n        updated to avoid re-running the logic. </s> remove         if app.config['SESSION_COOKIE_DOMAIN'] is not None:\n            return app.config['SESSION_COOKIE_DOMAIN']\n        if app.config['SERVER_NAME'] is not None:\n            # chop off the port which is usually not supported by browsers\n            rv = '.' + app.config['SERVER_NAME'].rsplit(':', 1)[0]\n\n            # Google chrome does not like cookies set to .localhost, so\n            # we just go with no domain then.  Flask documents anyways that\n            # cross domain cookies need a fully qualified domain name\n            if rv == '.localhost':\n                rv = None\n\n            # If we infer the cookie domain from the server name we need\n            # to check if we are in a subpath.  In that case we can't\n            # set a cross domain cookie.\n            if rv is not None:\n                path = self.get_cookie_path(app)\n                if path != '/':\n                    rv = rv.lstrip('.')\n\n            return rv\n </s> add         rv = app.config['SESSION_COOKIE_DOMAIN']\n\n        # set explicitly, or cached from SERVER_NAME detection\n        # if False, return None\n        if rv is not None:\n            return rv if rv else None\n\n        rv = app.config['SERVER_NAME']\n\n        # server name not set, cache False to return none next time\n        if not rv:\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        # chop off the port which is usually not supported by browsers\n        # remove any leading '.' since we'll add that later\n        rv = rv.rsplit(':', 1)[0].lstrip('.')\n\n        if '.' not in rv:\n            # Chrome doesn't allow names without a '.'\n            # this should only come up with localhost\n            # hack around this by not setting the name, and show a warning\n            warnings.warn(\n                '\"{rv}\" is not a valid cookie domain, it must contain a \".\".'\n                ' Add an entry to your hosts file, for example'\n                ' \"{rv}.localdomain\", and use that instead.'.format(rv=rv)\n            )\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        ip = is_ip(rv)\n\n        if ip:\n            warnings.warn(\n                'The session cookie domain is an IP address. This may not work'\n                ' as intended in some browsers. Add an entry to your hosts'\n                ' file, for example \"localhost.localdomain\", and use that'\n                ' instead.'\n            )\n\n        # if this is not an ip and app is mounted at the root, allow subdomain\n        # matching by adding a '.' prefix\n        if self.get_cookie_path(app) == '/' and not ip:\n            rv = '.' + rv\n\n        app.config['SESSION_COOKIE_DOMAIN'] = rv\n        return rv </s> remove         if domain is not None:\n            if is_ip(domain):\n                warnings.warn(\"IP introduced in SESSION_COOKIE_DOMAIN\", RuntimeWarning)\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     :param string: the string to check if it an IP or not\n <mask>     :param var_name: the name of the string that is being checked\n <mask> \n <mask>     :returns: True if string is an IP, False if not\n <mask>     :rtype: boolean\n <mask>     \"\"\"\n <mask>     import socket\n <mask> \n <mask>     for family in (socket.AF_INET, socket.AF_INET6):\n <mask>         try:\n </s> refactor session cookie domain logic\ncache result of session cookie domain\nadd warnings for session cookie domain issues\nadd changelog </s> remove     :param string: the string to check if it an IP or not\n    :param var_name: the name of the string that is being checked\n </s> add def is_ip(value):\n    \"\"\"Determine if the given string is an IP address. </s> remove def is_ip(ip):\n    \"\"\"Returns the if the string received is an IP or not.\n </s> add  </s> remove     import socket\n </s> add  </s> remove         \"\"\"Helpful helper method that returns the cookie domain that should\n        be used for the session cookie if session cookies are used.\n </s> add         \"\"\"Returns the domain that should be set for the session cookie.\n        \n        Uses ``SESSION_COOKIE_DOMAIN`` if it is configured, otherwise\n        falls back to detecting the domain based on ``SERVER_NAME``.\n        \n        Once detected (or if not set at all), ``SESSION_COOKIE_DOMAIN`` is\n        updated to avoid re-running the logic. </s> remove         if app.config['SESSION_COOKIE_DOMAIN'] is not None:\n            return app.config['SESSION_COOKIE_DOMAIN']\n        if app.config['SERVER_NAME'] is not None:\n            # chop off the port which is usually not supported by browsers\n            rv = '.' + app.config['SERVER_NAME'].rsplit(':', 1)[0]\n\n            # Google chrome does not like cookies set to .localhost, so\n            # we just go with no domain then.  Flask documents anyways that\n            # cross domain cookies need a fully qualified domain name\n            if rv == '.localhost':\n                rv = None\n\n            # If we infer the cookie domain from the server name we need\n            # to check if we are in a subpath.  In that case we can't\n            # set a cross domain cookie.\n            if rv is not None:\n                path = self.get_cookie_path(app)\n                if path != '/':\n                    rv = rv.lstrip('.')\n\n            return rv\n </s> add         rv = app.config['SESSION_COOKIE_DOMAIN']\n\n        # set explicitly, or cached from SERVER_NAME detection\n        # if False, return None\n        if rv is not None:\n            return rv if rv else None\n\n        rv = app.config['SERVER_NAME']\n\n        # server name not set, cache False to return none next time\n        if not rv:\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        # chop off the port which is usually not supported by browsers\n        # remove any leading '.' since we'll add that later\n        rv = rv.rsplit(':', 1)[0].lstrip('.')\n\n        if '.' not in rv:\n            # Chrome doesn't allow names without a '.'\n            # this should only come up with localhost\n            # hack around this by not setting the name, and show a warning\n            warnings.warn(\n                '\"{rv}\" is not a valid cookie domain, it must contain a \".\".'\n                ' Add an entry to your hosts file, for example'\n                ' \"{rv}.localdomain\", and use that instead.'.format(rv=rv)\n            )\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        ip = is_ip(rv)\n\n        if ip:\n            warnings.warn(\n                'The session cookie domain is an IP address. This may not work'\n                ' as intended in some browsers. Add an entry to your hosts'\n                ' file, for example \"localhost.localdomain\", and use that'\n                ' instead.'\n            )\n\n        # if this is not an ip and app is mounted at the root, allow subdomain\n        # matching by adding a '.' prefix\n        if self.get_cookie_path(app) == '/' and not ip:\n            rv = '.' + rv\n\n        app.config['SESSION_COOKIE_DOMAIN'] = rv\n        return rv </s> remove             socket.inet_pton(family, ip)\n </s> add             socket.inet_pton(family, value)", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace", "code_tokens": " <mask>     :returns: True if string is an IP, False if not\n <mask>     :rtype: boolean\n <mask>     \"\"\"\n <mask>     import socket\n <mask> \n <mask>     for family in (socket.AF_INET, socket.AF_INET6):\n <mask>         try:\n <mask>             socket.inet_pton(family, ip)\n </s> refactor session cookie domain logic\ncache result of session cookie domain\nadd warnings for session cookie domain issues\nadd changelog </s> remove     :returns: True if string is an IP, False if not\n    :rtype: boolean\n </s> add     :param value: value to check\n    :type value: str\n\n    :return: True if string is an IP address\n    :rtype: bool </s> remove     :param string: the string to check if it an IP or not\n    :param var_name: the name of the string that is being checked\n </s> add def is_ip(value):\n    \"\"\"Determine if the given string is an IP address. </s> remove def is_ip(ip):\n    \"\"\"Returns the if the string received is an IP or not.\n </s> add  </s> remove         \"\"\"Helpful helper method that returns the cookie domain that should\n        be used for the session cookie if session cookies are used.\n </s> add         \"\"\"Returns the domain that should be set for the session cookie.\n        \n        Uses ``SESSION_COOKIE_DOMAIN`` if it is configured, otherwise\n        falls back to detecting the domain based on ``SERVER_NAME``.\n        \n        Once detected (or if not set at all), ``SESSION_COOKIE_DOMAIN`` is\n        updated to avoid re-running the logic. </s> remove         if app.config['SESSION_COOKIE_DOMAIN'] is not None:\n            return app.config['SESSION_COOKIE_DOMAIN']\n        if app.config['SERVER_NAME'] is not None:\n            # chop off the port which is usually not supported by browsers\n            rv = '.' + app.config['SERVER_NAME'].rsplit(':', 1)[0]\n\n            # Google chrome does not like cookies set to .localhost, so\n            # we just go with no domain then.  Flask documents anyways that\n            # cross domain cookies need a fully qualified domain name\n            if rv == '.localhost':\n                rv = None\n\n            # If we infer the cookie domain from the server name we need\n            # to check if we are in a subpath.  In that case we can't\n            # set a cross domain cookie.\n            if rv is not None:\n                path = self.get_cookie_path(app)\n                if path != '/':\n                    rv = rv.lstrip('.')\n\n            return rv\n </s> add         rv = app.config['SESSION_COOKIE_DOMAIN']\n\n        # set explicitly, or cached from SERVER_NAME detection\n        # if False, return None\n        if rv is not None:\n            return rv if rv else None\n\n        rv = app.config['SERVER_NAME']\n\n        # server name not set, cache False to return none next time\n        if not rv:\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        # chop off the port which is usually not supported by browsers\n        # remove any leading '.' since we'll add that later\n        rv = rv.rsplit(':', 1)[0].lstrip('.')\n\n        if '.' not in rv:\n            # Chrome doesn't allow names without a '.'\n            # this should only come up with localhost\n            # hack around this by not setting the name, and show a warning\n            warnings.warn(\n                '\"{rv}\" is not a valid cookie domain, it must contain a \".\".'\n                ' Add an entry to your hosts file, for example'\n                ' \"{rv}.localdomain\", and use that instead.'.format(rv=rv)\n            )\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        ip = is_ip(rv)\n\n        if ip:\n            warnings.warn(\n                'The session cookie domain is an IP address. This may not work'\n                ' as intended in some browsers. Add an entry to your hosts'\n                ' file, for example \"localhost.localdomain\", and use that'\n                ' instead.'\n            )\n\n        # if this is not an ip and app is mounted at the root, allow subdomain\n        # matching by adding a '.' prefix\n        if self.get_cookie_path(app) == '/' and not ip:\n            rv = '.' + rv\n\n        app.config['SESSION_COOKIE_DOMAIN'] = rv\n        return rv", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \"\"\"\n <mask> \n <mask> import uuid\n <mask> import hashlib\n <mask> from warnings import warn\n <mask> from base64 import b64encode, b64decode\n <mask> from datetime import datetime\n <mask> from werkzeug.http import http_date, parse_date\n <mask> from werkzeug.datastructures import CallbackDict\n <mask> from . import Markup, json\n </s> refactor session cookie domain logic\ncache result of session cookie domain\nadd warnings for session cookie domain issues\nadd changelog </s> remove         if app.config['SESSION_COOKIE_DOMAIN'] is not None:\n            return app.config['SESSION_COOKIE_DOMAIN']\n        if app.config['SERVER_NAME'] is not None:\n            # chop off the port which is usually not supported by browsers\n            rv = '.' + app.config['SERVER_NAME'].rsplit(':', 1)[0]\n\n            # Google chrome does not like cookies set to .localhost, so\n            # we just go with no domain then.  Flask documents anyways that\n            # cross domain cookies need a fully qualified domain name\n            if rv == '.localhost':\n                rv = None\n\n            # If we infer the cookie domain from the server name we need\n            # to check if we are in a subpath.  In that case we can't\n            # set a cross domain cookie.\n            if rv is not None:\n                path = self.get_cookie_path(app)\n                if path != '/':\n                    rv = rv.lstrip('.')\n\n            return rv\n </s> add         rv = app.config['SESSION_COOKIE_DOMAIN']\n\n        # set explicitly, or cached from SERVER_NAME detection\n        # if False, return None\n        if rv is not None:\n            return rv if rv else None\n\n        rv = app.config['SERVER_NAME']\n\n        # server name not set, cache False to return none next time\n        if not rv:\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        # chop off the port which is usually not supported by browsers\n        # remove any leading '.' since we'll add that later\n        rv = rv.rsplit(':', 1)[0].lstrip('.')\n\n        if '.' not in rv:\n            # Chrome doesn't allow names without a '.'\n            # this should only come up with localhost\n            # hack around this by not setting the name, and show a warning\n            warnings.warn(\n                '\"{rv}\" is not a valid cookie domain, it must contain a \".\".'\n                ' Add an entry to your hosts file, for example'\n                ' \"{rv}.localdomain\", and use that instead.'.format(rv=rv)\n            )\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        ip = is_ip(rv)\n\n        if ip:\n            warnings.warn(\n                'The session cookie domain is an IP address. This may not work'\n                ' as intended in some browsers. Add an entry to your hosts'\n                ' file, for example \"localhost.localdomain\", and use that'\n                ' instead.'\n            )\n\n        # if this is not an ip and app is mounted at the root, allow subdomain\n        # matching by adding a '.' prefix\n        if self.get_cookie_path(app) == '/' and not ip:\n            rv = '.' + rv\n\n        app.config['SESSION_COOKIE_DOMAIN'] = rv\n        return rv </s> remove     import socket\n </s> add  </s> remove         \"\"\"Helpful helper method that returns the cookie domain that should\n        be used for the session cookie if session cookies are used.\n </s> add         \"\"\"Returns the domain that should be set for the session cookie.\n        \n        Uses ``SESSION_COOKIE_DOMAIN`` if it is configured, otherwise\n        falls back to detecting the domain based on ``SERVER_NAME``.\n        \n        Once detected (or if not set at all), ``SESSION_COOKIE_DOMAIN`` is\n        updated to avoid re-running the logic. </s> remove def is_ip(ip):\n    \"\"\"Returns the if the string received is an IP or not.\n </s> add  </s> remove     :returns: True if string is an IP, False if not\n    :rtype: boolean\n </s> add     :param value: value to check\n    :type value: str\n\n    :return: True if string is an IP address\n    :rtype: bool </s> remove     :param string: the string to check if it an IP or not\n    :param var_name: the name of the string that is being checked\n </s> add def is_ip(value):\n    \"\"\"Determine if the given string is an IP address.", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>         return isinstance(obj, self.null_session_class)\n <mask> \n <mask>     def get_cookie_domain(self, app):\n <mask>         \"\"\"Helpful helper method that returns the cookie domain that should\n <mask>         be used for the session cookie if session cookies are used.\n <mask>         \"\"\"\n <mask>         if app.config['SESSION_COOKIE_DOMAIN'] is not None:\n <mask>             return app.config['SESSION_COOKIE_DOMAIN']\n <mask>         if app.config['SERVER_NAME'] is not None:\n <mask>             # chop off the port which is usually not supported by browsers\n <mask>             rv = '.' + app.config['SERVER_NAME'].rsplit(':', 1)[0]\n <mask> \n <mask>             # Google chrome does not like cookies set to .localhost, so\n <mask>             # we just go with no domain then.  Flask documents anyways that\n <mask>             # cross domain cookies need a fully qualified domain name\n <mask>             if rv == '.localhost':\n <mask>                 rv = None\n <mask> \n <mask>             # If we infer the cookie domain from the server name we need\n <mask>             # to check if we are in a subpath.  In that case we can't\n <mask>             # set a cross domain cookie.\n <mask>             if rv is not None:\n <mask>                 path = self.get_cookie_path(app)\n <mask>                 if path != '/':\n <mask>                     rv = rv.lstrip('.')\n <mask> \n <mask>             return rv\n <mask> \n <mask>     def get_cookie_path(self, app):\n <mask>         \"\"\"Returns the path for which the cookie should be valid.  The\n </s> refactor session cookie domain logic\ncache result of session cookie domain\nadd warnings for session cookie domain issues\nadd changelog </s> remove         if domain is not None:\n            if is_ip(domain):\n                warnings.warn(\"IP introduced in SESSION_COOKIE_DOMAIN\", RuntimeWarning)\n </s> add  </s> add - Show warning when session cookie domain is a bare hostname or an IP\n  address, as these may not behave properly in some browsers, such as Chrome.\n  (`#2282`_)\n- Allow IP address as exact session cookie domain. (`#2282`_)\n- ``SESSION_COOKIE_DOMAIN`` is set if it is detected through ``SERVER_NAME``.\n  (`#2282`_) </s> remove def is_ip(ip):\n    \"\"\"Returns the if the string received is an IP or not.\n </s> add  </s> remove     :param string: the string to check if it an IP or not\n    :param var_name: the name of the string that is being checked\n </s> add def is_ip(value):\n    \"\"\"Determine if the given string is an IP address. </s> remove     :returns: True if string is an IP, False if not\n    :rtype: boolean\n </s> add     :param value: value to check\n    :type value: str\n\n    :return: True if string is an IP address\n    :rtype: bool", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             return self.session_class()\n <mask> \n <mask>     def save_session(self, app, session, response):\n <mask>         domain = self.get_cookie_domain(app)\n <mask>         if domain is not None:\n <mask>             if is_ip(domain):\n <mask>                 warnings.warn(\"IP introduced in SESSION_COOKIE_DOMAIN\", RuntimeWarning)\n <mask>         path = self.get_cookie_path(app)\n <mask> \n <mask>         # Delete case.  If there is no session we bail early.\n <mask>         # If the session was modified to be empty we remove the\n <mask>         # whole cookie.\n </s> refactor session cookie domain logic\ncache result of session cookie domain\nadd warnings for session cookie domain issues\nadd changelog </s> remove         if app.config['SESSION_COOKIE_DOMAIN'] is not None:\n            return app.config['SESSION_COOKIE_DOMAIN']\n        if app.config['SERVER_NAME'] is not None:\n            # chop off the port which is usually not supported by browsers\n            rv = '.' + app.config['SERVER_NAME'].rsplit(':', 1)[0]\n\n            # Google chrome does not like cookies set to .localhost, so\n            # we just go with no domain then.  Flask documents anyways that\n            # cross domain cookies need a fully qualified domain name\n            if rv == '.localhost':\n                rv = None\n\n            # If we infer the cookie domain from the server name we need\n            # to check if we are in a subpath.  In that case we can't\n            # set a cross domain cookie.\n            if rv is not None:\n                path = self.get_cookie_path(app)\n                if path != '/':\n                    rv = rv.lstrip('.')\n\n            return rv\n </s> add         rv = app.config['SESSION_COOKIE_DOMAIN']\n\n        # set explicitly, or cached from SERVER_NAME detection\n        # if False, return None\n        if rv is not None:\n            return rv if rv else None\n\n        rv = app.config['SERVER_NAME']\n\n        # server name not set, cache False to return none next time\n        if not rv:\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        # chop off the port which is usually not supported by browsers\n        # remove any leading '.' since we'll add that later\n        rv = rv.rsplit(':', 1)[0].lstrip('.')\n\n        if '.' not in rv:\n            # Chrome doesn't allow names without a '.'\n            # this should only come up with localhost\n            # hack around this by not setting the name, and show a warning\n            warnings.warn(\n                '\"{rv}\" is not a valid cookie domain, it must contain a \".\".'\n                ' Add an entry to your hosts file, for example'\n                ' \"{rv}.localdomain\", and use that instead.'.format(rv=rv)\n            )\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        ip = is_ip(rv)\n\n        if ip:\n            warnings.warn(\n                'The session cookie domain is an IP address. This may not work'\n                ' as intended in some browsers. Add an entry to your hosts'\n                ' file, for example \"localhost.localdomain\", and use that'\n                ' instead.'\n            )\n\n        # if this is not an ip and app is mounted at the root, allow subdomain\n        # matching by adding a '.' prefix\n        if self.get_cookie_path(app) == '/' and not ip:\n            rv = '.' + rv\n\n        app.config['SESSION_COOKIE_DOMAIN'] = rv\n        return rv </s> remove         \"\"\"Helpful helper method that returns the cookie domain that should\n        be used for the session cookie if session cookies are used.\n </s> add         \"\"\"Returns the domain that should be set for the session cookie.\n        \n        Uses ``SESSION_COOKIE_DOMAIN`` if it is configured, otherwise\n        falls back to detecting the domain based on ``SERVER_NAME``.\n        \n        Once detected (or if not set at all), ``SESSION_COOKIE_DOMAIN`` is\n        updated to avoid re-running the logic. </s> add - Show warning when session cookie domain is a bare hostname or an IP\n  address, as these may not behave properly in some browsers, such as Chrome.\n  (`#2282`_)\n- Allow IP address as exact session cookie domain. (`#2282`_)\n- ``SESSION_COOKIE_DOMAIN`` is set if it is detected through ``SERVER_NAME``.\n  (`#2282`_) </s> remove def is_ip(ip):\n    \"\"\"Returns the if the string received is an IP or not.\n </s> add  </s> remove     :param string: the string to check if it an IP or not\n    :param var_name: the name of the string that is being checked\n </s> add def is_ip(value):\n    \"\"\"Determine if the given string is an IP address. </s> remove     :returns: True if string is an IP, False if not\n    :rtype: boolean\n </s> add     :param value: value to check\n    :type value: str\n\n    :return: True if string is an IP address\n    :rtype: bool", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>   debug mode.\n <mask> \n <mask> Version 0.12.1\n <mask> --------------\n <mask> \n <mask> Bugfix release, released on March 31st 2017\n </s> safe_join on Windows uses posixpath\n\nfixes #2033\ncloses #2059 </s> remove             ('/a', '../b/c', ),\n </s> add             ('/a', '../b/c'), </s> remove             ('/a', 'b/../../c', ),\n </s> add             ('/a', 'b/../../c'), </s> remove             ('/a', 'b/../b/../../c', ),\n </s> add             ('/a', 'b/../b/../../c'), </s> remove             (('/a/b/c', './', ), '/a/b/c/.', ),\n            (('a/b/c', 'X/..'), 'a/b/c/.', ),\n </s> add             (('/a/b/c', './'), '/a/b/c/.'),\n            (('a/b/c', 'X/..'), 'a/b/c/.'), </s> remove             (('/a/b/c', '', ), '/a/b/c/', ),\n </s> add             (('/a/b/c', ''), '/a/b/c/'), </s> remove             (('a/b/c', ), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/', ), '/a/b/c'),\n            (('a', 'b', 'c', ), 'a/b/c'),\n            (('/a', 'b/c', ), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c', ),\n            (('/a/b', 'c/X/..'), '/a/b/c', ),\n </s> add             (('a/b/c',), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/'), '/a/b/c'),\n            (('a', 'b', 'c'), 'a/b/c'),\n            (('/a', 'b/c'), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c'),\n            (('/a/b', 'c/X/..'), '/a/b/c'),", "html_url": "https://github.com/pallets/flask/commit/f7c35bf0d51d1ae02709e39fe29110e12f64fb87", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     :raises: :class:`~werkzeug.exceptions.NotFound` if one or more passed\n <mask>             paths fall out of its boundaries.\n <mask>     \"\"\"\n <mask>     for filename in pathnames:\n <mask>         if filename != '':\n <mask>             filename = posixpath.normpath(filename)\n <mask> \n </s> safe_join on Windows uses posixpath\n\nfixes #2033\ncloses #2059 </s> remove         for sep in _os_alt_seps:\n            if sep in filename:\n                raise NotFound()\n        if os.path.isabs(filename) or \\\n           filename == '..' or \\\n           filename.startswith('../'):\n </s> add         if (\n            any(sep in filename for sep in _os_alt_seps)\n            or os.path.isabs(filename)\n            or filename == '..'\n            or filename.startswith('../')\n        ): </s> remove         directory = os.path.join(directory, filename)\n    return directory\n </s> add         parts.append(filename)\n\n    return posixpath.join(*parts) </s> remove             (('a/b/c', ), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/', ), '/a/b/c'),\n            (('a', 'b', 'c', ), 'a/b/c'),\n            (('/a', 'b/c', ), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c', ),\n            (('/a/b', 'c/X/..'), '/a/b/c', ),\n </s> add             (('a/b/c',), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/'), '/a/b/c'),\n            (('a', 'b', 'c'), 'a/b/c'),\n            (('/a', 'b/c'), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c'),\n            (('/a/b', 'c/X/..'), '/a/b/c'), </s> remove             ('/a', 'b/../../c', ),\n </s> add             ('/a', 'b/../../c'), </s> remove             ('/a', 'b/../b/../../c', ),\n </s> add             ('/a', 'b/../b/../../c'), </s> remove             ('/a', '../b/c', ),\n </s> add             ('/a', '../b/c'),", "html_url": "https://github.com/pallets/flask/commit/f7c35bf0d51d1ae02709e39fe29110e12f64fb87", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace replace replace keep replace replace keep", "code_tokens": " <mask>     for filename in pathnames:\n <mask>         if filename != '':\n <mask>             filename = posixpath.normpath(filename)\n <mask>         for sep in _os_alt_seps:\n <mask>             if sep in filename:\n <mask>                 raise NotFound()\n <mask>         if os.path.isabs(filename) or \\\n <mask>            filename == '..' or \\\n <mask>            filename.startswith('../'):\n <mask>             raise NotFound()\n <mask>         directory = os.path.join(directory, filename)\n <mask>     return directory\n <mask> \n </s> safe_join on Windows uses posixpath\n\nfixes #2033\ncloses #2059 </s> add     parts = [directory]\n </s> remove             ('/a', '../b/c', ),\n </s> add             ('/a', '../b/c'), </s> remove             ('/a', 'b/../../c', ),\n </s> add             ('/a', 'b/../../c'), </s> remove             ('/a', 'b/../b/../../c', ),\n </s> add             ('/a', 'b/../b/../../c'), </s> remove             (('/a/b/c', './', ), '/a/b/c/.', ),\n            (('a/b/c', 'X/..'), 'a/b/c/.', ),\n </s> add             (('/a/b/c', './'), '/a/b/c/.'),\n            (('a/b/c', 'X/..'), 'a/b/c/.'),", "html_url": "https://github.com/pallets/flask/commit/f7c35bf0d51d1ae02709e39fe29110e12f64fb87", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace keep replace keep keep", "code_tokens": " <mask>         passing = (\n <mask>             (('a/b/c', ), 'a/b/c'),\n <mask>             (('/', 'a/', 'b/', 'c/', ), '/a/b/c'),\n <mask>             (('a', 'b', 'c', ), 'a/b/c'),\n <mask>             (('/a', 'b/c', ), '/a/b/c'),\n <mask>             (('a/b', 'X/../c'), 'a/b/c', ),\n <mask>             (('/a/b', 'c/X/..'), '/a/b/c', ),\n <mask>             # If last path is '' add a slash\n <mask>             (('/a/b/c', '', ), '/a/b/c/', ),\n <mask>             # Preserve dot slash\n <mask>             (('/a/b/c', './', ), '/a/b/c/.', ),\n </s> safe_join on Windows uses posixpath\n\nfixes #2033\ncloses #2059 </s> remove             (('/a/b/c', './', ), '/a/b/c/.', ),\n            (('a/b/c', 'X/..'), 'a/b/c/.', ),\n </s> add             (('/a/b/c', './'), '/a/b/c/.'),\n            (('a/b/c', 'X/..'), 'a/b/c/.'), </s> remove             ('/a', '../b/c', ),\n </s> add             ('/a', '../b/c'), </s> remove             ('/a', 'b/../b/../../c', ),\n </s> add             ('/a', 'b/../b/../../c'), </s> remove             ('/a', 'b/../../c', ),\n </s> add             ('/a', 'b/../../c'), </s> remove         for sep in _os_alt_seps:\n            if sep in filename:\n                raise NotFound()\n        if os.path.isabs(filename) or \\\n           filename == '..' or \\\n           filename.startswith('../'):\n </s> add         if (\n            any(sep in filename for sep in _os_alt_seps)\n            or os.path.isabs(filename)\n            or filename == '..'\n            or filename.startswith('../')\n        ):", "html_url": "https://github.com/pallets/flask/commit/f7c35bf0d51d1ae02709e39fe29110e12f64fb87", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             (('/a/b', 'c/X/..'), '/a/b/c', ),\n <mask>             # If last path is '' add a slash\n <mask>             (('/a/b/c', '', ), '/a/b/c/', ),\n <mask>             # Preserve dot slash\n <mask>             (('/a/b/c', './', ), '/a/b/c/.', ),\n <mask>             (('a/b/c', 'X/..'), 'a/b/c/.', ),\n <mask>             # Base directory is always considered safe\n <mask>             (('../', 'a/b/c'), '../a/b/c'),\n <mask>             (('/..', ), '/..'),\n <mask>         )\n <mask> \n </s> safe_join on Windows uses posixpath\n\nfixes #2033\ncloses #2059 </s> remove             (('/a/b/c', '', ), '/a/b/c/', ),\n </s> add             (('/a/b/c', ''), '/a/b/c/'), </s> remove             (('a/b/c', ), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/', ), '/a/b/c'),\n            (('a', 'b', 'c', ), 'a/b/c'),\n            (('/a', 'b/c', ), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c', ),\n            (('/a/b', 'c/X/..'), '/a/b/c', ),\n </s> add             (('a/b/c',), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/'), '/a/b/c'),\n            (('a', 'b', 'c'), 'a/b/c'),\n            (('/a', 'b/c'), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c'),\n            (('/a/b', 'c/X/..'), '/a/b/c'), </s> remove             ('/a', 'b/../b/../../c', ),\n </s> add             ('/a', 'b/../b/../../c'), </s> remove             ('/a', 'b/../../c', ),\n </s> add             ('/a', 'b/../../c'), </s> remove             ('/a', '../b/c', ),\n </s> add             ('/a', '../b/c'), </s> remove         directory = os.path.join(directory, filename)\n    return directory\n </s> add         parts.append(filename)\n\n    return posixpath.join(*parts)", "html_url": "https://github.com/pallets/flask/commit/f7c35bf0d51d1ae02709e39fe29110e12f64fb87", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep replace keep keep keep", "code_tokens": " <mask>         # Should raise werkzeug.exceptions.NotFound on unsafe joins.\n <mask>         failing = (\n <mask>             # path.isabs and ``..'' checks\n <mask>             ('/a', 'b', '/c'),\n <mask>             ('/a', '../b/c', ),\n <mask>             ('/a', '..', 'b/c'),\n <mask>             # Boundaries violations after path normalization\n <mask>             ('/a', 'b/../b/../../c', ),\n <mask>             ('/a', 'b', 'c/../..'),\n <mask>             ('/a', 'b/../../c', ),\n <mask>         )\n </s> safe_join on Windows uses posixpath\n\nfixes #2033\ncloses #2059 </s> remove             ('/a', 'b/../../c', ),\n </s> add             ('/a', 'b/../../c'), </s> remove             (('a/b/c', ), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/', ), '/a/b/c'),\n            (('a', 'b', 'c', ), 'a/b/c'),\n            (('/a', 'b/c', ), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c', ),\n            (('/a/b', 'c/X/..'), '/a/b/c', ),\n </s> add             (('a/b/c',), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/'), '/a/b/c'),\n            (('a', 'b', 'c'), 'a/b/c'),\n            (('/a', 'b/c'), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c'),\n            (('/a/b', 'c/X/..'), '/a/b/c'), </s> remove             (('/a/b/c', './', ), '/a/b/c/.', ),\n            (('a/b/c', 'X/..'), 'a/b/c/.', ),\n </s> add             (('/a/b/c', './'), '/a/b/c/.'),\n            (('a/b/c', 'X/..'), 'a/b/c/.'), </s> remove             (('/a/b/c', '', ), '/a/b/c/', ),\n </s> add             (('/a/b/c', ''), '/a/b/c/'), </s> add Version 0.12.2\n--------------\n\nBugfix release\n\n- Fix a bug in `safe_join` on Windows.\n", "html_url": "https://github.com/pallets/flask/commit/f7c35bf0d51d1ae02709e39fe29110e12f64fb87", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             ('/a', '..', 'b/c'),\n <mask>             # Boundaries violations after path normalization\n <mask>             ('/a', 'b/../b/../../c', ),\n <mask>             ('/a', 'b', 'c/../..'),\n <mask>             ('/a', 'b/../../c', ),\n <mask>         )\n <mask> \n <mask>         for args in failing:\n <mask>             with pytest.raises(NotFound):\n <mask>                 print(flask.safe_join(*args))\n </s> safe_join on Windows uses posixpath\n\nfixes #2033\ncloses #2059 </s> remove             ('/a', 'b/../b/../../c', ),\n </s> add             ('/a', 'b/../b/../../c'), </s> remove             ('/a', '../b/c', ),\n </s> add             ('/a', '../b/c'), </s> remove             (('/a/b/c', './', ), '/a/b/c/.', ),\n            (('a/b/c', 'X/..'), 'a/b/c/.', ),\n </s> add             (('/a/b/c', './'), '/a/b/c/.'),\n            (('a/b/c', 'X/..'), 'a/b/c/.'), </s> remove             (('a/b/c', ), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/', ), '/a/b/c'),\n            (('a', 'b', 'c', ), 'a/b/c'),\n            (('/a', 'b/c', ), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c', ),\n            (('/a/b', 'c/X/..'), '/a/b/c', ),\n </s> add             (('a/b/c',), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/'), '/a/b/c'),\n            (('a', 'b', 'c'), 'a/b/c'),\n            (('/a', 'b/c'), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c'),\n            (('/a/b', 'c/X/..'), '/a/b/c'), </s> remove             (('/a/b/c', '', ), '/a/b/c/', ),\n </s> add             (('/a/b/c', ''), '/a/b/c/'), </s> remove         directory = os.path.join(directory, filename)\n    return directory\n </s> add         parts.append(filename)\n\n    return posixpath.join(*parts)", "html_url": "https://github.com/pallets/flask/commit/f7c35bf0d51d1ae02709e39fe29110e12f64fb87", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     environment: 'publish'\n <mask>     runs-on: ubuntu-latest\n <mask>     steps:\n <mask>       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n <mask>       # Try uploading to Test PyPI first, in case something fails.\n <mask>       - uses: pypa/gh-action-pypi-publish@29930c9cf57955dc1b98162d0d8bc3ec80d9e75c\n <mask>         with:\n <mask>           repository_url: https://test.pypi.org/legacy/\n </s> use oidc instead of token </s> remove           password: ${{ secrets.PYPI_TOKEN }}\n </s> add  </s> remove           password: ${{ secrets.TEST_PYPI_TOKEN }}\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f7d9956c0f0e9a80b1d345adac191f6ebd0ffee4", "file_name": ".github/workflows/publish.yaml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep replace", "code_tokens": " <mask>       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n <mask>       # Try uploading to Test PyPI first, in case something fails.\n <mask>       - uses: pypa/gh-action-pypi-publish@29930c9cf57955dc1b98162d0d8bc3ec80d9e75c\n <mask>         with:\n <mask>           password: ${{ secrets.TEST_PYPI_TOKEN }}\n <mask>           repository_url: https://test.pypi.org/legacy/\n <mask>           packages_dir: artifact/\n <mask>       - uses: pypa/gh-action-pypi-publish@29930c9cf57955dc1b98162d0d8bc3ec80d9e75c\n <mask>         with:\n <mask>           password: ${{ secrets.PYPI_TOKEN }}\n </s> use oidc instead of token </s> add     permissions:\n      id-token: write", "html_url": "https://github.com/pallets/flask/commit/f7d9956c0f0e9a80b1d345adac191f6ebd0ffee4", "file_name": ".github/workflows/publish.yaml"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace", "code_tokens": " <mask> babel==2.8.0              # via sphinx\n <mask> certifi==2020.4.5.1       # via requests\n <mask> chardet==3.0.4            # via requests\n <mask> colorama==0.4.3           # via sphinx\n <mask> docutils==0.16            # via sphinx\n <mask> idna==2.9                 # via requests\n <mask> imagesize==1.2.0          # via sphinx\n <mask> importlib-metadata==1.7.0  # via pallets-sphinx-themes\n </s> Bump sphinx-tabs from 1.1.13 to 1.3.0 (#3822)\n\nBumps [sphinx-tabs](https://github.com/executablebooks/sphinx-tabs) from 1.1.13 to 1.3.0.\r\n- [Release notes](https://github.com/executablebooks/sphinx-tabs/releases)\r\n- [Changelog](https://github.com/executablebooks/sphinx-tabs/blob/master/CHANGELOG.md)\r\n- [Commits](https://github.com/executablebooks/sphinx-tabs/compare/v1.1.13...v1.3.0)\r\n\r\nSigned-off-by: dependabot-preview[bot] <support@dependabot.com>\r\n\r\nCo-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com> </s> remove sphinx-tabs==1.1.13       # via -r requirements/docs.in\n </s> add sphinx-tabs==1.3.0        # via -r requirements/docs.in </s> remove pygments==2.6.1           # via sphinx\n </s> add pygments==2.6.1           # via sphinx, sphinx-tabs </s> remove zipp==3.1.0               # via importlib-metadata\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f7e33f240ee595349a46bf4eef95e1d9bdfee3da", "file_name": "requirements/docs.txt"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> jinja2==2.11.2            # via sphinx\n <mask> markupsafe==1.1.1         # via jinja2\n <mask> packaging==20.4           # via -r requirements/docs.in, pallets-sphinx-themes, sphinx\n <mask> pallets-sphinx-themes==1.2.3  # via -r requirements/docs.in\n <mask> pygments==2.6.1           # via sphinx\n <mask> pyparsing==2.4.7          # via packaging\n <mask> pytz==2020.1              # via babel\n <mask> requests==2.23.0          # via sphinx\n <mask> six==1.15.0               # via packaging\n <mask> snowballstemmer==2.0.0    # via sphinx\n </s> Bump sphinx-tabs from 1.1.13 to 1.3.0 (#3822)\n\nBumps [sphinx-tabs](https://github.com/executablebooks/sphinx-tabs) from 1.1.13 to 1.3.0.\r\n- [Release notes](https://github.com/executablebooks/sphinx-tabs/releases)\r\n- [Changelog](https://github.com/executablebooks/sphinx-tabs/blob/master/CHANGELOG.md)\r\n- [Commits](https://github.com/executablebooks/sphinx-tabs/compare/v1.1.13...v1.3.0)\r\n\r\nSigned-off-by: dependabot-preview[bot] <support@dependabot.com>\r\n\r\nCo-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com> </s> remove importlib-metadata==1.7.0  # via pallets-sphinx-themes\n </s> add  </s> remove sphinx-tabs==1.1.13       # via -r requirements/docs.in\n </s> add sphinx-tabs==1.3.0        # via -r requirements/docs.in </s> remove colorama==0.4.3           # via sphinx\n </s> add  </s> remove zipp==3.1.0               # via importlib-metadata\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f7e33f240ee595349a46bf4eef95e1d9bdfee3da", "file_name": "requirements/docs.txt"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> requests==2.23.0          # via sphinx\n <mask> six==1.15.0               # via packaging\n <mask> snowballstemmer==2.0.0    # via sphinx\n <mask> sphinx-issues==1.2.0      # via -r requirements/docs.in\n <mask> sphinx-tabs==1.1.13       # via -r requirements/docs.in\n <mask> sphinx==3.2.1             # via -r requirements/docs.in, pallets-sphinx-themes, sphinx-issues, sphinx-tabs, sphinxcontrib-log-cabinet\n <mask> sphinxcontrib-applehelp==1.0.2  # via sphinx\n <mask> sphinxcontrib-devhelp==1.0.2  # via sphinx\n <mask> sphinxcontrib-htmlhelp==1.0.3  # via sphinx\n <mask> sphinxcontrib-jsmath==1.0.1  # via sphinx\n </s> Bump sphinx-tabs from 1.1.13 to 1.3.0 (#3822)\n\nBumps [sphinx-tabs](https://github.com/executablebooks/sphinx-tabs) from 1.1.13 to 1.3.0.\r\n- [Release notes](https://github.com/executablebooks/sphinx-tabs/releases)\r\n- [Changelog](https://github.com/executablebooks/sphinx-tabs/blob/master/CHANGELOG.md)\r\n- [Commits](https://github.com/executablebooks/sphinx-tabs/compare/v1.1.13...v1.3.0)\r\n\r\nSigned-off-by: dependabot-preview[bot] <support@dependabot.com>\r\n\r\nCo-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com> </s> remove pygments==2.6.1           # via sphinx\n </s> add pygments==2.6.1           # via sphinx, sphinx-tabs </s> remove importlib-metadata==1.7.0  # via pallets-sphinx-themes\n </s> add  </s> remove colorama==0.4.3           # via sphinx\n </s> add  </s> remove zipp==3.1.0               # via importlib-metadata\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f7e33f240ee595349a46bf4eef95e1d9bdfee3da", "file_name": "requirements/docs.txt"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep", "code_tokens": " <mask> sphinxcontrib-log-cabinet==1.0.1  # via -r requirements/docs.in\n <mask> sphinxcontrib-qthelp==1.0.3  # via sphinx\n <mask> sphinxcontrib-serializinghtml==1.1.4  # via sphinx\n <mask> urllib3==1.25.9           # via requests\n <mask> zipp==3.1.0               # via importlib-metadata\n <mask> \n <mask> # The following packages are considered to be unsafe in a requirements file:\n <mask> # setuptools\n </s> Bump sphinx-tabs from 1.1.13 to 1.3.0 (#3822)\n\nBumps [sphinx-tabs](https://github.com/executablebooks/sphinx-tabs) from 1.1.13 to 1.3.0.\r\n- [Release notes](https://github.com/executablebooks/sphinx-tabs/releases)\r\n- [Changelog](https://github.com/executablebooks/sphinx-tabs/blob/master/CHANGELOG.md)\r\n- [Commits](https://github.com/executablebooks/sphinx-tabs/compare/v1.1.13...v1.3.0)\r\n\r\nSigned-off-by: dependabot-preview[bot] <support@dependabot.com>\r\n\r\nCo-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com> </s> remove importlib-metadata==1.7.0  # via pallets-sphinx-themes\n </s> add  </s> remove sphinx-tabs==1.1.13       # via -r requirements/docs.in\n </s> add sphinx-tabs==1.3.0        # via -r requirements/docs.in </s> remove pygments==2.6.1           # via sphinx\n </s> add pygments==2.6.1           # via sphinx, sphinx-tabs </s> remove colorama==0.4.3           # via sphinx\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f7e33f240ee595349a46bf4eef95e1d9bdfee3da", "file_name": "requirements/docs.txt"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         .. versionadded:: 0.7\n <mask>         \"\"\"\n <mask>         if blueprint.name in self.blueprints:\n <mask>             assert self.blueprints[blueprint.name] is blueprint, \\\n <mask>                 'A blueprint\\'s name collision ocurred between %r and ' \\\n <mask>                 '%r.  Both share the same name \"%s\"' % \\\n <mask>                 (blueprint, self.blueprints[blueprint.name], blueprint.name)\n </s> Register most stuff only once </s> remove         blueprint.register(self, options)\n </s> add             first_registration = True\n        blueprint.register(self, options, first_registration) </s> remove     def __init__(self, blueprint, app, options):\n </s> add     def __init__(self, blueprint, app, options, first_registration): </s> remove         def register_rule(state):\n            state.add_url_rule(rule, endpoint, view_func, **options)\n        self._record(register_rule)\n </s> add         self._record(lambda s:\n            s.add_url_rule(rule, endpoint, view_func, **options)) </s> remove         state = self.make_setup_state(app, options)\n </s> add         state = self.make_setup_state(app, options, first_registration) </s> remove     def register(self, app, options):\n </s> add     def make_setup_state(self, app, options, first_registration=False):\n        return BlueprintSetupState(self, app, options, first_registration)\n\n    def register(self, app, options, first_registration=False): </s> remove             self._record(lambda s: s.app.errorhandler(code)(f))\n </s> add             self._record_once(lambda s: s.app.errorhandler(code)(f))", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 '%r.  Both share the same name \"%s\"' % \\\n <mask>                 (blueprint, self.blueprints[blueprint.name], blueprint.name)\n <mask>         else:\n <mask>             self.blueprints[blueprint.name] = blueprint\n <mask>         blueprint.register(self, options)\n <mask> \n <mask>     def add_url_rule(self, rule, endpoint=None, view_func=None, **options):\n <mask>         \"\"\"Connects a URL rule.  Works exactly like the :meth:`route`\n <mask>         decorator.  If a view_func is provided it will be registered with the\n <mask>         endpoint.\n </s> Register most stuff only once </s> add         first_registration = False </s> remove         def register_rule(state):\n            state.add_url_rule(rule, endpoint, view_func, **options)\n        self._record(register_rule)\n </s> add         self._record(lambda s:\n            s.add_url_rule(rule, endpoint, view_func, **options)) </s> remove     def __init__(self, blueprint, app, options):\n </s> add     def __init__(self, blueprint, app, options, first_registration): </s> remove     def make_setup_state(self, app, options):\n        return BlueprintSetupState(self, app, options)\n </s> add     def _record_once(self, func):\n        def wrapper(state):\n            if state.first_registration:\n                func(state)\n        return self._record(update_wrapper(wrapper, func)) </s> remove     def register(self, app, options):\n </s> add     def make_setup_state(self, app, options, first_registration=False):\n        return BlueprintSetupState(self, app, options, first_registration)\n\n    def register(self, app, options, first_registration=False): </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> import os\n <mask> \n <mask> from .helpers import _PackageBoundObject, _endpoint_from_view_func\n <mask> \n <mask> \n </s> Register most stuff only once </s> remove         state = self.make_setup_state(app, options)\n </s> add         state = self.make_setup_state(app, options, first_registration) </s> remove             self._record(lambda s: s.app.errorhandler(code)(f))\n </s> add             self._record_once(lambda s: s.app.errorhandler(code)(f)) </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove             self._record(register_endpoint)\n </s> add             self._record_once(register_endpoint) </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.after_request_funcs\n </s> add         self._record_once(lambda s: s.app.after_request_funcs", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"Temporary holder object for registering a blueprint with the\n <mask>     application.\n <mask>     \"\"\"\n <mask> \n <mask>     def __init__(self, blueprint, app, options):\n <mask>         self.app = app\n <mask>         self.blueprint = blueprint\n <mask>         self.options = options\n <mask> \n <mask>         subdomain = self.options.get('subdomain')\n </s> Register most stuff only once </s> add         self.first_registration = first_registration </s> remove     def make_setup_state(self, app, options):\n        return BlueprintSetupState(self, app, options)\n </s> add     def _record_once(self, func):\n        def wrapper(state):\n            if state.first_registration:\n                func(state)\n        return self._record(update_wrapper(wrapper, func)) </s> remove     def register(self, app, options):\n </s> add     def make_setup_state(self, app, options, first_registration=False):\n        return BlueprintSetupState(self, app, options, first_registration)\n\n    def register(self, app, options, first_registration=False): </s> remove         blueprint.register(self, options)\n </s> add             first_registration = True\n        blueprint.register(self, options, first_registration) </s> remove             self._record(register_endpoint)\n </s> add             self._record_once(register_endpoint) </s> add         first_registration = False", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         self.blueprint = blueprint\n <mask>         self.options = options\n <mask> \n <mask>         subdomain = self.options.get('subdomain')\n <mask>         if subdomain is None:\n <mask>             subdomain = self.blueprint.subdomain\n </s> Register most stuff only once </s> remove     def __init__(self, blueprint, app, options):\n </s> add     def __init__(self, blueprint, app, options, first_registration): </s> remove         blueprint.register(self, options)\n </s> add             first_registration = True\n        blueprint.register(self, options, first_registration) </s> remove         state = self.make_setup_state(app, options)\n </s> add         state = self.make_setup_state(app, options, first_registration) </s> add         first_registration = False </s> remove             self._record(register_endpoint)\n </s> add             self._record_once(register_endpoint) </s> remove     def make_setup_state(self, app, options):\n        return BlueprintSetupState(self, app, options)\n </s> add     def _record_once(self, func):\n        def wrapper(state):\n            if state.first_registration:\n                func(state)\n        return self._record(update_wrapper(wrapper, func))", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def _record(self, func):\n <mask>         self.deferred_functions.append(func)\n <mask> \n <mask>     def make_setup_state(self, app, options):\n <mask>         return BlueprintSetupState(self, app, options)\n <mask> \n <mask>     def register(self, app, options):\n <mask>         \"\"\"Called by :meth:`Flask.register_blueprint` to register a blueprint\n <mask>         on the application.  This can be overridden to customize the register\n <mask>         behavior.  Keyword arguments from\n </s> Register most stuff only once </s> remove     def register(self, app, options):\n </s> add     def make_setup_state(self, app, options, first_registration=False):\n        return BlueprintSetupState(self, app, options, first_registration)\n\n    def register(self, app, options, first_registration=False): </s> remove     def __init__(self, blueprint, app, options):\n </s> add     def __init__(self, blueprint, app, options, first_registration): </s> remove         state = self.make_setup_state(app, options)\n </s> add         state = self.make_setup_state(app, options, first_registration) </s> remove         def register_rule(state):\n            state.add_url_rule(rule, endpoint, view_func, **options)\n        self._record(register_rule)\n </s> add         self._record(lambda s:\n            s.add_url_rule(rule, endpoint, view_func, **options)) </s> remove         blueprint.register(self, options)\n </s> add             first_registration = True\n        blueprint.register(self, options, first_registration) </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def make_setup_state(self, app, options):\n <mask>         return BlueprintSetupState(self, app, options)\n <mask> \n <mask>     def register(self, app, options):\n <mask>         \"\"\"Called by :meth:`Flask.register_blueprint` to register a blueprint\n <mask>         on the application.  This can be overridden to customize the register\n <mask>         behavior.  Keyword arguments from\n <mask>         :func:`~flask.Flask.register_blueprint` are directly forwarded to this\n <mask>         method in the `options` dictionary.\n </s> Register most stuff only once </s> remove     def make_setup_state(self, app, options):\n        return BlueprintSetupState(self, app, options)\n </s> add     def _record_once(self, func):\n        def wrapper(state):\n            if state.first_registration:\n                func(state)\n        return self._record(update_wrapper(wrapper, func)) </s> remove         state = self.make_setup_state(app, options)\n </s> add         state = self.make_setup_state(app, options, first_registration) </s> remove     def __init__(self, blueprint, app, options):\n </s> add     def __init__(self, blueprint, app, options, first_registration): </s> remove         def register_rule(state):\n            state.add_url_rule(rule, endpoint, view_func, **options)\n        self._record(register_rule)\n </s> add         self._record(lambda s:\n            s.add_url_rule(rule, endpoint, view_func, **options)) </s> remove         blueprint.register(self, options)\n </s> add             first_registration = True\n        blueprint.register(self, options, first_registration) </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         behavior.  Keyword arguments from\n <mask>         :func:`~flask.Flask.register_blueprint` are directly forwarded to this\n <mask>         method in the `options` dictionary.\n <mask>         \"\"\"\n <mask>         state = self.make_setup_state(app, options)\n <mask>         if self.has_static_folder:\n <mask>             state.add_url_rule(self.static_url_path + '/<path:filename>',\n <mask>                                view_func=self.send_static_file,\n <mask>                                endpoint='static')\n <mask> \n </s> Register most stuff only once </s> remove     def register(self, app, options):\n </s> add     def make_setup_state(self, app, options, first_registration=False):\n        return BlueprintSetupState(self, app, options, first_registration)\n\n    def register(self, app, options, first_registration=False): </s> remove     def make_setup_state(self, app, options):\n        return BlueprintSetupState(self, app, options)\n </s> add     def _record_once(self, func):\n        def wrapper(state):\n            if state.first_registration:\n                func(state)\n        return self._record(update_wrapper(wrapper, func)) </s> remove         def register_rule(state):\n            state.add_url_rule(rule, endpoint, view_func, **options)\n        self._record(register_rule)\n </s> add         self._record(lambda s:\n            s.add_url_rule(rule, endpoint, view_func, **options)) </s> add         first_registration = False </s> add from functools import update_wrapper </s> remove         blueprint.register(self, options)\n </s> add             first_registration = True\n        blueprint.register(self, options, first_registration)", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     def add_url_rule(self, rule, endpoint=None, view_func=None, **options):\n <mask>         \"\"\"Like :meth:`Flask.add_url_rule` but for a module.  The endpoint for\n <mask>         the :func:`url_for` function is prefixed with the name of the module.\n <mask>         \"\"\"\n <mask>         def register_rule(state):\n <mask>             state.add_url_rule(rule, endpoint, view_func, **options)\n <mask>         self._record(register_rule)\n <mask> \n <mask>     def endpoint(self, endpoint):\n <mask>         \"\"\"Like :meth:`Flask.endpoint` but for a module.  This does not\n <mask>         prefix the endpoint with the module name, this has to be done\n <mask>         explicitly by the user of this method.\n </s> Register most stuff only once </s> remove         blueprint.register(self, options)\n </s> add             first_registration = True\n        blueprint.register(self, options, first_registration) </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.after_request_funcs\n </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove             self._record(lambda s: s.app.errorhandler(code)(f))\n </s> add             self._record_once(lambda s: s.app.errorhandler(code)(f)) </s> remove     def register(self, app, options):\n </s> add     def make_setup_state(self, app, options, first_registration=False):\n        return BlueprintSetupState(self, app, options, first_registration)\n\n    def register(self, app, options, first_registration=False): </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         def decorator(f):\n <mask>             def register_endpoint(state):\n <mask>                 state.app.view_functions[endpoint] = f\n <mask>             self._record(register_endpoint)\n <mask>             return f\n <mask>         return decorator\n <mask> \n <mask>     def before_request(self, f):\n <mask>         \"\"\"Like :meth:`Flask.before_request` but for a module.  This function\n </s> Register most stuff only once </s> remove             self._record(lambda s: s.app.errorhandler(code)(f))\n </s> add             self._record_once(lambda s: s.app.errorhandler(code)(f)) </s> remove         self._record(lambda s: s.app.before_request_funcs\n </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.after_request_funcs\n </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.before_request_funcs\n </s> add         self._record_once(lambda s: s.app.before_request_funcs", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Like :meth:`Flask.before_request` but for a module.  This function\n <mask>         is only executed before each request that is handled by a function of\n <mask>         that module.\n <mask>         \"\"\"\n <mask>         self._record(lambda s: s.app.before_request_funcs\n <mask>             .setdefault(self.name, []).append(f))\n <mask>         return f\n <mask> \n <mask>     def before_app_request(self, f):\n <mask>         \"\"\"Like :meth:`Flask.before_request`.  Such a function is executed\n </s> Register most stuff only once </s> remove         self._record(lambda s: s.app.after_request_funcs\n </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.before_request_funcs\n </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.after_request_funcs\n </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove             self._record(register_endpoint)\n </s> add             self._record_once(register_endpoint)", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def before_app_request(self, f):\n <mask>         \"\"\"Like :meth:`Flask.before_request`.  Such a function is executed\n <mask>         before each request, even if outside of a module.\n <mask>         \"\"\"\n <mask>         self._record(lambda s: s.app.before_request_funcs\n <mask>             .setdefault(None, []).append(f))\n <mask>         return f\n <mask> \n <mask>     def after_request(self, f):\n <mask>         \"\"\"Like :meth:`Flask.after_request` but for a module.  This function\n </s> Register most stuff only once </s> remove         self._record(lambda s: s.app.before_request_funcs\n </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.after_request_funcs\n </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.after_request_funcs\n </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove             self._record(lambda s: s.app.errorhandler(code)(f))\n </s> add             self._record_once(lambda s: s.app.errorhandler(code)(f))", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Like :meth:`Flask.after_request` but for a module.  This function\n <mask>         is only executed after each request that is handled by a function of\n <mask>         that module.\n <mask>         \"\"\"\n <mask>         self._record(lambda s: s.app.after_request_funcs\n <mask>             .setdefault(self.name, []).append(f))\n <mask>         return f\n <mask> \n <mask>     def after_app_request(self, f):\n <mask>         \"\"\"Like :meth:`Flask.after_request` but for a module.  Such a function\n </s> Register most stuff only once </s> remove         self._record(lambda s: s.app.before_request_funcs\n </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.after_request_funcs\n </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.before_request_funcs\n </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove             self._record(lambda s: s.app.errorhandler(code)(f))\n </s> add             self._record_once(lambda s: s.app.errorhandler(code)(f))", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def after_app_request(self, f):\n <mask>         \"\"\"Like :meth:`Flask.after_request` but for a module.  Such a function\n <mask>         is executed after each request, even if outside of the module.\n <mask>         \"\"\"\n <mask>         self._record(lambda s: s.app.after_request_funcs\n <mask>             .setdefault(None, []).append(f))\n <mask>         return f\n <mask> \n <mask>     def context_processor(self, f):\n <mask>         \"\"\"Like :meth:`Flask.context_processor` but for a module.  This\n </s> Register most stuff only once </s> remove         self._record(lambda s: s.app.after_request_funcs\n </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.before_request_funcs\n </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.before_request_funcs\n </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove             self._record(lambda s: s.app.errorhandler(code)(f))\n </s> add             self._record_once(lambda s: s.app.errorhandler(code)(f))", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def context_processor(self, f):\n <mask>         \"\"\"Like :meth:`Flask.context_processor` but for a module.  This\n <mask>         function is only executed for requests handled by a module.\n <mask>         \"\"\"\n <mask>         self._record(lambda s: s.app.template_context_processors\n <mask>             .setdefault(self.name, []).append(f))\n <mask>         return f\n <mask> \n <mask>     def app_context_processor(self, f):\n <mask>         \"\"\"Like :meth:`Flask.context_processor` but for a module.  Such a\n </s> Register most stuff only once </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.after_request_funcs\n </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.after_request_funcs\n </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.before_request_funcs\n </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.before_request_funcs\n </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove             self._record(register_endpoint)\n </s> add             self._record_once(register_endpoint)", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def app_context_processor(self, f):\n <mask>         \"\"\"Like :meth:`Flask.context_processor` but for a module.  Such a\n <mask>         function is executed each request, even if outside of the module.\n <mask>         \"\"\"\n <mask>         self._record(lambda s: s.app.template_context_processors\n <mask>             .setdefault(None, []).append(f))\n <mask>         return f\n <mask> \n <mask>     def app_errorhandler(self, code):\n <mask>         \"\"\"Like :meth:`Flask.errorhandler` but for a module.  This\n </s> Register most stuff only once </s> remove         self._record(lambda s: s.app.after_request_funcs\n </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.before_request_funcs\n </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove             self._record(lambda s: s.app.errorhandler(code)(f))\n </s> add             self._record_once(lambda s: s.app.errorhandler(code)(f)) </s> remove         self._record(lambda s: s.app.after_request_funcs\n </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.before_request_funcs\n </s> add         self._record_once(lambda s: s.app.before_request_funcs", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep", "code_tokens": " <mask>         \"\"\"Like :meth:`Flask.errorhandler` but for a module.  This\n <mask>         handler is used for all requests, even if outside of the module.\n <mask>         \"\"\"\n <mask>         def decorator(f):\n <mask>             self._record(lambda s: s.app.errorhandler(code)(f))\n <mask>             return f\n <mask>         return decorator\n </s> Register most stuff only once </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove             self._record(register_endpoint)\n </s> add             self._record_once(register_endpoint) </s> remove         self._record(lambda s: s.app.after_request_funcs\n </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.before_request_funcs\n </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors\n </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.after_request_funcs\n </s> add         self._record_once(lambda s: s.app.after_request_funcs", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> from werkzeug.http import parse_cache_control_header, parse_options_header\n <mask> from werkzeug.http import http_date\n <mask> from flask._compat import StringIO, text_type\n <mask> from flask.helpers import get_debug_flag, make_response\n <mask> try:\n <mask>     from pytz import timezone\n <mask> except ImportError:\n <mask>     has_pytz = False\n <mask> else:\n <mask>     has_pytz = True\n <mask> \n <mask> \n <mask> def has_encoding(name):\n <mask>     try:\n <mask>         import codecs\n </s> Re-revert to not using pytz\n\nWill spin a tzinfo subclass. </s> remove         dt_naive = datetime.datetime(2017, 1, 1, 12, 34, 56)\n        dt_aware = timezone(tzname).localize(dt_naive)\n        dt_as_gmt = dt_aware.astimezone(timezone('GMT'))\n        expected = dt_as_gmt.strftime('\"%a, %d %b %Y %H:%M:%S %Z\"')\n        assert flask.json.JSONEncoder().encode(dt_aware) == expected\n </s> add         tzinfo = datetime.timezone(datetime.timedelta(hours=tz[1]), name=tz[0])\n        dt = datetime.datetime(2017, 1, 1, 12, 34, 56, tzinfo=tzinfo)\n        gmt = datetime.timezone(datetime.timedelta(), name='GMT')\n        expected = dt.astimezone(gmt).strftime('\"%a, %d %b %Y %H:%M:%S %Z\"')\n        assert flask.json.JSONEncoder().encode(dt) == expected </s> remove     @pytest.mark.skipif('not has_pytz')\n    @pytest.mark.parametrize('tzname', ('UTC', 'PST8PDT', 'Asia/Seoul'))\n    def test_jsonify_aware_datetimes(self, tzname):\n </s> add     @pytest.mark.parametrize('tz', (('UTC', 0), ('PST', -8), ('KST', 9)))\n    def test_jsonify_aware_datetimes(self, tz): </s> remove     pytz\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f80376027571ba5190ab6cf1411dd1dd9bb9c65e", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep replace replace replace replace replace keep", "code_tokens": " <mask>             assert rv.mimetype == 'application/json'\n <mask>             assert flask.json.loads(rv.data)['x'] == http_date(d.timetuple())\n <mask> \n <mask>     @pytest.mark.skipif('not has_pytz')\n <mask>     @pytest.mark.parametrize('tzname', ('UTC', 'PST8PDT', 'Asia/Seoul'))\n <mask>     def test_jsonify_aware_datetimes(self, tzname):\n <mask>         \"\"\"Test if aware datetime.datetime objects are converted into GMT.\"\"\"\n <mask>         dt_naive = datetime.datetime(2017, 1, 1, 12, 34, 56)\n <mask>         dt_aware = timezone(tzname).localize(dt_naive)\n <mask>         dt_as_gmt = dt_aware.astimezone(timezone('GMT'))\n <mask>         expected = dt_as_gmt.strftime('\"%a, %d %b %Y %H:%M:%S %Z\"')\n <mask>         assert flask.json.JSONEncoder().encode(dt_aware) == expected\n <mask> \n </s> Re-revert to not using pytz\n\nWill spin a tzinfo subclass. </s> remove try:\n    from pytz import timezone\nexcept ImportError:\n    has_pytz = False\nelse:\n    has_pytz = True\n </s> add  </s> remove     pytz\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f80376027571ba5190ab6cf1411dd1dd9bb9c65e", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     pytest>=3\n <mask>     coverage\n <mask>     greenlet\n <mask>     blinker\n <mask>     pytz\n <mask> \n <mask>     lowest: Werkzeug==0.9\n <mask>     lowest: Jinja2==2.4\n <mask>     lowest: itsdangerous==0.21\n <mask>     lowest: Click==4.0\n </s> Re-revert to not using pytz\n\nWill spin a tzinfo subclass. </s> remove         dt_naive = datetime.datetime(2017, 1, 1, 12, 34, 56)\n        dt_aware = timezone(tzname).localize(dt_naive)\n        dt_as_gmt = dt_aware.astimezone(timezone('GMT'))\n        expected = dt_as_gmt.strftime('\"%a, %d %b %Y %H:%M:%S %Z\"')\n        assert flask.json.JSONEncoder().encode(dt_aware) == expected\n </s> add         tzinfo = datetime.timezone(datetime.timedelta(hours=tz[1]), name=tz[0])\n        dt = datetime.datetime(2017, 1, 1, 12, 34, 56, tzinfo=tzinfo)\n        gmt = datetime.timezone(datetime.timedelta(), name='GMT')\n        expected = dt.astimezone(gmt).strftime('\"%a, %d %b %Y %H:%M:%S %Z\"')\n        assert flask.json.JSONEncoder().encode(dt) == expected </s> remove     @pytest.mark.skipif('not has_pytz')\n    @pytest.mark.parametrize('tzname', ('UTC', 'PST8PDT', 'Asia/Seoul'))\n    def test_jsonify_aware_datetimes(self, tzname):\n </s> add     @pytest.mark.parametrize('tz', (('UTC', 0), ('PST', -8), ('KST', 9)))\n    def test_jsonify_aware_datetimes(self, tz): </s> remove try:\n    from pytz import timezone\nexcept ImportError:\n    has_pytz = False\nelse:\n    has_pytz = True\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f80376027571ba5190ab6cf1411dd1dd9bb9c65e", "file_name": "tox.ini"}
{"docstring_tokens": "keep keep replace keep keep keep replace keep keep", "code_tokens": " <mask>         self.assert_equal(import_hooks, 1)\n <mask> \n <mask>     def test_flaskext_simple_import_normal(self):\n <mask>         from flask.ext.newext_simple import ext_id\n <mask>         self.assert_equal(ext_id, 'newext_simple')\n <mask> \n <mask>     def test_flaskext_simple_import_module(self):\n <mask>         from flask.ext import newext_simple\n <mask>         self.assert_equal(newext_simple.ext_id, 'newext_simple')\n </s> Added tests for old imports </s> remove     def test_flaskext_package_import_normal(self):\n </s> add     def test_flaskext_new_package_import_normal(self): </s> remove     def test_flaskext_package_import_module(self):\n </s> add     def test_flaskext_new_package_import_module(self): </s> remove     def test_flaskext_package_import_submodule(self):\n </s> add     def test_flaskext_new_package_import_submodule(self):", "html_url": "https://github.com/pallets/flask/commit/f80bfcaa28da98972002fb906c2559babe75801e", "file_name": "flask/testsuite/ext.py"}
{"docstring_tokens": "keep keep replace keep keep keep replace", "code_tokens": " <mask>         self.assert_equal(newext_simple.__name__, 'flask_newext_simple')\n <mask> \n <mask>     def test_flaskext_package_import_normal(self):\n <mask>         from flask.ext.newext_package import ext_id\n <mask>         self.assert_equal(ext_id, 'newext_package')\n <mask> \n <mask>     def test_flaskext_package_import_module(self):\n </s> Added tests for old imports </s> remove     def test_flaskext_simple_import_module(self):\n </s> add     def test_flaskext_new_simple_import_module(self): </s> remove     def test_flaskext_package_import_submodule(self):\n </s> add     def test_flaskext_new_package_import_submodule(self): </s> remove     def test_flaskext_simple_import_normal(self):\n </s> add     def test_flaskext_new_simple_import_normal(self):", "html_url": "https://github.com/pallets/flask/commit/f80bfcaa28da98972002fb906c2559babe75801e", "file_name": "flask/testsuite/ext.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         from flask.ext import newext_package\n <mask>         self.assert_equal(newext_package.ext_id, 'newext_package')\n <mask>         self.assert_equal(newext_package.__name__, 'flask_newext_package')\n <mask> \n <mask>     def test_flaskext_package_import_submodule(self):\n <mask>         from flask.ext.newext_package import submodule\n <mask>         self.assert_equal(submodule.__name__, 'flask_newext_package.submodule')\n <mask>         self.assert_equal(submodule.test_function(), 42)\n <mask> \n <mask> \n </s> Added tests for old imports </s> remove     def test_flaskext_package_import_module(self):\n </s> add     def test_flaskext_new_package_import_module(self): </s> remove     def test_flaskext_package_import_normal(self):\n </s> add     def test_flaskext_new_package_import_normal(self): </s> remove     def test_flaskext_simple_import_module(self):\n </s> add     def test_flaskext_new_simple_import_module(self): </s> remove     def test_flaskext_simple_import_normal(self):\n </s> add     def test_flaskext_new_simple_import_normal(self):", "html_url": "https://github.com/pallets/flask/commit/f80bfcaa28da98972002fb906c2559babe75801e", "file_name": "flask/testsuite/ext.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> that people can easily install the development version into their\n <mask> virtualenv without having to download the library by hand.\n <mask> \n <mask> Flask extensions must be licensed under a BSD, MIT or more liberal license\n <mask> to be able to be enlisted in the Flask Extension Registry.  Keep in mind\n <mask> that the Flask Extension Registry is a moderated place and libraries will\n <mask> be reviewed upfront if they behave as required.\n <mask> \n <mask> \"Hello Flaskext!\"\n <mask> -----------------\n </s> Some grammar and typo fixes </s> remove What's important about classes is that they encourage to be shared around\non module level.  In that case, the object itself must not under any\n </s> add When designing your classes, it's important to make them easily reusable\nat the module level. This means the object itself must not under any </s> remove between different application.\n </s> add between different applications. </s> remove you did, it might be a very good idea to get some more input.  This not\nonly to get an idea about what people might want to have from an\nextension, but also to avoid having multiple developers working on pretty\nmuch the same side by side.\n </s> add you did, it might be a very good idea to get some more input.  This not only\ngenerates useful feedback on what people might want from an extension, but\nalso avoids having multiple developers working in isolation on pretty much the\nsame problem.", "html_url": "https://github.com/pallets/flask/commit/f80ea4fe5d3f194c567d3fd279e1e84050a12b10", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> What to use depends on what you have in mind.  For the SQLite 3 extension\n <mask> we will use the class-based approach because it will provide users with an\n <mask> object that handles opening and closing database connections.\n <mask> \n <mask> What's important about classes is that they encourage to be shared around\n <mask> on module level.  In that case, the object itself must not under any\n <mask> circumstances store any application specific state and must be shareable\n <mask> between different application.\n <mask> \n <mask> The Extension Code\n <mask> ------------------\n </s> Some grammar and typo fixes </s> remove between different application.\n </s> add between different applications. </s> remove to be able to be enlisted in the Flask Extension Registry.  Keep in mind\n </s> add in order to be listed in the Flask Extension Registry.  Keep in mind </s> remove you did, it might be a very good idea to get some more input.  This not\nonly to get an idea about what people might want to have from an\nextension, but also to avoid having multiple developers working on pretty\nmuch the same side by side.\n </s> add you did, it might be a very good idea to get some more input.  This not only\ngenerates useful feedback on what people might want from an extension, but\nalso avoids having multiple developers working in isolation on pretty much the\nsame problem.", "html_url": "https://github.com/pallets/flask/commit/f80ea4fe5d3f194c567d3fd279e1e84050a12b10", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> What's important about classes is that they encourage to be shared around\n <mask> on module level.  In that case, the object itself must not under any\n <mask> circumstances store any application specific state and must be shareable\n <mask> between different application.\n <mask> \n <mask> The Extension Code\n <mask> ------------------\n <mask> \n <mask> Here's the contents of the `flask_sqlite3.py` for copy/paste::\n </s> Some grammar and typo fixes </s> remove What's important about classes is that they encourage to be shared around\non module level.  In that case, the object itself must not under any\n </s> add When designing your classes, it's important to make them easily reusable\nat the module level. This means the object itself must not under any </s> remove to be able to be enlisted in the Flask Extension Registry.  Keep in mind\n </s> add in order to be listed in the Flask Extension Registry.  Keep in mind </s> remove you did, it might be a very good idea to get some more input.  This not\nonly to get an idea about what people might want to have from an\nextension, but also to avoid having multiple developers working on pretty\nmuch the same side by side.\n </s> add you did, it might be a very good idea to get some more input.  This not only\ngenerates useful feedback on what people might want from an extension, but\nalso avoids having multiple developers working in isolation on pretty much the\nsame problem.", "html_url": "https://github.com/pallets/flask/commit/f80ea4fe5d3f194c567d3fd279e1e84050a12b10", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> development.  If you want to learn more, it's a very good idea to check\n <mask> out existing extensions on the `Flask Extension Registry`_.  If you feel\n <mask> lost there is still the `mailinglist`_ and the `IRC channel`_ to get some\n <mask> ideas for nice looking APIs.  Especially if you do something nobody before\n <mask> you did, it might be a very good idea to get some more input.  This not\n <mask> only to get an idea about what people might want to have from an\n <mask> extension, but also to avoid having multiple developers working on pretty\n <mask> much the same side by side.\n <mask> \n <mask> Remember: good API design is hard, so introduce your project on the\n <mask> mailinglist, and let other developers give you a helping hand with\n <mask> designing the API.\n <mask> \n </s> Some grammar and typo fixes </s> remove What's important about classes is that they encourage to be shared around\non module level.  In that case, the object itself must not under any\n </s> add When designing your classes, it's important to make them easily reusable\nat the module level. This means the object itself must not under any </s> remove between different application.\n </s> add between different applications. </s> remove to be able to be enlisted in the Flask Extension Registry.  Keep in mind\n </s> add in order to be listed in the Flask Extension Registry.  Keep in mind", "html_url": "https://github.com/pallets/flask/commit/f80ea4fe5d3f194c567d3fd279e1e84050a12b10", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                                   jsonify responses will be pretty printed\n <mask>                                   if they are not requested by an\n <mask>                                   XMLHttpRequest object (controlled by\n <mask>                                   the ``X-Requested-With`` header)\n <mask> ``TEMPLATES_AUTO_RELOAD``         Flask checks if template was modified each\n <mask>                                   time it is requested and reloads it if\n <mask>                                   necessary. But disk I/O is costly and it may\n <mask>                                   be viable to disable this feature by setting\n <mask>                                   this key to ``False``. This option does not\n <mask>                                   affect debug mode.\n <mask> ``EXPLAIN_TEMPLATE_LOADING``      If this is enabled then every attempt to\n <mask>                                   load a template will write an info\n <mask>                                   message to the logger explaining the\n <mask>                                   attempts to locate the template.  This\n <mask>                                   can be useful to figure out why\n </s> set TEMPLATE_AUTO_RELOAD default value to None </s> remove         'TEMPLATES_AUTO_RELOAD':                True,\n </s> add         'TEMPLATES_AUTO_RELOAD':                None, </s> remove             options['auto_reload'] = self.debug \\\n                or self.config['TEMPLATES_AUTO_RELOAD']\n </s> add             if self.config['TEMPLATES_AUTO_RELOAD'] is not None:\n                options['auto_reload'] = self.config['TEMPLATES_AUTO_RELOAD']\n            else:\n                options['auto_reload'] = self.debug </s> remove     assert not app.jinja_env.auto_reload\n </s> add     assert app.debug is False\n    assert app.jinja_env.auto_reload is False\n    # debug is False, config option is True\n    app = flask.Flask(__name__)\n    app.config['TEMPLATES_AUTO_RELOAD'] = True\n    assert app.debug is False\n    assert app.jinja_env.auto_reload is True\n    # debug is True, config option is None\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n    assert app.jinja_env.auto_reload is True\n    # debug is True, config option is False\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    app.config['TEMPLATES_AUTO_RELOAD'] = False\n    assert app.jinja_env.auto_reload is False\n    # debug is True, config option is True\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    app.config['TEMPLATES_AUTO_RELOAD'] = True\n    assert app.jinja_env.auto_reload is True </s> remove     assert app.config['TEMPLATES_AUTO_RELOAD']\n    assert app.jinja_env.auto_reload\n </s> add     assert app.debug is False\n    assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n    assert app.jinja_env.auto_reload is False\n    # debug is False, config option is False </s> add     # debug is False, config option is None", "html_url": "https://github.com/pallets/flask/commit/f88765d504ce2fa9bc3926c76910b11510522892", "file_name": "docs/config.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         'PREFERRED_URL_SCHEME':                 'http',\n <mask>         'JSON_AS_ASCII':                        True,\n <mask>         'JSON_SORT_KEYS':                       True,\n <mask>         'JSONIFY_PRETTYPRINT_REGULAR':          True,\n <mask>         'TEMPLATES_AUTO_RELOAD':                True,\n <mask>     })\n <mask> \n <mask>     #: The rule object to use for URL rules created.  This is used by\n <mask>     #: :meth:`add_url_rule`.  Defaults to :class:`werkzeug.routing.Rule`.\n <mask>     #:\n </s> set TEMPLATE_AUTO_RELOAD default value to None </s> remove ``TEMPLATES_AUTO_RELOAD``         Flask checks if template was modified each\n                                  time it is requested and reloads it if\n                                  necessary. But disk I/O is costly and it may\n                                  be viable to disable this feature by setting\n                                  this key to ``False``. This option does not\n                                  affect debug mode.\n </s> add ``TEMPLATES_AUTO_RELOAD``         If this is set to `True` every time a template\n                                  is requested Flask checks if the template was\n                                  modified and if yes, it will reload the\n                                  template. By default the value is ``None``\n                                  which means that Flask checks template\n                                  sources only in debug mode. </s> remove     assert not app.jinja_env.auto_reload\n </s> add     assert app.debug is False\n    assert app.jinja_env.auto_reload is False\n    # debug is False, config option is True\n    app = flask.Flask(__name__)\n    app.config['TEMPLATES_AUTO_RELOAD'] = True\n    assert app.debug is False\n    assert app.jinja_env.auto_reload is True\n    # debug is True, config option is None\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n    assert app.jinja_env.auto_reload is True\n    # debug is True, config option is False\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    app.config['TEMPLATES_AUTO_RELOAD'] = False\n    assert app.jinja_env.auto_reload is False\n    # debug is True, config option is True\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    app.config['TEMPLATES_AUTO_RELOAD'] = True\n    assert app.jinja_env.auto_reload is True </s> add     # debug is False, config option is None </s> remove     assert app.config['TEMPLATES_AUTO_RELOAD']\n    assert app.jinja_env.auto_reload\n </s> add     assert app.debug is False\n    assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n    assert app.jinja_env.auto_reload is False\n    # debug is False, config option is False </s> remove             options['auto_reload'] = self.debug \\\n                or self.config['TEMPLATES_AUTO_RELOAD']\n </s> add             if self.config['TEMPLATES_AUTO_RELOAD'] is not None:\n                options['auto_reload'] = self.config['TEMPLATES_AUTO_RELOAD']\n            else:\n                options['auto_reload'] = self.debug", "html_url": "https://github.com/pallets/flask/commit/f88765d504ce2fa9bc3926c76910b11510522892", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         options = dict(self.jinja_options)\n <mask>         if 'autoescape' not in options:\n <mask>             options['autoescape'] = self.select_jinja_autoescape\n <mask>         if 'auto_reload' not in options:\n <mask>             options['auto_reload'] = self.debug \\\n <mask>                 or self.config['TEMPLATES_AUTO_RELOAD']\n <mask>         rv = Environment(self, **options)\n <mask>         rv.globals.update(\n <mask>             url_for=url_for,\n <mask>             get_flashed_messages=get_flashed_messages,\n <mask>             config=self.config,\n </s> set TEMPLATE_AUTO_RELOAD default value to None </s> remove ``TEMPLATES_AUTO_RELOAD``         Flask checks if template was modified each\n                                  time it is requested and reloads it if\n                                  necessary. But disk I/O is costly and it may\n                                  be viable to disable this feature by setting\n                                  this key to ``False``. This option does not\n                                  affect debug mode.\n </s> add ``TEMPLATES_AUTO_RELOAD``         If this is set to `True` every time a template\n                                  is requested Flask checks if the template was\n                                  modified and if yes, it will reload the\n                                  template. By default the value is ``None``\n                                  which means that Flask checks template\n                                  sources only in debug mode. </s> remove     assert not app.jinja_env.auto_reload\n </s> add     assert app.debug is False\n    assert app.jinja_env.auto_reload is False\n    # debug is False, config option is True\n    app = flask.Flask(__name__)\n    app.config['TEMPLATES_AUTO_RELOAD'] = True\n    assert app.debug is False\n    assert app.jinja_env.auto_reload is True\n    # debug is True, config option is None\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n    assert app.jinja_env.auto_reload is True\n    # debug is True, config option is False\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    app.config['TEMPLATES_AUTO_RELOAD'] = False\n    assert app.jinja_env.auto_reload is False\n    # debug is True, config option is True\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    app.config['TEMPLATES_AUTO_RELOAD'] = True\n    assert app.jinja_env.auto_reload is True </s> remove     assert app.config['TEMPLATES_AUTO_RELOAD']\n    assert app.jinja_env.auto_reload\n </s> add     assert app.debug is False\n    assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n    assert app.jinja_env.auto_reload is False\n    # debug is False, config option is False </s> add     # debug is False, config option is None </s> remove         'TEMPLATES_AUTO_RELOAD':                True,\n </s> add         'TEMPLATES_AUTO_RELOAD':                None,", "html_url": "https://github.com/pallets/flask/commit/f88765d504ce2fa9bc3926c76910b11510522892", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     assert rv.data == b'<h1>Jameson</h1>'\n <mask> \n <mask> def test_templates_auto_reload():\n <mask>     app = flask.Flask(__name__)\n <mask>     assert app.debug is False\n <mask>     assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n <mask>     assert app.jinja_env.auto_reload is False\n <mask>     # debug is False, config option is False\n </s> set TEMPLATE_AUTO_RELOAD default value to None </s> remove     assert app.config['TEMPLATES_AUTO_RELOAD']\n    assert app.jinja_env.auto_reload\n </s> add     assert app.debug is False\n    assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n    assert app.jinja_env.auto_reload is False\n    # debug is False, config option is False </s> remove     assert not app.jinja_env.auto_reload\n </s> add     assert app.debug is False\n    assert app.jinja_env.auto_reload is False\n    # debug is False, config option is True\n    app = flask.Flask(__name__)\n    app.config['TEMPLATES_AUTO_RELOAD'] = True\n    assert app.debug is False\n    assert app.jinja_env.auto_reload is True\n    # debug is True, config option is None\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n    assert app.jinja_env.auto_reload is True\n    # debug is True, config option is False\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    app.config['TEMPLATES_AUTO_RELOAD'] = False\n    assert app.jinja_env.auto_reload is False\n    # debug is True, config option is True\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    app.config['TEMPLATES_AUTO_RELOAD'] = True\n    assert app.jinja_env.auto_reload is True </s> remove ``TEMPLATES_AUTO_RELOAD``         Flask checks if template was modified each\n                                  time it is requested and reloads it if\n                                  necessary. But disk I/O is costly and it may\n                                  be viable to disable this feature by setting\n                                  this key to ``False``. This option does not\n                                  affect debug mode.\n </s> add ``TEMPLATES_AUTO_RELOAD``         If this is set to `True` every time a template\n                                  is requested Flask checks if the template was\n                                  modified and if yes, it will reload the\n                                  template. By default the value is ``None``\n                                  which means that Flask checks template\n                                  sources only in debug mode. </s> remove             options['auto_reload'] = self.debug \\\n                or self.config['TEMPLATES_AUTO_RELOAD']\n </s> add             if self.config['TEMPLATES_AUTO_RELOAD'] is not None:\n                options['auto_reload'] = self.config['TEMPLATES_AUTO_RELOAD']\n            else:\n                options['auto_reload'] = self.debug </s> remove         'TEMPLATES_AUTO_RELOAD':                True,\n </s> add         'TEMPLATES_AUTO_RELOAD':                None,", "html_url": "https://github.com/pallets/flask/commit/f88765d504ce2fa9bc3926c76910b11510522892", "file_name": "tests/test_templating.py"}
{"docstring_tokens": "keep replace replace keep keep replace keep keep", "code_tokens": " <mask>     app = flask.Flask(__name__)\n <mask>     assert app.config['TEMPLATES_AUTO_RELOAD']\n <mask>     assert app.jinja_env.auto_reload\n <mask>     app = flask.Flask(__name__)\n <mask>     app.config['TEMPLATES_AUTO_RELOAD'] = False\n <mask>     assert not app.jinja_env.auto_reload\n <mask> \n <mask> def test_template_loader_debugging(test_apps):\n </s> set TEMPLATE_AUTO_RELOAD default value to None </s> remove             options['auto_reload'] = self.debug \\\n                or self.config['TEMPLATES_AUTO_RELOAD']\n </s> add             if self.config['TEMPLATES_AUTO_RELOAD'] is not None:\n                options['auto_reload'] = self.config['TEMPLATES_AUTO_RELOAD']\n            else:\n                options['auto_reload'] = self.debug </s> add     # debug is False, config option is None </s> remove ``TEMPLATES_AUTO_RELOAD``         Flask checks if template was modified each\n                                  time it is requested and reloads it if\n                                  necessary. But disk I/O is costly and it may\n                                  be viable to disable this feature by setting\n                                  this key to ``False``. This option does not\n                                  affect debug mode.\n </s> add ``TEMPLATES_AUTO_RELOAD``         If this is set to `True` every time a template\n                                  is requested Flask checks if the template was\n                                  modified and if yes, it will reload the\n                                  template. By default the value is ``None``\n                                  which means that Flask checks template\n                                  sources only in debug mode. </s> remove         'TEMPLATES_AUTO_RELOAD':                True,\n </s> add         'TEMPLATES_AUTO_RELOAD':                None,", "html_url": "https://github.com/pallets/flask/commit/f88765d504ce2fa9bc3926c76910b11510522892", "file_name": "tests/test_templating.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> Here you can see the full list of changes between each Flask release.\n <mask> \n <mask> Version 0.10.1\n <mask> --------------\n <mask> \n <mask> (bugfix release, released on June 14th 2013)\n <mask> \n </s> Fix broken test_appcontext_signals test case\n\nThis fixes #781 and ensures that Flask is tested with blinker installed. </s> add        blinker </s> remove             recorded.append('push')\n </s> add             recorded.append('pop')", "html_url": "https://github.com/pallets/flask/commit/f88cc2d2f9d14d97e33ddd2bbaa4b1885db06e1c", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         recorded = []\n <mask>         def record_push(sender, **kwargs):\n <mask>             recorded.append('push')\n <mask>         def record_pop(sender, **kwargs):\n <mask>             recorded.append('push')\n <mask> \n <mask>         @app.route('/')\n <mask>         def index():\n <mask>             return 'Hello'\n <mask> \n </s> Fix broken test_appcontext_signals test case\n\nThis fixes #781 and ensures that Flask is tested with blinker installed. </s> add        blinker </s> add Version 0.10.2\n--------------\n\n(bugfix release, release date to be announced)\n\n- Fixed broken `test_appcontext_signals()` test case.\n", "html_url": "https://github.com/pallets/flask/commit/f88cc2d2f9d14d97e33ddd2bbaa4b1885db06e1c", "file_name": "flask/testsuite/signals.py"}
{"docstring_tokens": "keep keep keep add keep", "code_tokens": " <mask> envlist = py26, py27, pypy, py33\n <mask> \n <mask> [testenv]\n <mask> deps = -egit+git://github.com/mitsuhiko/werkzeug.git#egg=werkzeug\n <mask> commands = python run-tests.py []\n </s> Fix broken test_appcontext_signals test case\n\nThis fixes #781 and ensures that Flask is tested with blinker installed. </s> remove             recorded.append('push')\n </s> add             recorded.append('pop') </s> add Version 0.10.2\n--------------\n\n(bugfix release, release date to be announced)\n\n- Fixed broken `test_appcontext_signals()` test case.\n", "html_url": "https://github.com/pallets/flask/commit/f88cc2d2f9d14d97e33ddd2bbaa4b1885db06e1c", "file_name": "tox.ini"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     ``@app.route(\"/login\", methods=[\"POST\"])``. :pr:`3907`\n <mask> -   Support async views, error handlers, before and after request, and\n <mask>     teardown functions. :pr:`3412`\n <mask> \n <mask> \n <mask> Version 1.1.2\n <mask> -------------\n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove                 if handler is not None:\n                    return handler\n </s> add                     if handler is not None:\n                        return handler </s> remove         bp = _request_ctx_stack.top.request.blueprint\n\n </s> add  </s> remove         if bp is not None and bp in self.url_value_preprocessors:\n            funcs = chain(funcs, self.url_value_preprocessors[bp])\n </s> add         for bp in self._request_blueprints():\n            if bp in self.url_value_preprocessors:\n                funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> add         self._blueprints = [] </s> remove     def register(self, app, options, first_registration=False):\n </s> add     def register_blueprint(self, blueprint, **options):\n        \"\"\"Register a :class:`~flask.Blueprint` on this blueprint. Keyword\n        arguments passed to this method will override the defaults set\n        on the blueprint.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        self._blueprints.append((blueprint, options))\n\n    def register(self, app, options): </s> add         self.name_prefix = self.options.get(\"name_prefix\", \"\")\n", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         funcs = self.template_context_processors[None]\n <mask>         reqctx = _request_ctx_stack.top\n <mask>         if reqctx is not None:\n <mask>             bp = reqctx.request.blueprint\n <mask>             if bp is not None and bp in self.template_context_processors:\n <mask>                 funcs = chain(funcs, self.template_context_processors[bp])\n <mask>         orig_ctx = context.copy()\n <mask>         for func in funcs:\n <mask>             context.update(func())\n <mask>         # make sure the original values win.  This makes it possible to\n <mask>         # easier add new variables in context processors without breaking\n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.after_request_funcs:\n                funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp])\n </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp]) </s> remove         if bp is not None and bp in self.url_value_preprocessors:\n            funcs = chain(funcs, self.url_value_preprocessors[bp])\n </s> add         for bp in self._request_blueprints():\n            if bp in self.url_value_preprocessors:\n                funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> remove         bp = ctx.request.blueprint\n </s> add  </s> remove         bp = _request_ctx_stack.top.request.blueprint\n\n </s> add  </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             accessed in :meth:`~flask.Blueprint.record` callbacks.\n <mask> \n <mask>         .. versionadded:: 0.7\n <mask>         \"\"\"\n <mask>         first_registration = False\n <mask> \n <mask>         if blueprint.name in self.blueprints:\n <mask>             assert self.blueprints[blueprint.name] is blueprint, (\n <mask>                 \"A name collision occurred between blueprints\"\n <mask>                 f\" {blueprint!r} and {self.blueprints[blueprint.name]!r}.\"\n <mask>                 f\" Both share the same name {blueprint.name!r}.\"\n <mask>                 f\" Blueprints that are created on the fly need unique\"\n <mask>                 f\" names.\"\n <mask>             )\n <mask>         else:\n <mask>             self.blueprints[blueprint.name] = blueprint\n <mask>             first_registration = True\n <mask> \n <mask>         blueprint.register(self, options, first_registration)\n <mask> \n <mask>     def iter_blueprints(self):\n <mask>         \"\"\"Iterates over all blueprints by the order they were registered.\n <mask> \n <mask>         .. versionadded:: 0.11\n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> add         first_registration = False\n\n        if self.name in app.blueprints:\n            assert app.blueprints[self.name] is self, (\n                \"A name collision occurred between blueprints\"\n                f\" {self!r} and {app.blueprints[self.name]!r}.\"\n                f\" Both share the same name {self.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            app.blueprints[self.name] = self\n            first_registration = True\n </s> remove     def register(self, app, options, first_registration=False):\n </s> add     def register_blueprint(self, blueprint, **options):\n        \"\"\"Register a :class:`~flask.Blueprint` on this blueprint. Keyword\n        arguments passed to this method will override the defaults set\n        on the blueprint.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        self._blueprints.append((blueprint, options))\n\n    def register(self, app, options): </s> remove         if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli)\n </s> add         if self.cli.commands:\n            if cli_resolved_group is None:\n                app.cli.commands.update(self.cli.commands)\n            elif cli_resolved_group is _sentinel:\n                self.cli.name = self.name\n                app.cli.add_command(self.cli)\n            else:\n                self.cli.name = cli_resolved_group\n                app.cli.add_command(self.cli)\n\n        for blueprint, bp_options in self._blueprints:\n            url_prefix = options.get(\"url_prefix\", \"\")\n            if \"url_prefix\" in bp_options:\n                url_prefix = (\n                    url_prefix.rstrip(\"/\") + \"/\" + bp_options[\"url_prefix\"].lstrip(\"/\")\n                )\n\n            bp_options[\"url_prefix\"] = url_prefix\n            bp_options[\"name_prefix\"] = options.get(\"name_prefix\", \"\") + self.name + \".\"\n            blueprint.register(app, bp_options) </s> remove         for name, c in (\n            (request.blueprint, code),\n            (None, code),\n            (request.blueprint, None),\n            (None, None),\n        ):\n            handler_map = self.error_handler_spec[name][c]\n </s> add         for c in [code, None]:\n            for name in chain(self._request_blueprints(), [None]):\n                handler_map = self.error_handler_spec[name][c] </s> add         self._blueprints = [] </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace keep replace replace", "code_tokens": " <mask> \n <mask>         for name, c in (\n <mask>             (request.blueprint, code),\n <mask>             (None, code),\n <mask>             (request.blueprint, None),\n <mask>             (None, None),\n <mask>         ):\n <mask>             handler_map = self.error_handler_spec[name][c]\n <mask> \n <mask>             if not handler_map:\n <mask>                 continue\n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove             for cls in exc_class.__mro__:\n                handler = handler_map.get(cls)\n </s> add                 for cls in exc_class.__mro__:\n                    handler = handler_map.get(cls) </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp])\n </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp]) </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.after_request_funcs:\n                funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> remove         if bp is not None and bp in self.url_value_preprocessors:\n            funcs = chain(funcs, self.url_value_preprocessors[bp])\n </s> add         for bp in self._request_blueprints():\n            if bp in self.url_value_preprocessors:\n                funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>             if not handler_map:\n <mask>                 continue\n <mask> \n <mask>             for cls in exc_class.__mro__:\n <mask>                 handler = handler_map.get(cls)\n <mask> \n <mask>                 if handler is not None:\n <mask>                     return handler\n <mask> \n <mask>     def handle_http_exception(self, e):\n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove             if not handler_map:\n                continue\n </s> add                 if not handler_map:\n                    continue </s> remove                 if handler is not None:\n                    return handler\n </s> add                     if handler is not None:\n                        return handler </s> remove         for name, c in (\n            (request.blueprint, code),\n            (None, code),\n            (request.blueprint, None),\n            (None, None),\n        ):\n            handler_map = self.error_handler_spec[name][c]\n </s> add         for c in [code, None]:\n            for name in chain(self._request_blueprints(), [None]):\n                handler_map = self.error_handler_spec[name][c] </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.after_request_funcs:\n                funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp])\n </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp]) </s> remove         if not self.cli.commands:\n            return\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>             for cls in exc_class.__mro__:\n <mask>                 handler = handler_map.get(cls)\n <mask> \n <mask>                 if handler is not None:\n <mask>                     return handler\n <mask> \n <mask>     def handle_http_exception(self, e):\n <mask>         \"\"\"Handles an HTTP exception.  By default this will invoke the\n <mask>         registered error handlers and fall back to returning the\n <mask>         exception as response.\n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove             for cls in exc_class.__mro__:\n                handler = handler_map.get(cls)\n </s> add                 for cls in exc_class.__mro__:\n                    handler = handler_map.get(cls) </s> remove             if not handler_map:\n                continue\n </s> add                 if not handler_map:\n                    continue </s> remove         for name, c in (\n            (request.blueprint, code),\n            (None, code),\n            (request.blueprint, None),\n            (None, None),\n        ):\n            handler_map = self.error_handler_spec[name][c]\n </s> add         for c in [code, None]:\n            for name in chain(self._request_blueprints(), [None]):\n                handler_map = self.error_handler_spec[name][c] </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.after_request_funcs:\n                funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> remove     def register(self, app, options, first_registration=False):\n </s> add     def register_blueprint(self, blueprint, **options):\n        \"\"\"Register a :class:`~flask.Blueprint` on this blueprint. Keyword\n        arguments passed to this method will override the defaults set\n        on the blueprint.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        self._blueprints.append((blueprint, options))\n\n    def register(self, app, options): </s> remove         bp = _request_ctx_stack.top.request.blueprint\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         value is handled as if it was the return value from the view, and\n <mask>         further request handling is stopped.\n <mask>         \"\"\"\n <mask> \n <mask>         bp = _request_ctx_stack.top.request.blueprint\n <mask> \n <mask>         funcs = self.url_value_preprocessors[None]\n <mask>         if bp is not None and bp in self.url_value_preprocessors:\n <mask>             funcs = chain(funcs, self.url_value_preprocessors[bp])\n <mask>         for func in funcs:\n <mask>             func(request.endpoint, request.view_args)\n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove         if bp is not None and bp in self.url_value_preprocessors:\n            funcs = chain(funcs, self.url_value_preprocessors[bp])\n </s> add         for bp in self._request_blueprints():\n            if bp in self.url_value_preprocessors:\n                funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp])\n </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp]) </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> remove             bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp])\n </s> add             for bp in self._request_blueprints():\n                if bp in self.template_context_processors:\n                    funcs = chain(funcs, self.template_context_processors[bp]) </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.after_request_funcs:\n                funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> remove         bp = ctx.request.blueprint\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep replace replace keep keep keep keep replace replace keep keep keep", "code_tokens": " <mask> \n <mask>         funcs = self.url_value_preprocessors[None]\n <mask>         if bp is not None and bp in self.url_value_preprocessors:\n <mask>             funcs = chain(funcs, self.url_value_preprocessors[bp])\n <mask>         for func in funcs:\n <mask>             func(request.endpoint, request.view_args)\n <mask> \n <mask>         funcs = self.before_request_funcs[None]\n <mask>         if bp is not None and bp in self.before_request_funcs:\n <mask>             funcs = chain(funcs, self.before_request_funcs[bp])\n <mask>         for func in funcs:\n <mask>             rv = func()\n <mask>             if rv is not None:\n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove         bp = _request_ctx_stack.top.request.blueprint\n\n </s> add  </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.after_request_funcs:\n                funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> remove             bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp])\n </s> add             for bp in self._request_blueprints():\n                if bp in self.template_context_processors:\n                    funcs = chain(funcs, self.template_context_processors[bp]) </s> remove         bp = ctx.request.blueprint\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep replace keep replace replace keep", "code_tokens": " <mask>         \"\"\"\n <mask>         ctx = _request_ctx_stack.top\n <mask>         bp = ctx.request.blueprint\n <mask>         funcs = ctx._after_request_functions\n <mask>         if bp is not None and bp in self.after_request_funcs:\n <mask>             funcs = chain(funcs, reversed(self.after_request_funcs[bp]))\n <mask>         if None in self.after_request_funcs:\n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove         if bp is not None and bp in self.url_value_preprocessors:\n            funcs = chain(funcs, self.url_value_preprocessors[bp])\n </s> add         for bp in self._request_blueprints():\n            if bp in self.url_value_preprocessors:\n                funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> remove             bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp])\n </s> add             for bp in self._request_blueprints():\n                if bp in self.template_context_processors:\n                    funcs = chain(funcs, self.template_context_processors[bp]) </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp])\n </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp]) </s> remove         bp = _request_ctx_stack.top.request.blueprint\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         if exc is _sentinel:\n <mask>             exc = sys.exc_info()[1]\n <mask>         funcs = reversed(self.teardown_request_funcs[None])\n <mask>         bp = _request_ctx_stack.top.request.blueprint\n <mask>         if bp is not None and bp in self.teardown_request_funcs:\n <mask>             funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))\n <mask>         for func in funcs:\n <mask>             func(exc)\n <mask>         request_tearing_down.send(self, exc=exc)\n <mask> \n <mask>     def do_teardown_appcontext(self, exc=_sentinel):\n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove         if bp is not None and bp in self.url_value_preprocessors:\n            funcs = chain(funcs, self.url_value_preprocessors[bp])\n </s> add         for bp in self._request_blueprints():\n            if bp in self.url_value_preprocessors:\n                funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp])\n </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp]) </s> remove         bp = _request_ctx_stack.top.request.blueprint\n\n </s> add  </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.after_request_funcs:\n                funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> remove             bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp])\n </s> add             for bp in self._request_blueprints():\n                if bp in self.template_context_processors:\n                    funcs = chain(funcs, self.template_context_processors[bp]) </s> remove         bp = ctx.request.blueprint\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep add", "code_tokens": " <mask>         WSGI application. This calls :meth:`wsgi_app`, which can be\n <mask>         wrapped to apply middleware.\n <mask>         \"\"\"\n <mask>         return self.wsgi_app(environ, start_response)\n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove     def register(self, app, options, first_registration=False):\n </s> add     def register_blueprint(self, blueprint, **options):\n        \"\"\"Register a :class:`~flask.Blueprint` on this blueprint. Keyword\n        arguments passed to this method will override the defaults set\n        on the blueprint.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        self._blueprints.append((blueprint, options))\n\n    def register(self, app, options): </s> remove         bp = ctx.request.blueprint\n </s> add  </s> remove             bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp])\n </s> add             for bp in self._request_blueprints():\n                if bp in self.template_context_processors:\n                    funcs = chain(funcs, self.template_context_processors[bp]) </s> add         first_registration = False\n\n        if self.name in app.blueprints:\n            assert app.blueprints[self.name] is self, (\n                \"A name collision occurred between blueprints\"\n                f\" {self!r} and {app.blueprints[self.name]!r}.\"\n                f\" Both share the same name {self.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            app.blueprints[self.name] = self\n            first_registration = True\n </s> remove                 if handler is not None:\n                    return handler\n </s> add                     if handler is not None:\n                        return handler </s> add         self.name_prefix = self.options.get(\"name_prefix\", \"\")\n", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         #: blueprint.\n <mask>         self.url_prefix = url_prefix\n <mask> \n <mask>         #: A dictionary with URL defaults that is added to each and every\n <mask>         #: URL that was defined with the blueprint.\n <mask>         self.url_defaults = dict(self.blueprint.url_values_defaults)\n <mask>         self.url_defaults.update(self.options.get(\"url_defaults\", ()))\n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove         if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli)\n </s> add         if self.cli.commands:\n            if cli_resolved_group is None:\n                app.cli.commands.update(self.cli.commands)\n            elif cli_resolved_group is _sentinel:\n                self.cli.name = self.name\n                app.cli.add_command(self.cli)\n            else:\n                self.cli.name = cli_resolved_group\n                app.cli.add_command(self.cli)\n\n        for blueprint, bp_options in self._blueprints:\n            url_prefix = options.get(\"url_prefix\", \"\")\n            if \"url_prefix\" in bp_options:\n                url_prefix = (\n                    url_prefix.rstrip(\"/\") + \"/\" + bp_options[\"url_prefix\"].lstrip(\"/\")\n                )\n\n            bp_options[\"url_prefix\"] = url_prefix\n            bp_options[\"name_prefix\"] = options.get(\"name_prefix\", \"\") + self.name + \".\"\n            blueprint.register(app, bp_options) </s> remove     def register(self, app, options, first_registration=False):\n </s> add     def register_blueprint(self, blueprint, **options):\n        \"\"\"Register a :class:`~flask.Blueprint` on this blueprint. Keyword\n        arguments passed to this method will override the defaults set\n        on the blueprint.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        self._blueprints.append((blueprint, options))\n\n    def register(self, app, options): </s> add         self._blueprints = [] </s> remove         bp = _request_ctx_stack.top.request.blueprint\n\n </s> add  </s> add         first_registration = False\n\n        if self.name in app.blueprints:\n            assert app.blueprints[self.name] is self, (\n                \"A name collision occurred between blueprints\"\n                f\" {self!r} and {app.blueprints[self.name]!r}.\"\n                f\" Both share the same name {self.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            app.blueprints[self.name] = self\n            first_registration = True\n </s> remove         first_registration = False\n\n        if blueprint.name in self.blueprints:\n            assert self.blueprints[blueprint.name] is blueprint, (\n                \"A name collision occurred between blueprints\"\n                f\" {blueprint!r} and {self.blueprints[blueprint.name]!r}.\"\n                f\" Both share the same name {blueprint.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            self.blueprints[blueprint.name] = blueprint\n            first_registration = True\n\n        blueprint.register(self, options, first_registration)\n </s> add         blueprint.register(self, options)", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if \"defaults\" in options:\n <mask>             defaults = dict(defaults, **options.pop(\"defaults\"))\n <mask>         self.app.add_url_rule(\n <mask>             rule,\n <mask>             f\"{self.blueprint.name}.{endpoint}\",\n <mask>             view_func,\n <mask>             defaults=defaults,\n <mask>             **options,\n <mask>         )\n <mask> \n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove         if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli)\n </s> add         if self.cli.commands:\n            if cli_resolved_group is None:\n                app.cli.commands.update(self.cli.commands)\n            elif cli_resolved_group is _sentinel:\n                self.cli.name = self.name\n                app.cli.add_command(self.cli)\n            else:\n                self.cli.name = cli_resolved_group\n                app.cli.add_command(self.cli)\n\n        for blueprint, bp_options in self._blueprints:\n            url_prefix = options.get(\"url_prefix\", \"\")\n            if \"url_prefix\" in bp_options:\n                url_prefix = (\n                    url_prefix.rstrip(\"/\") + \"/\" + bp_options[\"url_prefix\"].lstrip(\"/\")\n                )\n\n            bp_options[\"url_prefix\"] = url_prefix\n            bp_options[\"name_prefix\"] = options.get(\"name_prefix\", \"\") + self.name + \".\"\n            blueprint.register(app, bp_options) </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.after_request_funcs:\n                funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> add         first_registration = False\n\n        if self.name in app.blueprints:\n            assert app.blueprints[self.name] is self, (\n                \"A name collision occurred between blueprints\"\n                f\" {self!r} and {app.blueprints[self.name]!r}.\"\n                f\" Both share the same name {self.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            app.blueprints[self.name] = self\n            first_registration = True\n </s> remove         if bp is not None and bp in self.url_value_preprocessors:\n            funcs = chain(funcs, self.url_value_preprocessors[bp])\n </s> add         for bp in self._request_blueprints():\n            if bp in self.url_value_preprocessors:\n                funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp])\n </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp]) </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         self.url_values_defaults = url_defaults\n <mask>         self.cli_group = cli_group\n <mask> \n <mask>     def _is_setup_finished(self):\n <mask>         return self.warn_on_modifications and self._got_registered_once\n <mask> \n <mask>     def record(self, func):\n <mask>         \"\"\"Registers a function that is called when the blueprint is\n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> add         first_registration = False\n\n        if self.name in app.blueprints:\n            assert app.blueprints[self.name] is self, (\n                \"A name collision occurred between blueprints\"\n                f\" {self!r} and {app.blueprints[self.name]!r}.\"\n                f\" Both share the same name {self.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            app.blueprints[self.name] = self\n            first_registration = True\n </s> remove         if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli)\n </s> add         if self.cli.commands:\n            if cli_resolved_group is None:\n                app.cli.commands.update(self.cli.commands)\n            elif cli_resolved_group is _sentinel:\n                self.cli.name = self.name\n                app.cli.add_command(self.cli)\n            else:\n                self.cli.name = cli_resolved_group\n                app.cli.add_command(self.cli)\n\n        for blueprint, bp_options in self._blueprints:\n            url_prefix = options.get(\"url_prefix\", \"\")\n            if \"url_prefix\" in bp_options:\n                url_prefix = (\n                    url_prefix.rstrip(\"/\") + \"/\" + bp_options[\"url_prefix\"].lstrip(\"/\")\n                )\n\n            bp_options[\"url_prefix\"] = url_prefix\n            bp_options[\"name_prefix\"] = options.get(\"name_prefix\", \"\") + self.name + \".\"\n            blueprint.register(app, bp_options) </s> add         self.name_prefix = self.options.get(\"name_prefix\", \"\")\n </s> remove         first_registration = False\n\n        if blueprint.name in self.blueprints:\n            assert self.blueprints[blueprint.name] is blueprint, (\n                \"A name collision occurred between blueprints\"\n                f\" {blueprint!r} and {self.blueprints[blueprint.name]!r}.\"\n                f\" Both share the same name {blueprint.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            self.blueprints[blueprint.name] = blueprint\n            first_registration = True\n\n        blueprint.register(self, options, first_registration)\n </s> add         blueprint.register(self, options) </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> remove         bp = ctx.request.blueprint\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         Subclasses can override this to return a subclass of the setup state.\n <mask>         \"\"\"\n <mask>         return BlueprintSetupState(self, app, options, first_registration)\n <mask> \n <mask>     def register(self, app, options, first_registration=False):\n <mask>         \"\"\"Called by :meth:`Flask.register_blueprint` to register all\n <mask>         views and callbacks registered on the blueprint with the\n <mask>         application. Creates a :class:`.BlueprintSetupState` and calls\n <mask>         each :meth:`record` callbackwith it.\n <mask> \n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> add         first_registration = False\n\n        if self.name in app.blueprints:\n            assert app.blueprints[self.name] is self, (\n                \"A name collision occurred between blueprints\"\n                f\" {self!r} and {app.blueprints[self.name]!r}.\"\n                f\" Both share the same name {self.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            app.blueprints[self.name] = self\n            first_registration = True\n </s> add     def _request_blueprints(self):\n        if _request_ctx_stack.top.request.blueprint is None:\n            return []\n        else:\n            return reversed(_request_ctx_stack.top.request.blueprint.split(\".\")) </s> remove         first_registration = False\n\n        if blueprint.name in self.blueprints:\n            assert self.blueprints[blueprint.name] is blueprint, (\n                \"A name collision occurred between blueprints\"\n                f\" {blueprint!r} and {self.blueprints[blueprint.name]!r}.\"\n                f\" Both share the same name {blueprint.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            self.blueprints[blueprint.name] = blueprint\n            first_registration = True\n\n        blueprint.register(self, options, first_registration)\n </s> add         blueprint.register(self, options) </s> add         self.name_prefix = self.options.get(\"name_prefix\", \"\")\n </s> remove                 if handler is not None:\n                    return handler\n </s> add                     if handler is not None:\n                        return handler </s> remove         bp = ctx.request.blueprint\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         :param first_registration: Whether this is the first time this\n <mask>             blueprint has been registered on the application.\n <mask>         \"\"\"\n <mask>         self._got_registered_once = True\n <mask>         state = self.make_setup_state(app, options, first_registration)\n <mask> \n <mask>         if self.has_static_folder:\n <mask>             state.add_url_rule(\n <mask>                 f\"{self.static_url_path}/<path:filename>\",\n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove     def register(self, app, options, first_registration=False):\n </s> add     def register_blueprint(self, blueprint, **options):\n        \"\"\"Register a :class:`~flask.Blueprint` on this blueprint. Keyword\n        arguments passed to this method will override the defaults set\n        on the blueprint.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        self._blueprints.append((blueprint, options))\n\n    def register(self, app, options): </s> remove         first_registration = False\n\n        if blueprint.name in self.blueprints:\n            assert self.blueprints[blueprint.name] is blueprint, (\n                \"A name collision occurred between blueprints\"\n                f\" {blueprint!r} and {self.blueprints[blueprint.name]!r}.\"\n                f\" Both share the same name {blueprint.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            self.blueprints[blueprint.name] = blueprint\n            first_registration = True\n\n        blueprint.register(self, options, first_registration)\n </s> add         blueprint.register(self, options) </s> remove                 if handler is not None:\n                    return handler\n </s> add                     if handler is not None:\n                        return handler </s> add         self._blueprints = [] </s> remove         bp = ctx.request.blueprint\n </s> add  </s> remove         bp = _request_ctx_stack.top.request.blueprint\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep replace replace replace keep keep replace replace replace replace replace replace replace replace keep keep", "code_tokens": " <mask>             deferred(state)\n <mask> \n <mask>         if not self.cli.commands:\n <mask>             return\n <mask> \n <mask>         cli_resolved_group = options.get(\"cli_group\", self.cli_group)\n <mask> \n <mask>         if cli_resolved_group is None:\n <mask>             app.cli.commands.update(self.cli.commands)\n <mask>         elif cli_resolved_group is _sentinel:\n <mask>             self.cli.name = self.name\n <mask>             app.cli.add_command(self.cli)\n <mask>         else:\n <mask>             self.cli.name = cli_resolved_group\n <mask>             app.cli.add_command(self.cli)\n <mask> \n <mask>     def add_url_rule(self, rule, endpoint=None, view_func=None, **options):\n </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))\n </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> remove             for cls in exc_class.__mro__:\n                handler = handler_map.get(cls)\n </s> add                 for cls in exc_class.__mro__:\n                    handler = handler_map.get(cls) </s> add         first_registration = False\n\n        if self.name in app.blueprints:\n            assert app.blueprints[self.name] is self, (\n                \"A name collision occurred between blueprints\"\n                f\" {self!r} and {app.blueprints[self.name]!r}.\"\n                f\" Both share the same name {self.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            app.blueprints[self.name] = self\n            first_registration = True\n </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp])\n </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp]) </s> remove             if not handler_map:\n                continue\n </s> add                 if not handler_map:\n                    continue", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>    It's now also possible to use the ``in`` operator on it to see if an\n <mask>    attribute is defined and it yields all keys on iteration.\n <mask> \n <mask>    As of 1.0 you can use :meth:`pop` and :meth:`setdefault` in the same\n <mask>    way you would use them on a dictionary.\n <mask> \n <mask>    This is a proxy.  See :ref:`notes-on-proxies` for more information.\n <mask> \n <mask> \n </s> 1.0 -> 0.11 in the docs </s> remove in Flask 1.0.  Previously it was possible to use etags and mimetypes\n </s> add in Flask 0.11.  Previously it was possible to use etags and mimetypes </s> remove As of Flask 1.0, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 1.0 but is\n </s> add As of Flask 0.11, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 0.11 but is </s> remove Version 1.0\n-----------\n </s> add Version 0.11\n------------\n\n0.11 is an odd release in the Flask release cycle because it was supposed\nto be the 1.0 release.  However because there was such a long lead time up\nto the release we decided to push out a 0.11 release first with some\nchanges removed to make the transition easier.  If you have been tracking\nthe master branch which was 1.0 you might see some unexpected changes.\n\nIn case you did track the master branch you will notice that `flask --app`\nis removed now.  You need to use the environment variable to specify an\napplication. </s> remove Starting with Flask 1.0 the recommended way to work with the shell is the\n </s> add Starting with Flask 0.11 the recommended way to work with the shell is the </s> remove debug a problem.  By default as of Flask 1.0, errors are logged to your\n </s> add debug a problem.  By default as of Flask 0.11, errors are logged to your </s> remove Starting with Flask 1.0 there are multiple built-in ways to run a\n </s> add Starting with Flask 0.11 there are multiple built-in ways to run a", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/api.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> .. versionadded:: 0.11\n <mask> \n <mask> .. currentmodule:: flask\n <mask> \n <mask> One of the nice new features in Flask 1.0 is the built-in integration of\n <mask> the `click <http://click.pocoo.org/>`_ command line interface.  This\n <mask> enables a wide range of new features for the Flask ecosystem and your own\n <mask> applications.\n <mask> \n <mask> Basic Usage\n </s> 1.0 -> 0.11 in the docs </s> remove Starting with Flask 1.0 there are multiple built-in ways to run a\n </s> add Starting with Flask 0.11 there are multiple built-in ways to run a </s> remove As of Flask 1.0, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 1.0 but is\n </s> add As of Flask 0.11, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 0.11 but is </s> remove Flask 1.0 removed the ``debug_log_format`` attribute from Flask\n </s> add Flask 0.11 removed the ``debug_log_format`` attribute from Flask </s> remove Starting with Flask 1.0 the recommended way to work with the shell is the\n </s> add Starting with Flask 0.11 the recommended way to work with the shell is the </s> remove    As of 1.0 you can use :meth:`pop` and :meth:`setdefault` in the same\n </s> add    As of 0.11 you can use :meth:`pop` and :meth:`setdefault` in the same </s> remove debug a problem.  By default as of Flask 1.0, errors are logged to your\n </s> add debug a problem.  By default as of Flask 0.11, errors are logged to your", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/cli.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> -----------------\n <mask> \n <mask> Even if you get mails, you probably also want to log warnings.  It's a\n <mask> good idea to keep as much information around that might be required to\n <mask> debug a problem.  By default as of Flask 1.0, errors are logged to your\n <mask> webserver's log automatically.  Warnings however are not.  Please note\n <mask> that Flask itself will not issue any warnings in the core system, so it's\n <mask> your responsibility to warn in the code if something seems odd.\n <mask> \n <mask> There are a couple of handlers provided by the logging system out of the\n </s> 1.0 -> 0.11 in the docs </s> remove As of Flask 1.0, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 1.0 but is\n </s> add As of Flask 0.11, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 0.11 but is </s> remove Starting with Flask 1.0 there are multiple built-in ways to run a\n </s> add Starting with Flask 0.11 there are multiple built-in ways to run a </s> remove in Flask 1.0.  Previously it was possible to use etags and mimetypes\n </s> add in Flask 0.11.  Previously it was possible to use etags and mimetypes </s> remove    As of 1.0 you can use :meth:`pop` and :meth:`setdefault` in the same\n </s> add    As of 0.11 you can use :meth:`pop` and :meth:`setdefault` in the same </s> remove Flask 1.0 removed the ``debug_log_format`` attribute from Flask\n </s> add Flask 0.11 removed the ``debug_log_format`` attribute from Flask </s> remove Version 1.0\n-----------\n </s> add Version 0.11\n------------\n\n0.11 is an odd release in the Flask release cycle because it was supposed\nto be the 1.0 release.  However because there was such a long lead time up\nto the release we decided to push out a 0.11 release first with some\nchanges removed to make the transition easier.  If you have been tracking\nthe master branch which was 1.0 you might see some unexpected changes.\n\nIn case you did track the master branch you will notice that `flask --app`\nis removed now.  You need to use the environment variable to specify an\napplication.", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> Flask 0.8 introduced a redirect import system as a compatibility aid for app\n <mask> developers: Importing ``flask.ext.foo`` would try ``flask_foo`` and\n <mask> ``flaskext.foo`` in that order.\n <mask> \n <mask> As of Flask 1.0, most Flask extensions have transitioned to the new naming\n <mask> schema. The ``flask.ext.foo`` compatibility alias is still in Flask 1.0 but is\n <mask> now deprecated -- you should use ``flask_foo``.\n <mask> \n <mask> \n <mask> .. _OAuth extension: http://pythonhosted.org/Flask-OAuth/\n <mask> .. _mailinglist: http://flask.pocoo.org/mailinglist/\n </s> 1.0 -> 0.11 in the docs </s> remove    As of 1.0 you can use :meth:`pop` and :meth:`setdefault` in the same\n </s> add    As of 0.11 you can use :meth:`pop` and :meth:`setdefault` in the same </s> remove debug a problem.  By default as of Flask 1.0, errors are logged to your\n </s> add debug a problem.  By default as of Flask 0.11, errors are logged to your </s> remove One of the nice new features in Flask 1.0 is the built-in integration of\n </s> add One of the nice new features in Flask 0.11 is the built-in integration of </s> remove Starting with Flask 1.0 there are multiple built-in ways to run a\n </s> add Starting with Flask 0.11 there are multiple built-in ways to run a </s> remove in Flask 1.0.  Previously it was possible to use etags and mimetypes\n </s> add in Flask 0.11.  Previously it was possible to use etags and mimetypes </s> remove Version 1.0\n-----------\n </s> add Version 0.11\n------------\n\n0.11 is an odd release in the Flask release cycle because it was supposed\nto be the 1.0 release.  However because there was such a long lead time up\nto the release we decided to push out a 0.11 release first with some\nchanges removed to make the transition easier.  If you have been tracking\nthe master branch which was 1.0 you might see some unexpected changes.\n\nIn case you did track the master branch you will notice that `flask --app`\nis removed now.  You need to use the environment variable to specify an\napplication.", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ==================\n <mask> \n <mask> .. currentmodule:: flask\n <mask> \n <mask> Starting with Flask 1.0 there are multiple built-in ways to run a\n <mask> development server.  The best one is the :command:`flask` command line utility\n <mask> but you can also continue using the :meth:`Flask.run` method.\n <mask> \n <mask> Command Line\n <mask> ------------\n </s> 1.0 -> 0.11 in the docs </s> remove One of the nice new features in Flask 1.0 is the built-in integration of\n </s> add One of the nice new features in Flask 0.11 is the built-in integration of </s> remove Starting with Flask 1.0 the recommended way to work with the shell is the\n </s> add Starting with Flask 0.11 the recommended way to work with the shell is the </s> remove As of Flask 1.0, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 1.0 but is\n </s> add As of Flask 0.11, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 0.11 but is </s> remove Version 1.0\n-----------\n </s> add Version 0.11\n------------\n\n0.11 is an odd release in the Flask release cycle because it was supposed\nto be the 1.0 release.  However because there was such a long lead time up\nto the release we decided to push out a 0.11 release first with some\nchanges removed to make the transition easier.  If you have been tracking\nthe master branch which was 1.0 you might see some unexpected changes.\n\nIn case you did track the master branch you will notice that `flask --app`\nis removed now.  You need to use the environment variable to specify an\napplication. </s> remove debug a problem.  By default as of Flask 1.0, errors are logged to your\n </s> add debug a problem.  By default as of Flask 0.11, errors are logged to your </s> remove    As of 1.0 you can use :meth:`pop` and :meth:`setdefault` in the same\n </s> add    As of 0.11 you can use :meth:`pop` and :meth:`setdefault` in the same", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/server.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Command Line Interface\n <mask> ----------------------\n <mask> \n <mask> Starting with Flask 1.0 the recommended way to work with the shell is the\n <mask> ``flask shell`` command which does a lot of this automatically for you.\n <mask> For instance the shell is automatically initialized with a loaded\n <mask> application context.\n <mask> \n <mask> For more information see :ref:`cli`.\n </s> 1.0 -> 0.11 in the docs </s> remove Starting with Flask 1.0 there are multiple built-in ways to run a\n </s> add Starting with Flask 0.11 there are multiple built-in ways to run a </s> remove    As of 1.0 you can use :meth:`pop` and :meth:`setdefault` in the same\n </s> add    As of 0.11 you can use :meth:`pop` and :meth:`setdefault` in the same </s> remove Version 1.0\n-----------\n </s> add Version 0.11\n------------\n\n0.11 is an odd release in the Flask release cycle because it was supposed\nto be the 1.0 release.  However because there was such a long lead time up\nto the release we decided to push out a 0.11 release first with some\nchanges removed to make the transition easier.  If you have been tracking\nthe master branch which was 1.0 you might see some unexpected changes.\n\nIn case you did track the master branch you will notice that `flask --app`\nis removed now.  You need to use the environment variable to specify an\napplication. </s> remove One of the nice new features in Flask 1.0 is the built-in integration of\n </s> add One of the nice new features in Flask 0.11 is the built-in integration of </s> remove in Flask 1.0.  Previously it was possible to use etags and mimetypes\n </s> add in Flask 0.11.  Previously it was possible to use etags and mimetypes </s> remove As of Flask 1.0, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 1.0 but is\n </s> add As of Flask 0.11, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 0.11 but is", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     $ easy_install -U Flask\n <mask> \n <mask> .. _upgrading-to-10:\n <mask> \n <mask> Version 1.0\n <mask> -----------\n <mask> \n <mask> Debugging\n <mask> `````````\n <mask> \n <mask> Flask 1.0 removed the ``debug_log_format`` attribute from Flask\n </s> 1.0 -> 0.11 in the docs </s> remove Flask 1.0 removed the ``debug_log_format`` attribute from Flask\n </s> add Flask 0.11 removed the ``debug_log_format`` attribute from Flask </s> remove One of the nice new features in Flask 1.0 is the built-in integration of\n </s> add One of the nice new features in Flask 0.11 is the built-in integration of </s> remove As of Flask 1.0, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 1.0 but is\n </s> add As of Flask 0.11, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 0.11 but is </s> remove Starting with Flask 1.0 there are multiple built-in ways to run a\n </s> add Starting with Flask 0.11 there are multiple built-in ways to run a </s> remove Starting with Flask 1.0 the recommended way to work with the shell is the\n </s> add Starting with Flask 0.11 the recommended way to work with the shell is the </s> remove in Flask 1.0.  Previously it was possible to use etags and mimetypes\n </s> add in Flask 0.11.  Previously it was possible to use etags and mimetypes", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/upgrading.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Debugging\n <mask> `````````\n <mask> \n <mask> Flask 1.0 removed the ``debug_log_format`` attribute from Flask\n <mask> applications.  Instead the new ``LOGGER_HANDLER_POLICY`` configuration can\n <mask> be used to disable the default log handlers and custom log handlers can be\n <mask> set up.\n <mask> \n <mask> Error handling\n </s> 1.0 -> 0.11 in the docs </s> remove debug a problem.  By default as of Flask 1.0, errors are logged to your\n </s> add debug a problem.  By default as of Flask 0.11, errors are logged to your </s> remove Version 1.0\n-----------\n </s> add Version 0.11\n------------\n\n0.11 is an odd release in the Flask release cycle because it was supposed\nto be the 1.0 release.  However because there was such a long lead time up\nto the release we decided to push out a 0.11 release first with some\nchanges removed to make the transition easier.  If you have been tracking\nthe master branch which was 1.0 you might see some unexpected changes.\n\nIn case you did track the master branch you will notice that `flask --app`\nis removed now.  You need to use the environment variable to specify an\napplication. </s> remove One of the nice new features in Flask 1.0 is the built-in integration of\n </s> add One of the nice new features in Flask 0.11 is the built-in integration of </s> remove    As of 1.0 you can use :meth:`pop` and :meth:`setdefault` in the same\n </s> add    As of 0.11 you can use :meth:`pop` and :meth:`setdefault` in the same </s> remove Starting with Flask 1.0 there are multiple built-in ways to run a\n </s> add Starting with Flask 0.11 there are multiple built-in ways to run a </s> remove in Flask 1.0.  Previously it was possible to use etags and mimetypes\n </s> add in Flask 0.11.  Previously it was possible to use etags and mimetypes", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/upgrading.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> before, you should catch them with :exc:`RuntimeError` now.\n <mask> \n <mask> Additionally the :func:`~flask.send_file` function is now issuing\n <mask> deprecation warnings if you depend on functionality that will be removed\n <mask> in Flask 1.0.  Previously it was possible to use etags and mimetypes\n <mask> when file objects were passed.  This was unreliable and caused issues\n <mask> for a few setups.  If you get a deprecation warning, make sure to\n <mask> update your application to work with either filenames there or disable\n <mask> etag attaching and attach them yourself.\n <mask> \n </s> 1.0 -> 0.11 in the docs </s> remove    As of 1.0 you can use :meth:`pop` and :meth:`setdefault` in the same\n </s> add    As of 0.11 you can use :meth:`pop` and :meth:`setdefault` in the same </s> remove Version 1.0\n-----------\n </s> add Version 0.11\n------------\n\n0.11 is an odd release in the Flask release cycle because it was supposed\nto be the 1.0 release.  However because there was such a long lead time up\nto the release we decided to push out a 0.11 release first with some\nchanges removed to make the transition easier.  If you have been tracking\nthe master branch which was 1.0 you might see some unexpected changes.\n\nIn case you did track the master branch you will notice that `flask --app`\nis removed now.  You need to use the environment variable to specify an\napplication. </s> remove debug a problem.  By default as of Flask 1.0, errors are logged to your\n </s> add debug a problem.  By default as of Flask 0.11, errors are logged to your </s> remove As of Flask 1.0, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 1.0 but is\n </s> add As of Flask 0.11, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 0.11 but is </s> remove Starting with Flask 1.0 the recommended way to work with the shell is the\n </s> add Starting with Flask 0.11 the recommended way to work with the shell is the </s> remove Starting with Flask 1.0 there are multiple built-in ways to run a\n </s> add Starting with Flask 0.11 there are multiple built-in ways to run a", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/upgrading.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     session.setdefault('_flashes', []).append((category, message))\n <mask> \n <mask> \n <mask> def get_flashed_messages(with_categories=False):\n <mask>     \"\"\"Pulls all flashed messages from the session and returns them.\n <mask>     Further calls in the same request to the function will return\n <mask>     the same messages.  By default just the messages are returned,\n <mask>     but when `with_categories` is set to `True`, the return value will\n <mask>     be a list of tuples in the form ``(category, message)`` instead.\n </s> Allow category filtering in get_flashed_messages to allow rending categories in separate html blocks </s> add     :param category_filter: whitelist of categories to limit return values </s> add     .. versionchanged: 0.9\n        `category_filter` parameter added.\n </s> add     if category_filter:\n        flashes = filter(lambda f: f[0] in category_filter, flashes)", "html_url": "https://github.com/pallets/flask/commit/fa069f94dec3aeec4a81a00e7bbd8d95e400bf5f", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     .. versionchanged:: 0.3\n <mask>        `with_categories` parameter added.\n <mask> \n <mask>     :param with_categories: set to `True` to also receive categories.\n <mask>     :param category_filter: whitelist of categories to limit return values\n <mask>     \"\"\"\n <mask>     flashes = _request_ctx_stack.top.flashes\n <mask>     if flashes is None:\n <mask>         _request_ctx_stack.top.flashes = flashes = session.pop('_flashes') \\\n </s> Allow category filtering in get_flashed_messages to allow rending categories in separate html blocks </s> add     :param category_filter: whitelist of categories to limit return values </s> add     if category_filter:\n        flashes = filter(lambda f: f[0] in category_filter, flashes) </s> remove def get_flashed_messages(with_categories=False):\n </s> add def get_flashed_messages(with_categories=False, category_filter=[]):", "html_url": "https://github.com/pallets/flask/commit/fa069f94dec3aeec4a81a00e7bbd8d95e400bf5f", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     .. versionchanged: 0.9\n <mask>         `category_filter` parameter added.\n <mask> \n <mask>     :param with_categories: set to `True` to also receive categories.\n <mask>     \"\"\"\n <mask>     flashes = _request_ctx_stack.top.flashes\n <mask>     if flashes is None:\n <mask>         _request_ctx_stack.top.flashes = flashes = session.pop('_flashes') \\\n <mask>             if '_flashes' in session else []\n <mask>     if category_filter:\n </s> Allow category filtering in get_flashed_messages to allow rending categories in separate html blocks </s> add     if category_filter:\n        flashes = filter(lambda f: f[0] in category_filter, flashes) </s> add     .. versionchanged: 0.9\n        `category_filter` parameter added.\n </s> remove def get_flashed_messages(with_categories=False):\n </s> add def get_flashed_messages(with_categories=False, category_filter=[]):", "html_url": "https://github.com/pallets/flask/commit/fa069f94dec3aeec4a81a00e7bbd8d95e400bf5f", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     flashes = _request_ctx_stack.top.flashes\n <mask>     if flashes is None:\n <mask>         _request_ctx_stack.top.flashes = flashes = session.pop('_flashes') \\\n <mask>             if '_flashes' in session else []\n <mask>     if not with_categories:\n <mask>         return [x[1] for x in flashes]\n <mask>     return flashes\n <mask> \n </s> Allow category filtering in get_flashed_messages to allow rending categories in separate html blocks </s> add     :param category_filter: whitelist of categories to limit return values </s> add     .. versionchanged: 0.9\n        `category_filter` parameter added.\n </s> remove def get_flashed_messages(with_categories=False):\n </s> add def get_flashed_messages(with_categories=False, category_filter=[]):", "html_url": "https://github.com/pallets/flask/commit/fa069f94dec3aeec4a81a00e7bbd8d95e400bf5f", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def get_command(self, ctx, name):\n <mask>         info = ctx.ensure_object(ScriptInfo)\n <mask>         try:\n <mask>             rv = info.load_app().cli.get_command(ctx, name)\n <mask>             if rv is not None:\n <mask>                 return rv\n <mask>         except NoAppException:\n </s> Fixed the cli system failing syntax errors. </s> remove         # Find the command in the application first, if we can find it.\n        # If the app is not available, we just ignore this silently.\n </s> add  </s> remove         return click.Group.get_command(self, ctx, name)\n </s> add  </s> remove         except NoAppException:\n </s> add         except Exception:\n            # Here we intentionally swallow all exceptions as we don't\n            # want the help page to break if the app does not exist.\n            # If someone attempts to use the command we try to create\n            # the app again and this will give us the error.", "html_url": "https://github.com/pallets/flask/commit/fa6eded6f572dd4bc23b030f025156cdd1e63305", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             self.add_command(shell_command)\n <mask> \n <mask>     def get_command(self, ctx, name):\n <mask>         info = ctx.ensure_object(ScriptInfo)\n <mask>         # Find the command in the application first, if we can find it.\n <mask>         # If the app is not available, we just ignore this silently.\n <mask>         try:\n <mask>             rv = info.load_app().cli.get_command(ctx, name)\n <mask>             if rv is not None:\n <mask>                 return rv\n <mask>         except NoAppException:\n </s> Fixed the cli system failing syntax errors. </s> add         # We load built-in commands first as these should always be the\n        # same no matter what the app does.  If the app does want to\n        # override this it needs to make a custom instance of this group\n        # and not attach the default commands.\n        #\n        # This also means that the script stays functional in case the\n        # application completely fails.\n        rv = click.Group.get_command(self, ctx, name)\n        if rv is not None:\n            return rv\n </s> remove         return click.Group.get_command(self, ctx, name)\n </s> add  </s> remove         except NoAppException:\n </s> add         except Exception:\n            # Here we intentionally swallow all exceptions as we don't\n            # want the help page to break if the app does not exist.\n            # If someone attempts to use the command we try to create\n            # the app again and this will give us the error.", "html_url": "https://github.com/pallets/flask/commit/fa6eded6f572dd4bc23b030f025156cdd1e63305", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             if rv is not None:\n <mask>                 return rv\n <mask>         except NoAppException:\n <mask>             pass\n <mask>         return click.Group.get_command(self, ctx, name)\n <mask> \n <mask>     def list_commands(self, ctx):\n <mask>         # The commands available is the list of both the application (if\n <mask>         # available) plus the builtin commands.\n <mask>         rv = set(click.Group.list_commands(self, ctx))\n </s> Fixed the cli system failing syntax errors. </s> remove         # Find the command in the application first, if we can find it.\n        # If the app is not available, we just ignore this silently.\n </s> add  </s> add         # We load built-in commands first as these should always be the\n        # same no matter what the app does.  If the app does want to\n        # override this it needs to make a custom instance of this group\n        # and not attach the default commands.\n        #\n        # This also means that the script stays functional in case the\n        # application completely fails.\n        rv = click.Group.get_command(self, ctx, name)\n        if rv is not None:\n            return rv\n </s> remove         except NoAppException:\n </s> add         except Exception:\n            # Here we intentionally swallow all exceptions as we don't\n            # want the help page to break if the app does not exist.\n            # If someone attempts to use the command we try to create\n            # the app again and this will give us the error.", "html_url": "https://github.com/pallets/flask/commit/fa6eded6f572dd4bc23b030f025156cdd1e63305", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         rv = set(click.Group.list_commands(self, ctx))\n <mask>         info = ctx.ensure_object(ScriptInfo)\n <mask>         try:\n <mask>             rv.update(info.load_app().cli.list_commands(ctx))\n <mask>         except NoAppException:\n <mask>             pass\n <mask>         return sorted(rv)\n <mask> \n <mask>     def invoke_subcommand(self, ctx, cmd, cmd_name, args):\n <mask>         with_context = cmd.callback is None or \\\n </s> Fixed the cli system failing syntax errors. </s> remove         # Find the command in the application first, if we can find it.\n        # If the app is not available, we just ignore this silently.\n </s> add  </s> add         # We load built-in commands first as these should always be the\n        # same no matter what the app does.  If the app does want to\n        # override this it needs to make a custom instance of this group\n        # and not attach the default commands.\n        #\n        # This also means that the script stays functional in case the\n        # application completely fails.\n        rv = click.Group.get_command(self, ctx, name)\n        if rv is not None:\n            return rv\n </s> remove         return click.Group.get_command(self, ctx, name)\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/fa6eded6f572dd4bc23b030f025156cdd1e63305", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> import click\n <mask> \n <mask> from . import __version__\n <mask> from ._compat import iteritems, reraise\n <mask> from .globals import current_app\n <mask> from .helpers import get_debug_flag\n <mask> from ._compat import getargspec\n <mask> \n <mask> \n </s> be smarter about adding \".cli\" to reloader command\npython -m flask.cli raises an import warning on > 2.6\nit's only needed on 2.6, \"flask\" works otherwise\ncloses #2357 </s> remove         # This module is always executed as \"python -m flask.run\" and as such\n        # we need to ensure that we restore the actual command line so that\n        # the reloader can properly operate.\n        sys.argv = ['-m', this_module] + sys.argv[1:]\n </s> add         # Python rewrites \"python -m flask\" to the path to the file in argv.\n        # Restore the original command so that the reloader works.\n        sys.argv = ['-m', this_module] + args </s> remove         if sys.version_info >= (2, 7):\n            name = 'python -m ' + this_module.rsplit('.', 1)[0]\n        else:\n            name = 'python -m ' + this_module\n </s> add         this_module = 'flask'\n\n        if sys.version_info < (2, 7):\n            this_module += '.cli'\n\n        name = 'python -m ' + this_module </s> remove     this_module = __package__ + '.cli'\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/fa7e8d6073052adc5ba69702db4dec6571ef0bfd", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep replace keep keep keep replace replace replace replace keep keep keep keep", "code_tokens": " <mask> def main(as_module=False):\n <mask>     this_module = __package__ + '.cli'\n <mask>     args = sys.argv[1:]\n <mask> \n <mask>     if as_module:\n <mask>         if sys.version_info >= (2, 7):\n <mask>             name = 'python -m ' + this_module.rsplit('.', 1)[0]\n <mask>         else:\n <mask>             name = 'python -m ' + this_module\n <mask> \n <mask>         # This module is always executed as \"python -m flask.run\" and as such\n <mask>         # we need to ensure that we restore the actual command line so that\n <mask>         # the reloader can properly operate.\n </s> be smarter about adding \".cli\" to reloader command\npython -m flask.cli raises an import warning on > 2.6\nit's only needed on 2.6, \"flask\" works otherwise\ncloses #2357 </s> remove         # This module is always executed as \"python -m flask.run\" and as such\n        # we need to ensure that we restore the actual command line so that\n        # the reloader can properly operate.\n        sys.argv = ['-m', this_module] + sys.argv[1:]\n </s> add         # Python rewrites \"python -m flask\" to the path to the file in argv.\n        # Restore the original command so that the reloader works.\n        sys.argv = ['-m', this_module] + args </s> remove from ._compat import iteritems, reraise\n </s> add from ._compat import iteritems, reraise, PY2", "html_url": "https://github.com/pallets/flask/commit/fa7e8d6073052adc5ba69702db4dec6571ef0bfd", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             name = 'python -m ' + this_module.rsplit('.', 1)[0]\n <mask>         else:\n <mask>             name = 'python -m ' + this_module\n <mask> \n <mask>         # This module is always executed as \"python -m flask.run\" and as such\n <mask>         # we need to ensure that we restore the actual command line so that\n <mask>         # the reloader can properly operate.\n <mask>         sys.argv = ['-m', this_module] + sys.argv[1:]\n <mask>     else:\n <mask>         name = None\n <mask> \n <mask>     cli.main(args=args, prog_name=name)\n <mask> \n </s> be smarter about adding \".cli\" to reloader command\npython -m flask.cli raises an import warning on > 2.6\nit's only needed on 2.6, \"flask\" works otherwise\ncloses #2357 </s> remove         if sys.version_info >= (2, 7):\n            name = 'python -m ' + this_module.rsplit('.', 1)[0]\n        else:\n            name = 'python -m ' + this_module\n </s> add         this_module = 'flask'\n\n        if sys.version_info < (2, 7):\n            this_module += '.cli'\n\n        name = 'python -m ' + this_module </s> remove     this_module = __package__ + '.cli'\n </s> add  </s> remove from ._compat import iteritems, reraise\n </s> add from ._compat import iteritems, reraise, PY2", "html_url": "https://github.com/pallets/flask/commit/fa7e8d6073052adc5ba69702db4dec6571ef0bfd", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> import imp\n <mask> import os\n <mask> import sys\n <mask> \n <mask> from werkzeug import import_string\n <mask> \n <mask> \n <mask> class ConfigAttribute(object):\n </s> Test passes.\nAdded test for silent flag; added import of errno so it passed. </s> add         assert not app.config.from_pyfile('missing.cfg', silent=True) </s> remove             not app.config.from_envvar('FOO_SETTINGS', silent=True)\n </s> add             assert not app.config.from_envvar('FOO_SETTINGS', silent=True)", "html_url": "https://github.com/pallets/flask/commit/fa9817778c83eb35b9c2c4332ccb7e5190d1ffa2", "file_name": "flask/config.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             except RuntimeError, e:\n <mask>                 assert \"'FOO_SETTINGS' is not set\" in str(e)\n <mask>             else:\n <mask>                 assert 0, 'expected exception'\n <mask>             not app.config.from_envvar('FOO_SETTINGS', silent=True)\n <mask> \n <mask>             os.environ = {'FOO_SETTINGS': 'flask_tests.py'}\n <mask>             assert app.config.from_envvar('FOO_SETTINGS')\n <mask>             self.common_object_test(app)\n <mask>         finally:\n </s> Test passes.\nAdded test for silent flag; added import of errno so it passed. </s> add         assert not app.config.from_pyfile('missing.cfg', silent=True) </s> add import errno", "html_url": "https://github.com/pallets/flask/commit/fa9817778c83eb35b9c2c4332ccb7e5190d1ffa2", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>             assert msg.endswith(\"missing.cfg'\")\n <mask>         else:\n <mask>             assert 0, 'expected config'\n <mask> \n <mask> \n <mask> class SubdomainTestCase(unittest.TestCase):\n <mask> \n <mask>     def test_basic_support(self):\n </s> Test passes.\nAdded test for silent flag; added import of errno so it passed. </s> remove             not app.config.from_envvar('FOO_SETTINGS', silent=True)\n </s> add             assert not app.config.from_envvar('FOO_SETTINGS', silent=True) </s> add import errno", "html_url": "https://github.com/pallets/flask/commit/fa9817778c83eb35b9c2c4332ccb7e5190d1ffa2", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>   which can be used by subclasses to alter the default\n <mask>   behaviour for `OPTIONS` responses.\n <mask> \n <mask> Version 0.6.1\n <mask> -------------\n <mask> \n </s> Request local objects now fail properly with a RuntimeError.  This fixes #105 </s> add Version 0.7\n-----------\n\nDue to a bug in earlier implementations the request local proxies now\nraise a :exc:`RuntimeError` instead of an :exc:`AttributeError` when they\nare unbound.  If you cought these exceptions with :exc:`AttributeError`\nbefore, you should catch them with :exc:`RuntimeError` now.\n </s> add from functools import partial </s> add     def test_request_locals(self):\n        self.assertEqual(repr(flask.g), '<LocalProxy unbound>')\n        self.assertFalse(flask.g)\n </s> remove         except AttributeError:\n </s> add         except RuntimeError: </s> remove current_app = LocalProxy(lambda: _request_ctx_stack.top.app)\nrequest = LocalProxy(lambda: _request_ctx_stack.top.request)\nsession = LocalProxy(lambda: _request_ctx_stack.top.session)\ng = LocalProxy(lambda: _request_ctx_stack.top.g)\n </s> add current_app = LocalProxy(partial(_lookup_object, 'app'))\nrequest = LocalProxy(partial(_lookup_object, 'request'))\nsession = LocalProxy(partial(_lookup_object, 'session'))\ng = LocalProxy(partial(_lookup_object, 'g')) </s> add def _lookup_object(name):\n    top = _request_ctx_stack.top\n    if top is None:\n        raise RuntimeError('working outside of request context')\n    return getattr(top, name)\n", "html_url": "https://github.com/pallets/flask/commit/faa1c71e455a99e9b098aa9bb4667c07a1bab6aa", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> installation, make sure to pass it the ``-U`` parameter::\n <mask> \n <mask>     $ easy_install -U Flask\n <mask> \n <mask> Version 0.6\n <mask> -----------\n <mask> \n <mask> Flask 0.6 comes with a backwards incompatible change which affects the\n <mask> order of after-request handlers.  Previously they were called in the order\n </s> Request local objects now fail properly with a RuntimeError.  This fixes #105 </s> add - Unbound locals now raise a proper :exc:`RuntimeError` instead\n  of an :exc:`AttributeError`. </s> remove         except AttributeError:\n </s> add         except RuntimeError: </s> add     def test_request_locals(self):\n        self.assertEqual(repr(flask.g), '<LocalProxy unbound>')\n        self.assertFalse(flask.g)\n </s> add def _lookup_object(name):\n    top = _request_ctx_stack.top\n    if top is None:\n        raise RuntimeError('working outside of request context')\n    return getattr(top, name)\n </s> remove current_app = LocalProxy(lambda: _request_ctx_stack.top.app)\nrequest = LocalProxy(lambda: _request_ctx_stack.top.request)\nsession = LocalProxy(lambda: _request_ctx_stack.top.session)\ng = LocalProxy(lambda: _request_ctx_stack.top.g)\n </s> add current_app = LocalProxy(partial(_lookup_object, 'app'))\nrequest = LocalProxy(partial(_lookup_object, 'request'))\nsession = LocalProxy(partial(_lookup_object, 'session'))\ng = LocalProxy(partial(_lookup_object, 'g')) </s> add from functools import partial", "html_url": "https://github.com/pallets/flask/commit/faa1c71e455a99e9b098aa9bb4667c07a1bab6aa", "file_name": "docs/upgrading.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from werkzeug import LocalStack, LocalProxy\n <mask> \n <mask> def _lookup_object(name):\n <mask>     top = _request_ctx_stack.top\n <mask>     if top is None:\n </s> Request local objects now fail properly with a RuntimeError.  This fixes #105 </s> add def _lookup_object(name):\n    top = _request_ctx_stack.top\n    if top is None:\n        raise RuntimeError('working outside of request context')\n    return getattr(top, name)\n </s> remove current_app = LocalProxy(lambda: _request_ctx_stack.top.app)\nrequest = LocalProxy(lambda: _request_ctx_stack.top.request)\nsession = LocalProxy(lambda: _request_ctx_stack.top.session)\ng = LocalProxy(lambda: _request_ctx_stack.top.g)\n </s> add current_app = LocalProxy(partial(_lookup_object, 'app'))\nrequest = LocalProxy(partial(_lookup_object, 'request'))\nsession = LocalProxy(partial(_lookup_object, 'session'))\ng = LocalProxy(partial(_lookup_object, 'g')) </s> add     def test_request_locals(self):\n        self.assertEqual(repr(flask.g), '<LocalProxy unbound>')\n        self.assertFalse(flask.g)\n </s> add - Unbound locals now raise a proper :exc:`RuntimeError` instead\n  of an :exc:`AttributeError`. </s> remove         except AttributeError:\n </s> add         except RuntimeError: </s> add Version 0.7\n-----------\n\nDue to a bug in earlier implementations the request local proxies now\nraise a :exc:`RuntimeError` instead of an :exc:`AttributeError` when they\nare unbound.  If you cought these exceptions with :exc:`AttributeError`\nbefore, you should catch them with :exc:`RuntimeError` now.\n", "html_url": "https://github.com/pallets/flask/commit/faa1c71e455a99e9b098aa9bb4667c07a1bab6aa", "file_name": "flask/globals.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from functools import partial\n <mask> from werkzeug import LocalStack, LocalProxy\n <mask> \n <mask> # context locals\n <mask> _request_ctx_stack = LocalStack()\n <mask> current_app = LocalProxy(partial(_lookup_object, 'app'))\n <mask> request = LocalProxy(partial(_lookup_object, 'request'))\n <mask> session = LocalProxy(partial(_lookup_object, 'session'))\n </s> Request local objects now fail properly with a RuntimeError.  This fixes #105 </s> remove current_app = LocalProxy(lambda: _request_ctx_stack.top.app)\nrequest = LocalProxy(lambda: _request_ctx_stack.top.request)\nsession = LocalProxy(lambda: _request_ctx_stack.top.session)\ng = LocalProxy(lambda: _request_ctx_stack.top.g)\n </s> add current_app = LocalProxy(partial(_lookup_object, 'app'))\nrequest = LocalProxy(partial(_lookup_object, 'request'))\nsession = LocalProxy(partial(_lookup_object, 'session'))\ng = LocalProxy(partial(_lookup_object, 'g')) </s> add from functools import partial </s> add     def test_request_locals(self):\n        self.assertEqual(repr(flask.g), '<LocalProxy unbound>')\n        self.assertFalse(flask.g)\n </s> add - Unbound locals now raise a proper :exc:`RuntimeError` instead\n  of an :exc:`AttributeError`. </s> add Version 0.7\n-----------\n\nDue to a bug in earlier implementations the request local proxies now\nraise a :exc:`RuntimeError` instead of an :exc:`AttributeError` when they\nare unbound.  If you cought these exceptions with :exc:`AttributeError`\nbefore, you should catch them with :exc:`RuntimeError` now.\n </s> remove         except AttributeError:\n </s> add         except RuntimeError:", "html_url": "https://github.com/pallets/flask/commit/faa1c71e455a99e9b098aa9bb4667c07a1bab6aa", "file_name": "flask/globals.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace", "code_tokens": " <mask> from werkzeug import LocalStack, LocalProxy\n <mask> \n <mask> # context locals\n <mask> _request_ctx_stack = LocalStack()\n <mask> current_app = LocalProxy(lambda: _request_ctx_stack.top.app)\n <mask> request = LocalProxy(lambda: _request_ctx_stack.top.request)\n <mask> session = LocalProxy(lambda: _request_ctx_stack.top.session)\n <mask> g = LocalProxy(lambda: _request_ctx_stack.top.g)\n </s> Request local objects now fail properly with a RuntimeError.  This fixes #105 </s> add def _lookup_object(name):\n    top = _request_ctx_stack.top\n    if top is None:\n        raise RuntimeError('working outside of request context')\n    return getattr(top, name)\n </s> add from functools import partial </s> add     def test_request_locals(self):\n        self.assertEqual(repr(flask.g), '<LocalProxy unbound>')\n        self.assertFalse(flask.g)\n </s> add - Unbound locals now raise a proper :exc:`RuntimeError` instead\n  of an :exc:`AttributeError`. </s> add Version 0.7\n-----------\n\nDue to a bug in earlier implementations the request local proxies now\nraise a :exc:`RuntimeError` instead of an :exc:`AttributeError` when they\nare unbound.  If you cought these exceptions with :exc:`AttributeError`\nbefore, you should catch them with :exc:`RuntimeError` now.\n </s> remove         except AttributeError:\n </s> add         except RuntimeError:", "html_url": "https://github.com/pallets/flask/commit/faa1c71e455a99e9b098aa9bb4667c07a1bab6aa", "file_name": "flask/globals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         assert index() == 'Hello World!'\n <mask>         ctx.pop()\n <mask>         try:\n <mask>             index()\n <mask>         except AttributeError:\n <mask>             pass\n <mask>         else:\n <mask>             assert 0, 'expected runtime error'\n <mask> \n <mask>     def test_test_client_context_binding(self):\n </s> Request local objects now fail properly with a RuntimeError.  This fixes #105 </s> add     def test_request_locals(self):\n        self.assertEqual(repr(flask.g), '<LocalProxy unbound>')\n        self.assertFalse(flask.g)\n </s> add from functools import partial </s> add def _lookup_object(name):\n    top = _request_ctx_stack.top\n    if top is None:\n        raise RuntimeError('working outside of request context')\n    return getattr(top, name)\n </s> add Version 0.7\n-----------\n\nDue to a bug in earlier implementations the request local proxies now\nraise a :exc:`RuntimeError` instead of an :exc:`AttributeError` when they\nare unbound.  If you cought these exceptions with :exc:`AttributeError`\nbefore, you should catch them with :exc:`RuntimeError` now.\n </s> remove current_app = LocalProxy(lambda: _request_ctx_stack.top.app)\nrequest = LocalProxy(lambda: _request_ctx_stack.top.request)\nsession = LocalProxy(lambda: _request_ctx_stack.top.session)\ng = LocalProxy(lambda: _request_ctx_stack.top.g)\n </s> add current_app = LocalProxy(partial(_lookup_object, 'app'))\nrequest = LocalProxy(partial(_lookup_object, 'request'))\nsession = LocalProxy(partial(_lookup_object, 'session'))\ng = LocalProxy(partial(_lookup_object, 'g')) </s> add - Unbound locals now raise a proper :exc:`RuntimeError` instead\n  of an :exc:`AttributeError`.", "html_url": "https://github.com/pallets/flask/commit/faa1c71e455a99e9b098aa9bb4667c07a1bab6aa", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             pass\n <mask>         else:\n <mask>             assert \"Expected ValueError\"\n <mask> \n <mask> \n <mask> class JSONTestCase(unittest.TestCase):\n <mask> \n <mask>     def test_jsonify(self):\n <mask>         d = dict(a=23, b=42, c=[1, 2, 3])\n </s> Request local objects now fail properly with a RuntimeError.  This fixes #105 </s> remove         except AttributeError:\n </s> add         except RuntimeError: </s> add def _lookup_object(name):\n    top = _request_ctx_stack.top\n    if top is None:\n        raise RuntimeError('working outside of request context')\n    return getattr(top, name)\n </s> add from functools import partial </s> remove current_app = LocalProxy(lambda: _request_ctx_stack.top.app)\nrequest = LocalProxy(lambda: _request_ctx_stack.top.request)\nsession = LocalProxy(lambda: _request_ctx_stack.top.session)\ng = LocalProxy(lambda: _request_ctx_stack.top.g)\n </s> add current_app = LocalProxy(partial(_lookup_object, 'app'))\nrequest = LocalProxy(partial(_lookup_object, 'request'))\nsession = LocalProxy(partial(_lookup_object, 'session'))\ng = LocalProxy(partial(_lookup_object, 'g')) </s> add Version 0.7\n-----------\n\nDue to a bug in earlier implementations the request local proxies now\nraise a :exc:`RuntimeError` instead of an :exc:`AttributeError` when they\nare unbound.  If you cought these exceptions with :exc:`AttributeError`\nbefore, you should catch them with :exc:`RuntimeError` now.\n </s> add - Unbound locals now raise a proper :exc:`RuntimeError` instead\n  of an :exc:`AttributeError`.", "html_url": "https://github.com/pallets/flask/commit/faa1c71e455a99e9b098aa9bb4667c07a1bab6aa", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> request and get the information of the currently logged in user.  At the\n <mask> end of the request, the database connection is closed again.\n <mask> \n <mask> In Flask you can implement such things with the\n <mask> :meth:`~flask.Flask.request_init` and\n <mask> :meth:`~flask.Flask.request_shutdown` decorators in combination with the\n <mask> special :class:`~flask.g` object.\n <mask> \n <mask> \n <mask> .. _database-pattern:\n <mask> \n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove Flask allows us to do that with the :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators::\n </s> add Flask allows us to do that with the :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators:: </s> remove :meth:`~flask.Flask.request_shutdown` are called after a request and\n </s> add :meth:`~flask.Flask.after_request` are called after a request and </s> remove         #: To register a function here, use the :meth:`request_init`\n </s> add         #: To register a function here, use the :meth:`before_request` </s> remove         self.request_init_funcs = []\n </s> add         self.before_request_funcs = [] </s> remove     @app.request_init\n </s> add     @app.before_request </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before\n </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "docs/patterns.rst"}
{"docstring_tokens": "keep replace keep keep keep replace", "code_tokens": " <mask> \n <mask>     @app.request_init\n <mask>     def before_request():\n <mask>         g.db = connect_db()\n <mask> \n <mask>     @app.request_shutdown\n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove     @app.request_shutdown\n </s> add     @app.after_request </s> remove     @app.request_init\n </s> add     @app.before_request </s> remove @app.request_init\n </s> add @app.before_request </s> remove         @app.request_init\n </s> add         @app.before_request </s> remove         @app.request_shutdown\n </s> add         @app.after_request", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "docs/patterns.rst"}
{"docstring_tokens": "keep keep replace replace keep keep keep keep keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> before each request and shut them down afterwards.\n <mask> \n <mask> Flask allows us to do that with the :meth:`~flask.Flask.request_init` and\n <mask> :meth:`~flask.Flask.request_shutdown` decorators::\n <mask> \n <mask>     @app.request_init\n <mask>     def before_request():\n <mask>         g.db = connect_db()\n <mask> \n <mask> Flask allows us to do that with the :meth:`~flask.Flask.request_init` and\n <mask> :meth:`~flask.Flask.request_shutdown` decorators::\n <mask> \n <mask>     @app.request_init\n <mask>     def before_request():\n <mask>         g.db = connect_db()\n <mask> \n <mask>     @app.request_shutdown\n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove     @app.request_shutdown\n </s> add     @app.after_request </s> remove :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators in combination with the\n </s> add :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators in combination with the </s> remove @app.request_init\n </s> add @app.before_request </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before\n </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before </s> remove @app.request_init\n </s> add @app.before_request", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "docs/tutorial.rst"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>     def before_request():\n <mask>         g.db = connect_db()\n <mask> \n <mask>     @app.request_shutdown\n <mask>     def after_request(response):\n <mask>         g.db.close()\n <mask>         return response\n <mask> \n <mask> Functions marked with :meth:`~flask.Flask.request_init` are called before\n <mask> a request and passed no arguments, functions marked with\n <mask> :meth:`~flask.Flask.request_shutdown` are called after a request and\n <mask> passed the response that will be sent to the client.  They have to return\n <mask> that response object or a different one.  In this case we just return it\n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove :meth:`~flask.Flask.request_shutdown` are called after a request and\n </s> add :meth:`~flask.Flask.after_request` are called after a request and </s> remove Flask allows us to do that with the :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators::\n </s> add Flask allows us to do that with the :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators:: </s> remove     @app.request_init\n </s> add     @app.before_request </s> remove         before it's sent to the WSGI server.\n </s> add         before it's sent to the WSGI server.  By default this will\n        call all the :meth:`after_request` decorated functions. </s> remove @app.request_init\n </s> add @app.before_request", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "docs/tutorial.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         return response\n <mask> \n <mask> Functions marked with :meth:`~flask.Flask.request_init` are called before\n <mask> a request and passed no arguments, functions marked with\n <mask> :meth:`~flask.Flask.request_shutdown` are called after a request and\n <mask> passed the response that will be sent to the client.  They have to return\n <mask> that response object or a different one.  In this case we just return it\n <mask> unchanged.\n <mask> \n <mask> We store our current database connection on the special :data:`~flask.g`\n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before\n </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before </s> remove Flask allows us to do that with the :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators::\n </s> add Flask allows us to do that with the :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators:: </s> remove     @app.request_shutdown\n </s> add     @app.after_request </s> remove :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators in combination with the\n </s> add :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators in combination with the </s> remove         before it's sent to the WSGI server.\n </s> add         before it's sent to the WSGI server.  By default this will\n        call all the :meth:`after_request` decorated functions. </s> remove         #: To register a function here, use the :meth:`request_init`\n </s> add         #: To register a function here, use the :meth:`before_request`", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "docs/tutorial.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Step 5: The View Functions\n <mask> --------------------------\n <mask> \n <mask> Now that the database connections are working we can start writing the\n <mask> view functions.  We will need for of them:\n <mask> \n <mask> Show Entries\n <mask> ````````````\n <mask> \n <mask> This view shows all the entries stored in the database.  It listens on the\n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove Flask allows us to do that with the :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators::\n </s> add Flask allows us to do that with the :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators:: </s> remove :meth:`~flask.Flask.request_shutdown` are called after a request and\n </s> add :meth:`~flask.Flask.after_request` are called after a request and </s> remove         #: To register a function here, use the :meth:`request_init`\n </s> add         #: To register a function here, use the :meth:`before_request` </s> remove         call every as :func:`request_init` decorated function.\n </s> add         call every as :meth:`before_request` decorated function. </s> remove         before it's sent to the WSGI server.\n </s> add         before it's sent to the WSGI server.  By default this will\n        call all the :meth:`after_request` decorated functions. </s> remove         self.request_init_funcs = []\n </s> add         self.before_request_funcs = []", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "docs/tutorial.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             db.cursor().executescript(f.read())\n <mask>         db.commit()\n <mask> \n <mask> \n <mask> @app.request_init\n <mask> def before_request():\n <mask>     \"\"\"Make sure we are connected to the database each request.\"\"\"\n <mask>     g.db = connect_db()\n <mask> \n <mask> \n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove @app.request_shutdown\n </s> add @app.after_request </s> remove @app.request_init\n </s> add @app.before_request </s> remove Flask allows us to do that with the :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators::\n </s> add Flask allows us to do that with the :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators:: </s> remove     @app.request_init\n </s> add     @app.before_request </s> remove     @app.request_init\n </s> add     @app.before_request </s> remove     @app.request_shutdown\n </s> add     @app.after_request", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "examples/flaskr/flaskr.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"Make sure we are connected to the database each request.\"\"\"\n <mask>     g.db = connect_db()\n <mask> \n <mask> \n <mask> @app.request_shutdown\n <mask> def after_request(response):\n <mask>     \"\"\"Closes the database again at the end of the request.\"\"\"\n <mask>     g.db.close()\n <mask>     return response\n <mask> \n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove @app.request_init\n </s> add @app.before_request </s> remove @app.request_shutdown\n </s> add @app.after_request </s> remove @app.request_init\n </s> add @app.before_request </s> remove     @app.request_init\n </s> add     @app.before_request </s> remove     @app.request_shutdown\n </s> add     @app.after_request </s> remove     @app.request_shutdown\n </s> add     @app.after_request", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "examples/flaskr/flaskr.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return 'http://www.gravatar.com/avatar/%s?d=identicon&s=%d' % \\\n <mask>         (md5(email.strip().lower().encode('utf-8')).hexdigest(), size)\n <mask> \n <mask> \n <mask> @app.request_init\n <mask> def before_request():\n <mask>     \"\"\"Make sure we are connected to the database each request and look\n <mask>     up the current user so that we know he's there.\n <mask>     \"\"\"\n <mask>     g.db = connect_db()\n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove @app.request_init\n </s> add @app.before_request </s> remove @app.request_shutdown\n </s> add @app.after_request </s> remove Flask allows us to do that with the :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators::\n </s> add Flask allows us to do that with the :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators:: </s> remove     @app.request_init\n </s> add     @app.before_request </s> remove :meth:`~flask.Flask.request_shutdown` are called after a request and\n </s> add :meth:`~flask.Flask.after_request` are called after a request and </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before\n </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "examples/minitwit/minitwit.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         g.user = query_db('select * from user where user_id = ?',\n <mask>                           [session['user_id']], one=True)\n <mask> \n <mask> \n <mask> @app.request_shutdown\n <mask> def after_request(response):\n <mask>     \"\"\"Closes the database again at the end of the request.\"\"\"\n <mask>     g.db.close()\n <mask>     return response\n <mask> \n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove @app.request_shutdown\n </s> add @app.after_request </s> remove @app.request_init\n </s> add @app.before_request </s> remove     @app.request_shutdown\n </s> add     @app.after_request </s> remove         #: To register a function here, use the :meth:`request_init`\n </s> add         #: To register a function here, use the :meth:`before_request` </s> remove     @app.request_shutdown\n </s> add     @app.after_request </s> remove         self.request_init_funcs = []\n </s> add         self.before_request_funcs = []", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "examples/minitwit/minitwit.py"}
{"docstring_tokens": "keep keep replace keep replace keep keep", "code_tokens": " <mask>         #: can for example be used to open database connections or\n <mask>         #: getting hold of the currently logged in user.\n <mask>         #: To register a function here, use the :meth:`request_init`\n <mask>         #: decorator.\n <mask>         self.request_init_funcs = []\n <mask> \n <mask>         #: a list of functions that are called at the end of the\n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove         #: To register a function here use the :meth:`request_shtdown`\n </s> add         #: To register a function here use the :meth:`after_request` </s> remove         self.request_shutdown_funcs = []\n </s> add         self.after_request_funcs = [] </s> remove :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators in combination with the\n </s> add :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators in combination with the </s> remove view functions.  We will need for of them:\n </s> add view functions.  We will need four of them: </s> remove @app.request_shutdown\n </s> add @app.after_request", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep", "code_tokens": " <mask>         #: a list of functions that are called at the end of the\n <mask>         #: request.  Tha function is passed the current response\n <mask>         #: object and modify it in place or replace it.\n <mask>         #: To register a function here use the :meth:`request_shtdown`\n <mask>         #: decorator.\n <mask>         self.request_shutdown_funcs = []\n <mask> \n <mask>         #: a list of functions that are called without arguments\n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove         self.request_init_funcs = []\n </s> add         self.before_request_funcs = [] </s> remove         #: To register a function here, use the :meth:`request_init`\n </s> add         #: To register a function here, use the :meth:`before_request` </s> remove :meth:`~flask.Flask.request_shutdown` are called after a request and\n </s> add :meth:`~flask.Flask.after_request` are called after a request and </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before\n </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before </s> remove @app.request_shutdown\n </s> add @app.after_request", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep", "code_tokens": " <mask>             return f\n <mask>         return decorator\n <mask> \n <mask>     def request_init(self, f):\n <mask>         \"\"\"Registers a function to run before each request.\"\"\"\n <mask>         self.request_init_funcs.append(f)\n <mask>         return f\n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove     def request_shutdown(self, f):\n </s> add     def after_request(self, f): </s> remove         self.request_shutdown_funcs.append(f)\n </s> add         self.after_request_funcs.append(f) </s> remove @app.request_shutdown\n </s> add @app.after_request </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before\n </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before </s> remove @app.request_init\n </s> add @app.before_request", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Registers a function to run before each request.\"\"\"\n <mask>         self.request_init_funcs.append(f)\n <mask>         return f\n <mask> \n <mask>     def request_shutdown(self, f):\n <mask>         \"\"\"Register a function to be run after each request.\"\"\"\n <mask>         self.request_shutdown_funcs.append(f)\n <mask>         return f\n <mask> \n <mask>     def context_processor(self, f):\n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove         self.request_init_funcs.append(f)\n </s> add         self.before_request_funcs.append(f) </s> remove         self.request_shutdown_funcs.append(f)\n </s> add         self.after_request_funcs.append(f) </s> remove     def request_init(self, f):\n </s> add     def before_request(self, f): </s> remove @app.request_shutdown\n </s> add @app.after_request </s> remove @app.request_init\n </s> add @app.before_request </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before\n </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         return f\n <mask> \n <mask>     def request_shutdown(self, f):\n <mask>         \"\"\"Register a function to be run after each request.\"\"\"\n <mask>         self.request_shutdown_funcs.append(f)\n <mask>         return f\n <mask> \n <mask>     def context_processor(self, f):\n <mask>         \"\"\"Registers a template context processor function.\"\"\"\n <mask>         self.template_context_processors.append(f)\n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove     def request_shutdown(self, f):\n </s> add     def after_request(self, f): </s> remove         self.request_init_funcs.append(f)\n </s> add         self.before_request_funcs.append(f) </s> remove     def request_init(self, f):\n </s> add     def before_request(self, f): </s> remove @app.request_shutdown\n </s> add @app.after_request </s> remove         self.request_shutdown_funcs = []\n </s> add         self.after_request_funcs = [] </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before\n </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "flask.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>     def preprocess_request(self):\n <mask>         \"\"\"Called before the actual request dispatching and will\n <mask>         call every as :func:`request_init` decorated function.\n <mask>         If any of these function returns a value it's handled as\n <mask>         if it was the return value from the view and further\n <mask>         request handling is stopped.\n <mask>         \"\"\"\n <mask>         for func in self.request_init_funcs:\n <mask>             rv = func()\n <mask>             if rv is not None:\n <mask>                 return rv\n <mask> \n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove         for handler in self.request_shutdown_funcs:\n </s> add         for handler in self.after_request_funcs: </s> remove         before it's sent to the WSGI server.\n </s> add         before it's sent to the WSGI server.  By default this will\n        call all the :meth:`after_request` decorated functions. </s> remove         #: To register a function here, use the :meth:`request_init`\n </s> add         #: To register a function here, use the :meth:`before_request` </s> remove view functions.  We will need for of them:\n </s> add view functions.  We will need four of them: </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before\n </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 return rv\n <mask> \n <mask>     def process_response(self, response):\n <mask>         \"\"\"Can be overridden in order to modify the response object\n <mask>         before it's sent to the WSGI server.\n <mask> \n <mask>         :param response: a :attr:`response_class` object.\n <mask>         :return: a new response object or the same, has to be an\n <mask>                  instance of :attr:`response_class`.\n <mask>         \"\"\"\n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove         for func in self.request_init_funcs:\n </s> add         for func in self.before_request_funcs: </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before\n </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before </s> remove :meth:`~flask.Flask.request_shutdown` are called after a request and\n </s> add :meth:`~flask.Flask.after_request` are called after a request and </s> remove         self.request_init_funcs = []\n </s> add         self.before_request_funcs = [] </s> remove         #: To register a function here use the :meth:`request_shtdown`\n </s> add         #: To register a function here use the :meth:`after_request` </s> remove         self.request_shutdown_funcs = []\n </s> add         self.after_request_funcs = []", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         session = _request_ctx_stack.top.session\n <mask>         if session is not None:\n <mask>             self.save_session(session, response)\n <mask>         for handler in self.request_shutdown_funcs:\n <mask>             response = handler(response)\n <mask>         return response\n <mask> \n <mask>     def wsgi_app(self, environ, start_response):\n <mask>         \"\"\"The actual WSGI application.  This is not implemented in\n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove         for func in self.request_init_funcs:\n </s> add         for func in self.before_request_funcs: </s> remove         call every as :func:`request_init` decorated function.\n </s> add         call every as :meth:`before_request` decorated function. </s> remove         before it's sent to the WSGI server.\n </s> add         before it's sent to the WSGI server.  By default this will\n        call all the :meth:`after_request` decorated functions. </s> remove         #: To register a function here, use the :meth:`request_init`\n </s> add         #: To register a function here, use the :meth:`before_request` </s> remove         self.request_init_funcs = []\n </s> add         self.before_request_funcs = [] </s> remove @app.request_init\n </s> add @app.before_request", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace", "code_tokens": " <mask>     def test_request_processing(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         evts = []\n <mask>         @app.request_init\n <mask>         def before_request():\n <mask>             evts.append('before')\n <mask>         @app.request_shutdown\n </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove     @app.request_init\n </s> add     @app.before_request </s> remove     @app.request_shutdown\n </s> add     @app.after_request </s> remove     @app.request_shutdown\n </s> add     @app.after_request </s> remove     @app.request_init\n </s> add     @app.before_request </s> remove @app.request_init\n </s> add @app.before_request", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> markupsafe==1.1.1\n <mask>     # via jinja2\n <mask> nodeenv==1.5.0\n <mask>     # via pre-commit\n <mask> packaging==20.8\n <mask>     # via\n <mask>     #   -r requirements/docs.in\n <mask>     #   pallets-sphinx-themes\n <mask>     #   pytest\n <mask>     #   sphinx\n </s> Bump packaging from 20.8 to 20.9\n\nBumps [packaging](https://github.com/pypa/packaging) from 20.8 to 20.9.\n- [Release notes](https://github.com/pypa/packaging/releases)\n- [Changelog](https://github.com/pypa/packaging/blob/main/CHANGELOG.rst)\n- [Commits](https://github.com/pypa/packaging/compare/20.8...20.9)\n\nSigned-off-by: dependabot-preview[bot] <support@dependabot.com> </s> remove packaging==20.8\n </s> add packaging==20.9 </s> remove packaging==20.8\n </s> add packaging==20.9", "html_url": "https://github.com/pallets/flask/commit/fb5f04a8c71499391bab37aa4004ecc652724e0d", "file_name": "requirements/dev.txt"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> jinja2==2.11.2\n <mask>     # via sphinx\n <mask> markupsafe==1.1.1\n <mask>     # via jinja2\n <mask> packaging==20.8\n <mask>     # via\n <mask>     #   -r requirements/docs.in\n <mask>     #   pallets-sphinx-themes\n <mask>     #   sphinx\n <mask> pallets-sphinx-themes==1.2.3\n </s> Bump packaging from 20.8 to 20.9\n\nBumps [packaging](https://github.com/pypa/packaging) from 20.8 to 20.9.\n- [Release notes](https://github.com/pypa/packaging/releases)\n- [Changelog](https://github.com/pypa/packaging/blob/main/CHANGELOG.rst)\n- [Commits](https://github.com/pypa/packaging/compare/20.8...20.9)\n\nSigned-off-by: dependabot-preview[bot] <support@dependabot.com> </s> remove packaging==20.8\n </s> add packaging==20.9 </s> remove packaging==20.8\n </s> add packaging==20.9", "html_url": "https://github.com/pallets/flask/commit/fb5f04a8c71499391bab37aa4004ecc652724e0d", "file_name": "requirements/docs.txt"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> greenlet==1.0.0\n <mask>     # via -r requirements/tests.in\n <mask> iniconfig==1.1.1\n <mask>     # via pytest\n <mask> packaging==20.8\n <mask>     # via pytest\n <mask> pluggy==0.13.1\n <mask>     # via pytest\n <mask> py==1.9.0\n <mask>     # via pytest\n </s> Bump packaging from 20.8 to 20.9\n\nBumps [packaging](https://github.com/pypa/packaging) from 20.8 to 20.9.\n- [Release notes](https://github.com/pypa/packaging/releases)\n- [Changelog](https://github.com/pypa/packaging/blob/main/CHANGELOG.rst)\n- [Commits](https://github.com/pypa/packaging/compare/20.8...20.9)\n\nSigned-off-by: dependabot-preview[bot] <support@dependabot.com> </s> remove packaging==20.8\n </s> add packaging==20.9 </s> remove packaging==20.8\n </s> add packaging==20.9", "html_url": "https://github.com/pallets/flask/commit/fb5f04a8c71499391bab37aa4004ecc652724e0d", "file_name": "requirements/tests.txt"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> - ``FLASK_APP`` can be set to an app factory, with arguments if needed, for\n <mask>   example ``FLASK_APP=myproject.app:create_app('dev')``. (`#2326`_)\n <mask> - ``View.provide_automatic_options = True`` is set on the view function from\n <mask>   ``View.as_view``, to be detected in ``app.add_url_rule``. (`#2316`_)\n <mask> - Error handling will try handlers registered for ``blueprint, code``,\n <mask>   ``app, code``, ``blueprint, exception``, ``app, exception``. (`#2314`_)\n <mask> - ``Cookie`` is added to the response's ``Vary`` header if the session is\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove def test_prepare_exec_for_file(test_apps):\n    \"\"\"Expect the correct path to be set and the correct module name to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect, where\n    the parent directory of given file is added to `sys.path`.\n </s> add cwd = os.getcwd()\ntest_path = os.path.abspath(os.path.join(\n    os.path.dirname(__file__), 'test_apps'\n))\n\n\n@pytest.mark.parametrize('value,path,result', (\n    ('test', cwd, 'test'),\n    ('test.py', cwd, 'test'),\n    ('a/test', os.path.join(cwd, 'a'), 'test'),\n    ('test/__init__.py', cwd, 'test'),\n    ('test/__init__', cwd, 'test'),\n    # nested package\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', '__init__'),\n        test_path, 'cliapp.inner1'\n    ),\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', 'inner2'),\n        test_path, 'cliapp.inner1.inner2'\n    ),\n    # dotted name\n    ('test.a.b', cwd, 'test.a.b'),\n    (os.path.join(test_path, 'cliapp.app'), test_path, 'cliapp.app'),\n    # not a Python file, will be caught during import\n    (\n        os.path.join(test_path, 'cliapp', 'message.txt'),\n        test_path, 'cliapp.message.txt'\n    ),\n))\ndef test_prepare_import(request, value, path, result):\n    \"\"\"Expect the correct path to be set and the correct import and app names\n    to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect where the parent directory\n    of the given import is added to :data:`sys.path`. This is reset after the\n    test runs. </s> remove         self.app_import_path = app_import_path\n </s> add         self.app_import_path = app_import_path or os.environ.get('FLASK_APP') </s> remove                 raise RuntimeError('Failed to find application in module '\n </s> add                 raise NoAppException('Failed to find application in module ' </s> remove         if create_app is None:\n            if app_import_path is None:\n                app_import_path = find_default_import_path()\n            self.app_import_path = app_import_path\n        else:\n            app_import_path = None\n\n </s> add  </s> remove             rv = call_factory(self.create_app, self)\n </s> add             app = call_factory(self.create_app, self) </s> remove def prepare_exec_for_file(filename):\n </s> add def prepare_import(path):", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> .. _#2374: https://github.com/pallets/flask/pull/2374\n <mask> .. _#2373: https://github.com/pallets/flask/pull/2373\n <mask> .. _#2385: https://github.com/pallets/flask/issues/2385\n <mask> .. _#2412: https://github.com/pallets/flask/pull/2412\n <mask> \n <mask> Version 0.12.2\n <mask> --------------\n <mask> \n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove def test_locate_app(test_apps):\n    \"\"\"Test of locate_app.\"\"\"\n    script_info = ScriptInfo()\n    assert locate_app(script_info, \"cliapp.app\").name == \"testapp\"\n    assert locate_app(script_info, \"cliapp.app:testapp\").name == \"testapp\"\n    assert locate_app(script_info, \"cliapp.factory\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app()\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app2('foo', 'bar')\"\n    ).name == \"create_app2_foo_bar\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app2('foo', 'bar', )\"\n    ).name == \"create_app2_foo_bar\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app3('baz', 'qux')\"\n    ).name == \"create_app3_baz_qux\"\n    assert locate_app(script_info, \"cliapp.multiapp:app1\").name == \"app1\"\n    pytest.raises(\n        NoAppException, locate_app, script_info, \"notanpp.py\")\n    pytest.raises(\n        NoAppException, locate_app, script_info, \"cliapp/app\")\n    pytest.raises(\n        RuntimeError, locate_app, script_info, \"cliapp.app:notanapp\")\n    pytest.raises(\n        NoAppException, locate_app,\n        script_info, \"cliapp.factory:create_app2('foo')\")\n    pytest.raises(\n        NoAppException, locate_app,\n        script_info, \"cliapp.factory:create_app ()\")\n    pytest.raises(\n        NoAppException, locate_app, script_info, \"cliapp.importerrorapp\")\n    assert locate_app(\n        script_info, \"notanpp.py\", raise_if_not_found=False\n    ) is None\n\n\ndef test_find_default_import_path(test_apps, monkeypatch, tmpdir):\n    \"\"\"Test of find_default_import_path.\"\"\"\n    monkeypatch.delitem(os.environ, 'FLASK_APP', raising=False)\n    assert find_default_import_path() == None\n    monkeypatch.setitem(os.environ, 'FLASK_APP', 'notanapp')\n    assert find_default_import_path() == 'notanapp'\n    tmpfile = tmpdir.join('testapp.py')\n    tmpfile.write('')\n    monkeypatch.setitem(os.environ, 'FLASK_APP', str(tmpfile))\n    expect_rv = prepare_exec_for_file(str(tmpfile))\n    assert find_default_import_path() == expect_rv\n </s> add def test_locate_app_suppress_raise():\n    info = ScriptInfo()\n    app = locate_app(info, 'notanapp.py', None, raise_if_not_found=False)\n    assert app is None\n\n    # only direct import error is suppressed\n    with pytest.raises(NoAppException):\n        locate_app(\n            info, 'cliapp.importerrorapp', None, raise_if_not_found=False\n        ) </s> remove     if ':' in app_id:\n        module, app_obj = app_id.split(':', 1)\n    else:\n        module = app_id\n        app_obj = None\n\n </s> add  </s> remove     if app_obj is None:\n        return find_best_app(script_info, mod)\n </s> add     if app_name is None:\n        return find_best_app(script_info, module) </s> remove     mod = sys.modules[module]\n </s> add     module = sys.modules[module_name] </s> remove                 'The file/path provided ({module}) does not appear to exist.'\n                ' Please verify the path is correct. If app is not on'\n                ' PYTHONPATH, ensure the extension is .py.'.format(\n                    module=module)\n </s> add                 'Could not import \"{name}\".\"'.format(name=module_name) </s> remove                 'There was an error trying to import the app ({module}):\\n'\n                '{stack_trace}'.format(\n                    module=module, stack_trace=stack_trace\n                )\n </s> add                 'While importing \"{name}\", an ImportError was raised:'\n                '\\n\\n{tb}'.format(name=module_name, tb=traceback.format_exc())", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>             if isinstance(app, Flask):\n <mask>                 return app\n <mask>             else:\n <mask>                 raise RuntimeError('Failed to find application in module '\n <mask>                                    '\"{name}\"'.format(name=module))\n <mask>         except TypeError as e:\n <mask>             new_error = NoAppException(\n <mask>                 '{e}\\nThe app factory \"{factory}\" in module \"{module}\" could'\n <mask>                 ' not be called with the specified arguments (and a'\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove             if not rv:\n                raise NoAppException(\n                    'Could not locate Flask application. You did not provide '\n                    'the FLASK_APP environment variable, and a wsgi.py or '\n                    'app.py module was not found in the current directory.\\n\\n'\n                    'For more information see '\n                    'http://flask.pocoo.org/docs/latest/quickstart/'\n                )\n </s> add         if not app:\n            raise NoAppException(\n                'Could not locate a Flask application. You did not provide '\n                'the \"FLASK_APP\" environment variable, and a \"wsgi.py\" or '\n                '\"app.py\" module was not found in the current directory.'\n            ) </s> remove                 'The file/path provided ({module}) does not appear to exist.'\n                ' Please verify the path is correct. If app is not on'\n                ' PYTHONPATH, ensure the extension is .py.'.format(\n                    module=module)\n </s> add                 'Could not import \"{name}\".\"'.format(name=module_name) </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')):\n </s> add     if os.path.splitext(path)[1] == '.py':\n        path = os.path.splitext(path)[0]\n\n    if os.path.basename(path) == '__init__':\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, '__init__.py')): </s> add - ``FLASK_APP`` can point to local packages that are not installed in dev mode,\n  although `pip install -e` should still be preferred. (`#2414`_) </s> remove                     if rv:\n </s> add                     if app: </s> remove                 'There was an error trying to import the app ({module}):\\n'\n                '{stack_trace}'.format(\n                    module=module, stack_trace=stack_trace\n                )\n </s> add                 'While importing \"{name}\", an ImportError was raised:'\n                '\\n\\n{tb}'.format(name=module_name, tb=traceback.format_exc())", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep replace keep keep keep replace keep keep", "code_tokens": " <mask> \n <mask> def prepare_exec_for_file(filename):\n <mask>     \"\"\"Given a filename this will try to calculate the python path, add it\n <mask>     to the search path and return the actual module name that is expected.\n <mask>     \"\"\"\n <mask>     module = []\n <mask> \n <mask>     # Chop off file extensions or package markers\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')):\n </s> add     if os.path.splitext(path)[1] == '.py':\n        path = os.path.splitext(path)[0]\n\n    if os.path.basename(path) == '__init__':\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, '__init__.py')): </s> remove def test_prepare_exec_for_file(test_apps):\n    \"\"\"Expect the correct path to be set and the correct module name to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect, where\n    the parent directory of given file is added to `sys.path`.\n </s> add cwd = os.getcwd()\ntest_path = os.path.abspath(os.path.join(\n    os.path.dirname(__file__), 'test_apps'\n))\n\n\n@pytest.mark.parametrize('value,path,result', (\n    ('test', cwd, 'test'),\n    ('test.py', cwd, 'test'),\n    ('a/test', os.path.join(cwd, 'a'), 'test'),\n    ('test/__init__.py', cwd, 'test'),\n    ('test/__init__', cwd, 'test'),\n    # nested package\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', '__init__'),\n        test_path, 'cliapp.inner1'\n    ),\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', 'inner2'),\n        test_path, 'cliapp.inner1.inner2'\n    ),\n    # dotted name\n    ('test.a.b', cwd, 'test.a.b'),\n    (os.path.join(test_path, 'cliapp.app'), test_path, 'cliapp.app'),\n    # not a Python file, will be caught during import\n    (\n        os.path.join(test_path, 'cliapp', 'message.txt'),\n        test_path, 'cliapp.message.txt'\n    ),\n))\ndef test_prepare_import(request, value, path, result):\n    \"\"\"Expect the correct path to be set and the correct import and app names\n    to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect where the parent directory\n    of the given import is added to :data:`sys.path`. This is reset after the\n    test runs. </s> remove         self.app_import_path = app_import_path\n </s> add         self.app_import_path = app_import_path or os.environ.get('FLASK_APP') </s> remove         __import__(module)\n </s> add         __import__(module_name) </s> remove     if ':' in app_id:\n        module, app_obj = app_id.split(':', 1)\n    else:\n        module = app_id\n        app_obj = None\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep replace replace", "code_tokens": " <mask>     to the search path and return the actual module name that is expected.\n <mask>     \"\"\"\n <mask>     module = []\n <mask> \n <mask>     # Chop off file extensions or package markers\n <mask>     if os.path.split(filename)[1] == '__init__.py':\n <mask>         filename = os.path.dirname(filename)\n <mask>     elif filename.endswith('.py'):\n <mask>         filename = filename[:-3]\n <mask>     else:\n <mask>         raise NoAppException('The file provided (%s) does exist but is not a '\n <mask>                              'valid Python file.  This means that it cannot '\n <mask>                              'be used as application.  Please change the '\n <mask>                              'extension to .py' % filename)\n <mask>     filename = os.path.realpath(filename)\n <mask> \n <mask>     dirpath = filename\n <mask>     while 1:\n <mask>         dirpath, extra = os.path.split(dirpath)\n <mask>         module.append(extra)\n <mask>         if not os.path.isfile(os.path.join(dirpath, '__init__.py')):\n <mask>             break\n <mask> \n <mask>     if sys.path[0] != dirpath:\n <mask>         sys.path.insert(0, dirpath)\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove     module = []\n </s> add     path = os.path.realpath(path) </s> remove def prepare_exec_for_file(filename):\n </s> add def prepare_import(path): </s> remove                 'The file/path provided ({module}) does not appear to exist.'\n                ' Please verify the path is correct. If app is not on'\n                ' PYTHONPATH, ensure the extension is .py.'.format(\n                    module=module)\n </s> add                 'Could not import \"{name}\".\"'.format(name=module_name) </s> remove             if not rv:\n                raise NoAppException(\n                    'Could not locate Flask application. You did not provide '\n                    'the FLASK_APP environment variable, and a wsgi.py or '\n                    'app.py module was not found in the current directory.\\n\\n'\n                    'For more information see '\n                    'http://flask.pocoo.org/docs/latest/quickstart/'\n                )\n </s> add         if not app:\n            raise NoAppException(\n                'Could not locate a Flask application. You did not provide '\n                'the \"FLASK_APP\" environment variable, and a \"wsgi.py\" or '\n                '\"app.py\" module was not found in the current directory.'\n            ) </s> remove     return '.'.join(module[::-1])\n </s> add     return '.'.join(module_name[::-1])", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     if sys.path[0] != dirpath:\n <mask>         sys.path.insert(0, dirpath)\n <mask> \n <mask>     return '.'.join(module[::-1])\n <mask> \n <mask> \n <mask> def locate_app(script_info, app_id, raise_if_not_found=True):\n <mask>     \"\"\"Attempts to locate the application.\"\"\"\n <mask>     __traceback_hide__ = True\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove     if sys.path[0] != dirpath:\n        sys.path.insert(0, dirpath)\n </s> add     if sys.path[0] != path:\n        sys.path.insert(0, path) </s> remove def locate_app(script_info, app_id, raise_if_not_found=True):\n </s> add def locate_app(script_info, module_name, app_name, raise_if_not_found=True): </s> remove     if ':' in app_id:\n        module, app_obj = app_id.split(':', 1)\n    else:\n        module = app_id\n        app_obj = None\n\n </s> add  </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')):\n </s> add     if os.path.splitext(path)[1] == '.py':\n        path = os.path.splitext(path)[0]\n\n    if os.path.basename(path) == '__init__':\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, '__init__.py')): </s> remove                     if rv:\n </s> add                     if app: </s> remove             if not rv:\n                raise NoAppException(\n                    'Could not locate Flask application. You did not provide '\n                    'the FLASK_APP environment variable, and a wsgi.py or '\n                    'app.py module was not found in the current directory.\\n\\n'\n                    'For more information see '\n                    'http://flask.pocoo.org/docs/latest/quickstart/'\n                )\n </s> add         if not app:\n            raise NoAppException(\n                'Could not locate a Flask application. You did not provide '\n                'the \"FLASK_APP\" environment variable, and a \"wsgi.py\" or '\n                '\"app.py\" module was not found in the current directory.'\n            )", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask> \n <mask>     return '.'.join(module[::-1])\n <mask> \n <mask> \n <mask> def locate_app(script_info, app_id, raise_if_not_found=True):\n <mask>     \"\"\"Attempts to locate the application.\"\"\"\n <mask>     __traceback_hide__ = True\n <mask> \n <mask>     if ':' in app_id:\n <mask>         module, app_obj = app_id.split(':', 1)\n <mask>     else:\n <mask>         module = app_id\n <mask>         app_obj = None\n <mask> \n <mask>     try:\n <mask>         __import__(module)\n <mask>     except ImportError:\n <mask>         # Reraise the ImportError if it occurred within the imported module.\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove         __import__(module)\n </s> add         __import__(module_name) </s> remove     return '.'.join(module[::-1])\n </s> add     return '.'.join(module_name[::-1]) </s> remove             stack_trace = traceback.format_exc()\n </s> add  </s> remove     mod = sys.modules[module]\n </s> add     module = sys.modules[module_name] </s> remove     if sys.path[0] != dirpath:\n        sys.path.insert(0, dirpath)\n </s> add     if sys.path[0] != path:\n        sys.path.insert(0, path)", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace keep", "code_tokens": " <mask>     try:\n <mask>         __import__(module)\n <mask>     except ImportError:\n <mask>         # Reraise the ImportError if it occurred within the imported module.\n <mask>         # Determine this by checking whether the trace has a depth > 1.\n <mask>         if sys.exc_info()[-1].tb_next:\n <mask>             stack_trace = traceback.format_exc()\n <mask>             raise NoAppException(\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove     if ':' in app_id:\n        module, app_obj = app_id.split(':', 1)\n    else:\n        module = app_id\n        app_obj = None\n\n </s> add  </s> remove                 'There was an error trying to import the app ({module}):\\n'\n                '{stack_trace}'.format(\n                    module=module, stack_trace=stack_trace\n                )\n </s> add                 'While importing \"{name}\", an ImportError was raised:'\n                '\\n\\n{tb}'.format(name=module_name, tb=traceback.format_exc()) </s> remove     module = []\n </s> add     path = os.path.realpath(path) </s> remove                 raise RuntimeError('Failed to find application in module '\n </s> add                 raise NoAppException('Failed to find application in module ' </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')):\n </s> add     if os.path.splitext(path)[1] == '.py':\n        path = os.path.splitext(path)[0]\n\n    if os.path.basename(path) == '__init__':\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, '__init__.py')):", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep replace replace replace replace keep keep keep replace replace replace replace keep", "code_tokens": " <mask>             stack_trace = traceback.format_exc()\n <mask>             raise NoAppException(\n <mask>                 'There was an error trying to import the app ({module}):\\n'\n <mask>                 '{stack_trace}'.format(\n <mask>                     module=module, stack_trace=stack_trace\n <mask>                 )\n <mask>             )\n <mask>         elif raise_if_not_found:\n <mask>             raise NoAppException(\n <mask>                 'The file/path provided ({module}) does not appear to exist.'\n <mask>                 ' Please verify the path is correct. If app is not on'\n <mask>                 ' PYTHONPATH, ensure the extension is .py.'.format(\n <mask>                     module=module)\n <mask>             )\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove             stack_trace = traceback.format_exc()\n </s> add  </s> remove             if not rv:\n                raise NoAppException(\n                    'Could not locate Flask application. You did not provide '\n                    'the FLASK_APP environment variable, and a wsgi.py or '\n                    'app.py module was not found in the current directory.\\n\\n'\n                    'For more information see '\n                    'http://flask.pocoo.org/docs/latest/quickstart/'\n                )\n </s> add         if not app:\n            raise NoAppException(\n                'Could not locate a Flask application. You did not provide '\n                'the \"FLASK_APP\" environment variable, and a \"wsgi.py\" or '\n                '\"app.py\" module was not found in the current directory.'\n            ) </s> remove                     if rv:\n </s> add                     if app: </s> remove                 raise RuntimeError('Failed to find application in module '\n </s> add                 raise NoAppException('Failed to find application in module ' </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')):\n </s> add     if os.path.splitext(path)[1] == '.py':\n        path = os.path.splitext(path)[0]\n\n    if os.path.basename(path) == '__init__':\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, '__init__.py')):", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace keep keep keep keep", "code_tokens": " <mask>             )\n <mask>         else:\n <mask>             return\n <mask> \n <mask>     mod = sys.modules[module]\n <mask> \n <mask>     if app_obj is None:\n <mask>         return find_best_app(script_info, mod)\n <mask>     else:\n <mask>         return find_app_by_string(app_obj, script_info, mod)\n <mask> \n <mask> \n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove         return find_app_by_string(app_obj, script_info, mod)\n\n\ndef find_default_import_path():\n    app = os.environ.get('FLASK_APP')\n    if app is None:\n        return\n    if os.path.isfile(app):\n        return prepare_exec_for_file(app)\n    return app\n </s> add         return find_app_by_string(app_name, script_info, module) </s> remove                 'The file/path provided ({module}) does not appear to exist.'\n                ' Please verify the path is correct. If app is not on'\n                ' PYTHONPATH, ensure the extension is .py.'.format(\n                    module=module)\n </s> add                 'Could not import \"{name}\".\"'.format(name=module_name) </s> remove             rv = call_factory(self.create_app, self)\n </s> add             app = call_factory(self.create_app, self) </s> add         app = None\n </s> remove         self._loaded_app = rv\n        return rv\n </s> add         self._loaded_app = app\n        return app", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     if app_obj is None:\n <mask>         return find_best_app(script_info, mod)\n <mask>     else:\n <mask>         return find_app_by_string(app_obj, script_info, mod)\n <mask> \n <mask> \n <mask> def find_default_import_path():\n <mask>     app = os.environ.get('FLASK_APP')\n <mask>     if app is None:\n <mask>         return\n <mask>     if os.path.isfile(app):\n <mask>         return prepare_exec_for_file(app)\n <mask>     return app\n <mask> \n <mask> \n <mask> def get_version(ctx, param, value):\n <mask>     if not value or ctx.resilient_parsing:\n <mask>         return\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove     if app_obj is None:\n        return find_best_app(script_info, mod)\n </s> add     if app_name is None:\n        return find_best_app(script_info, module) </s> remove     mod = sys.modules[module]\n </s> add     module = sys.modules[module_name] </s> add         app = None\n </s> remove         self._loaded_app = rv\n        return rv\n </s> add         self._loaded_app = app\n        return app </s> remove             rv = call_factory(self.create_app, self)\n </s> add             app = call_factory(self.create_app, self) </s> remove             rv._reconfigure_for_run_debug(debug)\n </s> add             app._reconfigure_for_run_debug(debug)", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace keep replace keep keep keep", "code_tokens": " <mask>     def __init__(self, app_import_path=None, create_app=None):\n <mask>         if create_app is None:\n <mask>             if app_import_path is None:\n <mask>                 app_import_path = find_default_import_path()\n <mask>             self.app_import_path = app_import_path\n <mask>         else:\n <mask>             app_import_path = None\n <mask> \n <mask>         #: Optionally the import path for the Flask application.\n <mask>         self.app_import_path = app_import_path\n <mask>         #: Optionally a function that is passed the script info to create\n <mask>         #: the instance of the application.\n <mask>         self.create_app = create_app\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> add         app = None\n </s> remove             rv = call_factory(self.create_app, self)\n </s> add             app = call_factory(self.create_app, self) </s> remove                 rv = locate_app(self, self.app_import_path)\n </s> add                 path, name = (self.app_import_path.split(':', 1) + [None])[:2]\n                import_name = prepare_import(path)\n                app = locate_app(self, import_name, name) </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')):\n </s> add     if os.path.splitext(path)[1] == '.py':\n        path = os.path.splitext(path)[0]\n\n    if os.path.basename(path) == '__init__':\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, '__init__.py')): </s> remove             if not rv:\n                raise NoAppException(\n                    'Could not locate Flask application. You did not provide '\n                    'the FLASK_APP environment variable, and a wsgi.py or '\n                    'app.py module was not found in the current directory.\\n\\n'\n                    'For more information see '\n                    'http://flask.pocoo.org/docs/latest/quickstart/'\n                )\n </s> add         if not app:\n            raise NoAppException(\n                'Could not locate a Flask application. You did not provide '\n                'the \"FLASK_APP\" environment variable, and a \"wsgi.py\" or '\n                '\"app.py\" module was not found in the current directory.'\n            )", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         if self._loaded_app is not None:\n <mask>             return self._loaded_app\n <mask> \n <mask>         if self.create_app is not None:\n <mask>             app = call_factory(self.create_app, self)\n <mask>         else:\n <mask>             if self.app_import_path:\n <mask>                 path, name = (self.app_import_path.split(':', 1) + [None])[:2]\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove                 rv = locate_app(self, self.app_import_path)\n </s> add                 path, name = (self.app_import_path.split(':', 1) + [None])[:2]\n                import_name = prepare_import(path)\n                app = locate_app(self, import_name, name) </s> remove             rv = call_factory(self.create_app, self)\n </s> add             app = call_factory(self.create_app, self) </s> remove         self._loaded_app = rv\n        return rv\n </s> add         self._loaded_app = app\n        return app </s> remove             rv._reconfigure_for_run_debug(debug)\n </s> add             app._reconfigure_for_run_debug(debug) </s> remove         return find_app_by_string(app_obj, script_info, mod)\n\n\ndef find_default_import_path():\n    app = os.environ.get('FLASK_APP')\n    if app is None:\n        return\n    if os.path.isfile(app):\n        return prepare_exec_for_file(app)\n    return app\n </s> add         return find_app_by_string(app_name, script_info, module) </s> remove     if app_obj is None:\n        return find_best_app(script_info, mod)\n </s> add     if app_name is None:\n        return find_best_app(script_info, module)", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace", "code_tokens": " <mask>             return self._loaded_app\n <mask> \n <mask>         if self.create_app is not None:\n <mask>             rv = call_factory(self.create_app, self)\n <mask>         else:\n <mask>             if self.app_import_path:\n <mask>                 rv = locate_app(self, self.app_import_path)\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> add         app = None\n </s> remove                 for module in ['wsgi.py', 'app.py']:\n                    import_path = prepare_exec_for_file(module)\n                    rv = locate_app(\n                        self, import_path, raise_if_not_found=False\n </s> add                 for path in ('wsgi.py', 'app.py'):\n                    import_name = prepare_import(path)\n                    app = locate_app(\n                        self, import_name, None, raise_if_not_found=False </s> remove         self._loaded_app = rv\n        return rv\n </s> add         self._loaded_app = app\n        return app </s> remove             rv._reconfigure_for_run_debug(debug)\n </s> add             app._reconfigure_for_run_debug(debug) </s> remove     if app_obj is None:\n        return find_best_app(script_info, mod)\n </s> add     if app_name is None:\n        return find_best_app(script_info, module)", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace keep keep replace keep keep keep", "code_tokens": " <mask>             if self.app_import_path:\n <mask>                 rv = locate_app(self, self.app_import_path)\n <mask>             else:\n <mask>                 for module in ['wsgi.py', 'app.py']:\n <mask>                     import_path = prepare_exec_for_file(module)\n <mask>                     rv = locate_app(\n <mask>                         self, import_path, raise_if_not_found=False\n <mask>                     )\n <mask> \n <mask>                     if rv:\n <mask>                         break\n <mask> \n <mask>             if not rv:\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove                 rv = locate_app(self, self.app_import_path)\n </s> add                 path, name = (self.app_import_path.split(':', 1) + [None])[:2]\n                import_name = prepare_import(path)\n                app = locate_app(self, import_name, name) </s> remove             rv = call_factory(self.create_app, self)\n </s> add             app = call_factory(self.create_app, self) </s> remove             if not rv:\n                raise NoAppException(\n                    'Could not locate Flask application. You did not provide '\n                    'the FLASK_APP environment variable, and a wsgi.py or '\n                    'app.py module was not found in the current directory.\\n\\n'\n                    'For more information see '\n                    'http://flask.pocoo.org/docs/latest/quickstart/'\n                )\n </s> add         if not app:\n            raise NoAppException(\n                'Could not locate a Flask application. You did not provide '\n                'the \"FLASK_APP\" environment variable, and a \"wsgi.py\" or '\n                '\"app.py\" module was not found in the current directory.'\n            ) </s> remove             rv._reconfigure_for_run_debug(debug)\n </s> add             app._reconfigure_for_run_debug(debug) </s> remove         self._loaded_app = rv\n        return rv\n </s> add         self._loaded_app = app\n        return app", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>                     if rv:\n <mask>                         break\n <mask> \n <mask>             if not rv:\n <mask>                 raise NoAppException(\n <mask>                     'Could not locate Flask application. You did not provide '\n <mask>                     'the FLASK_APP environment variable, and a wsgi.py or '\n <mask>                     'app.py module was not found in the current directory.\\n\\n'\n <mask>                     'For more information see '\n <mask>                     'http://flask.pocoo.org/docs/latest/quickstart/'\n <mask>                 )\n <mask> \n <mask>         debug = get_debug_flag()\n <mask> \n <mask>         if debug is not None:\n <mask>             rv._reconfigure_for_run_debug(debug)\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove                     if rv:\n </s> add                     if app: </s> remove             rv._reconfigure_for_run_debug(debug)\n </s> add             app._reconfigure_for_run_debug(debug) </s> remove                 'The file/path provided ({module}) does not appear to exist.'\n                ' Please verify the path is correct. If app is not on'\n                ' PYTHONPATH, ensure the extension is .py.'.format(\n                    module=module)\n </s> add                 'Could not import \"{name}\".\"'.format(name=module_name) </s> remove                 raise RuntimeError('Failed to find application in module '\n </s> add                 raise NoAppException('Failed to find application in module ' </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')):\n </s> add     if os.path.splitext(path)[1] == '.py':\n        path = os.path.splitext(path)[0]\n\n    if os.path.basename(path) == '__init__':\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, '__init__.py')): </s> remove                 'There was an error trying to import the app ({module}):\\n'\n                '{stack_trace}'.format(\n                    module=module, stack_trace=stack_trace\n                )\n </s> add                 'While importing \"{name}\", an ImportError was raised:'\n                '\\n\\n{tb}'.format(name=module_name, tb=traceback.format_exc())", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep keep keep keep replace replace keep", "code_tokens": " <mask> \n <mask>         debug = get_debug_flag()\n <mask> \n <mask>         if debug is not None:\n <mask>             rv._reconfigure_for_run_debug(debug)\n <mask> \n <mask>         self._loaded_app = rv\n <mask>         return rv\n <mask> \n <mask> \n <mask>         if debug is not None:\n <mask>             rv._reconfigure_for_run_debug(debug)\n <mask> \n <mask>         self._loaded_app = rv\n <mask>         return rv\n <mask> \n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove             rv = call_factory(self.create_app, self)\n </s> add             app = call_factory(self.create_app, self) </s> remove                 rv = locate_app(self, self.app_import_path)\n </s> add                 path, name = (self.app_import_path.split(':', 1) + [None])[:2]\n                import_name = prepare_import(path)\n                app = locate_app(self, import_name, name) </s> add         app = None\n </s> remove             if not rv:\n                raise NoAppException(\n                    'Could not locate Flask application. You did not provide '\n                    'the FLASK_APP environment variable, and a wsgi.py or '\n                    'app.py module was not found in the current directory.\\n\\n'\n                    'For more information see '\n                    'http://flask.pocoo.org/docs/latest/quickstart/'\n                )\n </s> add         if not app:\n            raise NoAppException(\n                'Could not locate a Flask application. You did not provide '\n                'the \"FLASK_APP\" environment variable, and a \"wsgi.py\" or '\n                '\"app.py\" module was not found in the current directory.'\n            ) </s> remove                 for module in ['wsgi.py', 'app.py']:\n                    import_path = prepare_exec_for_file(module)\n                    rv = locate_app(\n                        self, import_path, raise_if_not_found=False\n </s> add                 for path in ('wsgi.py', 'app.py'):\n                    import_name = prepare_import(path)\n                    app = locate_app(\n                        self, import_name, None, raise_if_not_found=False", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def create_app():\n <mask>     return Flask('create_app')\n <mask> \n <mask> \n <mask> def create_app2(foo, bar):\n <mask>     return Flask(\"_\".join(['create_app2', foo, bar]))\n <mask> \n <mask> \n <mask> def create_app3(foo, bar, script_info):\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove def create_app3(foo, bar, script_info):\n    return Flask(\"_\".join(['create_app3', foo, bar]))\n </s> add def create_app3(foo, script_info):\n    return Flask('_'.join(['app3', foo, script_info.data['test']])) </s> remove         return find_app_by_string(app_obj, script_info, mod)\n\n\ndef find_default_import_path():\n    app = os.environ.get('FLASK_APP')\n    if app is None:\n        return\n    if os.path.isfile(app):\n        return prepare_exec_for_file(app)\n    return app\n </s> add         return find_app_by_string(app_name, script_info, module) </s> remove     if app_obj is None:\n        return find_best_app(script_info, mod)\n </s> add     if app_name is None:\n        return find_best_app(script_info, module) </s> remove     return '.'.join(module[::-1])\n </s> add     return '.'.join(module_name[::-1]) </s> remove     mod = sys.modules[module]\n </s> add     module = sys.modules[module_name]", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "tests/test_apps/cliapp/factory.py"}
{"docstring_tokens": "keep keep keep keep replace replace", "code_tokens": " <mask> def create_app2(foo, bar):\n <mask>     return Flask(\"_\".join(['create_app2', foo, bar]))\n <mask> \n <mask> \n <mask> def create_app3(foo, bar, script_info):\n <mask>     return Flask(\"_\".join(['create_app3', foo, bar]))\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove     return Flask(\"_\".join(['create_app2', foo, bar]))\n </s> add     return Flask('_'.join(['app2', foo, bar])) </s> remove     return Flask('create_app')\n </s> add     return Flask('app') </s> remove         return find_app_by_string(app_obj, script_info, mod)\n\n\ndef find_default_import_path():\n    app = os.environ.get('FLASK_APP')\n    if app is None:\n        return\n    if os.path.isfile(app):\n        return prepare_exec_for_file(app)\n    return app\n </s> add         return find_app_by_string(app_name, script_info, module) </s> remove     if app_obj is None:\n        return find_best_app(script_info, mod)\n </s> add     if app_name is None:\n        return find_best_app(script_info, module) </s> remove     return '.'.join(module[::-1])\n </s> add     return '.'.join(module_name[::-1]) </s> remove     mod = sys.modules[module]\n </s> add     module = sys.modules[module_name]", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "tests/test_apps/cliapp/factory.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> # This file was part of Flask-CLI and was modified under the terms its license,\n <mask> # the Revised BSD License.\n <mask> # Copyright (C) 2015 CERN.\n <mask> #\n <mask> from __future__ import absolute_import, print_function\n <mask> import os\n <mask> import sys\n <mask> from functools import partial\n <mask> \n <mask> import click\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove from flask import Flask, current_app\n </s> add  </s> remove             stack_trace = traceback.format_exc()\n </s> add  </s> remove from flask.cli import cli, AppGroup, FlaskGroup, NoAppException, ScriptInfo, \\\n    find_best_app, locate_app, with_appcontext, prepare_exec_for_file, \\\n    find_default_import_path, get_version\n </s> add from flask import Flask, current_app\nfrom flask.cli import AppGroup, FlaskGroup, NoAppException, ScriptInfo, \\\n    find_best_app, get_version, locate_app, prepare_import, with_appcontext </s> remove def test_prepare_exec_for_file(test_apps):\n    \"\"\"Expect the correct path to be set and the correct module name to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect, where\n    the parent directory of given file is added to `sys.path`.\n </s> add cwd = os.getcwd()\ntest_path = os.path.abspath(os.path.join(\n    os.path.dirname(__file__), 'test_apps'\n))\n\n\n@pytest.mark.parametrize('value,path,result', (\n    ('test', cwd, 'test'),\n    ('test.py', cwd, 'test'),\n    ('a/test', os.path.join(cwd, 'a'), 'test'),\n    ('test/__init__.py', cwd, 'test'),\n    ('test/__init__', cwd, 'test'),\n    # nested package\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', '__init__'),\n        test_path, 'cliapp.inner1'\n    ),\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', 'inner2'),\n        test_path, 'cliapp.inner1.inner2'\n    ),\n    # dotted name\n    ('test.a.b', cwd, 'test.a.b'),\n    (os.path.join(test_path, 'cliapp.app'), test_path, 'cliapp.app'),\n    # not a Python file, will be caught during import\n    (\n        os.path.join(test_path, 'cliapp', 'message.txt'),\n        test_path, 'cliapp.message.txt'\n    ),\n))\ndef test_prepare_import(request, value, path, result):\n    \"\"\"Expect the correct path to be set and the correct import and app names\n    to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect where the parent directory\n    of the given import is added to :data:`sys.path`. This is reset after the\n    test runs. </s> remove                 'There was an error trying to import the app ({module}):\\n'\n                '{stack_trace}'.format(\n                    module=module, stack_trace=stack_trace\n                )\n </s> add                 'While importing \"{name}\", an ImportError was raised:'\n                '\\n\\n{tb}'.format(name=module_name, tb=traceback.format_exc()) </s> remove     realpath = os.path.realpath('/tmp/share/test.py')\n    dirname = os.path.dirname(realpath)\n    assert prepare_exec_for_file('/tmp/share/test.py') == 'test'\n    assert dirname in sys.path\n\n    realpath = os.path.realpath('/tmp/share/__init__.py')\n    dirname = os.path.dirname(os.path.dirname(realpath))\n    assert prepare_exec_for_file('/tmp/share/__init__.py') == 'share'\n    assert dirname in sys.path\n </s> add     original_path = sys.path[:]\n\n    def reset_path():\n        sys.path[:] = original_path\n\n    request.addfinalizer(reset_path)\n\n    assert prepare_import(value) == result\n    assert sys.path[0] == path\n\n\n@pytest.mark.parametrize('iname,aname,result', (\n    ('cliapp.app', None, 'testapp'),\n    ('cliapp.app', 'testapp', 'testapp'),\n    ('cliapp.factory', None, 'app'),\n    ('cliapp.factory', 'create_app', 'app'),\n    ('cliapp.factory', 'create_app()', 'app'),\n    # no script_info\n    ('cliapp.factory', 'create_app2(\"foo\", \"bar\")', 'app2_foo_bar'),\n    # trailing comma space\n    ('cliapp.factory', 'create_app2(\"foo\", \"bar\", )', 'app2_foo_bar'),\n    # takes script_info\n    ('cliapp.factory', 'create_app3(\"foo\")', 'app3_foo_spam'),\n))\ndef test_locate_app(test_apps, iname, aname, result):\n    info = ScriptInfo()\n    info.data['test'] = 'spam'\n    assert locate_app(info, iname, aname).name == result\n\n\n@pytest.mark.parametrize('iname,aname', (\n    ('notanapp.py', None),\n    ('cliapp/app', None),\n    ('cliapp.app', 'notanapp'),\n    # not enough arguments\n    ('cliapp.factory', 'create_app2(\"foo\")'),\n    # nested import error\n    ('cliapp.importerrorapp', None),\n    # not a Python file\n    ('cliapp.message.txt', None),\n    # space before arg list\n    ('cliapp.factory', 'create_app ()'),\n))\ndef test_locate_app_raises(test_apps, iname, aname):\n    info = ScriptInfo()", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep replace keep replace replace replace keep keep keep keep", "code_tokens": " <mask> import click\n <mask> import pytest\n <mask> from click.testing import CliRunner\n <mask> from flask import Flask, current_app\n <mask> \n <mask> from flask.cli import cli, AppGroup, FlaskGroup, NoAppException, ScriptInfo, \\\n <mask>     find_best_app, locate_app, with_appcontext, prepare_exec_for_file, \\\n <mask>     find_default_import_path, get_version\n <mask> \n <mask> \n <mask> @pytest.fixture\n <mask> def runner():\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove from __future__ import absolute_import, print_function\n </s> add from __future__ import absolute_import\n </s> remove     return Flask('create_app')\n </s> add     return Flask('app') </s> remove def test_locate_app(test_apps):\n    \"\"\"Test of locate_app.\"\"\"\n    script_info = ScriptInfo()\n    assert locate_app(script_info, \"cliapp.app\").name == \"testapp\"\n    assert locate_app(script_info, \"cliapp.app:testapp\").name == \"testapp\"\n    assert locate_app(script_info, \"cliapp.factory\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app()\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app2('foo', 'bar')\"\n    ).name == \"create_app2_foo_bar\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app2('foo', 'bar', )\"\n    ).name == \"create_app2_foo_bar\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app3('baz', 'qux')\"\n    ).name == \"create_app3_baz_qux\"\n    assert locate_app(script_info, \"cliapp.multiapp:app1\").name == \"app1\"\n    pytest.raises(\n        NoAppException, locate_app, script_info, \"notanpp.py\")\n    pytest.raises(\n        NoAppException, locate_app, script_info, \"cliapp/app\")\n    pytest.raises(\n        RuntimeError, locate_app, script_info, \"cliapp.app:notanapp\")\n    pytest.raises(\n        NoAppException, locate_app,\n        script_info, \"cliapp.factory:create_app2('foo')\")\n    pytest.raises(\n        NoAppException, locate_app,\n        script_info, \"cliapp.factory:create_app ()\")\n    pytest.raises(\n        NoAppException, locate_app, script_info, \"cliapp.importerrorapp\")\n    assert locate_app(\n        script_info, \"notanpp.py\", raise_if_not_found=False\n    ) is None\n\n\ndef test_find_default_import_path(test_apps, monkeypatch, tmpdir):\n    \"\"\"Test of find_default_import_path.\"\"\"\n    monkeypatch.delitem(os.environ, 'FLASK_APP', raising=False)\n    assert find_default_import_path() == None\n    monkeypatch.setitem(os.environ, 'FLASK_APP', 'notanapp')\n    assert find_default_import_path() == 'notanapp'\n    tmpfile = tmpdir.join('testapp.py')\n    tmpfile.write('')\n    monkeypatch.setitem(os.environ, 'FLASK_APP', str(tmpfile))\n    expect_rv = prepare_exec_for_file(str(tmpfile))\n    assert find_default_import_path() == expect_rv\n </s> add def test_locate_app_suppress_raise():\n    info = ScriptInfo()\n    app = locate_app(info, 'notanapp.py', None, raise_if_not_found=False)\n    assert app is None\n\n    # only direct import error is suppressed\n    with pytest.raises(NoAppException):\n        locate_app(\n            info, 'cliapp.importerrorapp', None, raise_if_not_found=False\n        ) </s> remove         if create_app is None:\n            if app_import_path is None:\n                app_import_path = find_default_import_path()\n            self.app_import_path = app_import_path\n        else:\n            app_import_path = None\n\n </s> add  </s> remove def test_prepare_exec_for_file(test_apps):\n    \"\"\"Expect the correct path to be set and the correct module name to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect, where\n    the parent directory of given file is added to `sys.path`.\n </s> add cwd = os.getcwd()\ntest_path = os.path.abspath(os.path.join(\n    os.path.dirname(__file__), 'test_apps'\n))\n\n\n@pytest.mark.parametrize('value,path,result', (\n    ('test', cwd, 'test'),\n    ('test.py', cwd, 'test'),\n    ('a/test', os.path.join(cwd, 'a'), 'test'),\n    ('test/__init__.py', cwd, 'test'),\n    ('test/__init__', cwd, 'test'),\n    # nested package\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', '__init__'),\n        test_path, 'cliapp.inner1'\n    ),\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', 'inner2'),\n        test_path, 'cliapp.inner1.inner2'\n    ),\n    # dotted name\n    ('test.a.b', cwd, 'test.a.b'),\n    (os.path.join(test_path, 'cliapp.app'), test_path, 'cliapp.app'),\n    # not a Python file, will be caught during import\n    (\n        os.path.join(test_path, 'cliapp', 'message.txt'),\n        test_path, 'cliapp.message.txt'\n    ),\n))\ndef test_prepare_import(request, value, path, result):\n    \"\"\"Expect the correct path to be set and the correct import and app names\n    to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect where the parent directory\n    of the given import is added to :data:`sys.path`. This is reset after the\n    test runs.", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace replace keep replace replace replace replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>     pytest.raises(NoAppException, find_best_app, script_info, Module)\n <mask> \n <mask> \n <mask> def test_prepare_exec_for_file(test_apps):\n <mask>     \"\"\"Expect the correct path to be set and the correct module name to be returned.\n <mask> \n <mask>     :func:`prepare_exec_for_file` has a side effect, where\n <mask>     the parent directory of given file is added to `sys.path`.\n <mask>     \"\"\"\n <mask>     realpath = os.path.realpath('/tmp/share/test.py')\n <mask>     dirname = os.path.dirname(realpath)\n <mask>     assert prepare_exec_for_file('/tmp/share/test.py') == 'test'\n <mask>     assert dirname in sys.path\n <mask> \n <mask>     realpath = os.path.realpath('/tmp/share/__init__.py')\n <mask>     dirname = os.path.dirname(os.path.dirname(realpath))\n <mask>     assert prepare_exec_for_file('/tmp/share/__init__.py') == 'share'\n <mask>     assert dirname in sys.path\n <mask> \n <mask>     with pytest.raises(NoAppException):\n <mask>         prepare_exec_for_file('/tmp/share/test.txt')\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove         prepare_exec_for_file('/tmp/share/test.txt')\n </s> add         locate_app(info, iname, aname) </s> remove def test_locate_app(test_apps):\n    \"\"\"Test of locate_app.\"\"\"\n    script_info = ScriptInfo()\n    assert locate_app(script_info, \"cliapp.app\").name == \"testapp\"\n    assert locate_app(script_info, \"cliapp.app:testapp\").name == \"testapp\"\n    assert locate_app(script_info, \"cliapp.factory\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app()\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app2('foo', 'bar')\"\n    ).name == \"create_app2_foo_bar\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app2('foo', 'bar', )\"\n    ).name == \"create_app2_foo_bar\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app3('baz', 'qux')\"\n    ).name == \"create_app3_baz_qux\"\n    assert locate_app(script_info, \"cliapp.multiapp:app1\").name == \"app1\"\n    pytest.raises(\n        NoAppException, locate_app, script_info, \"notanpp.py\")\n    pytest.raises(\n        NoAppException, locate_app, script_info, \"cliapp/app\")\n    pytest.raises(\n        RuntimeError, locate_app, script_info, \"cliapp.app:notanapp\")\n    pytest.raises(\n        NoAppException, locate_app,\n        script_info, \"cliapp.factory:create_app2('foo')\")\n    pytest.raises(\n        NoAppException, locate_app,\n        script_info, \"cliapp.factory:create_app ()\")\n    pytest.raises(\n        NoAppException, locate_app, script_info, \"cliapp.importerrorapp\")\n    assert locate_app(\n        script_info, \"notanpp.py\", raise_if_not_found=False\n    ) is None\n\n\ndef test_find_default_import_path(test_apps, monkeypatch, tmpdir):\n    \"\"\"Test of find_default_import_path.\"\"\"\n    monkeypatch.delitem(os.environ, 'FLASK_APP', raising=False)\n    assert find_default_import_path() == None\n    monkeypatch.setitem(os.environ, 'FLASK_APP', 'notanapp')\n    assert find_default_import_path() == 'notanapp'\n    tmpfile = tmpdir.join('testapp.py')\n    tmpfile.write('')\n    monkeypatch.setitem(os.environ, 'FLASK_APP', str(tmpfile))\n    expect_rv = prepare_exec_for_file(str(tmpfile))\n    assert find_default_import_path() == expect_rv\n </s> add def test_locate_app_suppress_raise():\n    info = ScriptInfo()\n    app = locate_app(info, 'notanapp.py', None, raise_if_not_found=False)\n    assert app is None\n\n    # only direct import error is suppressed\n    with pytest.raises(NoAppException):\n        locate_app(\n            info, 'cliapp.importerrorapp', None, raise_if_not_found=False\n        ) </s> remove     module = []\n </s> add     path = os.path.realpath(path) </s> add - ``FLASK_APP`` can point to local packages that are not installed in dev mode,\n  although `pip install -e` should still be preferred. (`#2414`_) </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')):\n </s> add     if os.path.splitext(path)[1] == '.py':\n        path = os.path.splitext(path)[0]\n\n    if os.path.basename(path) == '__init__':\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, '__init__.py')):", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep replace keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask> \n <mask>     with pytest.raises(NoAppException):\n <mask>         prepare_exec_for_file('/tmp/share/test.txt')\n <mask> \n <mask> \n <mask> def test_locate_app(test_apps):\n <mask>     \"\"\"Test of locate_app.\"\"\"\n <mask>     script_info = ScriptInfo()\n <mask>     assert locate_app(script_info, \"cliapp.app\").name == \"testapp\"\n <mask>     assert locate_app(script_info, \"cliapp.app:testapp\").name == \"testapp\"\n <mask>     assert locate_app(script_info, \"cliapp.factory\").name == \"create_app\"\n <mask>     assert locate_app(\n <mask>         script_info, \"cliapp.factory\").name == \"create_app\"\n <mask>     assert locate_app(\n <mask>         script_info, \"cliapp.factory:create_app\").name == \"create_app\"\n <mask>     assert locate_app(\n <mask>         script_info, \"cliapp.factory:create_app()\").name == \"create_app\"\n <mask>     assert locate_app(\n <mask>         script_info, \"cliapp.factory:create_app2('foo', 'bar')\"\n <mask>     ).name == \"create_app2_foo_bar\"\n <mask>     assert locate_app(\n <mask>         script_info, \"cliapp.factory:create_app2('foo', 'bar', )\"\n <mask>     ).name == \"create_app2_foo_bar\"\n <mask>     assert locate_app(\n <mask>         script_info, \"cliapp.factory:create_app3('baz', 'qux')\"\n <mask>     ).name == \"create_app3_baz_qux\"\n <mask>     assert locate_app(script_info, \"cliapp.multiapp:app1\").name == \"app1\"\n <mask>     pytest.raises(\n <mask>         NoAppException, locate_app, script_info, \"notanpp.py\")\n <mask>     pytest.raises(\n <mask>         NoAppException, locate_app, script_info, \"cliapp/app\")\n <mask>     pytest.raises(\n <mask>         RuntimeError, locate_app, script_info, \"cliapp.app:notanapp\")\n <mask>     pytest.raises(\n <mask>         NoAppException, locate_app,\n <mask>         script_info, \"cliapp.factory:create_app2('foo')\")\n <mask>     pytest.raises(\n <mask>         NoAppException, locate_app,\n <mask>         script_info, \"cliapp.factory:create_app ()\")\n <mask>     pytest.raises(\n <mask>         NoAppException, locate_app, script_info, \"cliapp.importerrorapp\")\n <mask>     assert locate_app(\n <mask>         script_info, \"notanpp.py\", raise_if_not_found=False\n <mask>     ) is None\n <mask> \n <mask> \n <mask> def test_find_default_import_path(test_apps, monkeypatch, tmpdir):\n <mask>     \"\"\"Test of find_default_import_path.\"\"\"\n <mask>     monkeypatch.delitem(os.environ, 'FLASK_APP', raising=False)\n <mask>     assert find_default_import_path() == None\n <mask>     monkeypatch.setitem(os.environ, 'FLASK_APP', 'notanapp')\n <mask>     assert find_default_import_path() == 'notanapp'\n <mask>     tmpfile = tmpdir.join('testapp.py')\n <mask>     tmpfile.write('')\n <mask>     monkeypatch.setitem(os.environ, 'FLASK_APP', str(tmpfile))\n <mask>     expect_rv = prepare_exec_for_file(str(tmpfile))\n <mask>     assert find_default_import_path() == expect_rv\n <mask> \n <mask> \n <mask> def test_get_version(test_apps, capsys):\n <mask>     \"\"\"Test of get_version.\"\"\"\n </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove     realpath = os.path.realpath('/tmp/share/test.py')\n    dirname = os.path.dirname(realpath)\n    assert prepare_exec_for_file('/tmp/share/test.py') == 'test'\n    assert dirname in sys.path\n\n    realpath = os.path.realpath('/tmp/share/__init__.py')\n    dirname = os.path.dirname(os.path.dirname(realpath))\n    assert prepare_exec_for_file('/tmp/share/__init__.py') == 'share'\n    assert dirname in sys.path\n </s> add     original_path = sys.path[:]\n\n    def reset_path():\n        sys.path[:] = original_path\n\n    request.addfinalizer(reset_path)\n\n    assert prepare_import(value) == result\n    assert sys.path[0] == path\n\n\n@pytest.mark.parametrize('iname,aname,result', (\n    ('cliapp.app', None, 'testapp'),\n    ('cliapp.app', 'testapp', 'testapp'),\n    ('cliapp.factory', None, 'app'),\n    ('cliapp.factory', 'create_app', 'app'),\n    ('cliapp.factory', 'create_app()', 'app'),\n    # no script_info\n    ('cliapp.factory', 'create_app2(\"foo\", \"bar\")', 'app2_foo_bar'),\n    # trailing comma space\n    ('cliapp.factory', 'create_app2(\"foo\", \"bar\", )', 'app2_foo_bar'),\n    # takes script_info\n    ('cliapp.factory', 'create_app3(\"foo\")', 'app3_foo_spam'),\n))\ndef test_locate_app(test_apps, iname, aname, result):\n    info = ScriptInfo()\n    info.data['test'] = 'spam'\n    assert locate_app(info, iname, aname).name == result\n\n\n@pytest.mark.parametrize('iname,aname', (\n    ('notanapp.py', None),\n    ('cliapp/app', None),\n    ('cliapp.app', 'notanapp'),\n    # not enough arguments\n    ('cliapp.factory', 'create_app2(\"foo\")'),\n    # nested import error\n    ('cliapp.importerrorapp', None),\n    # not a Python file\n    ('cliapp.message.txt', None),\n    # space before arg list\n    ('cliapp.factory', 'create_app ()'),\n))\ndef test_locate_app_raises(test_apps, iname, aname):\n    info = ScriptInfo() </s> remove def test_prepare_exec_for_file(test_apps):\n    \"\"\"Expect the correct path to be set and the correct module name to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect, where\n    the parent directory of given file is added to `sys.path`.\n </s> add cwd = os.getcwd()\ntest_path = os.path.abspath(os.path.join(\n    os.path.dirname(__file__), 'test_apps'\n))\n\n\n@pytest.mark.parametrize('value,path,result', (\n    ('test', cwd, 'test'),\n    ('test.py', cwd, 'test'),\n    ('a/test', os.path.join(cwd, 'a'), 'test'),\n    ('test/__init__.py', cwd, 'test'),\n    ('test/__init__', cwd, 'test'),\n    # nested package\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', '__init__'),\n        test_path, 'cliapp.inner1'\n    ),\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', 'inner2'),\n        test_path, 'cliapp.inner1.inner2'\n    ),\n    # dotted name\n    ('test.a.b', cwd, 'test.a.b'),\n    (os.path.join(test_path, 'cliapp.app'), test_path, 'cliapp.app'),\n    # not a Python file, will be caught during import\n    (\n        os.path.join(test_path, 'cliapp', 'message.txt'),\n        test_path, 'cliapp.message.txt'\n    ),\n))\ndef test_prepare_import(request, value, path, result):\n    \"\"\"Expect the correct path to be set and the correct import and app names\n    to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect where the parent directory\n    of the given import is added to :data:`sys.path`. This is reset after the\n    test runs. </s> remove         return find_app_by_string(app_obj, script_info, mod)\n\n\ndef find_default_import_path():\n    app = os.environ.get('FLASK_APP')\n    if app is None:\n        return\n    if os.path.isfile(app):\n        return prepare_exec_for_file(app)\n    return app\n </s> add         return find_app_by_string(app_name, script_info, module) </s> remove     mod = sys.modules[module]\n </s> add     module = sys.modules[module_name] </s> remove from flask.cli import cli, AppGroup, FlaskGroup, NoAppException, ScriptInfo, \\\n    find_best_app, locate_app, with_appcontext, prepare_exec_for_file, \\\n    find_default_import_path, get_version\n </s> add from flask import Flask, current_app\nfrom flask.cli import AppGroup, FlaskGroup, NoAppException, ScriptInfo, \\\n    find_best_app, get_version, locate_app, prepare_import, with_appcontext", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.assert_('ConfigTestCase' not in app.config)\n <mask> \n <mask>     def test_config_from_file(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.config.from_pyfile(__file__.rsplit('.')[0] + '.py')\n <mask>         self.common_object_test(app)\n <mask> \n <mask>     def test_config_from_object(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.config.from_object(__name__)\n </s> Fixed a bug in the testsuite that caused problems when dots where in directory names </s> remove                 self.assert_(os.path.basename(__file__.rsplit('.')[0] + '.py') in out)\n </s> add                 self.assert_(os.path.basename(__file__.rsplit('.', 1)[0] + '.py') in out) </s> remove             os.environ = {'FOO_SETTINGS': __file__.rsplit('.')[0] + '.py'}\n </s> add             os.environ = {'FOO_SETTINGS': __file__.rsplit('.', 1)[0] + '.py'}", "html_url": "https://github.com/pallets/flask/commit/fbd6776e68a12aa7bf7d646ca03d568cedc616f3", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             else:\n <mask>                 self.assert_(0, 'expected exception')\n <mask>             self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True))\n <mask> \n <mask>             os.environ = {'FOO_SETTINGS': __file__.rsplit('.')[0] + '.py'}\n <mask>             self.assert_(app.config.from_envvar('FOO_SETTINGS'))\n <mask>             self.common_object_test(app)\n <mask>         finally:\n <mask>             os.environ = env\n <mask> \n </s> Fixed a bug in the testsuite that caused problems when dots where in directory names </s> remove         app.config.from_pyfile(__file__.rsplit('.')[0] + '.py')\n </s> add         app.config.from_pyfile(__file__.rsplit('.', 1)[0] + '.py') </s> remove                 self.assert_(os.path.basename(__file__.rsplit('.')[0] + '.py') in out)\n </s> add                 self.assert_(os.path.basename(__file__.rsplit('.', 1)[0] + '.py') in out)", "html_url": "https://github.com/pallets/flask/commit/fbd6776e68a12aa7bf7d646ca03d568cedc616f3", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             with catch_stderr() as err:\n <mask>                 c.get('/')\n <mask>                 out = err.getvalue()\n <mask>                 self.assert_('WARNING in helpers [' in out)\n <mask>                 self.assert_(os.path.basename(__file__.rsplit('.')[0] + '.py') in out)\n <mask>                 self.assert_('the standard library is dead' in out)\n <mask>                 self.assert_('this is a debug statement' in out)\n <mask> \n <mask>             with catch_stderr() as err:\n <mask>                 try:\n </s> Fixed a bug in the testsuite that caused problems when dots where in directory names </s> remove         app.config.from_pyfile(__file__.rsplit('.')[0] + '.py')\n </s> add         app.config.from_pyfile(__file__.rsplit('.', 1)[0] + '.py') </s> remove             os.environ = {'FOO_SETTINGS': __file__.rsplit('.')[0] + '.py'}\n </s> add             os.environ = {'FOO_SETTINGS': __file__.rsplit('.', 1)[0] + '.py'}", "html_url": "https://github.com/pallets/flask/commit/fbd6776e68a12aa7bf7d646ca03d568cedc616f3", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.assert_equal(rv.status_code, 405)\n <mask>         self.assert_equal(sorted(rv.allow), ['GET', 'HEAD', 'OPTIONS'])\n <mask>         rv = c.head('/')\n <mask>         self.assert_equal(rv.status_code, 200)\n <mask>         assert not rv.data  # head truncates\n <mask>         self.assert_equal(c.post('/more').data, 'POST')\n <mask>         self.assert_equal(c.get('/more').data, 'GET')\n <mask>         rv = c.delete('/more')\n <mask>         self.assert_equal(rv.status_code, 405)\n <mask>         self.assert_equal(sorted(rv.allow), ['GET', 'HEAD', 'OPTIONS', 'POST'])\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert not rv.data  # head truncates\n </s> add         self.assert_(not rv.data) # head truncates </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove             assert flask.url_for('static', filename='index.html') \\\n                == '/static/index.html'\n </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html') </s> remove         assert 'Internal Server Error' in rv.data\n </s> add         self.assert_('Internal Server Error' in rv.data) </s> remove         assert 'Internal Server Error' in rv.data\n </s> add         self.assert_('Internal Server Error' in rv.data)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.assert_equal(rv.status_code, 405)\n <mask>         self.assert_equal(sorted(rv.allow), ['GET', 'HEAD', 'OPTIONS'])\n <mask>         rv = c.head('/')\n <mask>         self.assert_equal(rv.status_code, 200)\n <mask>         assert not rv.data  # head truncates\n <mask>         self.assert_equal(c.post('/more').data, 'POST')\n <mask>         self.assert_equal(c.get('/more').data, 'GET')\n <mask>         rv = c.delete('/more')\n <mask>         self.assert_equal(rv.status_code, 405)\n <mask>         self.assert_equal(sorted(rv.allow), ['GET', 'HEAD', 'OPTIONS', 'POST'])\n </s> Changed assert to self.assert_ where it was still in place", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         def index():\n <mask>             flask.session['testing'] = 42\n <mask>             return 'Hello World'\n <mask>         rv = app.test_client().get('/', 'http://example.com/')\n <mask>         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n <mask>         assert 'httponly' in rv.headers['set-cookie'].lower()\n <mask> \n <mask>     def test_session_using_server_name_and_port(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.config.update(\n <mask>             SECRET_KEY='foo',\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove         assert 'path=/bar' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('path=/bar' in rv.headers['set-cookie'].lower()) </s> remove             assert isinstance(e, MyException)\n </s> add             self.assert_(isinstance(e, MyException)) </s> remove         assert 'after' not in evts\n </s> add         self.assert_('after' not in evts) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         def index():\n <mask>             flask.session['testing'] = 42\n <mask>             return 'Hello World'\n <mask>         rv = app.test_client().get('/', 'http://example.com:8080/')\n <mask>         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n <mask>         assert 'httponly' in rv.headers['set-cookie'].lower()\n <mask> \n <mask>     def test_session_using_application_root(self):\n <mask>         class PrefixPathMiddleware(object):\n <mask>             def __init__(self, app, prefix):\n <mask>                 self.app = app\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove         assert 'path=/bar' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('path=/bar' in rv.headers['set-cookie'].lower()) </s> remove             assert isinstance(e, MyException)\n </s> add             self.assert_(isinstance(e, MyException)) </s> remove         assert 'after' not in evts\n </s> add         self.assert_('after' not in evts) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def index():\n <mask>             flask.session['testing'] = 42\n <mask>             return 'Hello World'\n <mask>         rv = app.test_client().get('/', 'http://example.com:8080/')\n <mask>         assert 'path=/bar' in rv.headers['set-cookie'].lower()\n <mask> \n <mask>     def test_missing_session(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         def expect_exception(f, *args, **kwargs):\n <mask>             try:\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove                 assert e.args and 'session is unavailable' in e.args[0]\n </s> add                 self.assert_(e.args and 'session is unavailable' in e.args[0]) </s> remove             assert isinstance(e, MyException)\n </s> add             self.assert_(isinstance(e, MyException)) </s> remove         assert 'after' not in evts\n </s> add         self.assert_('after' not in evts) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep keep", "code_tokens": " <mask>             try:\n <mask>                 f(*args, **kwargs)\n <mask>             except RuntimeError, e:\n <mask>                 assert e.args and 'session is unavailable' in e.args[0]\n <mask>             else:\n <mask>                 assert False, 'expected exception'\n <mask>         with app.test_request_context():\n <mask>             assert flask.session.get('missing_key') is None\n <mask>             expect_exception(flask.session.__setitem__, 'foo', 42)\n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert flask.session.get('missing_key') is None\n </s> add             self.assert_(flask.session.get('missing_key') is None) </s> remove                 assert \"'FOO_SETTINGS' is not set\" in str(e)\n </s> add                 self.assert_(\"'FOO_SETTINGS' is not set\" in str(e)) </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True)\n </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True)) </s> remove         assert flask._request_ctx_stack.top is None\n </s> add         self.assert_(flask._request_ctx_stack.top is None) </s> remove         assert not flask.request\n        assert not flask.has_request_context()\n </s> add         self.assert_(not flask.request)\n        self.assert_(not flask.has_request_context())", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 assert e.args and 'session is unavailable' in e.args[0]\n <mask>             else:\n <mask>                 assert False, 'expected exception'\n <mask>         with app.test_request_context():\n <mask>             assert flask.session.get('missing_key') is None\n <mask>             expect_exception(flask.session.__setitem__, 'foo', 42)\n <mask>             expect_exception(flask.session.pop, 'foo')\n <mask> \n <mask>     def test_session_expiration(self):\n <mask>         permanent = True\n </s> Changed assert to self.assert_ where it was still in place </s> remove                 assert False, 'expected exception'\n </s> add                 self.assert_(False, 'expected exception') </s> remove                 assert e.args and 'session is unavailable' in e.args[0]\n </s> add                 self.assert_(e.args and 'session is unavailable' in e.args[0]) </s> remove         assert match is None\n </s> add         self.assert_(match is None) </s> remove         assert 'set-cookie' in rv.headers\n </s> add         self.assert_('set-cookie' in rv.headers) </s> remove         assert flask._request_ctx_stack.top is None\n </s> add         self.assert_(flask._request_ctx_stack.top is None) </s> remove         assert app.logger is not logger1\n </s> add         self.assert_(app.logger is not logger1)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return unicode(flask.session.permanent)\n <mask> \n <mask>         client = app.test_client()\n <mask>         rv = client.get('/')\n <mask>         assert 'set-cookie' in rv.headers\n <mask>         match = re.search(r'\\bexpires=([^;]+)', rv.headers['set-cookie'])\n <mask>         expires = parse_date(match.group())\n <mask>         expected = datetime.utcnow() + app.permanent_session_lifetime\n <mask>         self.assert_equal(expires.year, expected.year)\n <mask>         self.assert_equal(expires.month, expected.month)\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert match is None\n </s> add         self.assert_(match is None) </s> remove         assert 'set-cookie' in rv.headers\n </s> add         self.assert_('set-cookie' in rv.headers) </s> remove                 assert 'x-sendfile' in rv.headers\n </s> add                 self.assert_('x-sendfile' in rv.headers) </s> remove             assert rv.direct_passthrough\n            assert 'x-sendfile' in rv.headers\n </s> add             self.assert_(rv.direct_passthrough)\n            self.assert_('x-sendfile' in rv.headers) </s> remove                 assert 'x-sendfile' not in rv.headers\n </s> add                 self.assert_('x-sendfile' not in rv.headers) </s> remove             assert False\n </s> add             self.assert_(False)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask>         permanent = False\n <mask>         rv = app.test_client().get('/')\n <mask>         assert 'set-cookie' in rv.headers\n <mask>         match = re.search(r'\\bexpires=([^;]+)', rv.headers['set-cookie'])\n <mask>         assert match is None\n <mask> \n <mask>     def test_flashes(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.secret_key = 'testkey'\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert 'set-cookie' in rv.headers\n </s> add         self.assert_('set-cookie' in rv.headers) </s> remove             assert flask.session.modified\n </s> add             self.assert_(flask.session.modified) </s> remove             assert not flask.session.modified\n </s> add             self.assert_(not flask.session.modified) </s> remove             assert flask.session.get('missing_key') is None\n </s> add             self.assert_(flask.session.get('missing_key') is None) </s> remove         assert not flask.request\n        assert not flask.has_request_context()\n </s> add         self.assert_(not flask.request)\n        self.assert_(not flask.has_request_context())", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         app.secret_key = 'testkey'\n <mask> \n <mask>         with app.test_request_context():\n <mask>             assert not flask.session.modified\n <mask>             flask.flash('Zap')\n <mask>             flask.session.modified = False\n <mask>             flask.flash('Zip')\n <mask>             assert flask.session.modified\n <mask>             self.assert_equal(list(flask.get_flashed_messages()), ['Zap', 'Zip'])\n <mask> \n <mask>     def test_extended_flashing(self):\n <mask>         app = flask.Flask(__name__)\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert match is None\n </s> add         self.assert_(match is None) </s> remove             assert False\n </s> add             self.assert_(False) </s> remove             assert False\n </s> add             self.assert_(False) </s> remove         assert 'set-cookie' in rv.headers\n </s> add         self.assert_('set-cookie' in rv.headers) </s> remove                 assert 'x-sendfile' not in rv.headers\n </s> add                 self.assert_('x-sendfile' not in rv.headers)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep replace replace keep replace keep", "code_tokens": " <mask>         def index():\n <mask>             assert 'before' in evts\n <mask>             assert 'after' not in evts\n <mask>             return 'request'\n <mask>         assert 'after' not in evts\n <mask>         rv = app.test_client().get('/').data\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert 'after' in evts\n </s> add         self.assert_('after' in evts) </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove         assert 'path=/bar' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('path=/bar' in rv.headers['set-cookie'].lower()) </s> remove             assert isinstance(e, MyException)\n </s> add             self.assert_(isinstance(e, MyException))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             assert 'after' not in evts\n <mask>             return 'request'\n <mask>         assert 'after' not in evts\n <mask>         rv = app.test_client().get('/').data\n <mask>         assert 'after' in evts\n <mask>         self.assert_equal(rv, 'request|after')\n <mask> \n <mask>     def test_teardown_request_handler(self):\n <mask>         called = []\n <mask>         app = flask.Flask(__name__)\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert 'after' not in evts\n </s> add         self.assert_('after' not in evts) </s> remove             assert 'before' in evts\n            assert 'after' not in evts\n </s> add             self.assert_('before' in evts)\n            self.assert_('after' not in evts) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Internal Server Error' in rv.data\n </s> add         self.assert_('Internal Server Error' in rv.data) </s> remove         assert not flask.request\n        assert not flask.has_request_context()\n </s> add         self.assert_(not flask.request)\n        self.assert_(not flask.has_request_context())", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def root():\n <mask>             return \"Response\"\n <mask>         rv = app.test_client().get('/')\n <mask>         self.assert_equal(rv.status_code, 200)\n <mask>         assert 'Response' in rv.data\n <mask>         self.assert_equal(len(called), 1)\n <mask> \n <mask>     def test_teardown_request_handler_debug_mode(self):\n <mask>         called = []\n <mask>         app = flask.Flask(__name__)\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Internal Server Error' in rv.data\n </s> add         self.assert_('Internal Server Error' in rv.data) </s> remove         assert 'after' in evts\n </s> add         self.assert_('after' in evts) </s> remove             assert flask.url_for('static', filename='index.html') \\\n                == '/static/index.html'\n </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html') </s> remove         assert not rv.data  # head truncates\n </s> add         self.assert_(not rv.data) # head truncates </s> remove         assert not rv.data  # head truncates\n </s> add         self.assert_(not rv.data) # head truncates", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def root():\n <mask>             return \"Response\"\n <mask>         rv = app.test_client().get('/')\n <mask>         self.assert_equal(rv.status_code, 200)\n <mask>         assert 'Response' in rv.data\n <mask>         self.assert_equal(len(called), 1)\n <mask> \n <mask>     def test_teardown_request_handler_error(self):\n <mask>         called = []\n <mask>         app = flask.Flask(__name__)\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Internal Server Error' in rv.data\n </s> add         self.assert_('Internal Server Error' in rv.data) </s> remove         assert 'after' in evts\n </s> add         self.assert_('after' in evts) </s> remove             assert flask.url_for('static', filename='index.html') \\\n                == '/static/index.html'\n </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html') </s> remove         assert not rv.data  # head truncates\n </s> add         self.assert_(not rv.data) # head truncates </s> remove         assert not rv.data  # head truncates\n </s> add         self.assert_(not rv.data) # head truncates", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def fails():\n <mask>             1/0\n <mask>         rv = app.test_client().get('/')\n <mask>         self.assert_equal(rv.status_code, 500)\n <mask>         assert 'Internal Server Error' in rv.data\n <mask>         self.assert_equal(len(called), 2)\n <mask> \n <mask>     def test_before_after_request_order(self):\n <mask>         called = []\n <mask>         app = flask.Flask(__name__)\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert 'Internal Server Error' in rv.data\n </s> add         self.assert_('Internal Server Error' in rv.data) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove             assert not hasattr(flask.g, 'value')\n            assert 'Internal Server Error' in resp.data\n </s> add             self.assert_(not hasattr(flask.g, 'value'))\n            self.assert_('Internal Server Error' in resp.data) </s> remove         assert 'Exception on / [GET]' in err\n        assert 'Traceback (most recent call last):' in err\n        assert '1/0' in err\n        assert 'ZeroDivisionError:' in err\n </s> add         self.assert_('Exception on / [GET]' in err)\n        self.assert_('Traceback (most recent call last):' in err)\n        self.assert_('1/0' in err)\n        self.assert_('ZeroDivisionError:' in err) </s> remove         assert 'after' in evts\n </s> add         self.assert_('after' in evts)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         app = flask.Flask(__name__)\n <mask>         @app.errorhandler(MyException)\n <mask>         def handle_my_exception(e):\n <mask>             assert isinstance(e, MyException)\n <mask>             return '42'\n <mask>         @app.route('/')\n <mask>         def index():\n <mask>             raise MyException()\n <mask> \n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert False\n </s> add             self.assert_(False) </s> remove             assert 'before' in evts\n            assert 'after' not in evts\n </s> add             self.assert_('before' in evts)\n            self.assert_('after' not in evts) </s> remove         assert 'path=/bar' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('path=/bar' in rv.headers['set-cookie'].lower()) </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove             assert flask.url_for('static', filename='index.html') \\\n                == '/static/index.html'\n </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         c = app.test_client()\n <mask>         try:\n <mask>             c.get('/fail')\n <mask>         except KeyError, e:\n <mask>             assert isinstance(e, BadRequest)\n <mask>         else:\n <mask>             self.fail('Expected exception')\n <mask> \n <mask>     def test_trapping_of_all_http_exceptions(self):\n <mask>         app = flask.Flask(__name__)\n </s> Changed assert to self.assert_ where it was still in place </s> remove                 assert 'no file contents were transmitted' in str(e)\n                assert 'This was submitted: \"index.txt\"' in str(e)\n </s> add                 self.assert_('no file contents were transmitted' in str(e))\n                self.assert_('This was submitted: \"index.txt\"' in str(e)) </s> remove             assert False\n </s> add             self.assert_(False) </s> remove             assert 'init_jinja_globals' in str(log[0]['message'])\n </s> add             self.assert_('init_jinja_globals' in str(log[0]['message'])) </s> remove             assert isinstance(e, MyException)\n </s> add             self.assert_(isinstance(e, MyException)) </s> remove                     assert False, 'debug log ate the exception'\n </s> add                     self.assert_(False, 'debug log ate the exception') </s> remove                     assert 0, 'expected exception'\n </s> add                     self.assert_(0, 'expected exception')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         with app.test_client() as c:\n <mask>             try:\n <mask>                 c.post('/fail', data={'foo': 'index.txt'})\n <mask>             except DebugFilesKeyError, e:\n <mask>                 assert 'no file contents were transmitted' in str(e)\n <mask>                 assert 'This was submitted: \"index.txt\"' in str(e)\n <mask>             else:\n <mask>                 self.fail('Expected exception')\n <mask> \n <mask>     def test_teardown_on_pop(self):\n <mask>         buffer = []\n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert isinstance(e, BadRequest)\n </s> add             self.assert_(isinstance(e, BadRequest)) </s> remove             assert msg.startswith('[Errno 2] Unable to load configuration '\n                                  'file (No such file or directory):')\n            assert msg.endswith(\"missing.cfg'\")\n </s> add             self.assert_(msg.startswith('[Errno 2] Unable to load configuration '\n                                        'file (No such file or directory):'))\n            self.assert_(msg.endswith(\"missing.cfg'\")) </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True)\n </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True)) </s> remove                 assert \"'FOO_SETTINGS' is not set\" in str(e)\n </s> add                 self.assert_(\"'FOO_SETTINGS' is not set\" in str(e)) </s> remove                 assert 'WARNING in helpers [' in out\n                assert os.path.basename(__file__.rsplit('.')[0] + '.py') in out\n                assert 'the standard library is dead' in out\n                assert 'this is a debug statement' in out\n </s> add                 self.assert_('WARNING in helpers [' in out)\n                self.assert_(os.path.basename(__file__.rsplit('.')[0] + '.py') in out)\n                self.assert_('the standard library is dead' in out)\n                self.assert_('this is a debug statement' in out) </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt'\n </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         def hello():\n <mask>             pass\n <mask>         with app.test_request_context():\n <mask>             self.assert_equal(flask.url_for('hello', name='test x'), '/hello/test%20x')\n <mask>             assert flask.url_for('hello', name='test x', _external=True) \\\n <mask>                 == 'http://localhost/hello/test%20x'\n <mask> \n <mask>     def test_custom_converters(self):\n <mask>         from werkzeug.routing import BaseConverter\n <mask>         class ListConverter(BaseConverter):\n <mask>             def to_python(self, value):\n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert flask.render_template_string('{{ foo }}',\n                foo='<test>') == '<test>'\n            assert flask.render_template('mail.txt', foo='<test>') \\\n                == '<test> Mail'\n </s> add             self.assert_equal(flask.render_template_string('{{ foo }}',\n                              foo='<test>'), '<test>')\n            self.assert_equal(flask.render_template('mail.txt', foo='<test>'),\n                              '<test> Mail') </s> remove             assert flask.url_for('static', filename='index.html') \\\n                == '/static/index.html'\n </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html') </s> remove             assert 0, 'expected runtime error'\n </s> add             self.assert_(0, 'expected runtime error') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt'\n </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt'\n </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert isinstance(e, ValueError)\n </s> add             self.assert_(isinstance(e, ValueError))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         rv = app.test_client().get('/static/index.html')\n <mask>         self.assert_equal(rv.status_code, 200)\n <mask>         self.assert_equal(rv.data.strip(), '<h1>Hello World!</h1>')\n <mask>         with app.test_request_context():\n <mask>             assert flask.url_for('static', filename='index.html') \\\n <mask>                 == '/static/index.html'\n <mask> \n <mask>     def test_none_response(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         @app.route('/')\n <mask>         def test():\n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt'\n </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt'\n </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.render_template_string('{{ foo }}',\n                foo='<test>') == '<test>'\n            assert flask.render_template('mail.txt', foo='<test>') \\\n                == '<test> Mail'\n </s> add             self.assert_equal(flask.render_template_string('{{ foo }}',\n                              foo='<test>'), '<test>')\n            self.assert_equal(flask.render_template('mail.txt', foo='<test>'),\n                              '<test> Mail') </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove             assert flask.url_for('hello', name='test x', _external=True) \\\n                == 'http://localhost/hello/test%20x'\n </s> add             self.assert_equal(flask.url_for('hello', name='test x', _external=True),\n                              'http://localhost/hello/test%20x')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         except ValueError, e:\n <mask>             self.assert_equal(str(e), 'View function did not return a response')\n <mask>             pass\n <mask>         else:\n <mask>             assert \"Expected ValueError\"\n <mask> \n <mask>     def test_request_locals(self):\n <mask>         self.assert_equal(repr(flask.g), '<LocalProxy unbound>')\n <mask>         self.assertFalse(flask.g)\n <mask> \n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert isinstance(e, ValueError)\n </s> add             self.assert_(isinstance(e, ValueError)) </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove             assert 0, 'expected runtime error'\n </s> add             self.assert_(0, 'expected runtime error') </s> remove                     assert 0, 'expected exception'\n </s> add                     self.assert_(0, 'expected exception') </s> remove             assert isinstance(e, BadRequest)\n </s> add             self.assert_(isinstance(e, BadRequest))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         try:\n <mask>             with app.test_request_context('/', environ_overrides={'HTTP_HOST': 'localhost'}):\n <mask>                 pass\n <mask>         except Exception, e:\n <mask>             assert isinstance(e, ValueError)\n <mask>             self.assert_equal(str(e), \"the server name provided \" +\n <mask>                     \"('localhost.localdomain:5000') does not match the \" + \\\n <mask>                     \"server name from the WSGI environment ('localhost')\")\n <mask> \n <mask>         try:\n </s> Changed assert to self.assert_ where it was still in place </s> remove                     assert False, 'debug log ate the exception'\n </s> add                     self.assert_(False, 'debug log ate the exception') </s> remove             assert \"Expected ValueError\"\n </s> add             self.assert_(\"Expected ValueError\") </s> remove             assert isinstance(e, BadRequest)\n </s> add             self.assert_(isinstance(e, BadRequest)) </s> remove                 assert \"'FOO_SETTINGS' is not set\" in str(e)\n </s> add                 self.assert_(\"'FOO_SETTINGS' is not set\" in str(e)) </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt'\n </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt'\n </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app.config['MAX_CONTENT_LENGTH'] = 64\n <mask>         @app.before_request\n <mask>         def always_first():\n <mask>             flask.request.form['myfile']\n <mask>             assert False\n <mask>         @app.route('/accept', methods=['POST'])\n <mask>         def accept_file():\n <mask>             flask.request.form['myfile']\n <mask>             assert False\n <mask>         @app.errorhandler(413)\n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert False\n </s> add             self.assert_(False) </s> remove             assert flask.session.modified\n </s> add             self.assert_(flask.session.modified) </s> remove         assert 'set-cookie' in rv.headers\n </s> add         self.assert_('set-cookie' in rv.headers) </s> remove         assert match is None\n </s> add         self.assert_(match is None) </s> remove             assert not flask.session.modified\n </s> add             self.assert_(not flask.session.modified) </s> remove         assert 'Exception on / [GET]' in err\n        assert 'Traceback (most recent call last):' in err\n        assert '1/0' in err\n        assert 'ZeroDivisionError:' in err\n </s> add         self.assert_('Exception on / [GET]' in err)\n        self.assert_('Traceback (most recent call last):' in err)\n        self.assert_('1/0' in err)\n        self.assert_('ZeroDivisionError:' in err)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             assert False\n <mask>         @app.route('/accept', methods=['POST'])\n <mask>         def accept_file():\n <mask>             flask.request.form['myfile']\n <mask>             assert False\n <mask>         @app.errorhandler(413)\n <mask>         def catcher(error):\n <mask>             return '42'\n <mask> \n <mask>         c = app.test_client()\n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert False\n </s> add             self.assert_(False) </s> remove             assert 'init_jinja_globals' in str(log[0]['message'])\n </s> add             self.assert_('init_jinja_globals' in str(log[0]['message'])) </s> remove             assert isinstance(e, MyException)\n </s> add             self.assert_(isinstance(e, MyException)) </s> remove             assert isinstance(e, BadRequest)\n </s> add             self.assert_(isinstance(e, BadRequest)) </s> remove             assert flask.session.modified\n </s> add             self.assert_(flask.session.modified) </s> remove         assert 'set-cookie' in rv.headers\n </s> add         self.assert_('set-cookie' in rv.headers)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep replace replace keep keep keep keep", "code_tokens": " <mask>         with app.test_request_context('/?name=World'):\n <mask>             self.assert_equal(index(), 'Hello World!')\n <mask>         with app.test_request_context('/meh'):\n <mask>             self.assert_equal(meh(), 'http://localhost/meh')\n <mask>         assert flask._request_ctx_stack.top is None\n <mask> \n <mask>     def test_context_test(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         assert not flask.request\n <mask>         assert not flask.has_request_context()\n <mask>         ctx = app.test_request_context()\n <mask>         ctx.push()\n <mask>         try:\n <mask>             assert flask.request\n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert flask.request\n            assert flask.has_request_context()\n </s> add             self.assert_(flask.request)\n            self.assert_(flask.has_request_context()) </s> remove             assert not hasattr(flask.g, 'value')\n            assert 'Internal Server Error' in resp.data\n </s> add             self.assert_(not hasattr(flask.g, 'value'))\n            self.assert_('Internal Server Error' in resp.data) </s> remove             assert flask.session.get('missing_key') is None\n </s> add             self.assert_(flask.session.get('missing_key') is None) </s> remove         assert match is None\n </s> add         self.assert_(match is None) </s> remove         assert app.logger is not logger1\n </s> add         self.assert_(app.logger is not logger1)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         assert not flask.has_request_context()\n <mask>         ctx = app.test_request_context()\n <mask>         ctx.push()\n <mask>         try:\n <mask>             assert flask.request\n <mask>             assert flask.has_request_context()\n <mask>         finally:\n <mask>             ctx.pop()\n <mask> \n <mask>     def test_manual_context_binding(self):\n <mask>         app = flask.Flask(__name__)\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert not flask.request\n        assert not flask.has_request_context()\n </s> add         self.assert_(not flask.request)\n        self.assert_(not flask.has_request_context()) </s> remove         assert flask._request_ctx_stack.top is None\n </s> add         self.assert_(flask._request_ctx_stack.top is None) </s> remove             assert app.config.from_envvar('FOO_SETTINGS')\n </s> add             self.assert_(app.config.from_envvar('FOO_SETTINGS')) </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True)\n </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True)) </s> remove                     assert 0, 'expected exception'\n </s> add                     self.assert_(0, 'expected exception') </s> remove             assert flask.session.modified\n </s> add             self.assert_(flask.session.modified)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             index()\n <mask>         except RuntimeError:\n <mask>             pass\n <mask>         else:\n <mask>             assert 0, 'expected runtime error'\n <mask> \n <mask> \n <mask> class SubdomainTestCase(FlaskTestCase):\n <mask> \n <mask>     def test_basic_support(self):\n </s> Changed assert to self.assert_ where it was still in place </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove                     assert 0, 'expected exception'\n </s> add                     self.assert_(0, 'expected exception') </s> remove             assert 0, 'expected config'\n        assert not app.config.from_pyfile('missing.cfg', silent=True)\n </s> add             self.assert_(0, 'expected config')\n        self.assert_(not app.config.from_pyfile('missing.cfg', silent=True)) </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         rv = c.get('/admin/static/css/test.css')\n <mask>         self.assert_equal(rv.data.strip(), '/* nested file */')\n <mask> \n <mask>         with app.test_request_context():\n <mask>             assert flask.url_for('admin.static', filename='test.txt') \\\n <mask>                 == '/admin/static/test.txt'\n <mask> \n <mask>         with app.test_request_context():\n <mask>             try:\n <mask>                 flask.render_template('missing.html')\n <mask>             except TemplateNotFound, e:\n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt'\n </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.url_for('static', filename='index.html') \\\n                == '/static/index.html'\n </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html') </s> remove             assert flask.render_template_string('{{ foo }}',\n                foo='<test>') == '<test>'\n            assert flask.render_template('mail.txt', foo='<test>') \\\n                == '<test> Mail'\n </s> add             self.assert_equal(flask.render_template_string('{{ foo }}',\n                              foo='<test>'), '<test>')\n            self.assert_equal(flask.render_template('mail.txt', foo='<test>'),\n                              '<test> Mail') </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove             assert flask.url_for('hello', name='test x', _external=True) \\\n                == 'http://localhost/hello/test%20x'\n </s> add             self.assert_equal(flask.url_for('hello', name='test x', _external=True),\n                              'http://localhost/hello/test%20x')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 flask.render_template('missing.html')\n <mask>             except TemplateNotFound, e:\n <mask>                 self.assert_equal(e.name, 'missing.html')\n <mask>             else:\n <mask>                 assert 0, 'expected exception'\n <mask> \n <mask>         with flask.Flask(__name__).test_request_context():\n <mask>             self.assert_equal(flask.render_template('nested/nested.txt'), 'I\\'m nested')\n <mask> \n <mask>     def test_safe_access(self):\n </s> Changed assert to self.assert_ where it was still in place </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt'\n </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt'\n </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove                     assert 0, 'expected exception'\n </s> add                     self.assert_(0, 'expected exception') </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True)\n </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 f('/etc/passwd')\n <mask>             except NotFound:\n <mask>                 pass\n <mask>             else:\n <mask>                 assert 0, 'expected exception'\n <mask>             try:\n <mask>                 f('../__init__.py')\n <mask>             except NotFound:\n <mask>                 pass\n <mask>             else:\n </s> Changed assert to self.assert_ where it was still in place </s> remove                     assert 0, 'expected exception'\n </s> add                     self.assert_(0, 'expected exception') </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove             assert 0, 'expected runtime error'\n </s> add             self.assert_(0, 'expected runtime error') </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove                     assert False, 'debug log ate the exception'\n </s> add                     self.assert_(False, 'debug log ate the exception')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 f('../__init__.py')\n <mask>             except NotFound:\n <mask>                 pass\n <mask>             else:\n <mask>                 assert 0, 'expected exception'\n <mask> \n <mask>             # testcase for a security issue that may exist on windows systems\n <mask>             import os\n <mask>             import ntpath\n <mask>             old_path = os.path\n </s> Changed assert to self.assert_ where it was still in place </s> remove                     assert 0, 'expected exception'\n </s> add                     self.assert_(0, 'expected exception') </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove             assert 0, 'expected runtime error'\n </s> add             self.assert_(0, 'expected runtime error') </s> remove             assert flask.url_for('hello', name='test x', _external=True) \\\n                == 'http://localhost/hello/test%20x'\n </s> add             self.assert_equal(flask.url_for('hello', name='test x', _external=True),\n                              'http://localhost/hello/test%20x') </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     f('..\\\\__init__.py')\n <mask>                 except NotFound:\n <mask>                     pass\n <mask>                 else:\n <mask>                     assert 0, 'expected exception'\n <mask>             finally:\n <mask>                 os.path = old_path\n <mask> \n <mask>     @emits_module_deprecation_warning\n <mask>     def test_endpoint_decorator(self):\n </s> Changed assert to self.assert_ where it was still in place </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove             assert app.config.from_envvar('FOO_SETTINGS')\n </s> add             self.assert_(app.config.from_envvar('FOO_SETTINGS')) </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True)\n </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True)) </s> remove             assert 0, 'expected runtime error'\n </s> add             self.assert_(0, 'expected runtime error') </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         rv = c.get('/admin/static/css/test.css')\n <mask>         self.assert_equal(rv.data.strip(), '/* nested file */')\n <mask> \n <mask>         with app.test_request_context():\n <mask>             assert flask.url_for('admin.static', filename='test.txt') \\\n <mask>                 == '/admin/static/test.txt'\n <mask> \n <mask>         with app.test_request_context():\n <mask>             try:\n <mask>                 flask.render_template('missing.html')\n <mask>             except TemplateNotFound, e:\n </s> Changed assert to self.assert_ where it was still in place", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 flask.render_template('missing.html')\n <mask>             except TemplateNotFound, e:\n <mask>                 self.assert_equal(e.name, 'missing.html')\n <mask>             else:\n <mask>                 assert 0, 'expected exception'\n <mask> \n <mask>         with flask.Flask(__name__).test_request_context():\n <mask>             self.assert_equal(flask.render_template('nested/nested.txt'), 'I\\'m nested')\n <mask> \n <mask>     def test_templates_list(self):\n </s> Changed assert to self.assert_ where it was still in place </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt'\n </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt'\n </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove                     assert 0, 'expected exception'\n </s> add                     self.assert_(0, 'expected exception') </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception') </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True)\n </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def common_object_test(self, app):\n <mask>         self.assert_equal(app.secret_key, 'devkey')\n <mask>         self.assert_equal(app.config['TEST_KEY'], 'foo')\n <mask>         assert 'ConfigTestCase' not in app.config\n <mask> \n <mask>     def test_config_from_file(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.config.from_pyfile(__file__.rsplit('.')[0] + '.py')\n <mask>         self.common_object_test(app)\n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert app.config.from_envvar('FOO_SETTINGS')\n </s> add             self.assert_(app.config.from_envvar('FOO_SETTINGS')) </s> remove         assert app.logger is logger1\n </s> add         self.assert_(app.logger is logger1) </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True)\n </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True)) </s> remove         assert app.logger is not logger1\n </s> add         self.assert_(app.logger is not logger1) </s> remove             assert flask.session.get('missing_key') is None\n </s> add             self.assert_(flask.session.get('missing_key') is None) </s> remove                 assert 'WARNING in helpers [' in out\n                assert os.path.basename(__file__.rsplit('.')[0] + '.py') in out\n                assert 'the standard library is dead' in out\n                assert 'this is a debug statement' in out\n </s> add                 self.assert_('WARNING in helpers [' in out)\n                self.assert_(os.path.basename(__file__.rsplit('.')[0] + '.py') in out)\n                self.assert_('the standard library is dead' in out)\n                self.assert_('this is a debug statement' in out)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep replace keep replace replace", "code_tokens": " <mask>                 app.config.from_envvar('FOO_SETTINGS')\n <mask>             except RuntimeError, e:\n <mask>                 assert \"'FOO_SETTINGS' is not set\" in str(e)\n <mask>             else:\n <mask>                 assert 0, 'expected exception'\n <mask>             assert not app.config.from_envvar('FOO_SETTINGS', silent=True)\n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert app.config.from_envvar('FOO_SETTINGS')\n </s> add             self.assert_(app.config.from_envvar('FOO_SETTINGS')) </s> remove                 assert False, 'expected exception'\n </s> add                 self.assert_(False, 'expected exception') </s> remove             assert msg.startswith('[Errno 2] Unable to load configuration '\n                                  'file (No such file or directory):')\n            assert msg.endswith(\"missing.cfg'\")\n </s> add             self.assert_(msg.startswith('[Errno 2] Unable to load configuration '\n                                        'file (No such file or directory):'))\n            self.assert_(msg.endswith(\"missing.cfg'\")) </s> remove                 assert e.args and 'session is unavailable' in e.args[0]\n </s> add                 self.assert_(e.args and 'session is unavailable' in e.args[0]) </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 assert 0, 'expected exception'\n <mask>             assert not app.config.from_envvar('FOO_SETTINGS', silent=True)\n <mask> \n <mask>             os.environ = {'FOO_SETTINGS': __file__.rsplit('.')[0] + '.py'}\n <mask>             assert app.config.from_envvar('FOO_SETTINGS')\n <mask>             self.common_object_test(app)\n <mask>         finally:\n <mask>             os.environ = env\n <mask> \n <mask>     def test_config_missing(self):\n </s> Changed assert to self.assert_ where it was still in place </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True)\n </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True)) </s> remove                 assert \"'FOO_SETTINGS' is not set\" in str(e)\n </s> add                 self.assert_(\"'FOO_SETTINGS' is not set\" in str(e)) </s> remove                     assert 0, 'expected exception'\n </s> add                     self.assert_(0, 'expected exception') </s> remove             assert flask.request\n            assert flask.has_request_context()\n </s> add             self.assert_(flask.request)\n            self.assert_(flask.has_request_context()) </s> remove         assert 'ConfigTestCase' not in app.config\n </s> add         self.assert_('ConfigTestCase' not in app.config) </s> remove             assert 0, 'expected config'\n        assert not app.config.from_pyfile('missing.cfg', silent=True)\n </s> add             self.assert_(0, 'expected config')\n        self.assert_(not app.config.from_pyfile('missing.cfg', silent=True))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep replace replace replace keep replace replace keep keep", "code_tokens": " <mask>         except IOError, e:\n <mask>             msg = str(e)\n <mask>             assert msg.startswith('[Errno 2] Unable to load configuration '\n <mask>                                   'file (No such file or directory):')\n <mask>             assert msg.endswith(\"missing.cfg'\")\n <mask>         else:\n <mask>             assert 0, 'expected config'\n <mask>         assert not app.config.from_pyfile('missing.cfg', silent=True)\n <mask> \n <mask> \n </s> Changed assert to self.assert_ where it was still in place </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True)\n </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True)) </s> remove                 assert \"'FOO_SETTINGS' is not set\" in str(e)\n </s> add                 self.assert_(\"'FOO_SETTINGS' is not set\" in str(e)) </s> remove             assert app.config.from_envvar('FOO_SETTINGS')\n </s> add             self.assert_(app.config.from_envvar('FOO_SETTINGS')) </s> remove                 assert 'no file contents were transmitted' in str(e)\n                assert 'This was submitted: \"index.txt\"' in str(e)\n </s> add                 self.assert_('no file contents were transmitted' in str(e))\n                self.assert_('This was submitted: \"index.txt\"' in str(e)) </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>             c = app.test_client()\n <mask>             self.assert_equal(c.get('/').data, '42')\n <mask>             self.assert_equal(len(log), 1)\n <mask>             assert 'init_jinja_globals' in str(log[0]['message'])\n <mask> \n <mask> \n <mask> def suite():\n <mask>     suite = unittest.TestSuite()\n <mask>     suite.addTest(unittest.makeSuite(DeprecationsTestCase))\n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert False\n </s> add             self.assert_(False) </s> remove             assert isinstance(e, BadRequest)\n </s> add             self.assert_(isinstance(e, BadRequest)) </s> remove             assert isinstance(recorded[0], ZeroDivisionError)\n </s> add             self.assert_(isinstance(recorded[0], ZeroDivisionError)) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove                 assert 'x-sendfile' not in rv.headers\n </s> add                 self.assert_('x-sendfile' not in rv.headers)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/deprecations.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def test_send_file_regular(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         with app.test_request_context():\n <mask>             rv = flask.send_file('static/index.html')\n <mask>             assert rv.direct_passthrough\n <mask>             self.assert_equal(rv.mimetype, 'text/html')\n <mask>             with app.open_resource('static/index.html') as f:\n <mask>                 self.assert_equal(rv.data, f.read())\n <mask> \n <mask>     def test_send_file_xsendfile(self):\n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert rv.direct_passthrough\n            assert 'x-sendfile' in rv.headers\n </s> add             self.assert_(rv.direct_passthrough)\n            self.assert_('x-sendfile' in rv.headers) </s> remove                 assert 'x-sendfile' in rv.headers\n </s> add                 self.assert_('x-sendfile' in rv.headers) </s> remove                 assert 'x-sendfile' not in rv.headers\n </s> add                 self.assert_('x-sendfile' not in rv.headers) </s> remove         assert 'set-cookie' in rv.headers\n </s> add         self.assert_('set-cookie' in rv.headers) </s> remove             assert flask.render_template_string('{{ foo }}',\n                foo='<test>') == '<test>'\n            assert flask.render_template('mail.txt', foo='<test>') \\\n                == '<test> Mail'\n </s> add             self.assert_equal(flask.render_template_string('{{ foo }}',\n                              foo='<test>'), '<test>')\n            self.assert_equal(flask.render_template('mail.txt', foo='<test>'),\n                              '<test> Mail') </s> remove             assert flask.url_for('static', filename='index.html') \\\n                == '/static/index.html'\n </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         app = flask.Flask(__name__)\n <mask>         app.use_x_sendfile = True\n <mask>         with app.test_request_context():\n <mask>             rv = flask.send_file('static/index.html')\n <mask>             assert rv.direct_passthrough\n <mask>             assert 'x-sendfile' in rv.headers\n <mask>             self.assert_equal(rv.headers['x-sendfile'],\n <mask>                 os.path.join(app.root_path, 'static/index.html'))\n <mask>             self.assert_equal(rv.mimetype, 'text/html')\n <mask> \n <mask>     def test_send_file_object(self):\n </s> Changed assert to self.assert_ where it was still in place </s> remove                 assert 'x-sendfile' in rv.headers\n </s> add                 self.assert_('x-sendfile' in rv.headers) </s> remove             assert rv.direct_passthrough\n </s> add             self.assert_(rv.direct_passthrough) </s> remove                 assert 'x-sendfile' not in rv.headers\n </s> add                 self.assert_('x-sendfile' not in rv.headers) </s> remove         assert match is None\n </s> add         self.assert_(match is None) </s> remove         assert 'set-cookie' in rv.headers\n </s> add         self.assert_('set-cookie' in rv.headers) </s> remove             assert flask.session.get('missing_key') is None\n </s> add             self.assert_(flask.session.get('missing_key') is None)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             with app.test_request_context():\n <mask>                 f = open(os.path.join(app.root_path, 'static/index.html'))\n <mask>                 rv = flask.send_file(f)\n <mask>                 self.assert_equal(rv.mimetype, 'text/html')\n <mask>                 assert 'x-sendfile' in rv.headers\n <mask>                 self.assert_equal(rv.headers['x-sendfile'],\n <mask>                     os.path.join(app.root_path, 'static/index.html'))\n <mask>             # mimetypes + etag\n <mask>             self.assert_equal(len(captured), 2)\n <mask> \n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert rv.direct_passthrough\n            assert 'x-sendfile' in rv.headers\n </s> add             self.assert_(rv.direct_passthrough)\n            self.assert_('x-sendfile' in rv.headers) </s> remove                 assert 'x-sendfile' not in rv.headers\n </s> add                 self.assert_('x-sendfile' not in rv.headers) </s> remove             assert rv.direct_passthrough\n </s> add             self.assert_(rv.direct_passthrough) </s> remove         assert 'set-cookie' in rv.headers\n </s> add         self.assert_('set-cookie' in rv.headers) </s> remove         assert 'Internal Server Error' in rv.data\n </s> add         self.assert_('Internal Server Error' in rv.data) </s> remove         assert match is None\n </s> add         self.assert_(match is None)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         with catch_warnings() as captured:\n <mask>             with app.test_request_context():\n <mask>                 f = StringIO('Test')\n <mask>                 rv = flask.send_file(f)\n <mask>                 assert 'x-sendfile' not in rv.headers\n <mask>             # etags\n <mask>             self.assert_equal(len(captured), 1)\n <mask> \n <mask>     def test_attachment(self):\n <mask>         app = flask.Flask(__name__)\n </s> Changed assert to self.assert_ where it was still in place </s> remove                 assert 'x-sendfile' in rv.headers\n </s> add                 self.assert_('x-sendfile' in rv.headers) </s> remove             assert rv.direct_passthrough\n            assert 'x-sendfile' in rv.headers\n </s> add             self.assert_(rv.direct_passthrough)\n            self.assert_('x-sendfile' in rv.headers) </s> remove             assert rv.direct_passthrough\n </s> add             self.assert_(rv.direct_passthrough) </s> remove         assert match is None\n </s> add         self.assert_(match is None) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace", "code_tokens": " <mask>     def test_logger_cache(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         logger1 = app.logger\n <mask>         assert app.logger is logger1\n <mask>         self.assert_equal(logger1.name, __name__)\n <mask>         app.logger_name = __name__ + '/test_logger_cache'\n <mask>         assert app.logger is not logger1\n </s> Changed assert to self.assert_ where it was still in place </s> remove                 assert \"'FOO_SETTINGS' is not set\" in str(e)\n </s> add                 self.assert_(\"'FOO_SETTINGS' is not set\" in str(e)) </s> remove         assert match is None\n </s> add         self.assert_(match is None) </s> remove         assert not flask.request\n        assert not flask.has_request_context()\n </s> add         self.assert_(not flask.request)\n        self.assert_(not flask.has_request_context()) </s> remove         assert flask._request_ctx_stack.top is None\n </s> add         self.assert_(flask._request_ctx_stack.top is None) </s> remove         assert 'set-cookie' in rv.headers\n </s> add         self.assert_('set-cookie' in rv.headers)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         with app.test_client() as c:\n <mask>             with catch_stderr() as err:\n <mask>                 c.get('/')\n <mask>                 out = err.getvalue()\n <mask>                 assert 'WARNING in helpers [' in out\n <mask>                 assert os.path.basename(__file__.rsplit('.')[0] + '.py') in out\n <mask>                 assert 'the standard library is dead' in out\n <mask>                 assert 'this is a debug statement' in out\n <mask> \n <mask>             with catch_stderr() as err:\n <mask>                 try:\n <mask>                     c.get('/exc')\n <mask>                 except ZeroDivisionError:\n </s> Changed assert to self.assert_ where it was still in place </s> remove                     assert False, 'debug log ate the exception'\n </s> add                     self.assert_(False, 'debug log ate the exception') </s> remove                 assert 'no file contents were transmitted' in str(e)\n                assert 'This was submitted: \"index.txt\"' in str(e)\n </s> add                 self.assert_('no file contents were transmitted' in str(e))\n                self.assert_('This was submitted: \"index.txt\"' in str(e)) </s> remove             assert rv.direct_passthrough\n </s> add             self.assert_(rv.direct_passthrough) </s> remove                 assert 'x-sendfile' not in rv.headers\n </s> add                 self.assert_('x-sendfile' not in rv.headers) </s> remove         assert flask._request_ctx_stack.top is None\n </s> add         self.assert_(flask._request_ctx_stack.top is None) </s> remove                 assert \"'FOO_SETTINGS' is not set\" in str(e)\n </s> add                 self.assert_(\"'FOO_SETTINGS' is not set\" in str(e))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     c.get('/exc')\n <mask>                 except ZeroDivisionError:\n <mask>                     pass\n <mask>                 else:\n <mask>                     assert False, 'debug log ate the exception'\n <mask> \n <mask>     def test_exception_logging(self):\n <mask>         out = StringIO()\n <mask>         app = flask.Flask(__name__)\n <mask>         app.logger_name = 'flask_tests/test_exception_logging'\n </s> Changed assert to self.assert_ where it was still in place </s> remove                 assert 'WARNING in helpers [' in out\n                assert os.path.basename(__file__.rsplit('.')[0] + '.py') in out\n                assert 'the standard library is dead' in out\n                assert 'this is a debug statement' in out\n </s> add                 self.assert_('WARNING in helpers [' in out)\n                self.assert_(os.path.basename(__file__.rsplit('.')[0] + '.py') in out)\n                self.assert_('the standard library is dead' in out)\n                self.assert_('this is a debug statement' in out) </s> remove                     assert 0, 'expected exception'\n </s> add                     self.assert_(0, 'expected exception') </s> remove         assert app.logger is logger1\n </s> add         self.assert_(app.logger is logger1) </s> remove         assert app.logger is not logger1\n </s> add         self.assert_(app.logger is not logger1) </s> remove             assert flask.session.get('missing_key') is None\n </s> add             self.assert_(flask.session.get('missing_key') is None) </s> remove                 assert 0, 'expected exception'\n </s> add                 self.assert_(0, 'expected exception')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace replace replace replace keep", "code_tokens": " <mask> \n <mask>         rv = app.test_client().get('/')\n <mask>         self.assert_equal(rv.status_code, 500)\n <mask>         assert 'Internal Server Error' in rv.data\n <mask> \n <mask>         err = out.getvalue()\n <mask>         assert 'Exception on / [GET]' in err\n <mask>         assert 'Traceback (most recent call last):' in err\n <mask>         assert '1/0' in err\n <mask>         assert 'ZeroDivisionError:' in err\n <mask> \n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert 'Internal Server Error' in rv.data\n </s> add         self.assert_('Internal Server Error' in rv.data) </s> remove             assert not hasattr(flask.g, 'value')\n            assert 'Internal Server Error' in resp.data\n </s> add             self.assert_(not hasattr(flask.g, 'value'))\n            self.assert_('Internal Server Error' in resp.data) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'set-cookie' in rv.headers\n </s> add         self.assert_('set-cookie' in rv.headers)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         flask.got_request_exception.connect(record, app)\n <mask>         try:\n <mask>             self.assert_equal(app.test_client().get('/').status_code, 500)\n <mask>             self.assert_equal(len(recorded), 1)\n <mask>             assert isinstance(recorded[0], ZeroDivisionError)\n <mask>         finally:\n <mask>             flask.got_request_exception.disconnect(record, app)\n <mask> \n <mask> \n <mask> def suite():\n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert 'init_jinja_globals' in str(log[0]['message'])\n </s> add             self.assert_('init_jinja_globals' in str(log[0]['message'])) </s> remove             assert flask.request\n            assert flask.has_request_context()\n </s> add             self.assert_(flask.request)\n            self.assert_(flask.has_request_context()) </s> remove             assert app.config.from_envvar('FOO_SETTINGS')\n </s> add             self.assert_(app.config.from_envvar('FOO_SETTINGS')) </s> remove                     assert 0, 'expected exception'\n </s> add                     self.assert_(0, 'expected exception') </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/signals.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_no_escaping(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         with app.test_request_context():\n <mask>             assert flask.render_template_string('{{ foo }}',\n <mask>                 foo='<test>') == '<test>'\n <mask>             assert flask.render_template('mail.txt', foo='<test>') \\\n <mask>                 == '<test> Mail'\n <mask> \n <mask>     def test_macros(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         with app.test_request_context():\n <mask>             macro = flask.get_template_attribute('_macro.html', 'hello')\n </s> Changed assert to self.assert_ where it was still in place </s> remove             assert flask.url_for('static', filename='index.html') \\\n                == '/static/index.html'\n </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt'\n </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt'\n </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.url_for('hello', name='test x', _external=True) \\\n                == 'http://localhost/hello/test%20x'\n </s> add             self.assert_equal(flask.url_for('hello', name='test x', _external=True),\n                              'http://localhost/hello/test%20x') </s> remove             assert rv.direct_passthrough\n </s> add             self.assert_(rv.direct_passthrough) </s> remove             assert rv.direct_passthrough\n            assert 'x-sendfile' in rv.headers\n </s> add             self.assert_(rv.direct_passthrough)\n            self.assert_('x-sendfile' in rv.headers)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app = flask.Flask(__name__)\n <mask>         @app.template_filter()\n <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         assert 'my_reverse' in  app.jinja_env.filters.keys()\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse']('abcd'), 'dcba')\n <mask> \n <mask>     def test_template_filter_with_name(self):\n <mask>         app = flask.Flask(__name__)\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert 'strrev' in  app.jinja_env.filters.keys()\n </s> add         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> remove         assert 'path=/bar' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('path=/bar' in rv.headers['set-cookie'].lower()) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove             assert isinstance(e, MyException)\n </s> add             self.assert_(isinstance(e, MyException))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app = flask.Flask(__name__)\n <mask>         @app.template_filter('strrev')\n <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         assert 'strrev' in  app.jinja_env.filters.keys()\n <mask>         self.assert_equal(app.jinja_env.filters['strrev'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['strrev']('abcd'), 'dcba')\n <mask> \n <mask>     def test_template_filter_with_template(self):\n <mask>         app = flask.Flask(__name__)\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert 'my_reverse' in  app.jinja_env.filters.keys()\n </s> add         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> remove         assert 'path=/bar' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('path=/bar' in rv.headers['set-cookie'].lower()) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data\n </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove             assert isinstance(e, MyException)\n </s> add             self.assert_(isinstance(e, MyException))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             self.assert_equal(resp.data, 'Hello World!')\n <mask>             self.assert_equal(resp.status_code, 200)\n <mask> \n <mask>             resp = c.get('/other')\n <mask>             assert not hasattr(flask.g, 'value')\n <mask>             assert 'Internal Server Error' in resp.data\n <mask>             self.assert_equal(resp.status_code, 500)\n <mask>             flask.g.value = 23\n <mask> \n <mask>         try:\n <mask>             flask.g.value\n </s> Changed assert to self.assert_ where it was still in place </s> remove         assert 'Internal Server Error' in rv.data\n </s> add         self.assert_('Internal Server Error' in rv.data) </s> remove         assert 'Internal Server Error' in rv.data\n </s> add         self.assert_('Internal Server Error' in rv.data) </s> remove         assert 'Exception on / [GET]' in err\n        assert 'Traceback (most recent call last):' in err\n        assert '1/0' in err\n        assert 'ZeroDivisionError:' in err\n </s> add         self.assert_('Exception on / [GET]' in err)\n        self.assert_('Traceback (most recent call last):' in err)\n        self.assert_('1/0' in err)\n        self.assert_('ZeroDivisionError:' in err) </s> remove         assert flask._request_ctx_stack.top is None\n </s> add         self.assert_(flask._request_ctx_stack.top is None) </s> remove         assert 'path=/bar' in rv.headers['set-cookie'].lower()\n </s> add         self.assert_('path=/bar' in rv.headers['set-cookie'].lower()) </s> remove         assert not flask.request\n        assert not flask.has_request_context()\n </s> add         self.assert_(not flask.request)\n        self.assert_(not flask.has_request_context())", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/testing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         for cls in self.default_tags:\n <mask>             self.register(cls)\n <mask> \n <mask>     def register(self, tag_class, force=False, index=-1):\n <mask>         \"\"\"Register a new tag with this serializer.\n <mask> \n <mask>         :param tag_class: tag class to register. Will be instantiated with this\n <mask>             serializer instance.\n <mask>         :param force: overwrite an existing tag. If false (default), a\n </s> Fix default index for TaggedJSONSerializer.register()\n\nChange the default value of ``index`` to ``None`` in ``register()`` so\nthat it is possible to insert a new tag as the penultimate item in the\norder list. </s> remove         if index == -1:\n </s> add         if index is None: </s> remove             the new tag is a special case of an existing tag. If -1 (default),\n            the tag is appended to the end of the order.\n </s> add             the new tag is a special case of an existing tag. If ``None``\n            (default), the tag is appended to the end of the order. </s> add def test_tag_order():\n    class Tag1(JSONTag):\n        key = ' 1'\n\n    class Tag2(JSONTag):\n        key = ' 2'\n\n    s = TaggedJSONSerializer()\n\n    s.register(Tag1, index=-1)\n    assert isinstance(s.order[-2], Tag1)\n\n    s.register(Tag2, index=None)\n    assert isinstance(s.order[-1], Tag2)", "html_url": "https://github.com/pallets/flask/commit/fc6a1d9354124690e632323d46ee35c3b8c9c8d2", "file_name": "flask/json/tag.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             serializer instance.\n <mask>         :param force: overwrite an existing tag. If false (default), a\n <mask>             :exc:`KeyError` is raised.\n <mask>         :param index: index to insert the new tag in the tag order. Useful when\n <mask>             the new tag is a special case of an existing tag. If -1 (default),\n <mask>             the tag is appended to the end of the order.\n <mask> \n <mask>         :raise KeyError: if the tag key is already registered and ``force`` is\n <mask>             not true.\n <mask>         \"\"\"\n <mask>         tag = tag_class(self)\n </s> Fix default index for TaggedJSONSerializer.register()\n\nChange the default value of ``index`` to ``None`` in ``register()`` so\nthat it is possible to insert a new tag as the penultimate item in the\norder list. </s> remove         if index == -1:\n </s> add         if index is None: </s> remove     def register(self, tag_class, force=False, index=-1):\n </s> add     def register(self, tag_class, force=False, index=None): </s> add def test_tag_order():\n    class Tag1(JSONTag):\n        key = ' 1'\n\n    class Tag2(JSONTag):\n        key = ' 2'\n\n    s = TaggedJSONSerializer()\n\n    s.register(Tag1, index=-1)\n    assert isinstance(s.order[-2], Tag1)\n\n    s.register(Tag2, index=None)\n    assert isinstance(s.order[-1], Tag2)", "html_url": "https://github.com/pallets/flask/commit/fc6a1d9354124690e632323d46ee35c3b8c9c8d2", "file_name": "flask/json/tag.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 raise KeyError(\"Tag '{0}' is already registered.\".format(key))\n <mask> \n <mask>             self.tags[key] = tag\n <mask> \n <mask>         if index == -1:\n <mask>             self.order.append(tag)\n <mask>         else:\n <mask>             self.order.insert(index, tag)\n <mask> \n <mask>     def tag(self, value):\n </s> Fix default index for TaggedJSONSerializer.register()\n\nChange the default value of ``index`` to ``None`` in ``register()`` so\nthat it is possible to insert a new tag as the penultimate item in the\norder list. </s> add def test_tag_order():\n    class Tag1(JSONTag):\n        key = ' 1'\n\n    class Tag2(JSONTag):\n        key = ' 2'\n\n    s = TaggedJSONSerializer()\n\n    s.register(Tag1, index=-1)\n    assert isinstance(s.order[-2], Tag1)\n\n    s.register(Tag2, index=None)\n    assert isinstance(s.order[-1], Tag2) </s> remove     def register(self, tag_class, force=False, index=-1):\n </s> add     def register(self, tag_class, force=False, index=None): </s> remove             the new tag is a special case of an existing tag. If -1 (default),\n            the tag is appended to the end of the order.\n </s> add             the new tag is a special case of an existing tag. If ``None``\n            (default), the tag is appended to the end of the order.", "html_url": "https://github.com/pallets/flask/commit/fc6a1d9354124690e632323d46ee35c3b8c9c8d2", "file_name": "flask/json/tag.py"}
{"docstring_tokens": "keep keep keep add", "code_tokens": " <mask>     t = JSONTag(None)\n <mask>     pytest.raises(NotImplementedError, t.check, None)\n <mask>     pytest.raises(NotImplementedError, t.to_json, None)\n <mask>     pytest.raises(NotImplementedError, t.to_python, None)\n </s> Fix default index for TaggedJSONSerializer.register()\n\nChange the default value of ``index`` to ``None`` in ``register()`` so\nthat it is possible to insert a new tag as the penultimate item in the\norder list. </s> remove         if index == -1:\n </s> add         if index is None: </s> remove             the new tag is a special case of an existing tag. If -1 (default),\n            the tag is appended to the end of the order.\n </s> add             the new tag is a special case of an existing tag. If ``None``\n            (default), the tag is appended to the end of the order. </s> remove     def register(self, tag_class, force=False, index=-1):\n </s> add     def register(self, tag_class, force=False, index=None):", "html_url": "https://github.com/pallets/flask/commit/fc6a1d9354124690e632323d46ee35c3b8c9c8d2", "file_name": "tests/test_json_tag.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> Unreleased\n <mask> \n <mask> \n <mask> Version 2.0.0\n <mask> -------------\n <mask> \n <mask> Released 2021-05-11\n <mask> \n </s> Re-add filename param for send_from_directory\n\nAdd a deprecation warning for the old name </s> add     if filename is not None:\n        warnings.warn(\n            \"The 'filename' parameter has been renamed to 'path'. The\"\n            \" old name will be removed in Flask 2.1.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        path = filename\n </s> add     .. versionchanged:: 2.0\n        ``path`` replaces the ``filename`` parameter.\n </s> remove def send_from_directory(directory: str, path: str, **kwargs: t.Any) -> \"Response\":\n </s> add def send_from_directory(\n    directory: str, path: str, filename: t.Optional[str] = None, **kwargs: t.Any\n) -> \"Response\":", "html_url": "https://github.com/pallets/flask/commit/fc82dd50e39700b14799df17578e2497b8f0248c", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     return path\n <mask> \n <mask> \n <mask> def send_from_directory(directory: str, path: str, **kwargs: t.Any) -> \"Response\":\n <mask>     \"\"\"Send a file from within a directory using :func:`send_file`.\n <mask> \n <mask>     .. code-block:: python\n <mask> \n <mask>         @app.route(\"/uploads/<path:name>\")\n </s> Re-add filename param for send_from_directory\n\nAdd a deprecation warning for the old name </s> add     .. versionchanged:: 2.0\n        ``path`` replaces the ``filename`` parameter.\n </s> add     if filename is not None:\n        warnings.warn(\n            \"The 'filename' parameter has been renamed to 'path'. The\"\n            \" old name will be removed in Flask 2.1.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        path = filename\n </s> add -   Re-add the ``filename`` parameter in ``send_from_directory``. The\n    ``filename`` parameter has been renamed to ``path``, the old name\n    is deprecated. :pr:`4019`\n", "html_url": "https://github.com/pallets/flask/commit/fc82dd50e39700b14799df17578e2497b8f0248c", "file_name": "src/flask/helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         ``directory``.\n <mask>     :param kwargs: Arguments to pass to :func:`send_file`.\n <mask> \n <mask>     .. versionadded:: 2.0\n <mask>         Moved the implementation to Werkzeug. This is now a wrapper to\n <mask>         pass some Flask-specific arguments.\n <mask> \n <mask>     .. versionadded:: 0.5\n <mask>     \"\"\"\n </s> Re-add filename param for send_from_directory\n\nAdd a deprecation warning for the old name </s> add     if filename is not None:\n        warnings.warn(\n            \"The 'filename' parameter has been renamed to 'path'. The\"\n            \" old name will be removed in Flask 2.1.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        path = filename\n </s> add -   Re-add the ``filename`` parameter in ``send_from_directory``. The\n    ``filename`` parameter has been renamed to ``path``, the old name\n    is deprecated. :pr:`4019`\n </s> remove def send_from_directory(directory: str, path: str, **kwargs: t.Any) -> \"Response\":\n </s> add def send_from_directory(\n    directory: str, path: str, filename: t.Optional[str] = None, **kwargs: t.Any\n) -> \"Response\":", "html_url": "https://github.com/pallets/flask/commit/fc82dd50e39700b14799df17578e2497b8f0248c", "file_name": "src/flask/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         pass some Flask-specific arguments.\n <mask> \n <mask>     .. versionadded:: 0.5\n <mask>     \"\"\"\n <mask>     return werkzeug.utils.send_from_directory(  # type: ignore\n <mask>         directory, path, **_prepare_send_file_kwargs(**kwargs)\n <mask>     )\n <mask> \n </s> Re-add filename param for send_from_directory\n\nAdd a deprecation warning for the old name </s> add     .. versionchanged:: 2.0\n        ``path`` replaces the ``filename`` parameter.\n </s> remove def send_from_directory(directory: str, path: str, **kwargs: t.Any) -> \"Response\":\n </s> add def send_from_directory(\n    directory: str, path: str, filename: t.Optional[str] = None, **kwargs: t.Any\n) -> \"Response\": </s> add -   Re-add the ``filename`` parameter in ``send_from_directory``. The\n    ``filename`` parameter has been renamed to ``path``, the old name\n    is deprecated. :pr:`4019`\n", "html_url": "https://github.com/pallets/flask/commit/fc82dd50e39700b14799df17578e2497b8f0248c", "file_name": "src/flask/helpers.py"}
{"docstring_tokens": "keep replace replace replace replace replace keep replace replace keep keep keep keep", "code_tokens": " <mask> \n <mask> Extension objects are not initially bound to an application. Using\n <mask> ``db.init_app``, the app gets configured for the extension. No\n <mask> application-specific state is stored on the extension object, so one extension\n <mask> object can be used for multiple apps. For more information about the design of\n <mask> extensions refer to :doc:`/extensiondev`.\n <mask> \n <mask> Your `model.py` might look like this when using `Flask-SQLAlchemy\n <mask> <http://pythonhosted.org/Flask-SQLAlchemy/>`_::\n <mask> \n <mask>     from flask.ext.sqlalchemy import SQLAlchemy\n <mask>     # no app object passed! Instead we use use db.init_app in the factory.\n <mask>     db = SQLAlchemy()\n </s> Update appfactories.rst, make extension related section clearer </s> remove     from flask.ext.sqlalchemy import SQLAlchemy\n    # no app object passed! Instead we use use db.init_app in the factory.\n </s> add  </s> add     \nand in your application.py (or equivalent)::\n\n    def create_app(config_filename):\n        app = Flask(__name__)\n        app.config.from_pyfile(config_filename)\n\n        from yourapplication.model import db\n        db.init_app(app)\n </s> remove     # create some models\n </s> add Using this design pattern, no application-specific state is stored on the\nextension object, so one extension object can be used for multiple apps. \nFor more information about the design of extensions refer to :doc:`/extensiondev`.", "html_url": "https://github.com/pallets/flask/commit/fc85bf42ae8fcd6cc76c734d0871bb78ad2a8f06", "file_name": "docs/patterns/appfactories.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Your `model.py` might look like this when using `Flask-SQLAlchemy\n <mask> <http://pythonhosted.org/Flask-SQLAlchemy/>`_::\n <mask> \n <mask>     from flask.ext.sqlalchemy import SQLAlchemy\n <mask>     # no app object passed! Instead we use use db.init_app in the factory.\n <mask>     db = SQLAlchemy()\n <mask> \n <mask>     # create some models\n <mask> \n <mask> Using Applications\n </s> Update appfactories.rst, make extension related section clearer </s> remove     # create some models\n </s> add Using this design pattern, no application-specific state is stored on the\nextension object, so one extension object can be used for multiple apps. \nFor more information about the design of extensions refer to :doc:`/extensiondev`. </s> add     \nand in your application.py (or equivalent)::\n\n    def create_app(config_filename):\n        app = Flask(__name__)\n        app.config.from_pyfile(config_filename)\n\n        from yourapplication.model import db\n        db.init_app(app)\n </s> remove Extension objects are not initially bound to an application. Using\n``db.init_app``, the app gets configured for the extension. No\napplication-specific state is stored on the extension object, so one extension\nobject can be used for multiple apps. For more information about the design of\nextensions refer to :doc:`/extensiondev`.\n </s> add Factories & Extensions\n---------------------- </s> remove Your `model.py` might look like this when using `Flask-SQLAlchemy\n<http://pythonhosted.org/Flask-SQLAlchemy/>`_::\n </s> add It's preferable to create your extensions and app factories so that the\nextension object does not initially get bound to the application.\n\nUsing `Flask-SQLAlchemy <http://pythonhosted.org/Flask-SQLAlchemy/>`_, \nas an example, you should **not** do::\n    \n    def create_app(config_filename):\n        app = Flask(__name__)\n        app.config.from_pyfile(config_filename)\n\n        db = SQLAlchemy(app)\n\nBut, rather, in model.py (or equivalent)::", "html_url": "https://github.com/pallets/flask/commit/fc85bf42ae8fcd6cc76c734d0871bb78ad2a8f06", "file_name": "docs/patterns/appfactories.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> But, rather, in model.py (or equivalent)::\n <mask> \n <mask>     db = SQLAlchemy()\n <mask> \n <mask> Using this design pattern, no application-specific state is stored on the\n <mask> extension object, so one extension object can be used for multiple apps. \n <mask> For more information about the design of extensions refer to :doc:`/extensiondev`.\n </s> Update appfactories.rst, make extension related section clearer </s> remove Your `model.py` might look like this when using `Flask-SQLAlchemy\n<http://pythonhosted.org/Flask-SQLAlchemy/>`_::\n </s> add It's preferable to create your extensions and app factories so that the\nextension object does not initially get bound to the application.\n\nUsing `Flask-SQLAlchemy <http://pythonhosted.org/Flask-SQLAlchemy/>`_, \nas an example, you should **not** do::\n    \n    def create_app(config_filename):\n        app = Flask(__name__)\n        app.config.from_pyfile(config_filename)\n\n        db = SQLAlchemy(app)\n\nBut, rather, in model.py (or equivalent):: </s> remove     from flask.ext.sqlalchemy import SQLAlchemy\n    # no app object passed! Instead we use use db.init_app in the factory.\n </s> add  </s> remove     # create some models\n </s> add Using this design pattern, no application-specific state is stored on the\nextension object, so one extension object can be used for multiple apps. \nFor more information about the design of extensions refer to :doc:`/extensiondev`. </s> remove Extension objects are not initially bound to an application. Using\n``db.init_app``, the app gets configured for the extension. No\napplication-specific state is stored on the extension object, so one extension\nobject can be used for multiple apps. For more information about the design of\nextensions refer to :doc:`/extensiondev`.\n </s> add Factories & Extensions\n----------------------", "html_url": "https://github.com/pallets/flask/commit/fc85bf42ae8fcd6cc76c734d0871bb78ad2a8f06", "file_name": "docs/patterns/appfactories.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     from flask.ext.sqlalchemy import SQLAlchemy\n <mask>     # no app object passed! Instead we use use db.init_app in the factory.\n <mask>     db = SQLAlchemy()\n <mask> \n <mask>     # create some models\n <mask> \n <mask> Using Applications\n <mask> ------------------\n <mask> \n <mask> So to use such an application you then have to create the application\n </s> Update appfactories.rst, make extension related section clearer </s> remove     from flask.ext.sqlalchemy import SQLAlchemy\n    # no app object passed! Instead we use use db.init_app in the factory.\n </s> add  </s> remove Your `model.py` might look like this when using `Flask-SQLAlchemy\n<http://pythonhosted.org/Flask-SQLAlchemy/>`_::\n </s> add It's preferable to create your extensions and app factories so that the\nextension object does not initially get bound to the application.\n\nUsing `Flask-SQLAlchemy <http://pythonhosted.org/Flask-SQLAlchemy/>`_, \nas an example, you should **not** do::\n    \n    def create_app(config_filename):\n        app = Flask(__name__)\n        app.config.from_pyfile(config_filename)\n\n        db = SQLAlchemy(app)\n\nBut, rather, in model.py (or equivalent):: </s> remove Extension objects are not initially bound to an application. Using\n``db.init_app``, the app gets configured for the extension. No\napplication-specific state is stored on the extension object, so one extension\nobject can be used for multiple apps. For more information about the design of\nextensions refer to :doc:`/extensiondev`.\n </s> add Factories & Extensions\n---------------------- </s> add     \nand in your application.py (or equivalent)::\n\n    def create_app(config_filename):\n        app = Flask(__name__)\n        app.config.from_pyfile(config_filename)\n\n        from yourapplication.model import db\n        db.init_app(app)\n", "html_url": "https://github.com/pallets/flask/commit/fc85bf42ae8fcd6cc76c734d0871bb78ad2a8f06", "file_name": "docs/patterns/appfactories.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> -   JSON support no longer uses simplejson. To use another JSON module,\n <mask>     override ``app.json_encoder`` and ``json_decoder``. :issue:`3555`\n <mask> -   The ``encoding`` option to JSON functions is deprecated. :pr:`3562`\n <mask> -   Add :meth:`sessions.SessionInterface.get_cookie_name` to allow\n <mask>     setting the session cookie name dynamically. :pr:`3369`\n <mask> -   Add :meth:`Config.from_file` to load config using arbitrary file\n <mask>     loaders, such as ``toml.load`` or ``json.load``.\n </s> deprecate passing script_info to factory </s> remove     \"\"\"Checks if the given string is a variable name or a function. If it is a\n    function, it checks for specified arguments and whether it takes a\n    ``script_info`` argument and calls the function with the appropriate\n    arguments.\n </s> add     \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly. </s> remove When calling an application factory, if the factory takes an argument named\n``script_info``, then the :class:`~cli.ScriptInfo` instance is passed as a\nkeyword argument. If the application factory takes only one argument and no\nparentheses follow the factory name, the :class:`~cli.ScriptInfo` instance\nis passed as a positional argument. If parentheses follow the factory name,\ntheir contents are parsed as Python literals and passes as arguments to the\nfunction. This means that strings must still be in quotes.\n </s> add If parentheses follow the factory name, their contents are parsed as\nPython literals and passed as arguments to the function. This means that\nstrings must still be in quotes. </s> remove     elif not arguments and len(arg_names) == 1 and arg_defaults is None:\n </s> add     elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n        warnings.warn(\n            \"Script info is deprecated and will not be passed as the\"\n            \" first argument to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> remove     if \"script_info\" in arg_names:\n </s> add     if \"script_info\" in args_spec.args:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> remove     arg_names = args_spec.args\n    arg_defaults = args_spec.defaults\n </s> add  </s> remove         # takes script_info\n        (\"cliapp.factory\", 'create_app3(\"foo\")', \"app3_foo_spam\"),\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> ``app`` or ``application``, then any application instance. If no instance is\n <mask> found, the command looks for a factory function named ``create_app`` or\n <mask> ``make_app`` that returns an instance.\n <mask> \n <mask> When calling an application factory, if the factory takes an argument named\n <mask> ``script_info``, then the :class:`~cli.ScriptInfo` instance is passed as a\n <mask> keyword argument. If the application factory takes only one argument and no\n <mask> parentheses follow the factory name, the :class:`~cli.ScriptInfo` instance\n <mask> is passed as a positional argument. If parentheses follow the factory name,\n <mask> their contents are parsed as Python literals and passes as arguments to the\n <mask> function. This means that strings must still be in quotes.\n <mask> \n <mask> \n <mask> Run the Development Server\n <mask> --------------------------\n <mask> \n </s> deprecate passing script_info to factory </s> remove     \"\"\"Checks if the given string is a variable name or a function. If it is a\n    function, it checks for specified arguments and whether it takes a\n    ``script_info`` argument and calls the function with the appropriate\n    arguments.\n </s> add     \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly. </s> remove     elif not arguments and len(arg_names) == 1 and arg_defaults is None:\n </s> add     elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n        warnings.warn(\n            \"Script info is deprecated and will not be passed as the\"\n            \" first argument to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> add -   Passing ``script_info`` to app factory functions is deprecated. This\n    was not portable outside the ``flask`` command. Use\n    ``click.get_current_context().obj`` if it's needed. :issue:`3552` </s> remove     arg_names = args_spec.args\n    arg_defaults = args_spec.defaults\n </s> add  </s> remove     if \"script_info\" in arg_names:\n </s> add     if \"script_info\" in args_spec.args:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> remove     def create_app(info):\n </s> add     def create_app():", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "docs/cli.rst"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> import sys\n <mask> import traceback\n <mask> from functools import update_wrapper\n <mask> from operator import attrgetter\n <mask> from threading import Lock\n <mask> from threading import Thread\n </s> deprecate passing script_info to factory </s> remove     \"\"\"Checks if the given string is a variable name or a function. If it is a\n    function, it checks for specified arguments and whether it takes a\n    ``script_info`` argument and calls the function with the appropriate\n    arguments.\n </s> add     \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly. </s> remove         def create_app(info):\n </s> add         def create_app(): </s> remove         def create_app(info):\n </s> add         def create_app(): </s> remove When calling an application factory, if the factory takes an argument named\n``script_info``, then the :class:`~cli.ScriptInfo` instance is passed as a\nkeyword argument. If the application factory takes only one argument and no\nparentheses follow the factory name, the :class:`~cli.ScriptInfo` instance\nis passed as a positional argument. If parentheses follow the factory name,\ntheir contents are parsed as Python literals and passes as arguments to the\nfunction. This means that strings must still be in quotes.\n </s> add If parentheses follow the factory name, their contents are parsed as\nPython literals and passed as arguments to the function. This means that\nstrings must still be in quotes. </s> remove     arg_names = args_spec.args\n    arg_defaults = args_spec.defaults\n </s> add  </s> remove     if \"script_info\" in arg_names:\n </s> add     if \"script_info\" in args_spec.args:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in 2.1.\",\n            DeprecationWarning,\n        )", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep replace replace keep replace keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     args_spec = inspect.getfullargspec(app_factory)\n <mask>     arg_names = args_spec.args\n <mask>     arg_defaults = args_spec.defaults\n <mask> \n <mask>     if \"script_info\" in arg_names:\n <mask>         return app_factory(*arguments, script_info=script_info)\n <mask>     elif arguments:\n <mask>         return app_factory(*arguments)\n </s> deprecate passing script_info to factory </s> remove     elif not arguments and len(arg_names) == 1 and arg_defaults is None:\n </s> add     elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n        warnings.warn(\n            \"Script info is deprecated and will not be passed as the\"\n            \" first argument to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> remove         def create_app(info):\n </s> add         def create_app(): </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     \"\"\"Checks if the given string is a variable name or a function. If it is a\n    function, it checks for specified arguments and whether it takes a\n    ``script_info`` argument and calls the function with the appropriate\n    arguments.\n </s> add     \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly.", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     if \"script_info\" in arg_names:\n <mask>         return app_factory(*arguments, script_info=script_info)\n <mask>     elif arguments:\n <mask>         return app_factory(*arguments)\n <mask>     elif not arguments and len(arg_names) == 1 and arg_defaults is None:\n <mask>         return app_factory(script_info)\n <mask> \n <mask>     return app_factory()\n <mask> \n <mask> \n </s> deprecate passing script_info to factory </s> remove     if \"script_info\" in arg_names:\n </s> add     if \"script_info\" in args_spec.args:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> remove     arg_names = args_spec.args\n    arg_defaults = args_spec.defaults\n </s> add  </s> remove     \"\"\"Checks if the given string is a variable name or a function. If it is a\n    function, it checks for specified arguments and whether it takes a\n    ``script_info`` argument and calls the function with the appropriate\n    arguments.\n </s> add     \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly. </s> remove When calling an application factory, if the factory takes an argument named\n``script_info``, then the :class:`~cli.ScriptInfo` instance is passed as a\nkeyword argument. If the application factory takes only one argument and no\nparentheses follow the factory name, the :class:`~cli.ScriptInfo` instance\nis passed as a positional argument. If parentheses follow the factory name,\ntheir contents are parsed as Python literals and passes as arguments to the\nfunction. This means that strings must still be in quotes.\n </s> add If parentheses follow the factory name, their contents are parsed as\nPython literals and passed as arguments to the function. This means that\nstrings must still be in quotes. </s> remove def create_app3(foo, script_info):\n    return Flask(\"_\".join([\"app3\", foo, script_info.data[\"test\"]]))\n\n\n </s> add  </s> remove     def create_app(info):\n </s> add     def create_app():", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         del tb\n <mask> \n <mask> \n <mask> def find_app_by_string(script_info, module, app_name):\n <mask>     \"\"\"Checks if the given string is a variable name or a function. If it is a\n <mask>     function, it checks for specified arguments and whether it takes a\n <mask>     ``script_info`` argument and calls the function with the appropriate\n <mask>     arguments.\n <mask>     \"\"\"\n <mask>     from . import Flask\n <mask> \n <mask>     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n <mask> \n </s> deprecate passing script_info to factory </s> remove When calling an application factory, if the factory takes an argument named\n``script_info``, then the :class:`~cli.ScriptInfo` instance is passed as a\nkeyword argument. If the application factory takes only one argument and no\nparentheses follow the factory name, the :class:`~cli.ScriptInfo` instance\nis passed as a positional argument. If parentheses follow the factory name,\ntheir contents are parsed as Python literals and passes as arguments to the\nfunction. This means that strings must still be in quotes.\n </s> add If parentheses follow the factory name, their contents are parsed as\nPython literals and passed as arguments to the function. This means that\nstrings must still be in quotes. </s> remove     arg_names = args_spec.args\n    arg_defaults = args_spec.defaults\n </s> add  </s> add -   Passing ``script_info`` to app factory functions is deprecated. This\n    was not portable outside the ``flask`` command. Use\n    ``click.get_current_context().obj`` if it's needed. :issue:`3552` </s> remove     elif not arguments and len(arg_names) == 1 and arg_defaults is None:\n </s> add     elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n        warnings.warn(\n            \"Script info is deprecated and will not be passed as the\"\n            \" first argument to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> remove     if \"script_info\" in arg_names:\n </s> add     if \"script_info\" in args_spec.args:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> add import warnings", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep", "code_tokens": " <mask> def create_app2(foo, bar):\n <mask>     return Flask(\"_\".join([\"app2\", foo, bar]))\n <mask> \n <mask> \n <mask> def create_app3(foo, script_info):\n <mask>     return Flask(\"_\".join([\"app3\", foo, script_info.data[\"test\"]]))\n <mask> \n <mask> \n <mask> def no_app():\n <mask>     pass\n </s> deprecate passing script_info to factory </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove         def create_app(info):\n </s> add         def create_app(): </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_apps/cliapp/factory.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app():\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     assert isinstance(find_best_app(script_info, Module), Flask)\n <mask>     assert find_best_app(script_info, Module).name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def create_app(foo):\n <mask>             return Flask(\"appname\")\n </s> deprecate passing script_info to factory </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove         def create_app(info):\n </s> add         def create_app(): </s> remove     def create_app(info):\n </s> add     def create_app():", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app(foo):\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     assert isinstance(find_best_app(script_info, Module), Flask)\n <mask>     assert find_best_app(script_info, Module).name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def create_app(foo=None, script_info=None):\n <mask>             return Flask(\"appname\")\n </s> deprecate passing script_info to factory </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove def create_app3(foo, script_info):\n    return Flask(\"_\".join([\"app3\", foo, script_info.data[\"test\"]]))\n\n\n </s> add  </s> remove         def create_app(info):\n </s> add         def create_app():", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app(foo=None, script_info=None):\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     assert isinstance(find_best_app(script_info, Module), Flask)\n <mask>     assert find_best_app(script_info, Module).name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def make_app():\n <mask>             return Flask(\"appname\")\n </s> deprecate passing script_info to factory </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove def create_app3(foo, script_info):\n    return Flask(\"_\".join([\"app3\", foo, script_info.data[\"test\"]]))\n\n\n </s> add  </s> remove         def create_app(info):\n </s> add         def create_app():", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def make_app():\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     assert isinstance(find_best_app(script_info, Module), Flask)\n <mask>     assert find_best_app(script_info, Module).name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         myapp = Flask(\"appname1\")\n <mask> \n <mask>         @staticmethod\n </s> deprecate passing script_info to factory </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testapp\"))\n </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testapp\")) </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testappgroup\"))\n </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testappgroup\"))", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         # no script_info\n <mask>         (\"cliapp.factory\", 'create_app2(\"foo\", \"bar\")', \"app2_foo_bar\"),\n <mask>         # trailing comma space\n <mask>         (\"cliapp.factory\", 'create_app2(\"foo\", \"bar\", )', \"app2_foo_bar\"),\n <mask>         # takes script_info\n <mask>         (\"cliapp.factory\", 'create_app3(\"foo\")', \"app3_foo_spam\"),\n <mask>         # strip whitespace\n <mask>         (\"cliapp.factory\", \" create_app () \", \"app\"),\n <mask>     ),\n <mask> )\n <mask> def test_locate_app(test_apps, iname, aname, result):\n </s> deprecate passing script_info to factory </s> remove     info.data[\"test\"] = \"spam\"\n </s> add  </s> remove     arg_names = args_spec.args\n    arg_defaults = args_spec.defaults\n </s> add  </s> remove When calling an application factory, if the factory takes an argument named\n``script_info``, then the :class:`~cli.ScriptInfo` instance is passed as a\nkeyword argument. If the application factory takes only one argument and no\nparentheses follow the factory name, the :class:`~cli.ScriptInfo` instance\nis passed as a positional argument. If parentheses follow the factory name,\ntheir contents are parsed as Python literals and passes as arguments to the\nfunction. This means that strings must still be in quotes.\n </s> add If parentheses follow the factory name, their contents are parsed as\nPython literals and passed as arguments to the function. This means that\nstrings must still be in quotes. </s> remove     if \"script_info\" in arg_names:\n </s> add     if \"script_info\" in args_spec.args:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> remove     elif not arguments and len(arg_names) == 1 and arg_defaults is None:\n </s> add     elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n        warnings.warn(\n            \"Script info is deprecated and will not be passed as the\"\n            \" first argument to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> remove     \"\"\"Checks if the given string is a variable name or a function. If it is a\n    function, it checks for specified arguments and whether it takes a\n    ``script_info`` argument and calls the function with the appropriate\n    arguments.\n </s> add     \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly.", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     ),\n <mask> )\n <mask> def test_locate_app(test_apps, iname, aname, result):\n <mask>     info = ScriptInfo()\n <mask>     info.data[\"test\"] = \"spam\"\n <mask>     assert locate_app(info, iname, aname).name == result\n <mask> \n <mask> \n <mask> @pytest.mark.parametrize(\n <mask>     \"iname,aname\",\n </s> deprecate passing script_info to factory </s> remove         # takes script_info\n        (\"cliapp.factory\", 'create_app3(\"foo\")', \"app3_foo_spam\"),\n </s> add  </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testapp\"))\n </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testapp\")) </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testappgroup\"))\n </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testappgroup\")) </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     app = obj.load_app()\n <mask>     assert app.name == \"testapp\"\n <mask>     assert obj.load_app() is app\n <mask> \n <mask>     def create_app(info):\n <mask>         return Flask(\"createapp\")\n <mask> \n <mask>     obj = ScriptInfo(create_app=create_app)\n <mask>     app = obj.load_app()\n <mask>     assert app.name == \"createapp\"\n </s> deprecate passing script_info to factory </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testapp\"))\n </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testapp\")) </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testappgroup\"))\n </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testappgroup\"))", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @with_appcontext\n <mask>     def testcmd():\n <mask>         click.echo(current_app.name)\n <mask> \n <mask>     obj = ScriptInfo(create_app=lambda info: Flask(\"testapp\"))\n <mask> \n <mask>     result = runner.invoke(testcmd, obj=obj)\n <mask>     assert result.exit_code == 0\n <mask>     assert result.output == \"testapp\\n\"\n <mask> \n </s> deprecate passing script_info to factory </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testappgroup\"))\n </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testappgroup\")) </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     info.data[\"test\"] = \"spam\"\n </s> add  </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @subgroup.command(with_appcontext=True)\n <mask>     def test2():\n <mask>         click.echo(current_app.name)\n <mask> \n <mask>     obj = ScriptInfo(create_app=lambda info: Flask(\"testappgroup\"))\n <mask> \n <mask>     result = runner.invoke(cli, [\"test\"], obj=obj)\n <mask>     assert result.exit_code == 0\n <mask>     assert result.output == \"testappgroup\\n\"\n <mask> \n </s> deprecate passing script_info to factory </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testapp\"))\n </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testapp\")) </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     info.data[\"test\"] = \"spam\"\n </s> add  </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def test_flaskgroup(runner):\n <mask>     \"\"\"Test FlaskGroup.\"\"\"\n <mask> \n <mask>     def create_app(info):\n <mask>         return Flask(\"flaskgroup\")\n <mask> \n <mask>     @click.group(cls=FlaskGroup, create_app=create_app)\n <mask>     def cli(**params):\n <mask>         pass\n </s> deprecate passing script_info to factory </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove def create_app3(foo, script_info):\n    return Flask(\"_\".join([\"app3\", foo, script_info.data[\"test\"]]))\n\n\n </s> add  </s> remove         def create_app(info):\n </s> add         def create_app(): </s> remove         def create_app(info):\n </s> add         def create_app(): </s> remove     def create_app(info):\n </s> add     def create_app():", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> @pytest.mark.parametrize(\"set_debug_flag\", (True, False))\n <mask> def test_flaskgroup_debug(runner, set_debug_flag):\n <mask>     \"\"\"Test FlaskGroup debug flag behavior.\"\"\"\n <mask> \n <mask>     def create_app(info):\n <mask>         app = Flask(\"flaskgroup\")\n <mask>         app.debug = True\n <mask>         return app\n <mask> \n <mask>     @click.group(cls=FlaskGroup, create_app=create_app, set_debug_flag=set_debug_flag)\n </s> deprecate passing script_info to factory </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove         def create_app(info):\n </s> add         def create_app(): </s> remove         def create_app(info):\n </s> add         def create_app(): </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def test_print_exceptions(runner):\n <mask>     \"\"\"Print the stacktrace if the CLI.\"\"\"\n <mask> \n <mask>     def create_app(info):\n <mask>         raise Exception(\"oh no\")\n <mask>         return Flask(\"flaskgroup\")\n <mask> \n <mask>     @click.group(cls=FlaskGroup, create_app=create_app)\n <mask>     def cli(**params):\n </s> deprecate passing script_info to factory </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove         def create_app(info):\n </s> add         def create_app(): </s> remove     \"\"\"Checks if the given string is a variable name or a function. If it is a\n    function, it checks for specified arguments and whether it takes a\n    ``script_info`` argument and calls the function with the appropriate\n    arguments.\n </s> add     \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly. </s> remove         def create_app(info):\n </s> add         def create_app(): </s> remove     def create_app(info):\n </s> add     def create_app():", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> class TestRoutes:\n <mask>     @pytest.fixture\n <mask>     def invoke(self, runner):\n <mask>         def create_app(info):\n <mask>             app = Flask(__name__)\n <mask>             app.testing = True\n <mask> \n <mask>             @app.route(\"/get_post/<int:x>/<int:y>\", methods=[\"GET\", \"POST\"])\n <mask>             def yyy_get_post(x, y):\n </s> deprecate passing script_info to factory </s> remove         def create_app(info):\n </s> add         def create_app(): </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         return partial(runner.invoke, cli)\n <mask> \n <mask>     @pytest.fixture\n <mask>     def invoke_no_routes(self, runner):\n <mask>         def create_app(info):\n <mask>             app = Flask(__name__, static_folder=None)\n <mask>             app.testing = True\n <mask> \n <mask>             return app\n <mask> \n </s> deprecate passing script_info to factory </s> remove         def create_app(info):\n </s> add         def create_app(): </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     def create_app(info):\n </s> add     def create_app(): </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"\n </s> add     with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> -   The return value from :meth:`cli.load_dotenv` is more consistent\n <mask>     with the documentation. It will return ``False`` if python-dotenv is\n <mask>     not installed, or if the given path isn't a file. :issue:`2937`\n <mask> \n <mask> .. _#2935: https://github.com/pallets/flask/issues/2935\n <mask> .. _#2957: https://github.com/pallets/flask/issues/2957\n <mask> .. _#2994: https://github.com/pallets/flask/pull/2994\n </s> FakeSignal should stub connect_via method </s> remove                 \"signalling support is unavailable \"\n                \"because the blinker library is \"\n                \"not installed.\"\n </s> add                 \"Signalling support is unavailable because the blinker\"\n                \" library is not installed.\" </s> add         def send(self, *args, **kwargs):\n            pass\n </s> remove         send = lambda *a, **kw: None\n        connect = (\n            disconnect\n        ) = (\n            has_receivers_for\n        ) = receivers_for = temporarily_connected_to = connected_to = _fail\n </s> add         connect = connect_via = connected_to = temporarily_connected_to = _fail\n        disconnect = _fail\n        has_receivers_for = receivers_for = _fail", "html_url": "https://github.com/pallets/flask/commit/fcf2eb4753d02caf258c5b1473fbb74721a3f489", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>             self.name = name\n <mask>             self.__doc__ = doc\n <mask> \n <mask>         def _fail(self, *args, **kwargs):\n <mask>             raise RuntimeError(\n <mask>                 \"Signalling support is unavailable because the blinker\"\n <mask>                 \" library is not installed.\"\n <mask>             )\n </s> FakeSignal should stub connect_via method </s> remove                 \"signalling support is unavailable \"\n                \"because the blinker library is \"\n                \"not installed.\"\n </s> add                 \"Signalling support is unavailable because the blinker\"\n                \" library is not installed.\" </s> remove         send = lambda *a, **kw: None\n        connect = (\n            disconnect\n        ) = (\n            has_receivers_for\n        ) = receivers_for = temporarily_connected_to = connected_to = _fail\n </s> add         connect = connect_via = connected_to = temporarily_connected_to = _fail\n        disconnect = _fail\n        has_receivers_for = receivers_for = _fail </s> add -   Signaling support has a stub for the ``connect_via`` method when\n    the Blinker library is not installed. :pr:`3208`", "html_url": "https://github.com/pallets/flask/commit/fcf2eb4753d02caf258c5b1473fbb74721a3f489", "file_name": "flask/signals.py"}
{"docstring_tokens": "keep replace replace replace keep keep replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>             raise RuntimeError(\n <mask>                 \"signalling support is unavailable \"\n <mask>                 \"because the blinker library is \"\n <mask>                 \"not installed.\"\n <mask>             )\n <mask> \n <mask>         send = lambda *a, **kw: None\n <mask>         connect = (\n <mask>             disconnect\n <mask>         ) = (\n <mask>             has_receivers_for\n <mask>         ) = receivers_for = temporarily_connected_to = connected_to = _fail\n <mask>         del _fail\n <mask> \n <mask> \n </s> FakeSignal should stub connect_via method </s> add         def send(self, *args, **kwargs):\n            pass\n </s> add -   Signaling support has a stub for the ``connect_via`` method when\n    the Blinker library is not installed. :pr:`3208`", "html_url": "https://github.com/pallets/flask/commit/fcf2eb4753d02caf258c5b1473fbb74721a3f489", "file_name": "flask/signals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Security Headers\n <mask> ----------------\n <mask> \n <mask> This section contains a list of headers supported by Flask.\n <mask> To configure HTTPS and handle the headers listed below we suggest the package `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_. \n <mask> \n <mask> HTTP Strict Transport Security (HSTS)\n <mask> -------------------------------------\n <mask> \n </s> Add capitalize and other details </s> remove Redirects http requests to https on all urls, preventing Man-in-the-middle (MITM) attacks.\n </s> add Redirects HTTP requests to HTTPS on all URLs, preventing man-in-the-middle (MITM) attacks. </s> remove This enables your web server to authenticate with a client browser using a specific certificate key to prevent Man-in-the-middle (MITM) attacks.\n </s> add This enables your web server to authenticate with a client browser using a specific certificate key to prevent man-in-the-middle (MITM) attacks. </s> remove While these headers are not directly security related, they have important options that may affect your flask application.\n </s> add While these headers are not directly security related, they have important options that may affect your Flask application. </s> remove Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and Man-in-the-middle (MITM) related attacks.\n </s> add Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and man-in-the-middle (MITM) related attacks. </s> remove Cookie options\n </s> add Cookie Options </s> remove X-Frame-Options (Clickjacking protection)\n </s> add X-Frame-Options (Clickjacking Protection)", "html_url": "https://github.com/pallets/flask/commit/fcfd03146011dbb2ab77868b2f56374d51b39d56", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> HTTP Strict Transport Security (HSTS)\n <mask> -------------------------------------\n <mask> \n <mask> Redirects http requests to https on all urls, preventing Man-in-the-middle (MITM) attacks.\n <mask> \n <mask> Example:\n <mask> \n <mask> .. sourcecode:: none\n <mask>    \n </s> Add capitalize and other details </s> remove This section contains a list of headers supported by Flask.\n </s> add This section contains a list of HTTP security headers supported by Flask. </s> remove This enables your web server to authenticate with a client browser using a specific certificate key to prevent Man-in-the-middle (MITM) attacks.\n </s> add This enables your web server to authenticate with a client browser using a specific certificate key to prevent man-in-the-middle (MITM) attacks. </s> remove Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and Man-in-the-middle (MITM) related attacks.\n </s> add Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and man-in-the-middle (MITM) related attacks. </s> remove X-Frame-Options (Clickjacking protection)\n </s> add X-Frame-Options (Clickjacking Protection) </s> remove While these headers are not directly security related, they have important options that may affect your flask application.\n </s> add While these headers are not directly security related, they have important options that may affect your Flask application. </s> remove Cookie options\n </s> add Cookie Options", "html_url": "https://github.com/pallets/flask/commit/fcfd03146011dbb2ab77868b2f56374d51b39d56", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> HTTP Public Key Pinning (HPKP)\n <mask> ------------------------------\n <mask> \n <mask> This enables your web server to authenticate with a client browser using a specific certificate key to prevent Man-in-the-middle (MITM) attacks.\n <mask> \n <mask> Example:\n <mask> \n <mask> .. sourcecode:: none\n <mask> \n </s> Add capitalize and other details </s> remove X-Frame-Options (Clickjacking protection)\n </s> add X-Frame-Options (Clickjacking Protection) </s> remove This section contains a list of headers supported by Flask.\n </s> add This section contains a list of HTTP security headers supported by Flask. </s> remove Redirects http requests to https on all urls, preventing Man-in-the-middle (MITM) attacks.\n </s> add Redirects HTTP requests to HTTPS on all URLs, preventing man-in-the-middle (MITM) attacks. </s> remove Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and Man-in-the-middle (MITM) related attacks.\n </s> add Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and man-in-the-middle (MITM) related attacks. </s> remove While these headers are not directly security related, they have important options that may affect your flask application.\n </s> add While these headers are not directly security related, they have important options that may affect your Flask application. </s> remove Cookie options\n </s> add Cookie Options", "html_url": "https://github.com/pallets/flask/commit/fcfd03146011dbb2ab77868b2f56374d51b39d56", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>    Public-Key-Pins: pin-sha256=\"base64==\"; max-age=expireTime [; includeSubDomains][; report-uri=\"reportURI\"] \n <mask> \n <mask> See also `Public Key Pinning <https://developer.mozilla.org/en-US/docs/Web/HTTP/Public_Key_Pinning>`_.\n <mask> \n <mask> X-Frame-Options (Clickjacking protection)\n <mask> -----------------------------------------\n <mask> \n <mask> Prevents the client from clicking page elements outside of the website, avoiding hijacking or UI redress attacks.\n <mask> \n <mask> .. sourcecode:: none\n </s> Add capitalize and other details </s> remove This enables your web server to authenticate with a client browser using a specific certificate key to prevent Man-in-the-middle (MITM) attacks.\n </s> add This enables your web server to authenticate with a client browser using a specific certificate key to prevent man-in-the-middle (MITM) attacks. </s> remove While these headers are not directly security related, they have important options that may affect your flask application.\n </s> add While these headers are not directly security related, they have important options that may affect your Flask application. </s> remove Cookie options\n </s> add Cookie Options </s> remove Redirects http requests to https on all urls, preventing Man-in-the-middle (MITM) attacks.\n </s> add Redirects HTTP requests to HTTPS on all URLs, preventing man-in-the-middle (MITM) attacks. </s> remove Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and Man-in-the-middle (MITM) related attacks.\n </s> add Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and man-in-the-middle (MITM) related attacks. </s> remove This section contains a list of headers supported by Flask.\n </s> add This section contains a list of HTTP security headers supported by Flask.", "html_url": "https://github.com/pallets/flask/commit/fcfd03146011dbb2ab77868b2f56374d51b39d56", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Content Security Policy (CSP)\n <mask> -----------------------------\n <mask> \n <mask> Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and Man-in-the-middle (MITM) related attacks.\n <mask> \n <mask> Example:\n <mask> \n <mask> .. sourcecode:: none\n <mask>    \n </s> Add capitalize and other details </s> remove This enables your web server to authenticate with a client browser using a specific certificate key to prevent Man-in-the-middle (MITM) attacks.\n </s> add This enables your web server to authenticate with a client browser using a specific certificate key to prevent man-in-the-middle (MITM) attacks. </s> remove Redirects http requests to https on all urls, preventing Man-in-the-middle (MITM) attacks.\n </s> add Redirects HTTP requests to HTTPS on all URLs, preventing man-in-the-middle (MITM) attacks. </s> remove This section contains a list of headers supported by Flask.\n </s> add This section contains a list of HTTP security headers supported by Flask. </s> remove Cookie options\n </s> add Cookie Options </s> remove X-Frame-Options (Clickjacking protection)\n </s> add X-Frame-Options (Clickjacking Protection) </s> remove While these headers are not directly security related, they have important options that may affect your flask application.\n </s> add While these headers are not directly security related, they have important options that may affect your Flask application.", "html_url": "https://github.com/pallets/flask/commit/fcfd03146011dbb2ab77868b2f56374d51b39d56", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>    Content-Security-Policy: default-src https:; script-src 'nonce-{random}'; object-src 'none'\n <mask> \n <mask> See also `Content Security Policy <https://csp.withgoogle.com/docs/index.html>`_.\n <mask> \n <mask> Cookie options\n <mask> --------------\n <mask> \n <mask> While these headers are not directly security related, they have important options that may affect your flask application.\n <mask> \n <mask> - ``Secure`` limits your cookies to HTTPS traffic only.\n </s> Add capitalize and other details </s> remove While these headers are not directly security related, they have important options that may affect your flask application.\n </s> add While these headers are not directly security related, they have important options that may affect your Flask application. </s> remove X-Frame-Options (Clickjacking protection)\n </s> add X-Frame-Options (Clickjacking Protection) </s> remove Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and Man-in-the-middle (MITM) related attacks.\n </s> add Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and man-in-the-middle (MITM) related attacks. </s> remove This section contains a list of headers supported by Flask.\n </s> add This section contains a list of HTTP security headers supported by Flask. </s> remove This enables your web server to authenticate with a client browser using a specific certificate key to prevent Man-in-the-middle (MITM) attacks.\n </s> add This enables your web server to authenticate with a client browser using a specific certificate key to prevent man-in-the-middle (MITM) attacks. </s> remove Redirects http requests to https on all urls, preventing Man-in-the-middle (MITM) attacks.\n </s> add Redirects HTTP requests to HTTPS on all URLs, preventing man-in-the-middle (MITM) attacks.", "html_url": "https://github.com/pallets/flask/commit/fcfd03146011dbb2ab77868b2f56374d51b39d56", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Cookie options\n <mask> --------------\n <mask> \n <mask> While these headers are not directly security related, they have important options that may affect your flask application.\n <mask> \n <mask> - ``Secure`` limits your cookies to HTTPS traffic only.\n <mask> - ``HttpOnly`` protects the contents of your cookie from being visible to XSS.\n <mask> - ``SameSite`` ensures that cookies can only be requested from the same domain that created them but this feature is not yet fully supported across all browsers.  \n <mask> \n </s> Add capitalize and other details </s> remove Cookie options\n </s> add Cookie Options </s> remove This section contains a list of headers supported by Flask.\n </s> add This section contains a list of HTTP security headers supported by Flask. </s> remove X-Frame-Options (Clickjacking protection)\n </s> add X-Frame-Options (Clickjacking Protection) </s> remove Redirects http requests to https on all urls, preventing Man-in-the-middle (MITM) attacks.\n </s> add Redirects HTTP requests to HTTPS on all URLs, preventing man-in-the-middle (MITM) attacks. </s> remove This enables your web server to authenticate with a client browser using a specific certificate key to prevent Man-in-the-middle (MITM) attacks.\n </s> add This enables your web server to authenticate with a client browser using a specific certificate key to prevent man-in-the-middle (MITM) attacks. </s> remove Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and Man-in-the-middle (MITM) related attacks.\n </s> add Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and man-in-the-middle (MITM) related attacks.", "html_url": "https://github.com/pallets/flask/commit/fcfd03146011dbb2ab77868b2f56374d51b39d56", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             (None, code),\n <mask>             (request.blueprint, None),\n <mask>             (None, None),\n <mask>         ):\n <mask>             handler_map = self.error_handler_spec.setdefault(name, {}).get(c)\n <mask> \n <mask>             if not handler_map:\n <mask>                 continue\n <mask> \n <mask>             for cls in exc_class.__mro__:\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         funcs = self.before_request_funcs.get(None, ())\n </s> add         funcs = self.before_request_funcs[None] </s> remove         funcs = self.url_value_preprocessors.get(None, ())\n </s> add         funcs = self.url_value_preprocessors[None] </s> remove         funcs = reversed(self.teardown_request_funcs.get(None, ()))\n </s> add         funcs = reversed(self.teardown_request_funcs[None]) </s> remove         funcs = self.url_default_functions.get(None, ())\n </s> add         funcs = self.url_default_functions[None] </s> remove             funcs = chain(funcs, self.url_default_functions.get(bp, ()))\n </s> add             funcs = chain(funcs, self.url_default_functions[bp]) </s> remove         self.after_request_funcs = {}\n </s> add         self.after_request_funcs = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep replace keep keep replace keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         funcs = self.url_default_functions.get(None, ())\n <mask>         if \".\" in endpoint:\n <mask>             bp = endpoint.rsplit(\".\", 1)[0]\n <mask>             funcs = chain(funcs, self.url_default_functions.get(bp, ()))\n <mask>         for func in funcs:\n <mask>             func(endpoint, values)\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         funcs = self.before_request_funcs.get(None, ())\n </s> add         funcs = self.before_request_funcs[None] </s> remove         funcs = self.url_value_preprocessors.get(None, ())\n </s> add         funcs = self.url_value_preprocessors[None] </s> remove         funcs = reversed(self.teardown_request_funcs.get(None, ()))\n </s> add         funcs = reversed(self.teardown_request_funcs[None]) </s> remove             handler_map = self.error_handler_spec.setdefault(name, {}).get(c)\n </s> add             handler_map = self.error_handler_spec[name][c] </s> remove                 app_dict.setdefault(key, []).extend(values)\n </s> add                 app_dict[key].extend(values)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask> \n <mask>         bp = _request_ctx_stack.top.request.blueprint\n <mask> \n <mask>         funcs = self.url_value_preprocessors.get(None, ())\n <mask>         if bp is not None and bp in self.url_value_preprocessors:\n <mask>             funcs = chain(funcs, self.url_value_preprocessors[bp])\n <mask>         for func in funcs:\n <mask>             func(request.endpoint, request.view_args)\n <mask> \n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         funcs = self.before_request_funcs.get(None, ())\n </s> add         funcs = self.before_request_funcs[None] </s> remove         funcs = reversed(self.teardown_request_funcs.get(None, ()))\n </s> add         funcs = reversed(self.teardown_request_funcs[None]) </s> remove             funcs = chain(funcs, self.url_default_functions.get(bp, ()))\n </s> add             funcs = chain(funcs, self.url_default_functions[bp]) </s> remove         funcs = self.url_default_functions.get(None, ())\n </s> add         funcs = self.url_default_functions[None] </s> remove                 app_dict.setdefault(key, []).extend(values)\n </s> add                 app_dict[key].extend(values) </s> remove             handler_map = self.error_handler_spec.setdefault(name, {}).get(c)\n </s> add             handler_map = self.error_handler_spec[name][c]", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             funcs = chain(funcs, self.url_value_preprocessors[bp])\n <mask>         for func in funcs:\n <mask>             func(request.endpoint, request.view_args)\n <mask> \n <mask>         funcs = self.before_request_funcs.get(None, ())\n <mask>         if bp is not None and bp in self.before_request_funcs:\n <mask>             funcs = chain(funcs, self.before_request_funcs[bp])\n <mask>         for func in funcs:\n <mask>             rv = func()\n <mask>             if rv is not None:\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         funcs = self.url_value_preprocessors.get(None, ())\n </s> add         funcs = self.url_value_preprocessors[None] </s> remove         funcs = reversed(self.teardown_request_funcs.get(None, ()))\n </s> add         funcs = reversed(self.teardown_request_funcs[None]) </s> remove             funcs = chain(funcs, self.url_default_functions.get(bp, ()))\n </s> add             funcs = chain(funcs, self.url_default_functions[bp]) </s> remove         funcs = self.url_default_functions.get(None, ())\n </s> add         funcs = self.url_default_functions[None] </s> remove             handler_map = self.error_handler_spec.setdefault(name, {}).get(c)\n </s> add             handler_map = self.error_handler_spec[name][c] </s> remove                 app_dict.setdefault(key, []).extend(values)\n </s> add                 app_dict[key].extend(values)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             Added the ``exc`` argument.\n <mask>         \"\"\"\n <mask>         if exc is _sentinel:\n <mask>             exc = sys.exc_info()[1]\n <mask>         funcs = reversed(self.teardown_request_funcs.get(None, ()))\n <mask>         bp = _request_ctx_stack.top.request.blueprint\n <mask>         if bp is not None and bp in self.teardown_request_funcs:\n <mask>             funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))\n <mask>         for func in funcs:\n <mask>             func(exc)\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         funcs = self.url_value_preprocessors.get(None, ())\n </s> add         funcs = self.url_value_preprocessors[None] </s> remove         funcs = self.before_request_funcs.get(None, ())\n </s> add         funcs = self.before_request_funcs[None] </s> remove             funcs = chain(funcs, self.url_default_functions.get(bp, ()))\n </s> add             funcs = chain(funcs, self.url_default_functions[bp]) </s> remove         funcs = self.url_default_functions.get(None, ())\n </s> add         funcs = self.url_default_functions[None] </s> remove                 app_dict.setdefault(key, []).extend(values)\n </s> add                 app_dict[key].extend(values) </s> remove             handler_map = self.error_handler_spec.setdefault(name, {}).get(c)\n </s> add             handler_map = self.error_handler_spec[name][c]", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             Values of dict must be lists.\n <mask>             \"\"\"\n <mask>             for key, values in self_dict.items():\n <mask>                 key = self.name if key is None else f\"{self.name}.{key}\"\n <mask>                 app_dict.setdefault(key, []).extend(values)\n <mask> \n <mask>         def merge_dict_nested(self_dict, app_dict):\n <mask>             \"\"\"Merges self_dict into app_dict. Replaces None keys with self.name.\n <mask>             Values of dict must be dict.\n <mask>             \"\"\"\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.url_value_preprocessors.setdefault(None, []).append(f)\n </s> add         self.url_value_preprocessors[None].append(f) </s> remove         self.before_request_funcs = {}\n </s> add         self.before_request_funcs = defaultdict(list) </s> remove         funcs = self.before_request_funcs.get(None, ())\n </s> add         funcs = self.before_request_funcs[None] </s> remove         funcs = self.url_value_preprocessors.get(None, ())\n </s> add         funcs = self.url_value_preprocessors[None] </s> remove         self.url_value_preprocessors = {}\n </s> add         self.url_value_preprocessors = defaultdict(list) </s> remove         self.after_request_funcs = {}\n </s> add         self.after_request_funcs = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: function.\n <mask>         #:\n <mask>         #: To register an error handler, use the :meth:`errorhandler`\n <mask>         #: decorator.\n <mask>         self.error_handler_spec = {}\n <mask> \n <mask>         #: A dictionary with lists of functions that will be called at the\n <mask>         #: beginning of each request. The key of the dictionary is the name of\n <mask>         #: the blueprint this function is active for, or ``None`` for all\n <mask>         #: requests. To register a function, use the :meth:`before_request`\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.before_request_funcs = {}\n </s> add         self.before_request_funcs = defaultdict(list) </s> remove         self.template_context_processors = {None: [_default_template_ctx_processor]}\n </s> add         self.template_context_processors = defaultdict(\n            list, {None: [_default_template_ctx_processor]}\n        ) </s> remove         self.after_request_funcs = {}\n </s> add         self.after_request_funcs = defaultdict(list) </s> remove         self.teardown_request_funcs = {}\n </s> add         self.teardown_request_funcs = defaultdict(list) </s> remove         self.url_value_preprocessors = {}\n </s> add         self.url_value_preprocessors = defaultdict(list) </s> remove         self.after_request_funcs.setdefault(None, []).append(f)\n </s> add         self.after_request_funcs[None].append(f)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: beginning of each request. The key of the dictionary is the name of\n <mask>         #: the blueprint this function is active for, or ``None`` for all\n <mask>         #: requests. To register a function, use the :meth:`before_request`\n <mask>         #: decorator.\n <mask>         self.before_request_funcs = {}\n <mask> \n <mask>         #: A dictionary with lists of functions that should be called after\n <mask>         #: each request.  The key of the dictionary is the name of the blueprint\n <mask>         #: this function is active for, ``None`` for all requests.  This can for\n <mask>         #: example be used to close database connections. To register a function\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.after_request_funcs = {}\n </s> add         self.after_request_funcs = defaultdict(list) </s> remove         self.error_handler_spec = {}\n </s> add         self.error_handler_spec = defaultdict(lambda: defaultdict(dict)) </s> remove         self.template_context_processors = {None: [_default_template_ctx_processor]}\n </s> add         self.template_context_processors = defaultdict(\n            list, {None: [_default_template_ctx_processor]}\n        ) </s> remove         self.teardown_request_funcs = {}\n </s> add         self.teardown_request_funcs = defaultdict(list) </s> remove         self.url_value_preprocessors = {}\n </s> add         self.url_value_preprocessors = defaultdict(list) </s> remove         self.before_request_funcs.setdefault(None, []).append(f)\n </s> add         self.before_request_funcs[None].append(f)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: each request.  The key of the dictionary is the name of the blueprint\n <mask>         #: this function is active for, ``None`` for all requests.  This can for\n <mask>         #: example be used to close database connections. To register a function\n <mask>         #: here, use the :meth:`after_request` decorator.\n <mask>         self.after_request_funcs = {}\n <mask> \n <mask>         #: A dictionary with lists of functions that are called after\n <mask>         #: each request, even if an exception has occurred. The key of the\n <mask>         #: dictionary is the name of the blueprint this function is active for,\n <mask>         #: ``None`` for all requests. These functions are not allowed to modify\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.before_request_funcs = {}\n </s> add         self.before_request_funcs = defaultdict(list) </s> remove         self.template_context_processors = {None: [_default_template_ctx_processor]}\n </s> add         self.template_context_processors = defaultdict(\n            list, {None: [_default_template_ctx_processor]}\n        ) </s> remove         self.error_handler_spec = {}\n </s> add         self.error_handler_spec = defaultdict(lambda: defaultdict(dict)) </s> remove         self.teardown_request_funcs = {}\n </s> add         self.teardown_request_funcs = defaultdict(list) </s> remove         self.url_value_preprocessors = {}\n </s> add         self.url_value_preprocessors = defaultdict(list) </s> remove         self.after_request_funcs.setdefault(None, []).append(f)\n </s> add         self.after_request_funcs[None].append(f)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: teardown_request function. To register a function here, use the\n <mask>         #: :meth:`teardown_request` decorator.\n <mask>         #:\n <mask>         #: .. versionadded:: 0.7\n <mask>         self.teardown_request_funcs = {}\n <mask> \n <mask>         #: A dictionary with list of functions that are called without argument\n <mask>         #: to populate the template context.  The key of the dictionary is the\n <mask>         #: name of the blueprint this function is active for, ``None`` for all\n <mask>         #: requests.  Each returns a dictionary that the template context is\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.template_context_processors = {None: [_default_template_ctx_processor]}\n </s> add         self.template_context_processors = defaultdict(\n            list, {None: [_default_template_ctx_processor]}\n        ) </s> remove         self.after_request_funcs = {}\n </s> add         self.after_request_funcs = defaultdict(list) </s> remove         self.error_handler_spec = {}\n </s> add         self.error_handler_spec = defaultdict(lambda: defaultdict(dict)) </s> remove         self.before_request_funcs = {}\n </s> add         self.before_request_funcs = defaultdict(list) </s> remove         self.url_value_preprocessors = {}\n </s> add         self.url_value_preprocessors = defaultdict(list) </s> remove         self.url_default_functions = {}\n </s> add         self.url_default_functions = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: name of the blueprint this function is active for, ``None`` for all\n <mask>         #: requests.  Each returns a dictionary that the template context is\n <mask>         #: updated with.  To register a function here, use the\n <mask>         #: :meth:`context_processor` decorator.\n <mask>         self.template_context_processors = {None: [_default_template_ctx_processor]}\n <mask> \n <mask>         #: A dictionary with lists of functions that are called before the\n <mask>         #: :attr:`before_request_funcs` functions. The key of the dictionary is\n <mask>         #: the name of the blueprint this function is active for, or ``None``\n <mask>         #: for all requests. To register a function, use\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.teardown_request_funcs = {}\n </s> add         self.teardown_request_funcs = defaultdict(list) </s> remove         self.before_request_funcs = {}\n </s> add         self.before_request_funcs = defaultdict(list) </s> remove         self.after_request_funcs = {}\n </s> add         self.after_request_funcs = defaultdict(list) </s> remove         self.error_handler_spec = {}\n </s> add         self.error_handler_spec = defaultdict(lambda: defaultdict(dict)) </s> remove         self.url_value_preprocessors = {}\n </s> add         self.url_value_preprocessors = defaultdict(list) </s> remove         self.url_default_functions = {}\n </s> add         self.url_default_functions = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: for all requests. To register a function, use\n <mask>         #: :meth:`url_value_preprocessor`.\n <mask>         #:\n <mask>         #: .. versionadded:: 0.7\n <mask>         self.url_value_preprocessors = {}\n <mask> \n <mask>         #: A dictionary with lists of functions that can be used as URL value\n <mask>         #: preprocessors.  The key ``None`` here is used for application wide\n <mask>         #: callbacks, otherwise the key is the name of the blueprint.\n <mask>         #: Each of these functions has the chance to modify the dictionary\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.after_request_funcs = {}\n </s> add         self.after_request_funcs = defaultdict(list) </s> remove         self.before_request_funcs = {}\n </s> add         self.before_request_funcs = defaultdict(list) </s> remove         self.teardown_request_funcs = {}\n </s> add         self.teardown_request_funcs = defaultdict(list) </s> remove         self.template_context_processors = {None: [_default_template_ctx_processor]}\n </s> add         self.template_context_processors = defaultdict(\n            list, {None: [_default_template_ctx_processor]}\n        ) </s> remove         self.error_handler_spec = {}\n </s> add         self.error_handler_spec = defaultdict(lambda: defaultdict(dict)) </s> remove         self.url_default_functions = {}\n </s> add         self.url_default_functions = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: provide a :meth:`url_defaults` function that adds the parameters\n <mask>         #: automatically again that were removed that way.\n <mask>         #:\n <mask>         #: .. versionadded:: 0.7\n <mask>         self.url_default_functions = {}\n <mask> \n <mask>     def _is_setup_finished(self):\n <mask>         raise NotImplementedError\n <mask> \n <mask>     def _method_route(self, method, rule, options):\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.teardown_request_funcs = {}\n </s> add         self.teardown_request_funcs = defaultdict(list) </s> remove         self.url_value_preprocessors = {}\n </s> add         self.url_value_preprocessors = defaultdict(list) </s> remove         self.error_handler_spec = {}\n </s> add         self.error_handler_spec = defaultdict(lambda: defaultdict(dict)) </s> remove         self.before_request_funcs = {}\n </s> add         self.before_request_funcs = defaultdict(list) </s> remove         funcs = self.url_default_functions.get(None, ())\n </s> add         funcs = self.url_default_functions[None] </s> remove         self.template_context_processors = {None: [_default_template_ctx_processor]}\n </s> add         self.template_context_processors = defaultdict(\n            list, {None: [_default_template_ctx_processor]}\n        )", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         The function will be called without any arguments. If it returns a\n <mask>         non-None value, the value is handled as if it was the return value from\n <mask>         the view, and further request handling is stopped.\n <mask>         \"\"\"\n <mask>         self.before_request_funcs.setdefault(None, []).append(f)\n <mask>         return f\n <mask> \n <mask>     @setupmethod\n <mask>     def after_request(self, f):\n <mask>         \"\"\"Register a function to be run after each request.\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.after_request_funcs.setdefault(None, []).append(f)\n </s> add         self.after_request_funcs[None].append(f) </s> remove         self.teardown_request_funcs.setdefault(None, []).append(f)\n </s> add         self.teardown_request_funcs[None].append(f) </s> remove         self.url_value_preprocessors.setdefault(None, []).append(f)\n </s> add         self.url_value_preprocessors[None].append(f) </s> remove         self.url_default_functions.setdefault(None, []).append(f)\n </s> add         self.url_default_functions[None].append(f) </s> remove         self.before_request_funcs = {}\n </s> add         self.before_request_funcs = defaultdict(list) </s> remove         self.url_value_preprocessors = {}\n </s> add         self.url_value_preprocessors = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         As of Flask 0.7 this function might not be executed at the end of the\n <mask>         request in case an unhandled exception occurred.\n <mask>         \"\"\"\n <mask>         self.after_request_funcs.setdefault(None, []).append(f)\n <mask>         return f\n <mask> \n <mask>     @setupmethod\n <mask>     def teardown_request(self, f):\n <mask>         \"\"\"Register a function to be run at the end of each request,\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.before_request_funcs.setdefault(None, []).append(f)\n </s> add         self.before_request_funcs[None].append(f) </s> remove         self.after_request_funcs = {}\n </s> add         self.after_request_funcs = defaultdict(list) </s> remove         self.error_handler_spec = {}\n </s> add         self.error_handler_spec = defaultdict(lambda: defaultdict(dict)) </s> remove         self.url_default_functions.setdefault(None, []).append(f)\n </s> add         self.url_default_functions[None].append(f) </s> remove         self.url_value_preprocessors.setdefault(None, []).append(f)\n </s> add         self.url_value_preprocessors[None].append(f) </s> remove         self.before_request_funcs = {}\n </s> add         self.before_request_funcs = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>            immediately.  Instead it will keep it alive so that the interactive\n <mask>            debugger can still access it.  This behavior can be controlled\n <mask>            by the ``PRESERVE_CONTEXT_ON_EXCEPTION`` configuration variable.\n <mask>         \"\"\"\n <mask>         self.teardown_request_funcs.setdefault(None, []).append(f)\n <mask>         return f\n <mask> \n <mask>     @setupmethod\n <mask>     def context_processor(self, f):\n <mask>         \"\"\"Registers a template context processor function.\"\"\"\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.before_request_funcs.setdefault(None, []).append(f)\n </s> add         self.before_request_funcs[None].append(f) </s> remove         self.after_request_funcs.setdefault(None, []).append(f)\n </s> add         self.after_request_funcs[None].append(f) </s> remove         self.url_default_functions.setdefault(None, []).append(f)\n </s> add         self.url_default_functions[None].append(f) </s> remove         self.url_value_preprocessors.setdefault(None, []).append(f)\n </s> add         self.url_value_preprocessors[None].append(f) </s> remove         self.teardown_request_funcs = {}\n </s> add         self.teardown_request_funcs = defaultdict(list) </s> remove         self.before_request_funcs = {}\n </s> add         self.before_request_funcs = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         The function is passed the endpoint name and values dict. The return\n <mask>         value is ignored.\n <mask>         \"\"\"\n <mask>         self.url_value_preprocessors.setdefault(None, []).append(f)\n <mask>         return f\n <mask> \n <mask>     @setupmethod\n <mask>     def url_defaults(self, f):\n <mask>         \"\"\"Callback function for URL defaults for all view functions of the\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.url_default_functions.setdefault(None, []).append(f)\n </s> add         self.url_default_functions[None].append(f) </s> remove         self.before_request_funcs.setdefault(None, []).append(f)\n </s> add         self.before_request_funcs[None].append(f) </s> remove         self.url_value_preprocessors = {}\n </s> add         self.url_value_preprocessors = defaultdict(list) </s> remove         self.after_request_funcs.setdefault(None, []).append(f)\n </s> add         self.after_request_funcs[None].append(f) </s> remove         self.before_request_funcs = {}\n </s> add         self.before_request_funcs = defaultdict(list) </s> remove         self.after_request_funcs = {}\n </s> add         self.after_request_funcs = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Callback function for URL defaults for all view functions of the\n <mask>         application.  It's called with the endpoint and values and should\n <mask>         update the values passed in place.\n <mask>         \"\"\"\n <mask>         self.url_default_functions.setdefault(None, []).append(f)\n <mask>         return f\n <mask> \n <mask>     @setupmethod\n <mask>     def errorhandler(self, code_or_exception):\n <mask>         \"\"\"Register a function to handle errors by code or exception class.\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.url_value_preprocessors.setdefault(None, []).append(f)\n </s> add         self.url_value_preprocessors[None].append(f) </s> remove         self.after_request_funcs.setdefault(None, []).append(f)\n </s> add         self.after_request_funcs[None].append(f) </s> remove         self.before_request_funcs.setdefault(None, []).append(f)\n </s> add         self.before_request_funcs[None].append(f) </s> remove         handlers = self.error_handler_spec.setdefault(key, {}).setdefault(code, {})\n        handlers[exc_class] = f\n </s> add         self.error_handler_spec[key][code][exc_class] = f </s> remove         self.before_request_funcs = {}\n </s> add         self.before_request_funcs = defaultdict(list) </s> remove         self.teardown_request_funcs.setdefault(None, []).append(f)\n </s> add         self.teardown_request_funcs[None].append(f)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 \" code. Use a subclass of HTTPException with that code\"\n <mask>                 \" instead.\"\n <mask>             )\n <mask> \n <mask>         handlers = self.error_handler_spec.setdefault(key, {}).setdefault(code, {})\n <mask>         handlers[exc_class] = f\n <mask> \n <mask>     @staticmethod\n <mask>     def _get_exc_class_and_code(exc_class_or_code):\n <mask>         \"\"\"Get the exception class being handled. For HTTP status codes\n <mask>         or ``HTTPException`` subclasses, return both the exception and\n </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.url_default_functions.setdefault(None, []).append(f)\n </s> add         self.url_default_functions[None].append(f) </s> remove         self.after_request_funcs.setdefault(None, []).append(f)\n </s> add         self.after_request_funcs[None].append(f) </s> remove         self.template_context_processors = {None: [_default_template_ctx_processor]}\n </s> add         self.template_context_processors = defaultdict(\n            list, {None: [_default_template_ctx_processor]}\n        ) </s> remove         self.after_request_funcs = {}\n </s> add         self.after_request_funcs = defaultdict(list) </s> remove         self.error_handler_spec = {}\n </s> add         self.error_handler_spec = defaultdict(lambda: defaultdict(dict)) </s> remove         self.before_request_funcs = {}\n </s> add         self.before_request_funcs = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>   behaviour for `OPTIONS` responses.\n <mask> - Unbound locals now raise a proper :exc:`RuntimeError` instead\n <mask>   of an :exc:`AttributeError`.\n <mask> \n <mask> Version 0.6.1\n <mask> -------------\n <mask> \n <mask> Bugfix release, release date to be announced.\n <mask> \n </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> add     .. versionchanged:: 0.7\n       mimetype guessing and etag support for file objects was\n       deprecated because it was unreliable.  Pass a filename if you are\n       able to, otherwise attach an etag yourself.  This functionality\n       will be removed in Flask 1.0\n </s> add         # XXX: this behaviour is now deprecated because it was unreliable.\n        # removed in Flask 1.0\n        if not attachment_filename and not mimetype \\\n           and isinstance(filename, basestring):\n            warn(DeprecationWarning('The filename support for file objects '\n                'passed to send_file is not deprecated.  Pass an '\n                'attach_filename if you want mimetypes to be guessed.'),\n                stacklevel=2)\n        if add_etags:\n            warn(DeprecationWarning('In future flask releases etags will no '\n                'longer be generated for file objects passed to the send_file '\n                'function because this behaviour was unreliable.  Pass '\n                'filenames instead if possible, otherwise attach an etag '\n                'yourself based on another value'), stacklevel=2)\n </s> remove     to sent certain files as attachment (HTML for instance).\n </s> add     to sent certain files as attachment (HTML for instance).  The mimetype\n    guessing requires a `filename` or an `attachment_filename` to be\n    provided. </s> add         from warnings import warn </s> add     \"\"\"Catch stderr in a StringIO\"\"\" </s> remove                                  attachment_filename='index.txt')\n </s> add                                  attachment_filename='index.txt',\n                                 add_etags=False)", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     requires support of the underlying webserver for `X-Sendfile`.\n <mask> \n <mask>     By default it will try to guess the mimetype for you, but you can\n <mask>     also explicitly provide one.  For extra security you probably want\n <mask>     to sent certain files as attachment (HTML for instance).\n <mask> \n <mask>     Please never pass filenames to this function from user sources without\n <mask>     checking them first.  Something like this is usually sufficient to\n <mask>     avoid security problems::\n <mask> \n </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> add     .. versionchanged:: 0.7\n       mimetype guessing and etag support for file objects was\n       deprecated because it was unreliable.  Pass a filename if you are\n       able to, otherwise attach an etag yourself.  This functionality\n       will be removed in Flask 1.0\n </s> add         # XXX: this behaviour is now deprecated because it was unreliable.\n        # removed in Flask 1.0\n        if not attachment_filename and not mimetype \\\n           and isinstance(filename, basestring):\n            warn(DeprecationWarning('The filename support for file objects '\n                'passed to send_file is not deprecated.  Pass an '\n                'attach_filename if you want mimetypes to be guessed.'),\n                stacklevel=2)\n        if add_etags:\n            warn(DeprecationWarning('In future flask releases etags will no '\n                'longer be generated for file objects passed to the send_file '\n                'function because this behaviour was unreliable.  Pass '\n                'filenames instead if possible, otherwise attach an etag '\n                'yourself based on another value'), stacklevel=2)\n </s> add - Mimetype guessing and etag support based on file objects is now\n  deprecated for :func:`flask.send_file` because it was unreliable.\n  Pass filenames instead or attach your own etags and provide a\n  proper mimetype by hand. </s> add         from warnings import warn </s> remove                                  attachment_filename='index.txt')\n </s> add                                  attachment_filename='index.txt',\n                                 add_etags=False) </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f, as_attachment=True)\n            value, options = parse_options_header(rv.headers['Content-Disposition'])\n            assert value == 'attachment'\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f, as_attachment=True)\n                value, options = parse_options_header(rv.headers['Content-Disposition'])\n                assert value == 'attachment'\n            # mimetypes + etag\n            assert len(captured) == 2", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>     .. versionadded:: 0.5\n <mask>        The `add_etags`, `cache_timeout` and `conditional` parameters were\n <mask>        added.  The default behaviour is now to attach etags.\n <mask> \n <mask>     :param filename_or_fp: the filename of the file to send.  This is\n <mask>                            relative to the :attr:`~Flask.root_path` if a\n <mask>                            relative path is specified.\n <mask>                            Alternatively a file object might be provided\n <mask>                            in which case `X-Sendfile` might not work and\n </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> add         # XXX: this behaviour is now deprecated because it was unreliable.\n        # removed in Flask 1.0\n        if not attachment_filename and not mimetype \\\n           and isinstance(filename, basestring):\n            warn(DeprecationWarning('The filename support for file objects '\n                'passed to send_file is not deprecated.  Pass an '\n                'attach_filename if you want mimetypes to be guessed.'),\n                stacklevel=2)\n        if add_etags:\n            warn(DeprecationWarning('In future flask releases etags will no '\n                'longer be generated for file objects passed to the send_file '\n                'function because this behaviour was unreliable.  Pass '\n                'filenames instead if possible, otherwise attach an etag '\n                'yourself based on another value'), stacklevel=2)\n </s> remove     to sent certain files as attachment (HTML for instance).\n </s> add     to sent certain files as attachment (HTML for instance).  The mimetype\n    guessing requires a `filename` or an `attachment_filename` to be\n    provided. </s> add - Mimetype guessing and etag support based on file objects is now\n  deprecated for :func:`flask.send_file` because it was unreliable.\n  Pass filenames instead or attach your own etags and provide a\n  proper mimetype by hand. </s> add         from warnings import warn </s> add     \"\"\"Catch stderr in a StringIO\"\"\" </s> remove         with app.test_request_context():\n            f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert 'x-sendfile' not in rv.headers\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert 'x-sendfile' not in rv.headers\n            # etags\n            assert len(captured) == 1", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         filename = filename_or_fp\n <mask>         file = None\n <mask>     else:\n <mask>         file = filename_or_fp\n <mask>         filename = getattr(file, 'name', None)\n <mask> \n <mask>         # XXX: this behaviour is now deprecated because it was unreliable.\n <mask>         # removed in Flask 1.0\n <mask>         if not attachment_filename and not mimetype \\\n </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> add         # XXX: this behaviour is now deprecated because it was unreliable.\n        # removed in Flask 1.0\n        if not attachment_filename and not mimetype \\\n           and isinstance(filename, basestring):\n            warn(DeprecationWarning('The filename support for file objects '\n                'passed to send_file is not deprecated.  Pass an '\n                'attach_filename if you want mimetypes to be guessed.'),\n                stacklevel=2)\n        if add_etags:\n            warn(DeprecationWarning('In future flask releases etags will no '\n                'longer be generated for file objects passed to the send_file '\n                'function because this behaviour was unreliable.  Pass '\n                'filenames instead if possible, otherwise attach an etag '\n                'yourself based on another value'), stacklevel=2)\n </s> add     .. versionchanged:: 0.7\n       mimetype guessing and etag support for file objects was\n       deprecated because it was unreliable.  Pass a filename if you are\n       able to, otherwise attach an etag yourself.  This functionality\n       will be removed in Flask 1.0\n </s> add - Mimetype guessing and etag support based on file objects is now\n  deprecated for :func:`flask.send_file` because it was unreliable.\n  Pass filenames instead or attach your own etags and provide a\n  proper mimetype by hand. </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            assert rv.mimetype == 'text/html'\n            assert 'x-sendfile' in rv.headers\n            assert rv.headers['x-sendfile'] == \\\n                os.path.join(app.root_path, 'static/index.html')\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                assert rv.mimetype == 'text/html'\n                assert 'x-sendfile' in rv.headers\n                assert rv.headers['x-sendfile'] == \\\n                    os.path.join(app.root_path, 'static/index.html')\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove         with app.test_request_context():\n            f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert 'x-sendfile' not in rv.headers\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert 'x-sendfile' not in rv.headers\n            # etags\n            assert len(captured) == 1 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f, as_attachment=True)\n            value, options = parse_options_header(rv.headers['Content-Disposition'])\n            assert value == 'attachment'\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f, as_attachment=True)\n                value, options = parse_options_header(rv.headers['Content-Disposition'])\n                assert value == 'attachment'\n            # mimetypes + etag\n            assert len(captured) == 2", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         from warnings import warn\n <mask>         file = filename_or_fp\n <mask>         filename = getattr(file, 'name', None)\n <mask>     if filename is not None:\n <mask>         if not os.path.isabs(filename):\n <mask>             filename = os.path.join(current_app.root_path, filename)\n <mask>     if mimetype is None and (filename or attachment_filename):\n <mask>         mimetype = mimetypes.guess_type(filename or attachment_filename)[0]\n </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> add         from warnings import warn </s> add     .. versionchanged:: 0.7\n       mimetype guessing and etag support for file objects was\n       deprecated because it was unreliable.  Pass a filename if you are\n       able to, otherwise attach an etag yourself.  This functionality\n       will be removed in Flask 1.0\n </s> add - Mimetype guessing and etag support based on file objects is now\n  deprecated for :func:`flask.send_file` because it was unreliable.\n  Pass filenames instead or attach your own etags and provide a\n  proper mimetype by hand. </s> remove         with app.test_request_context():\n            f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert 'x-sendfile' not in rv.headers\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert 'x-sendfile' not in rv.headers\n            # etags\n            assert len(captured) == 1 </s> remove     to sent certain files as attachment (HTML for instance).\n </s> add     to sent certain files as attachment (HTML for instance).  The mimetype\n    guessing requires a `filename` or an `attachment_filename` to be\n    provided. </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f, as_attachment=True)\n            value, options = parse_options_header(rv.headers['Content-Disposition'])\n            assert value == 'attachment'\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f, as_attachment=True)\n                value, options = parse_options_header(rv.headers['Content-Disposition'])\n                assert value == 'attachment'\n            # mimetypes + etag\n            assert len(captured) == 2", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> @contextmanager\n <mask> def catch_stderr():\n <mask>     old_stderr = sys.stderr\n <mask>     sys.stderr = rv = StringIO()\n <mask>     try:\n <mask>         yield rv\n </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f, as_attachment=True)\n            value, options = parse_options_header(rv.headers['Content-Disposition'])\n            assert value == 'attachment'\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f, as_attachment=True)\n                value, options = parse_options_header(rv.headers['Content-Disposition'])\n                assert value == 'attachment'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            with app.open_resource('static/index.html') as f:\n                assert rv.data == f.read()\n            assert rv.mimetype == 'text/html'\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                with app.open_resource('static/index.html') as f:\n                    assert rv.data == f.read()\n                assert rv.mimetype == 'text/html'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove         with app.test_request_context():\n            f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert 'x-sendfile' not in rv.headers\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert 'x-sendfile' not in rv.headers\n            # etags\n            assert len(captured) == 1 </s> remove             f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'application/octet-stream'\n            f = StringIO('Test')\n            rv = flask.send_file(f, mimetype='text/plain')\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'text/plain'\n </s> add             with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'application/octet-stream'\n            # etags\n            assert len(captured) == 1\n            with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f, mimetype='text/plain')\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'text/plain'\n            # etags\n            assert len(captured) == 1 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            assert rv.mimetype == 'text/html'\n            assert 'x-sendfile' in rv.headers\n            assert rv.headers['x-sendfile'] == \\\n                os.path.join(app.root_path, 'static/index.html')\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                assert rv.mimetype == 'text/html'\n                assert 'x-sendfile' in rv.headers\n                assert rv.headers['x-sendfile'] == \\\n                    os.path.join(app.root_path, 'static/index.html')\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove                                  attachment_filename='index.txt')\n </s> add                                  attachment_filename='index.txt',\n                                 add_etags=False)", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep replace replace replace replace replace replace replace keep", "code_tokens": " <mask>             assert rv.mimetype == 'text/html'\n <mask> \n <mask>     def test_send_file_object(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         with app.test_request_context():\n <mask>             f = open(os.path.join(app.root_path, 'static/index.html'))\n <mask>             rv = flask.send_file(f)\n <mask>             with app.open_resource('static/index.html') as f:\n <mask>                 assert rv.data == f.read()\n <mask>             assert rv.mimetype == 'text/html'\n <mask> \n <mask>         app.use_x_sendfile = True\n <mask>         with app.test_request_context():\n <mask>             f = open(os.path.join(app.root_path, 'static/index.html'))\n <mask>             rv = flask.send_file(f)\n <mask>             assert rv.mimetype == 'text/html'\n <mask>             assert 'x-sendfile' in rv.headers\n <mask>             assert rv.headers['x-sendfile'] == \\\n <mask>                 os.path.join(app.root_path, 'static/index.html')\n <mask> \n </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> remove         with app.test_request_context():\n            f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert 'x-sendfile' not in rv.headers\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert 'x-sendfile' not in rv.headers\n            # etags\n            assert len(captured) == 1 </s> remove             f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'application/octet-stream'\n            f = StringIO('Test')\n            rv = flask.send_file(f, mimetype='text/plain')\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'text/plain'\n </s> add             with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'application/octet-stream'\n            # etags\n            assert len(captured) == 1\n            with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f, mimetype='text/plain')\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'text/plain'\n            # etags\n            assert len(captured) == 1 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f, as_attachment=True)\n            value, options = parse_options_header(rv.headers['Content-Disposition'])\n            assert value == 'attachment'\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f, as_attachment=True)\n                value, options = parse_options_header(rv.headers['Content-Disposition'])\n                assert value == 'attachment'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> add     \"\"\"Catch stderr in a StringIO\"\"\" </s> remove                                  attachment_filename='index.txt')\n </s> add                                  attachment_filename='index.txt',\n                                 add_etags=False)", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace replace replace keep keep replace replace replace replace keep keep", "code_tokens": " <mask>         app.use_x_sendfile = False\n <mask>         with app.test_request_context():\n <mask>             f = StringIO('Test')\n <mask>             rv = flask.send_file(f)\n <mask>             assert rv.data == 'Test'\n <mask>             assert rv.mimetype == 'application/octet-stream'\n <mask>             f = StringIO('Test')\n <mask>             rv = flask.send_file(f, mimetype='text/plain')\n <mask>             assert rv.data == 'Test'\n <mask>             assert rv.mimetype == 'text/plain'\n <mask> \n <mask>         app.use_x_sendfile = True\n <mask>         with app.test_request_context():\n <mask>             f = StringIO('Test')\n <mask>             rv = flask.send_file(f)\n <mask>             assert 'x-sendfile' not in rv.headers\n <mask> \n <mask>     def test_attachment(self):\n </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            assert rv.mimetype == 'text/html'\n            assert 'x-sendfile' in rv.headers\n            assert rv.headers['x-sendfile'] == \\\n                os.path.join(app.root_path, 'static/index.html')\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                assert rv.mimetype == 'text/html'\n                assert 'x-sendfile' in rv.headers\n                assert rv.headers['x-sendfile'] == \\\n                    os.path.join(app.root_path, 'static/index.html')\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            with app.open_resource('static/index.html') as f:\n                assert rv.data == f.read()\n            assert rv.mimetype == 'text/html'\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                with app.open_resource('static/index.html') as f:\n                    assert rv.data == f.read()\n                assert rv.mimetype == 'text/html'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f, as_attachment=True)\n            value, options = parse_options_header(rv.headers['Content-Disposition'])\n            assert value == 'attachment'\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f, as_attachment=True)\n                value, options = parse_options_header(rv.headers['Content-Disposition'])\n                assert value == 'attachment'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> add     \"\"\"Catch stderr in a StringIO\"\"\" </s> remove                                  attachment_filename='index.txt')\n </s> add                                  attachment_filename='index.txt',\n                                 add_etags=False)", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             assert 'x-sendfile' not in rv.headers\n <mask> \n <mask>     def test_attachment(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         with app.test_request_context():\n <mask>             f = open(os.path.join(app.root_path, 'static/index.html'))\n <mask>             rv = flask.send_file(f, as_attachment=True)\n <mask>             value, options = parse_options_header(rv.headers['Content-Disposition'])\n <mask>             assert value == 'attachment'\n <mask> \n <mask>         with app.test_request_context():\n <mask>             assert options['filename'] == 'index.html'\n <mask>             rv = flask.send_file('static/index.html', as_attachment=True)\n <mask>             value, options = parse_options_header(rv.headers['Content-Disposition'])\n </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> remove                                  attachment_filename='index.txt')\n </s> add                                  attachment_filename='index.txt',\n                                 add_etags=False) </s> remove         with app.test_request_context():\n            f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert 'x-sendfile' not in rv.headers\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert 'x-sendfile' not in rv.headers\n            # etags\n            assert len(captured) == 1 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            assert rv.mimetype == 'text/html'\n            assert 'x-sendfile' in rv.headers\n            assert rv.headers['x-sendfile'] == \\\n                os.path.join(app.root_path, 'static/index.html')\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                assert rv.mimetype == 'text/html'\n                assert 'x-sendfile' in rv.headers\n                assert rv.headers['x-sendfile'] == \\\n                    os.path.join(app.root_path, 'static/index.html')\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            with app.open_resource('static/index.html') as f:\n                assert rv.data == f.read()\n            assert rv.mimetype == 'text/html'\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                with app.open_resource('static/index.html') as f:\n                    assert rv.data == f.read()\n                assert rv.mimetype == 'text/html'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove             f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'application/octet-stream'\n            f = StringIO('Test')\n            rv = flask.send_file(f, mimetype='text/plain')\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'text/plain'\n </s> add             with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'application/octet-stream'\n            # etags\n            assert len(captured) == 1\n            with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f, mimetype='text/plain')\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'text/plain'\n            # etags\n            assert len(captured) == 1 </s> add     \"\"\"Catch stderr in a StringIO\"\"\"", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             assert options['filename'] == 'index.html'\n <mask> \n <mask>         with app.test_request_context():\n <mask>             rv = flask.send_file(StringIO('Test'), as_attachment=True,\n <mask>                                  attachment_filename='index.txt')\n <mask>             assert rv.mimetype == 'text/plain'\n <mask>             value, options = parse_options_header(rv.headers['Content-Disposition'])\n <mask>             assert value == 'attachment'\n <mask>             assert options['filename'] == 'index.txt'\n <mask> \n </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f, as_attachment=True)\n            value, options = parse_options_header(rv.headers['Content-Disposition'])\n            assert value == 'attachment'\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f, as_attachment=True)\n                value, options = parse_options_header(rv.headers['Content-Disposition'])\n                assert value == 'attachment'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove             f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'application/octet-stream'\n            f = StringIO('Test')\n            rv = flask.send_file(f, mimetype='text/plain')\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'text/plain'\n </s> add             with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'application/octet-stream'\n            # etags\n            assert len(captured) == 1\n            with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f, mimetype='text/plain')\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'text/plain'\n            # etags\n            assert len(captured) == 1 </s> remove         with app.test_request_context():\n            f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert 'x-sendfile' not in rv.headers\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert 'x-sendfile' not in rv.headers\n            # etags\n            assert len(captured) == 1 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            with app.open_resource('static/index.html') as f:\n                assert rv.data == f.read()\n            assert rv.mimetype == 'text/html'\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                with app.open_resource('static/index.html') as f:\n                    assert rv.data == f.read()\n                assert rv.mimetype == 'text/html'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            assert rv.mimetype == 'text/html'\n            assert 'x-sendfile' in rv.headers\n            assert rv.headers['x-sendfile'] == \\\n                os.path.join(app.root_path, 'static/index.html')\n </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                assert rv.mimetype == 'text/html'\n                assert 'x-sendfile' in rv.headers\n                assert rv.headers['x-sendfile'] == \\\n                    os.path.join(app.root_path, 'static/index.html')\n            # mimetypes + etag\n            assert len(captured) == 2 </s> add     \"\"\"Catch stderr in a StringIO\"\"\"", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> Unreleased\n <mask> \n <mask> -   Refactor ``register_error_handler`` to consolidate error checking.\n <mask>     Rewrite some error messages to be more consistent. :issue:`4559`\n <mask> \n <mask> \n <mask> Version 2.1.2\n </s> add redirect method to app </s> add def test_redirect_no_app():\n    response = flask.redirect(\"https://localhost\", 307)\n    assert response.location == \"https://localhost\"\n    assert response.status_code == 307\n\n\ndef test_redirect_with_app(app):\n    def redirect(location, code=302):\n        raise ValueError\n\n    app.redirect = redirect\n\n    with app.app_context(), pytest.raises(ValueError):\n        flask.redirect(\"other\")\n\n </s> add     def redirect(self, location: str, code: int = 302) -> BaseResponse:\n        \"\"\"Create a redirect response object.\n\n        :param location: the url of the redirect\n        :param code: http return code\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return _wz_redirect(location, code=code, Response=self.response_class)\n </s> add     from werkzeug.wrappers import Response as BaseResponse </s> add from werkzeug.utils import redirect as _wz_redirect </s> add from werkzeug.utils import redirect as _wz_redirect </s> add from .helpers import redirect as redirect", "html_url": "https://github.com/pallets/flask/commit/fdab801fbbd9de5adbdb3320ca4a1cb116c892f5", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from markupsafe import escape\n <mask> from markupsafe import Markup\n <mask> from werkzeug.exceptions import abort as abort\n <mask> from werkzeug.utils import redirect as redirect\n <mask> \n <mask> from . import json as json\n <mask> from .app import Flask as Flask\n <mask> from .app import Request as Request\n <mask> from .app import Response as Response\n </s> add redirect method to app </s> add from werkzeug.utils import redirect as _wz_redirect </s> add from .helpers import redirect as redirect </s> add from werkzeug.utils import redirect as _wz_redirect </s> add     from werkzeug.wrappers import Response as BaseResponse </s> add def test_redirect_no_app():\n    response = flask.redirect(\"https://localhost\", 307)\n    assert response.location == \"https://localhost\"\n    assert response.status_code == 307\n\n\ndef test_redirect_with_app(app):\n    def redirect(location, code=302):\n        raise ValueError\n\n    app.redirect = redirect\n\n    with app.app_context(), pytest.raises(ValueError):\n        flask.redirect(\"other\")\n\n </s> add     def redirect(self, location: str, code: int = 302) -> BaseResponse:\n        \"\"\"Create a redirect response object.\n\n        :param location: the url of the redirect\n        :param code: http return code\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return _wz_redirect(location, code=code, Response=self.response_class)\n", "html_url": "https://github.com/pallets/flask/commit/fdab801fbbd9de5adbdb3320ca4a1cb116c892f5", "file_name": "src/flask/__init__.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> from .helpers import get_flashed_messages as get_flashed_messages\n <mask> from .helpers import get_template_attribute as get_template_attribute\n <mask> from .helpers import make_response as make_response\n <mask> from .helpers import send_file as send_file\n <mask> from .helpers import send_from_directory as send_from_directory\n <mask> from .helpers import stream_with_context as stream_with_context\n <mask> from .helpers import url_for as url_for\n </s> add redirect method to app </s> remove from werkzeug.utils import redirect as redirect\n </s> add  </s> add from werkzeug.utils import redirect as _wz_redirect </s> add from werkzeug.utils import redirect as _wz_redirect </s> add     from werkzeug.wrappers import Response as BaseResponse </s> add     def redirect(self, location: str, code: int = 302) -> BaseResponse:\n        \"\"\"Create a redirect response object.\n\n        :param location: the url of the redirect\n        :param code: http return code\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return _wz_redirect(location, code=code, Response=self.response_class)\n </s> add def test_redirect_no_app():\n    response = flask.redirect(\"https://localhost\", 307)\n    assert response.location == \"https://localhost\"\n    assert response.status_code == 307\n\n\ndef test_redirect_with_app(app):\n    def redirect(location, code=302):\n        raise ValueError\n\n    app.redirect = redirect\n\n    with app.app_context(), pytest.raises(ValueError):\n        flask.redirect(\"other\")\n\n", "html_url": "https://github.com/pallets/flask/commit/fdab801fbbd9de5adbdb3320ca4a1cb116c892f5", "file_name": "src/flask/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> from werkzeug.routing import RoutingException\n <mask> from werkzeug.routing import Rule\n <mask> from werkzeug.wrappers import Response as BaseResponse\n <mask> \n <mask> from . import cli\n <mask> from . import json\n <mask> from .config import Config\n </s> add redirect method to app </s> remove from werkzeug.utils import redirect as redirect\n </s> add  </s> add from werkzeug.utils import redirect as _wz_redirect </s> add     from werkzeug.wrappers import Response as BaseResponse </s> add from .helpers import redirect as redirect </s> add     def redirect(self, location: str, code: int = 302) -> BaseResponse:\n        \"\"\"Create a redirect response object.\n\n        :param location: the url of the redirect\n        :param code: http return code\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return _wz_redirect(location, code=code, Response=self.response_class)\n </s> add def test_redirect_no_app():\n    response = flask.redirect(\"https://localhost\", 307)\n    assert response.location == \"https://localhost\"\n    assert response.status_code == 307\n\n\ndef test_redirect_with_app(app):\n    def redirect(location, code=302):\n        raise ValueError\n\n    app.redirect = redirect\n\n    with app.app_context(), pytest.raises(ValueError):\n        flask.redirect(\"other\")\n\n", "html_url": "https://github.com/pallets/flask/commit/fdab801fbbd9de5adbdb3320ca4a1cb116c892f5", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>             ) from None\n <mask> \n <mask>         return asgiref_async_to_sync(func)\n <mask> \n <mask>     def make_response(self, rv: ResponseReturnValue) -> Response:\n <mask>         \"\"\"Convert the return value from a view function to an instance of\n <mask>         :attr:`response_class`.\n <mask> \n <mask>         :param rv: the return value from the view function. The view function\n <mask>             must return a response. Returning ``None``, or the view ending\n </s> add redirect method to app </s> add     from werkzeug.wrappers import Response as BaseResponse </s> add def test_redirect_no_app():\n    response = flask.redirect(\"https://localhost\", 307)\n    assert response.location == \"https://localhost\"\n    assert response.status_code == 307\n\n\ndef test_redirect_with_app(app):\n    def redirect(location, code=302):\n        raise ValueError\n\n    app.redirect = redirect\n\n    with app.app_context(), pytest.raises(ValueError):\n        flask.redirect(\"other\")\n\n </s> add from werkzeug.utils import redirect as _wz_redirect </s> add from werkzeug.utils import redirect as _wz_redirect </s> remove from werkzeug.utils import redirect as redirect\n </s> add  </s> add from .helpers import redirect as redirect", "html_url": "https://github.com/pallets/flask/commit/fdab801fbbd9de5adbdb3320ca4a1cb116c892f5", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> from werkzeug.routing import BuildError\n <mask> from werkzeug.urls import url_quote\n <mask> \n <mask> from .globals import _app_ctx_stack\n <mask> from .globals import _request_ctx_stack\n <mask> from .globals import current_app\n <mask> from .globals import request\n </s> add redirect method to app </s> add from werkzeug.utils import redirect as _wz_redirect </s> remove from werkzeug.utils import redirect as redirect\n </s> add  </s> add from .helpers import redirect as redirect </s> add     from werkzeug.wrappers import Response as BaseResponse </s> add     def redirect(self, location: str, code: int = 302) -> BaseResponse:\n        \"\"\"Create a redirect response object.\n\n        :param location: the url of the redirect\n        :param code: http return code\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return _wz_redirect(location, code=code, Response=self.response_class)\n </s> add def test_redirect_no_app():\n    response = flask.redirect(\"https://localhost\", 307)\n    assert response.location == \"https://localhost\"\n    assert response.status_code == 307\n\n\ndef test_redirect_with_app(app):\n    def redirect(location, code=302):\n        raise ValueError\n\n    app.redirect = redirect\n\n    with app.app_context(), pytest.raises(ValueError):\n        flask.redirect(\"other\")\n\n", "html_url": "https://github.com/pallets/flask/commit/fdab801fbbd9de5adbdb3320ca4a1cb116c892f5", "file_name": "src/flask/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> if t.TYPE_CHECKING:  # pragma: no cover\n <mask>     from .wrappers import Response\n <mask> \n <mask> \n <mask> def get_env() -> str:\n <mask>     \"\"\"Get the environment the app is running in, indicated by the\n </s> add redirect method to app </s> add     def redirect(self, location: str, code: int = 302) -> BaseResponse:\n        \"\"\"Create a redirect response object.\n\n        :param location: the url of the redirect\n        :param code: http return code\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return _wz_redirect(location, code=code, Response=self.response_class)\n </s> remove from werkzeug.utils import redirect as redirect\n </s> add  </s> add from werkzeug.utils import redirect as _wz_redirect </s> add def test_redirect_no_app():\n    response = flask.redirect(\"https://localhost\", 307)\n    assert response.location == \"https://localhost\"\n    assert response.status_code == 307\n\n\ndef test_redirect_with_app(app):\n    def redirect(location, code=302):\n        raise ValueError\n\n    app.redirect = redirect\n\n    with app.app_context(), pytest.raises(ValueError):\n        flask.redirect(\"other\")\n\n </s> add from werkzeug.utils import redirect as _wz_redirect </s> add from .helpers import redirect as redirect", "html_url": "https://github.com/pallets/flask/commit/fdab801fbbd9de5adbdb3320ca4a1cb116c892f5", "file_name": "src/flask/helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         assert flask.url_for(\"myview\", _method=\"POST\") == \"/myview/create\"\n <mask> \n <mask> \n <mask> class TestNoImports:\n <mask>     \"\"\"Test Flasks are created without import.\n <mask> \n <mask>     Avoiding ``__import__`` helps create Flask instances where there are errors\n <mask>     at import time.  Those runtime errors will be apparent to the user soon\n <mask>     enough, but tools which build Flask instances meta-programmatically benefit\n </s> add redirect method to app </s> add -   Add an ``app.redirect`` method, which ``flask.redirect`` will call.\n    This makes it possible for an app to override how redirects work.\n    :issue:`4569` </s> remove from werkzeug.utils import redirect as redirect\n </s> add  </s> add     from werkzeug.wrappers import Response as BaseResponse </s> add     def redirect(self, location: str, code: int = 302) -> BaseResponse:\n        \"\"\"Create a redirect response object.\n\n        :param location: the url of the redirect\n        :param code: http return code\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return _wz_redirect(location, code=code, Response=self.response_class)\n </s> add from werkzeug.utils import redirect as _wz_redirect </s> add from werkzeug.utils import redirect as _wz_redirect", "html_url": "https://github.com/pallets/flask/commit/fdab801fbbd9de5adbdb3320ca4a1cb116c892f5", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         app = flask.Flask(__name__, instance_path=here)\n <mask>         self.assert_equal(app.instance_path, here)\n <mask> \n <mask>     def test_uninstalled_module_paths(self):\n <mask>         from config_module_app import app\n <mask>         here = os.path.abspath(os.path.dirname(__file__))\n <mask>         self.assert_equal(app.instance_path, os.path.join(here, 'test_apps', 'instance'))\n <mask> \n <mask>     def test_uninstalled_package_paths(self):\n </s> Update tests for new module helpers. </s> remove         import types\n        expected_prefix = os.path.abspath('foo')\n        mod = types.ModuleType('myapp')\n        mod.__file__ = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp.py')\n        sys.modules['myapp'] = mod\n </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        sys.path.append(site_packages) </s> remove         import types\n        expected_prefix = os.path.abspath('foo')\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod\n </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        installed_path = os.path.join(expected_prefix, 'path')\n        sys.path.append(installed_path) </s> remove             sys.modules['myapp'] = None\n\n    def test_prefix_installed_paths(self):\n        import types\n        expected_prefix = os.path.abspath(sys.prefix)\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod\n </s> add             sys.prefix = real_prefix\n            sys.path.remove(installed_path)\n            if 'installed_package' in sys.modules:\n                del sys.modules['installed_package']\n\n    def test_prefix_package_paths(self):\n        here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        sys.path.append(site_packages) </s> remove         import types\n        expected_prefix = os.path.abspath(sys.prefix)\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'MyApp.egg', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod\n </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        egg_path = os.path.join(site_packages, 'SiteEgg.egg')\n        sys.path.append(site_packages)\n        sys.path.append(egg_path) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance'))\n </s> add             import site_package\n            self.assert_equal(site_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_package-instance')) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance'))\n </s> add             import installed_package\n            self.assert_equal(installed_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'installed_package-instance'))", "html_url": "https://github.com/pallets/flask/commit/fde6e364a497cd44d049df17c93d1fd05ec09f90", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace keep replace replace replace replace", "code_tokens": " <mask> \n <mask>     def test_installed_module_paths(self):\n <mask>         import types\n <mask>         expected_prefix = os.path.abspath('foo')\n <mask>         mod = types.ModuleType('myapp')\n <mask>         mod.__file__ = os.path.join(expected_prefix, 'lib', 'python2.5',\n <mask>                                     'site-packages', 'myapp.py')\n <mask>         sys.modules['myapp'] = mod\n <mask>         try:\n <mask>             mod.app = flask.Flask(mod.__name__)\n <mask>             self.assert_equal(mod.app.instance_path,\n <mask>                              os.path.join(expected_prefix, 'var',\n <mask>                                           'myapp-instance'))\n </s> Update tests for new module helpers. </s> remove         import types\n        expected_prefix = os.path.abspath('foo')\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod\n </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        installed_path = os.path.join(expected_prefix, 'path')\n        sys.path.append(installed_path) </s> remove             sys.modules['myapp'] = None\n\n    def test_prefix_installed_paths(self):\n        import types\n        expected_prefix = os.path.abspath(sys.prefix)\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod\n </s> add             sys.prefix = real_prefix\n            sys.path.remove(installed_path)\n            if 'installed_package' in sys.modules:\n                del sys.modules['installed_package']\n\n    def test_prefix_package_paths(self):\n        here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        sys.path.append(site_packages) </s> remove         import types\n        expected_prefix = os.path.abspath(sys.prefix)\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'MyApp.egg', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod\n </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        egg_path = os.path.join(site_packages, 'SiteEgg.egg')\n        sys.path.append(site_packages)\n        sys.path.append(egg_path) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance'))\n </s> add             import site_package\n            self.assert_equal(site_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_package-instance')) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance'))\n </s> add             import installed_package\n            self.assert_equal(installed_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'installed_package-instance'))", "html_url": "https://github.com/pallets/flask/commit/fde6e364a497cd44d049df17c93d1fd05ec09f90", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace replace replace replace replace replace replace replace keep", "code_tokens": " <mask>                              os.path.join(expected_prefix, 'var',\n <mask>                                           'myapp-instance'))\n <mask>         finally:\n <mask>             sys.modules['myapp'] = None\n <mask> \n <mask>     def test_installed_package_paths(self):\n <mask>         import types\n <mask>         expected_prefix = os.path.abspath('foo')\n <mask>         package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n <mask>                                     'site-packages', 'myapp')\n <mask>         mod = types.ModuleType('myapp')\n <mask>         mod.__path__ = [package_path]\n <mask>         mod.__file__ = os.path.join(package_path, '__init__.py')\n <mask>         sys.modules['myapp'] = mod\n <mask>         try:\n </s> Update tests for new module helpers. </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance'))\n </s> add             import site_app\n            self.assert_equal(site_app.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_app-instance')) </s> remove         import types\n        expected_prefix = os.path.abspath(sys.prefix)\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'MyApp.egg', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod\n </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        egg_path = os.path.join(site_packages, 'SiteEgg.egg')\n        sys.path.append(site_packages)\n        sys.path.append(egg_path) </s> remove             sys.modules['myapp'] = None\n\n    def test_prefix_installed_paths(self):\n        import types\n        expected_prefix = os.path.abspath(sys.prefix)\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod\n </s> add             sys.prefix = real_prefix\n            sys.path.remove(installed_path)\n            if 'installed_package' in sys.modules:\n                del sys.modules['installed_package']\n\n    def test_prefix_package_paths(self):\n        here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        sys.path.append(site_packages) </s> remove         import types\n        expected_prefix = os.path.abspath('foo')\n        mod = types.ModuleType('myapp')\n        mod.__file__ = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp.py')\n        sys.modules['myapp'] = mod\n </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        sys.path.append(site_packages) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance'))\n </s> add             import site_package\n            self.assert_equal(site_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_package-instance'))", "html_url": "https://github.com/pallets/flask/commit/fde6e364a497cd44d049df17c93d1fd05ec09f90", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace keep replace replace replace replace replace replace replace replace replace replace replace keep keep", "code_tokens": " <mask>         mod.__file__ = os.path.join(package_path, '__init__.py')\n <mask>         sys.modules['myapp'] = mod\n <mask>         try:\n <mask>             mod.app = flask.Flask(mod.__name__)\n <mask>             self.assert_equal(mod.app.instance_path,\n <mask>                              os.path.join(expected_prefix, 'var',\n <mask>                                           'myapp-instance'))\n <mask>         finally:\n <mask>             sys.modules['myapp'] = None\n <mask> \n <mask>     def test_prefix_installed_paths(self):\n <mask>         import types\n <mask>         expected_prefix = os.path.abspath(sys.prefix)\n <mask>         package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n <mask>                                     'site-packages', 'myapp')\n <mask>         mod = types.ModuleType('myapp')\n <mask>         mod.__path__ = [package_path]\n <mask>         mod.__file__ = os.path.join(package_path, '__init__.py')\n <mask>         sys.modules['myapp'] = mod\n <mask>         try:\n <mask>             mod.app = flask.Flask(mod.__name__)\n </s> Update tests for new module helpers. </s> remove         import types\n        expected_prefix = os.path.abspath(sys.prefix)\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'MyApp.egg', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod\n </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        egg_path = os.path.join(site_packages, 'SiteEgg.egg')\n        sys.path.append(site_packages)\n        sys.path.append(egg_path) </s> remove         import types\n        expected_prefix = os.path.abspath('foo')\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod\n </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        installed_path = os.path.join(expected_prefix, 'path')\n        sys.path.append(installed_path) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance'))\n </s> add             import site_app\n            self.assert_equal(site_app.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_app-instance')) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance'))\n </s> add             import site_package\n            self.assert_equal(site_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_package-instance')) </s> remove         import types\n        expected_prefix = os.path.abspath('foo')\n        mod = types.ModuleType('myapp')\n        mod.__file__ = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp.py')\n        sys.modules['myapp'] = mod\n </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        sys.path.append(site_packages)", "html_url": "https://github.com/pallets/flask/commit/fde6e364a497cd44d049df17c93d1fd05ec09f90", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep replace replace replace replace keep replace keep", "code_tokens": " <mask>         sys.modules['myapp'] = mod\n <mask>         try:\n <mask>             mod.app = flask.Flask(mod.__name__)\n <mask>             self.assert_equal(mod.app.instance_path,\n <mask>                              os.path.join(expected_prefix, 'var',\n <mask>                                           'myapp-instance'))\n <mask>         finally:\n <mask>             sys.modules['myapp'] = None\n <mask> \n </s> Update tests for new module helpers.", "html_url": "https://github.com/pallets/flask/commit/fde6e364a497cd44d049df17c93d1fd05ec09f90", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace keep replace replace replace replace keep keep keep", "code_tokens": " <mask>         finally:\n <mask>             sys.modules['myapp'] = None\n <mask> \n <mask>     def test_egg_installed_paths(self):\n <mask>         import types\n <mask>         expected_prefix = os.path.abspath(sys.prefix)\n <mask>         package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n <mask>                                     'site-packages', 'MyApp.egg', 'myapp')\n <mask>         mod = types.ModuleType('myapp')\n <mask>         mod.__path__ = [package_path]\n <mask>         mod.__file__ = os.path.join(package_path, '__init__.py')\n <mask>         sys.modules['myapp'] = mod\n <mask>         try:\n <mask>             mod.app = flask.Flask(mod.__name__)\n <mask>             self.assert_equal(mod.app.instance_path,\n <mask>                              os.path.join(expected_prefix, 'var',\n <mask>                                           'myapp-instance'))\n <mask>         finally:\n <mask>             sys.modules['myapp'] = None\n <mask> \n </s> Update tests for new module helpers.", "html_url": "https://github.com/pallets/flask/commit/fde6e364a497cd44d049df17c93d1fd05ec09f90", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             self.assert_equal(mod.app.instance_path,\n <mask>                              os.path.join(expected_prefix, 'var',\n <mask>                                           'myapp-instance'))\n <mask>         finally:\n <mask>             sys.modules['myapp'] = None\n <mask> \n <mask> \n <mask> def suite():\n <mask>     suite = unittest.TestSuite()\n <mask>     suite.addTest(unittest.makeSuite(ConfigTestCase))\n </s> Update tests for new module helpers. </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance'))\n </s> add             import site_egg # in SiteEgg.egg\n            self.assert_equal(site_egg.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_egg-instance')) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance'))\n </s> add             import site_app\n            self.assert_equal(site_app.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_app-instance')) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance'))\n </s> add             import site_package\n            self.assert_equal(site_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_package-instance')) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance'))\n </s> add             import installed_package\n            self.assert_equal(installed_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'installed_package-instance')) </s> remove             sys.modules['myapp'] = None\n </s> add             sys.prefix = real_prefix\n            sys.path.remove(site_packages)\n            if 'site_package' in sys.modules:\n                del sys.modules['site_package'] </s> remove             sys.modules['myapp'] = None\n </s> add             sys.prefix = real_prefix\n            sys.path.remove(site_packages)\n            if 'site_app' in sys.modules:\n                del sys.modules['site_app']", "html_url": "https://github.com/pallets/flask/commit/fde6e364a497cd44d049df17c93d1fd05ec09f90", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \"\"\"\n <mask> \n <mask> from datetime import datetime\n <mask> from werkzeug.http import http_date, parse_date\n <mask> from werkzeug.datastructures import CallbackDict\n <mask> from .helpers import json\n </s> Various improvements in regards to the itsdangerous usage, bumped to 0.17 </s> add     session_class = SecureCookieSession </s> remove     session_class = SecureCookieSession\n </s> add     #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(hashlib.sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = 'hmac'\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples. </s> add     \"\"\"The default session interface that stores sessions in signed cookies\n    through the :mod:`itsdangerous` module.\n    \"\"\"\n    #: the salt that should be applied on top of the secret key for the\n    #: signing of cookie based sessions. </s> remove         s = self.get_serializer(app)\n </s> add         s = self.get_signing_serializer(app) </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer)\n </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs) </s> remove     def get_serializer(self, app):\n </s> add     def get_signing_serializer(self, app):", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep replace keep replace keep keep keep", "code_tokens": " <mask>             if isinstance(value, tuple):\n <mask>                 return {'##t': [_tag(x) for x in value]}\n <mask>             elif callable(getattr(value, '__html__', None)):\n <mask>                 return {'##m': unicode(value.__html__())}\n <mask>             elif isinstance(value, list):\n <mask>                 return [_tag(x) for x in value]\n <mask>             elif isinstance(value, datetime):\n </s> Various improvements in regards to the itsdangerous usage, bumped to 0.17 </s> remove                 return {'##d': http_date(value)}\n </s> add                 return {' d': http_date(value)} </s> remove             elif the_key == '##d':\n </s> add             elif the_key == ' d': </s> remove             elif the_key == '##m':\n </s> add             elif the_key == ' m': </s> remove             if the_key == '##t':\n </s> add             if the_key == ' t': </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer)\n </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs)", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 return {'##m': unicode(value.__html__())}\n <mask>             elif isinstance(value, list):\n <mask>                 return [_tag(x) for x in value]\n <mask>             elif isinstance(value, datetime):\n <mask>                 return {'##d': http_date(value)}\n <mask>             elif isinstance(value, dict):\n <mask>                 return dict((k, _tag(v)) for k, v in value.iteritems())\n <mask>             return value\n <mask>         return json.dumps(_tag(value), separators=(',', ':'))\n <mask> \n </s> Various improvements in regards to the itsdangerous usage, bumped to 0.17 </s> remove                 return {'##m': unicode(value.__html__())}\n </s> add                 return {' m': unicode(value.__html__())} </s> remove                 return {'##t': [_tag(x) for x in value]}\n </s> add                 return {' t': [_tag(x) for x in value]} </s> remove             elif the_key == '##d':\n </s> add             elif the_key == ' d': </s> remove             elif the_key == '##m':\n </s> add             elif the_key == ' m': </s> remove             if the_key == '##t':\n </s> add             if the_key == ' t': </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer)\n </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs)", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep", "code_tokens": " <mask>             if len(obj) != 1:\n <mask>                 return obj\n <mask>             the_key, the_value = obj.iteritems().next()\n <mask>             if the_key == '##t':\n <mask>                 return tuple(the_value)\n <mask>             elif the_key == '##m':\n <mask>                 return Markup(the_value)\n <mask>             elif the_key == '##d':\n </s> Various improvements in regards to the itsdangerous usage, bumped to 0.17 </s> remove             elif the_key == '##d':\n </s> add             elif the_key == ' d': </s> remove                 return {'##m': unicode(value.__html__())}\n </s> add                 return {' m': unicode(value.__html__())} </s> remove                 return {'##t': [_tag(x) for x in value]}\n </s> add                 return {' t': [_tag(x) for x in value]} </s> remove                 return {'##d': http_date(value)}\n </s> add                 return {' d': http_date(value)} </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer)\n </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs)", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             if the_key == '##t':\n <mask>                 return tuple(the_value)\n <mask>             elif the_key == '##m':\n <mask>                 return Markup(the_value)\n <mask>             elif the_key == '##d':\n <mask>                 return parse_date(the_value)\n <mask>             return obj\n <mask>         return json.loads(value, object_hook=object_hook)\n <mask> \n <mask> \n </s> Various improvements in regards to the itsdangerous usage, bumped to 0.17 </s> remove             elif the_key == '##m':\n </s> add             elif the_key == ' m': </s> remove             if the_key == '##t':\n </s> add             if the_key == ' t': </s> remove                 return {'##m': unicode(value.__html__())}\n </s> add                 return {' m': unicode(value.__html__())} </s> remove                 return {'##d': http_date(value)}\n </s> add                 return {' d': http_date(value)} </s> remove                 return {'##t': [_tag(x) for x in value]}\n </s> add                 return {' t': [_tag(x) for x in value]} </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer)\n </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs)", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     #: this type.\n <mask>     null_session_class = NullSession\n <mask> \n <mask>     def make_null_session(self, app):\n <mask>         \"\"\"Creates a null session which acts as a replacement object if the\n <mask>         real session support could not be loaded due to a configuration\n <mask>         error.  This mainly aids the user experience because the job of the\n </s> Various improvements in regards to the itsdangerous usage, bumped to 0.17 </s> remove     session_class = SecureCookieSession\n </s> add     #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(hashlib.sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = 'hmac'\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples. </s> add     \"\"\"The default session interface that stores sessions in signed cookies\n    through the :mod:`itsdangerous` module.\n    \"\"\"\n    #: the salt that should be applied on top of the secret key for the\n    #: signing of cookie based sessions. </s> add     session_class = SecureCookieSession </s> remove     def get_serializer(self, app):\n </s> add     def get_signing_serializer(self, app): </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer)\n </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs) </s> remove         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app)\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> class SecureCookieSessionInterface(SessionInterface):\n <mask>     salt = 'cookie-session'\n <mask>     #: the hash function to use for the signature.  The default is sha1\n <mask>     digest_method = staticmethod(hashlib.sha1)\n <mask>     #: the name of the itsdangerous supported key derivation.  The default\n <mask>     #: is hmac.\n <mask>     key_derivation = 'hmac'\n </s> Various improvements in regards to the itsdangerous usage, bumped to 0.17 </s> remove     session_class = SecureCookieSession\n </s> add     #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(hashlib.sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = 'hmac'\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples. </s> add     #: A flag that indicates if the session interface is pickle based.\n    #: This can be used by flask extensions to make a decision in regards\n    #: to how to deal with the session object.\n    #:\n    #: .. versionadded:: 0.10\n    pickle_based = False\n </s> add     session_class = SecureCookieSession </s> remove     def get_serializer(self, app):\n </s> add     def get_signing_serializer(self, app): </s> remove         s = self.get_serializer(app)\n </s> add         s = self.get_signing_serializer(app) </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer)\n </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs)", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> class SecureCookieSessionInterface(SessionInterface):\n <mask>     salt = 'cookie-session'\n <mask>     session_class = SecureCookieSession\n <mask>     serializer = session_json_serializer\n <mask> \n <mask>     def get_serializer(self, app):\n <mask>         if not app.secret_key:\n <mask>             return None\n </s> Various improvements in regards to the itsdangerous usage, bumped to 0.17 </s> remove     def get_serializer(self, app):\n </s> add     def get_signing_serializer(self, app): </s> add     session_class = SecureCookieSession </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer)\n </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs) </s> add     \"\"\"The default session interface that stores sessions in signed cookies\n    through the :mod:`itsdangerous` module.\n    \"\"\"\n    #: the salt that should be applied on top of the secret key for the\n    #: signing of cookie based sessions. </s> remove         s = self.get_serializer(app)\n </s> add         s = self.get_signing_serializer(app) </s> remove         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app)\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     #: JSON derived serializer with support for some extra Python types\n <mask>     #: such as datetime objects or tuples.\n <mask>     serializer = session_json_serializer\n <mask> \n <mask>     def get_signing_serializer(self, app):\n <mask>         if not app.secret_key:\n <mask>             return None\n <mask>         signer_kwargs = dict(\n <mask>             key_derivation=self.key_derivation,\n </s> Various improvements in regards to the itsdangerous usage, bumped to 0.17 </s> remove     session_class = SecureCookieSession\n </s> add     #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(hashlib.sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = 'hmac'\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples. </s> remove     def get_serializer(self, app):\n </s> add     def get_signing_serializer(self, app): </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer)\n </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs) </s> add     #: A flag that indicates if the session interface is pickle based.\n    #: This can be used by flask extensions to make a decision in regards\n    #: to how to deal with the session object.\n    #:\n    #: .. versionadded:: 0.10\n    pickle_based = False\n </s> add     \"\"\"The default session interface that stores sessions in signed cookies\n    through the :mod:`itsdangerous` module.\n    \"\"\"\n    #: the salt that should be applied on top of the secret key for the\n    #: signing of cookie based sessions. </s> remove         s = self.get_serializer(app)\n </s> add         s = self.get_signing_serializer(app)", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep replace replace replace keep", "code_tokens": " <mask>     salt = 'cookie-session'\n <mask>     session_class = SecureCookieSession\n <mask>     serializer = session_json_serializer\n <mask> \n <mask>     def get_serializer(self, app):\n <mask>         if not app.secret_key:\n <mask>             return None\n <mask>         return URLSafeTimedSerializer(app.secret_key,\n <mask>                                       salt=self.salt,\n <mask>                                       serializer=self.serializer)\n <mask> \n </s> Various improvements in regards to the itsdangerous usage, bumped to 0.17 </s> add     session_class = SecureCookieSession </s> remove     session_class = SecureCookieSession\n </s> add     #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(hashlib.sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = 'hmac'\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples. </s> remove         s = self.get_serializer(app)\n </s> add         s = self.get_signing_serializer(app) </s> remove         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app)\n </s> add  </s> remove             if the_key == '##t':\n </s> add             if the_key == ' t':", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                                       salt=self.salt,\n <mask>                                       serializer=self.serializer)\n <mask> \n <mask>     def open_session(self, app, request):\n <mask>         s = self.get_serializer(app)\n <mask>         if s is None:\n <mask>             return None\n <mask>         val = request.cookies.get(app.session_cookie_name)\n <mask>         if not val:\n <mask>             return self.session_class()\n </s> Various improvements in regards to the itsdangerous usage, bumped to 0.17 </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer)\n </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs) </s> remove     def get_serializer(self, app):\n </s> add     def get_signing_serializer(self, app): </s> remove         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app)\n </s> add  </s> add     session_class = SecureCookieSession </s> remove         val = self.get_serializer(app).dumps(dict(session))\n </s> add         val = self.get_signing_serializer(app).dumps(dict(session)) </s> remove     session_class = SecureCookieSession\n </s> add     #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(hashlib.sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = 'hmac'\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples.", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def save_session(self, app, session, response):\n <mask>         domain = self.get_cookie_domain(app)\n <mask>         path = self.get_cookie_path(app)\n <mask>         httponly = self.get_cookie_httponly(app)\n <mask>         secure = self.get_cookie_secure(app)\n <mask>         if not session:\n <mask>             if session.modified:\n <mask>                 response.delete_cookie(app.session_cookie_name,\n <mask>                                        domain=domain, path=path)\n <mask>             return\n </s> Various improvements in regards to the itsdangerous usage, bumped to 0.17 </s> add         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app) </s> remove         val = self.get_serializer(app).dumps(dict(session))\n </s> add         val = self.get_signing_serializer(app).dumps(dict(session)) </s> remove         s = self.get_serializer(app)\n </s> add         s = self.get_signing_serializer(app) </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer)\n </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs) </s> remove     def get_serializer(self, app):\n </s> add     def get_signing_serializer(self, app): </s> add     session_class = SecureCookieSession", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>                 response.delete_cookie(app.session_cookie_name,\n <mask>                                        domain=domain, path=path)\n <mask>             return\n <mask>         expires = self.get_expiration_time(app, session)\n <mask>         val = self.get_signing_serializer(app).dumps(dict(session))\n <mask>         response.set_cookie(app.session_cookie_name, val,\n <mask>                             expires=expires, httponly=httponly,\n </s> Various improvements in regards to the itsdangerous usage, bumped to 0.17 </s> remove         val = self.get_serializer(app).dumps(dict(session))\n </s> add         val = self.get_signing_serializer(app).dumps(dict(session)) </s> remove         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app)\n </s> add  </s> remove         s = self.get_serializer(app)\n </s> add         s = self.get_signing_serializer(app) </s> remove     def get_serializer(self, app):\n </s> add     def get_signing_serializer(self, app): </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer)\n </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs) </s> add     session_class = SecureCookieSession", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep", "code_tokens": " <mask>                 response.delete_cookie(app.session_cookie_name,\n <mask>                                        domain=domain, path=path)\n <mask>             return\n <mask>         expires = self.get_expiration_time(app, session)\n <mask>         val = self.get_serializer(app).dumps(dict(session))\n <mask>         response.set_cookie(app.session_cookie_name, val,\n <mask>                             expires=expires, httponly=httponly,\n <mask>                             domain=domain, path=path, secure=secure)\n </s> Various improvements in regards to the itsdangerous usage, bumped to 0.17 </s> add         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app) </s> remove         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app)\n </s> add  </s> remove         s = self.get_serializer(app)\n </s> add         s = self.get_signing_serializer(app) </s> remove     def get_serializer(self, app):\n </s> add     def get_signing_serializer(self, app): </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer)\n </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs) </s> add     session_class = SecureCookieSession", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     platforms='any',\n <mask>     install_requires=[\n <mask>         'Werkzeug>=0.7',\n <mask>         'Jinja2>=2.4',\n <mask>         'itsdangerous>=0.16'\n <mask>     ],\n <mask>     classifiers=[\n <mask>         'Development Status :: 4 - Beta',\n <mask>         'Environment :: Web Environment',\n <mask>         'Intended Audience :: Developers',\n </s> Various improvements in regards to the itsdangerous usage, bumped to 0.17 </s> remove         val = self.get_serializer(app).dumps(dict(session))\n </s> add         val = self.get_signing_serializer(app).dumps(dict(session)) </s> remove                 return {'##t': [_tag(x) for x in value]}\n </s> add                 return {' t': [_tag(x) for x in value]} </s> remove                 return {'##m': unicode(value.__html__())}\n </s> add                 return {' m': unicode(value.__html__())} </s> remove                 return {'##d': http_date(value)}\n </s> add                 return {' d': http_date(value)} </s> remove             if the_key == '##t':\n </s> add             if the_key == ' t': </s> remove             elif the_key == '##m':\n </s> add             elif the_key == ' m':", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             sqlite3.py\n <mask>         setup.py\n <mask>         LICENSE\n <mask> \n <mask> Here the contents of the most important files:\n <mask> \n <mask> flaskext/__init__.py\n <mask> ````````````````````\n <mask> \n <mask> The only purpose of this file is to mark the package as namespace package.\n </s> Fix some typos in the docs </s> remove Here the contents of the `flaskext/sqlite3.py` for copy/paste::\n </s> add Here's the contents of the `flaskext/sqlite3.py` for copy/paste:: </s> remove is only allowing objects as toplevel elements when using\n </s> add is to only allow objects as toplevel elements when using </s> remove WTForm's field function that renders the field for us.  They keyword\n </s> add WTForm's field function that renders the field for us.  The keyword </s> remove set.  This is used by Flask internally to figure out how to do name the\n </s> add set.  This is used by Flask internally to figure out how to name the </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to\n </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to </s> remove So here what the lines of code do:\n </s> add So here's what the lines of code do:", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> The Extension Code\n <mask> ------------------\n <mask> \n <mask> Here the contents of the `flaskext/sqlite3.py` for copy/paste::\n <mask> \n <mask>     from __future__ import absolute_import\n <mask>     import sqlite3\n <mask>     from flask import g\n <mask> \n </s> Fix some typos in the docs </s> remove Here how the module would look like with initialization functions::\n </s> add Here's what the module would look like with initialization functions:: </s> remove set.  This is used by Flask internally to figure out how to do name the\n </s> add set.  This is used by Flask internally to figure out how to name the </s> remove Here the contents of the most important files:\n </s> add Here's the contents of the most important files: </s> remove So here what the lines of code do:\n </s> add So here's what the lines of code do: </s> remove the changes are the nice kind, the kind where you don't have th change\n </s> add the changes are the nice kind, the kind where you don't have to change </s> remove Depening on the error code it is less or more likely for the user to\n </s> add Depending on the error code it is less or more likely for the user to", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def after_request(self, response):\n <mask>             g.sqlite3_db.close()\n <mask>             return response\n <mask> \n <mask> So here what the lines of code do:\n <mask> \n <mask> 1.  the ``__future__`` import is necessary to activate absolute imports.\n <mask>     This is needed because otherwise we could not call our module\n <mask>     `sqlite3.py` and import the top-level `sqlite3` module which actually\n <mask>     implements the connection to SQLite.\n </s> Fix some typos in the docs </s> remove set.  This is used by Flask internally to figure out how to do name the\n </s> add set.  This is used by Flask internally to figure out how to name the </s> remove Here how the module would look like with initialization functions::\n </s> add Here's what the module would look like with initialization functions:: </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to\n </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to </s> remove is only allowing objects as toplevel elements when using\n </s> add is to only allow objects as toplevel elements when using </s> remove Here the HTML code needed for our little application (`index.html`).\n </s> add Here's the HTML code needed for our little application (`index.html`). </s> remove WTForm's field function that renders the field for us.  They keyword\n </s> add WTForm's field function that renders the field for us.  The keyword", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Initialization Functions\n <mask> ------------------------\n <mask> \n <mask> Here how the module would look like with initialization functions::\n <mask> \n <mask>     from __future__ import absolute_import\n <mask>     import sqlite3\n <mask>     from flask import g\n <mask> \n </s> Fix some typos in the docs </s> remove Here the contents of the `flaskext/sqlite3.py` for copy/paste::\n </s> add Here's the contents of the `flaskext/sqlite3.py` for copy/paste:: </s> remove set.  This is used by Flask internally to figure out how to do name the\n </s> add set.  This is used by Flask internally to figure out how to name the </s> remove So here what the lines of code do:\n </s> add So here's what the lines of code do: </s> remove explained below.  It basically tells flask to think we are handling a\n </s> add explained below.  It basically tells Flask to think we are handling a </s> remove the changes are the nice kind, the kind where you don't have th change\n </s> add the changes are the nice kind, the kind where you don't have to change </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to\n </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Flask comes with a handy :func:`~flask.abort` function that aborts a\n <mask> request with an HTTP error code early.  It will also provide a plain black\n <mask> and white error page for you with a basic description, but nothing fancy.\n <mask> \n <mask> Depening on the error code it is less or more likely for the user to\n <mask> actually see such an error.\n <mask> \n <mask> Common Error Codes\n <mask> ------------------\n <mask> \n </s> Fix some typos in the docs </s> remove is only allowing objects as toplevel elements when using\n </s> add is to only allow objects as toplevel elements when using </s> remove attacker now creates a page that sents a post request to that page with\n </s> add attacker now creates a page that sends a post request to that page with </s> remove Here the HTML code needed for our little application (`index.html`).\n </s> add Here's the HTML code needed for our little application (`index.html`). </s> remove You index.html template either has to extend a `layout.html` template with\n </s> add Your index.html template either has to extend a `layout.html` template with </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to\n </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to </s> remove Here an example `_formhelpers.html` template with such a macro:\n </s> add Here's an example `_formhelpers.html` template with such a macro:", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/patterns/errorpages.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> is quite simple: it's on localhost port something and directly on the root\n <mask> of that server.  But what if you later decide to move your application to\n <mask> a different location?  For example to ``http://example.com/myapp``?  On\n <mask> the server side this never was a problem because we were using the handy\n <mask> :func:`~flask.url_for` function that did could answer that question for\n <mask> us, but if we are using jQuery we should better not hardcode the path to\n <mask> the application but make that dynamic, so how can we do that?\n <mask> \n <mask> A simple method would be to add a script tag to our page that sets a\n <mask> global variable to the prefix to the root of the application.  Something\n <mask> like this:\n </s> Fix some typos in the docs </s> remove Here the HTML code needed for our little application (`index.html`).\n </s> add Here's the HTML code needed for our little application (`index.html`). </s> remove You index.html template either has to extend a `layout.html` template with\n </s> add Your index.html template either has to extend a `layout.html` template with </s> remove WTForm's field function that renders the field for us.  They keyword\n </s> add WTForm's field function that renders the field for us.  The keyword </s> remove Depening on the error code it is less or more likely for the user to\n </s> add Depending on the error code it is less or more likely for the user to </s> remove is only allowing objects as toplevel elements when using\n </s> add is to only allow objects as toplevel elements when using </s> remove the changes are the nice kind, the kind where you don't have th change\n </s> add the changes are the nice kind, the kind where you don't have to change", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/patterns/jquery.rst"}
{"docstring_tokens": "keep keep replace keep replace keep keep keep keep", "code_tokens": " <mask> --------\n <mask> \n <mask> You index.html template either has to extend a `layout.html` template with\n <mask> jQuery loaded and the `$SCRIPT_ROOT` variable set, or do that on the top.\n <mask> Here the HTML code needed for our little application (`index.html`).\n <mask> Notice that we also drop the script directly into the HTML here.  It is\n <mask> usually a better idea to have that in a separate script file:\n <mask> \n <mask> .. sourcecode:: html\n </s> Fix some typos in the docs </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to\n </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to </s> remove Depening on the error code it is less or more likely for the user to\n </s> add Depending on the error code it is less or more likely for the user to </s> remove Here an example `_formhelpers.html` template with such a macro:\n </s> add Here's an example `_formhelpers.html` template with such a macro: </s> remove WTForm's field function that renders the field for us.  They keyword\n </s> add WTForm's field function that renders the field for us.  The keyword </s> remove the changes are the nice kind, the kind where you don't have th change\n </s> add the changes are the nice kind, the kind where you don't have to change", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/patterns/jquery.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def __call__(self, *args, **kwargs):\n <mask>             return self.view(*args, **kwargs)\n <mask> \n <mask> What's important here is is that `__module__` and `__name__` are properly\n <mask> set.  This is used by Flask internally to figure out how to do name the\n <mask> URL rules in case you don't provide a name for the rule yourself.\n <mask> \n <mask> Then you can define your central place to combine the views like this::\n <mask> \n <mask>     from flask import Flask\n </s> Fix some typos in the docs </s> remove the changes are the nice kind, the kind where you don't have th change\n </s> add the changes are the nice kind, the kind where you don't have to change </s> remove So here what the lines of code do:\n </s> add So here's what the lines of code do: </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to\n </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to </s> remove Depening on the error code it is less or more likely for the user to\n </s> add Depending on the error code it is less or more likely for the user to </s> remove is only allowing objects as toplevel elements when using\n </s> add is to only allow objects as toplevel elements when using </s> remove WTForm's field function that renders the field for us.  They keyword\n </s> add WTForm's field function that renders the field for us.  The keyword", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/patterns/lazyloading.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> how easy this is.  WTForms does half the form generation for us already.\n <mask> To make it even nicer, we can write a macro that renders a field with\n <mask> label and a list of errors if there are any.\n <mask> \n <mask> Here an example `_formhelpers.html` template with such a macro:\n <mask> \n <mask> .. sourcecode:: html+jinja\n <mask> \n <mask>     {% macro render_field(field) %}\n <mask>       <dt>{{ field.label }}\n </s> Fix some typos in the docs </s> remove WTForm's field function that renders the field for us.  They keyword\n </s> add WTForm's field function that renders the field for us.  The keyword </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to\n </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to </s> remove Here the HTML code needed for our little application (`index.html`).\n </s> add Here's the HTML code needed for our little application (`index.html`). </s> remove Depening on the error code it is less or more likely for the user to\n </s> add Depending on the error code it is less or more likely for the user to </s> remove You index.html template either has to extend a `layout.html` template with\n </s> add Your index.html template either has to extend a `layout.html` template with </s> remove the changes are the nice kind, the kind where you don't have th change\n </s> add the changes are the nice kind, the kind where you don't have to change", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/patterns/wtforms.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       </dd>\n <mask>     {% endmacro %}\n <mask> \n <mask> This macro accepts a couple of keyword arguments that are forwarded to\n <mask> WTForm's field function that renders the field for us.  They keyword\n <mask> arguments will be inserted as HTML attributes.  So for example you can\n <mask> call ``render_field(form.username, class='username')`` to add a class to\n <mask> the input element.  Note that WTForms returns standard Python unicode\n <mask> strings, so we have to tell Jinja2 that this data is already HTML escaped\n <mask> with the `|safe` filter.\n </s> Fix some typos in the docs </s> remove Here an example `_formhelpers.html` template with such a macro:\n </s> add Here's an example `_formhelpers.html` template with such a macro: </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to\n </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to </s> remove You index.html template either has to extend a `layout.html` template with\n </s> add Your index.html template either has to extend a `layout.html` template with </s> remove Here the HTML code needed for our little application (`index.html`).\n </s> add Here's the HTML code needed for our little application (`index.html`). </s> remove Depening on the error code it is less or more likely for the user to\n </s> add Depending on the error code it is less or more likely for the user to </s> remove set.  This is used by Flask internally to figure out how to do name the\n </s> add set.  This is used by Flask internally to figure out how to name the", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/patterns/wtforms.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> /login?next=/\n <mask> /user/John%20Doe\n <mask> \n <mask> (This also uses the :meth:`~flask.Flask.test_request_context` method\n <mask> explained below.  It basically tells flask to think we are handling a\n <mask> request even though we are not, we are in an interactive Python shell.\n <mask> Have a look at the explanation below. :ref:`context-locals`).\n <mask> \n <mask> Why would you want to build URLs instead of hardcoding them in your\n <mask> templates?  There are three good reasons for this:\n </s> Fix some typos in the docs </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to\n </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to </s> remove the changes are the nice kind, the kind where you don't have th change\n </s> add the changes are the nice kind, the kind where you don't have to change </s> remove Depening on the error code it is less or more likely for the user to\n </s> add Depending on the error code it is less or more likely for the user to </s> remove WTForm's field function that renders the field for us.  They keyword\n </s> add WTForm's field function that renders the field for us.  The keyword </s> remove set.  This is used by Flask internally to figure out how to do name the\n </s> add set.  This is used by Flask internally to figure out how to name the </s> remove attacker now creates a page that sents a post request to that page with\n </s> add attacker now creates a page that sends a post request to that page with", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> do stupid things without them knowing.\n <mask> \n <mask> Say you have a specific URL that, when you sent `POST` requests to will\n <mask> delete a user's profile (say `http://example.com/user/delete`).  If an\n <mask> attacker now creates a page that sents a post request to that page with\n <mask> some JavaScript he just has to trick some users to that page and their\n <mask> profiles will end up being deleted.\n <mask> \n <mask> Imagine you would run Facebook with millions of concurrent users and\n <mask> someone would send out links to images of little kittens.  When a user\n </s> Fix some typos in the docs </s> remove Depening on the error code it is less or more likely for the user to\n </s> add Depending on the error code it is less or more likely for the user to </s> remove is only allowing objects as toplevel elements when using\n </s> add is to only allow objects as toplevel elements when using </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to\n </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to </s> remove You index.html template either has to extend a `layout.html` template with\n </s> add Your index.html template either has to extend a `layout.html` template with </s> remove Here the HTML code needed for our little application (`index.html`).\n </s> add Here's the HTML code needed for our little application (`index.html`). </s> remove WTForm's field function that renders the field for us.  They keyword\n </s> add WTForm's field function that renders the field for us.  The keyword", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep", "code_tokens": " <mask> \n <mask> Because it is a syntax error in JavaScript to have an object literal\n <mask> (``{...}``) toplevel an attacker could not just do a request to an\n <mask> external URL with the script tag to load up the data.  So what Flask does\n <mask> is only allowing objects as toplevel elements when using\n <mask> :func:`~flask.jsonify`.  Make sure to do the same when using an ordinary\n <mask> JSON generate function.\n </s> Fix some typos in the docs </s> remove attacker now creates a page that sents a post request to that page with\n </s> add attacker now creates a page that sends a post request to that page with </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to\n </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to </s> remove Depening on the error code it is less or more likely for the user to\n </s> add Depending on the error code it is less or more likely for the user to </s> remove So here what the lines of code do:\n </s> add So here's what the lines of code do: </s> remove set.  This is used by Flask internally to figure out how to do name the\n </s> add set.  This is used by Flask internally to figure out how to name the </s> remove You index.html template either has to extend a `layout.html` template with\n </s> add Your index.html template either has to extend a `layout.html` template with", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Upgrading to Newer Releases\n <mask> ===========================\n <mask> \n <mask> Flask itself is changing like any software is changing over time.  Most of\n <mask> the changes are the nice kind, the kind where you don't have th change\n <mask> anything in your code to profit from a new release.\n <mask> \n <mask> However every once in a while there are changes that do require some\n <mask> changes in your code or there are changes that make it possible for you to\n <mask> improve your own code quality by taking advantage of new features in\n </s> Fix some typos in the docs </s> remove set.  This is used by Flask internally to figure out how to do name the\n </s> add set.  This is used by Flask internally to figure out how to name the </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to\n </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to </s> remove Depening on the error code it is less or more likely for the user to\n </s> add Depending on the error code it is less or more likely for the user to </s> remove Here the HTML code needed for our little application (`index.html`).\n </s> add Here's the HTML code needed for our little application (`index.html`). </s> remove explained below.  It basically tells flask to think we are handling a\n </s> add explained below.  It basically tells Flask to think we are handling a </s> remove You index.html template either has to extend a `layout.html` template with\n </s> add Your index.html template either has to extend a `layout.html` template with", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/upgrading.rst"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> -   When using ad-hoc certificates, check for the cryptography library\n <mask>     instead of PyOpenSSL. :pr:`3492`\n <mask> \n <mask> \n <mask> Version 1.1.2\n <mask> -------------\n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove def call_factory(script_info, app_factory, arguments=()):\n </s> add def call_factory(script_info, app_factory, args=None, kwargs=None): </s> remove     args_spec = inspect.getfullargspec(app_factory)\n </s> add     sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs </s> remove Python literals and passed as arguments to the function. This means that\nstrings must still be in quotes.\n </s> add Python literals and passed as arguments and keyword arguments to the\nfunction. This means that strings must still be in quotes. </s> remove     name, args = match.groups()\n </s> add     if isinstance(expr, ast.Name):\n        name = expr.id\n        args = kwargs = None\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in expr.keywords}\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            )\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) </s> remove     :param factory: the factory function that was called\n    :return: true if the call failed\n </s> add     :param f: The function that was called.\n    :return: ``True`` if the call failed. </s> remove def _called_with_wrong_args(factory):\n </s> add def _called_with_wrong_args(f):", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> found, the command looks for a factory function named ``create_app`` or\n <mask> ``make_app`` that returns an instance.\n <mask> \n <mask> If parentheses follow the factory name, their contents are parsed as\n <mask> Python literals and passed as arguments to the function. This means that\n <mask> strings must still be in quotes.\n <mask> \n <mask> \n <mask> Run the Development Server\n <mask> --------------------------\n <mask> \n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove     if \"script_info\" in args_spec.args:\n </s> add     if \"script_info\" in sig.parameters: </s> remove     args_spec = inspect.getfullargspec(app_factory)\n </s> add     sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs </s> remove def _called_with_wrong_args(factory):\n </s> add def _called_with_wrong_args(f): </s> remove     :param factory: the factory function that was called\n    :return: true if the call failed\n </s> add     :param f: The function that was called.\n    :return: ``True`` if the call failed. </s> remove     name, args = match.groups()\n </s> add     if isinstance(expr, ast.Name):\n        name = expr.id\n        args = kwargs = None\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in expr.keywords}\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            )\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) </s> remove             \" first argument to the app factory function in 2.1.\",\n </s> add             \" single argument to the app factory function in 2.1.\",", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "docs/cli.rst"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>     )\n <mask> \n <mask> \n <mask> def call_factory(script_info, app_factory, arguments=()):\n <mask>     \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n <mask>     of arguments. Checks for the existence of a script_info argument and calls\n <mask>     the app_factory depending on that and the arguments provided.\n <mask>     \"\"\"\n <mask>     args_spec = inspect.getfullargspec(app_factory)\n <mask> \n <mask>     if \"script_info\" in args_spec.args:\n <mask>         warnings.warn(\n <mask>             \"The 'script_info' argument is deprecated and will not be\"\n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove     if \"script_info\" in args_spec.args:\n </s> add     if \"script_info\" in sig.parameters: </s> remove         return app_factory(*arguments, script_info=script_info)\n    elif arguments:\n        return app_factory(*arguments)\n    elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n </s> add         kwargs[\"script_info\"] = script_info\n\n    if (\n        not args\n        and len(sig.parameters) == 1\n        and next(iter(sig.parameters.values())).default is inspect.Parameter.empty\n    ): </s> remove             \" first argument to the app factory function in 2.1.\",\n </s> add             \" single argument to the app factory function in 2.1.\", </s> remove         return app_factory(script_info)\n </s> add         args.append(script_info) </s> remove Python literals and passed as arguments to the function. This means that\nstrings must still be in quotes.\n </s> add Python literals and passed as arguments and keyword arguments to the\nfunction. This means that strings must still be in quotes.", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     the app_factory depending on that and the arguments provided.\n <mask>     \"\"\"\n <mask>     args_spec = inspect.getfullargspec(app_factory)\n <mask> \n <mask>     if \"script_info\" in args_spec.args:\n <mask>         warnings.warn(\n <mask>             \"The 'script_info' argument is deprecated and will not be\"\n <mask>             \" passed to the app factory function in 2.1.\",\n <mask>             DeprecationWarning,\n <mask>         )\n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove     args_spec = inspect.getfullargspec(app_factory)\n </s> add     sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs </s> remove         return app_factory(*arguments, script_info=script_info)\n    elif arguments:\n        return app_factory(*arguments)\n    elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n </s> add         kwargs[\"script_info\"] = script_info\n\n    if (\n        not args\n        and len(sig.parameters) == 1\n        and next(iter(sig.parameters.values())).default is inspect.Parameter.empty\n    ): </s> remove def call_factory(script_info, app_factory, arguments=()):\n </s> add def call_factory(script_info, app_factory, args=None, kwargs=None): </s> remove             \" first argument to the app factory function in 2.1.\",\n </s> add             \" single argument to the app factory function in 2.1.\", </s> remove         return app_factory(script_info)\n </s> add         args.append(script_info) </s> remove Python literals and passed as arguments to the function. This means that\nstrings must still be in quotes.\n </s> add Python literals and passed as arguments and keyword arguments to the\nfunction. This means that strings must still be in quotes.", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep replace replace replace replace keep keep replace keep keep keep keep", "code_tokens": " <mask>         )\n <mask>         return app_factory(*arguments, script_info=script_info)\n <mask>     elif arguments:\n <mask>         return app_factory(*arguments)\n <mask>     elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n <mask>         warnings.warn(\n <mask>             \"Script info is deprecated and will not be passed as the\"\n <mask>             \" first argument to the app factory function in 2.1.\",\n <mask>             DeprecationWarning,\n <mask>         )\n <mask>         return app_factory(script_info)\n <mask> \n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove         return app_factory(script_info)\n </s> add         args.append(script_info) </s> remove     if \"script_info\" in args_spec.args:\n </s> add     if \"script_info\" in sig.parameters: </s> remove     args_spec = inspect.getfullargspec(app_factory)\n </s> add     sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs </s> remove Python literals and passed as arguments to the function. This means that\nstrings must still be in quotes.\n </s> add Python literals and passed as arguments and keyword arguments to the\nfunction. This means that strings must still be in quotes. </s> remove     return app_factory()\n </s> add     return app_factory(*args, **kwargs)", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep replace keep replace", "code_tokens": " <mask>             DeprecationWarning,\n <mask>         )\n <mask>         return app_factory(script_info)\n <mask> \n <mask>     return app_factory()\n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove             \" first argument to the app factory function in 2.1.\",\n </s> add             \" single argument to the app factory function in 2.1.\", </s> remove def _called_with_wrong_args(factory):\n </s> add def _called_with_wrong_args(f): </s> remove         return app_factory(*arguments, script_info=script_info)\n    elif arguments:\n        return app_factory(*arguments)\n    elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n </s> add         kwargs[\"script_info\"] = script_info\n\n    if (\n        not args\n        and len(sig.parameters) == 1\n        and next(iter(sig.parameters.values())).default is inspect.Parameter.empty\n    ): </s> remove     if \"script_info\" in args_spec.args:\n </s> add     if \"script_info\" in sig.parameters: </s> remove         # didn't reach the factory\n </s> add         # Didn't reach the function.", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace replace keep", "code_tokens": " <mask> \n <mask> def _called_with_wrong_args(factory):\n <mask>     \"\"\"Check whether calling a function raised a ``TypeError`` because\n <mask>     the call failed or because something in the factory raised the\n <mask>     error.\n <mask> \n <mask>     :param factory: the factory function that was called\n <mask>     :return: true if the call failed\n <mask>     \"\"\"\n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove     return app_factory()\n </s> add     return app_factory(*args, **kwargs) </s> remove             if tb.tb_frame.f_code is factory.__code__:\n                # in the factory, it was called successfully\n </s> add             if tb.tb_frame.f_code is f.__code__:\n                # In the function, it was called successfully. </s> remove     if \"script_info\" in args_spec.args:\n </s> add     if \"script_info\" in sig.parameters: </s> remove         return app_factory(script_info)\n </s> add         args.append(script_info) </s> remove Python literals and passed as arguments to the function. This means that\nstrings must still be in quotes.\n </s> add Python literals and passed as arguments and keyword arguments to the\nfunction. This means that strings must still be in quotes.", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep replace keep keep keep", "code_tokens": " <mask>     tb = sys.exc_info()[2]\n <mask> \n <mask>     try:\n <mask>         while tb is not None:\n <mask>             if tb.tb_frame.f_code is factory.__code__:\n <mask>                 # in the factory, it was called successfully\n <mask>                 return False\n <mask> \n <mask>             tb = tb.tb_next\n <mask> \n <mask>         # didn't reach the factory\n <mask>         return True\n <mask>     finally:\n <mask>         # explicitly delete tb as it is circular referenced\n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove         # explicitly delete tb as it is circular referenced\n </s> add         # Delete tb to break a circular reference. </s> remove     :param factory: the factory function that was called\n    :return: true if the call failed\n </s> add     :param f: The function that was called.\n    :return: ``True`` if the call failed. </s> add     # If the attribute is a function, call it with any args and kwargs\n    # to get the real application. </s> remove     name, args = match.groups()\n </s> add     if isinstance(expr, ast.Name):\n        name = expr.id\n        args = kwargs = None\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in expr.keywords}\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            )\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) </s> remove         app = None\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         # didn't reach the factory\n <mask>         return True\n <mask>     finally:\n <mask>         # explicitly delete tb as it is circular referenced\n <mask>         # https://docs.python.org/2/library/sys.html#sys.exc_info\n <mask>         del tb\n <mask> \n <mask> \n <mask> def find_app_by_string(script_info, module, app_name):\n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove         # didn't reach the factory\n </s> add         # Didn't reach the function. </s> remove             if tb.tb_frame.f_code is factory.__code__:\n                # in the factory, it was called successfully\n </s> add             if tb.tb_frame.f_code is f.__code__:\n                # In the function, it was called successfully. </s> add     # If the attribute is a function, call it with any args and kwargs\n    # to get the real application. </s> remove     :param factory: the factory function that was called\n    :return: true if the call failed\n </s> add     :param f: The function that was called.\n    :return: ``True`` if the call failed. </s> remove     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n\n    if not match:\n </s> add     # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError: </s> remove         # no script_info\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep replace keep", "code_tokens": " <mask>     \"\"\"\n <mask>     from . import Flask\n <mask> \n <mask>     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n <mask> \n <mask>     if not match:\n <mask>         raise NoAppException(\n <mask>             f\"{app_name!r} is not a valid variable name or function expression.\"\n <mask>         )\n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove     name, args = match.groups()\n </s> add     if isinstance(expr, ast.Name):\n        name = expr.id\n        args = kwargs = None\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in expr.keywords}\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            )\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) </s> remove         app = None\n\n </s> add  </s> remove     :param factory: the factory function that was called\n    :return: true if the call failed\n </s> add     :param f: The function that was called.\n    :return: ``True`` if the call failed. </s> remove                 f\"{e}\\nThe factory {app_name!r} in module\"\n </s> add                 f\"The factory {app_name!r} in module\" </s> remove     if \"script_info\" in args_spec.args:\n </s> add     if \"script_info\" in sig.parameters:", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep replace keep keep keep replace replace keep keep keep", "code_tokens": " <mask>         )\n <mask> \n <mask>     name, args = match.groups()\n <mask> \n <mask>     try:\n <mask>         attr = getattr(module, name)\n <mask>     except AttributeError as e:\n <mask>         raise NoAppException(e.args[0])\n <mask> \n <mask>     if inspect.isfunction(attr):\n <mask>         if args:\n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove         if args:\n            try:\n                args = ast.literal_eval(f\"({args},)\")\n            except (ValueError, SyntaxError):\n                raise NoAppException(f\"Could not parse the arguments in {app_name!r}.\")\n        else:\n            args = ()\n\n </s> add  </s> remove             app = call_factory(script_info, attr, args)\n        except TypeError as e:\n </s> add             app = call_factory(script_info, attr, args, kwargs)\n        except TypeError: </s> remove             f\"{app_name!r} is not a valid variable name or function expression.\"\n </s> add             f\"Failed to parse {app_name!r} as an attribute name or function call.\" </s> remove     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n\n    if not match:\n </s> add     # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError: </s> add     # If the attribute is a function, call it with any args and kwargs\n    # to get the real application.", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         raise NoAppException(\n <mask>             f\"Failed to find attribute {name!r} in {module.__name__!r}.\"\n <mask>         )\n <mask> \n <mask>     if inspect.isfunction(attr):\n <mask>         try:\n <mask>             app = call_factory(script_info, attr, args, kwargs)\n <mask>         except TypeError:\n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove     except AttributeError as e:\n        raise NoAppException(e.args[0])\n </s> add     except AttributeError:\n        raise NoAppException(\n            f\"Failed to find attribute {name!r} in {module.__name__!r}.\"\n        ) </s> remove             app = call_factory(script_info, attr, args)\n        except TypeError as e:\n </s> add             app = call_factory(script_info, attr, args, kwargs)\n        except TypeError: </s> remove         if args:\n            try:\n                args = ast.literal_eval(f\"({args},)\")\n            except (ValueError, SyntaxError):\n                raise NoAppException(f\"Could not parse the arguments in {app_name!r}.\")\n        else:\n            args = ()\n\n </s> add  </s> remove     name, args = match.groups()\n </s> add     if isinstance(expr, ast.Name):\n        name = expr.id\n        args = kwargs = None\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in expr.keywords}\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            )\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) </s> remove             f\"{app_name!r} is not a valid variable name or function expression.\"\n </s> add             f\"Failed to parse {app_name!r} as an attribute name or function call.\" </s> remove     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n\n    if not match:\n </s> add     # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace replace keep replace replace", "code_tokens": " <mask>     if inspect.isfunction(attr):\n <mask>         if args:\n <mask>             try:\n <mask>                 args = ast.literal_eval(f\"({args},)\")\n <mask>             except (ValueError, SyntaxError):\n <mask>                 raise NoAppException(f\"Could not parse the arguments in {app_name!r}.\")\n <mask>         else:\n <mask>             args = ()\n <mask> \n <mask>         try:\n <mask>             app = call_factory(script_info, attr, args)\n <mask>         except TypeError as e:\n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove     except AttributeError as e:\n        raise NoAppException(e.args[0])\n </s> add     except AttributeError:\n        raise NoAppException(\n            f\"Failed to find attribute {name!r} in {module.__name__!r}.\"\n        ) </s> add     # If the attribute is a function, call it with any args and kwargs\n    # to get the real application. </s> remove     name, args = match.groups()\n </s> add     if isinstance(expr, ast.Name):\n        name = expr.id\n        args = kwargs = None\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in expr.keywords}\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            )\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) </s> remove             f\"{app_name!r} is not a valid variable name or function expression.\"\n </s> add             f\"Failed to parse {app_name!r} as an attribute name or function call.\" </s> remove     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n\n    if not match:\n </s> add     # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             if not _called_with_wrong_args(attr):\n <mask>                 raise\n <mask> \n <mask>             raise NoAppException(\n <mask>                 f\"{e}\\nThe factory {app_name!r} in module\"\n <mask>                 f\" {module.__name__!r} could not be called with the\"\n <mask>                 \" specified arguments.\"\n <mask>             )\n <mask>     else:\n <mask>         app = attr\n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove             app = call_factory(script_info, attr, args)\n        except TypeError as e:\n </s> add             app = call_factory(script_info, attr, args, kwargs)\n        except TypeError: </s> remove     name, args = match.groups()\n </s> add     if isinstance(expr, ast.Name):\n        name = expr.id\n        args = kwargs = None\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in expr.keywords}\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            )\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) </s> remove         if args:\n            try:\n                args = ast.literal_eval(f\"({args},)\")\n            except (ValueError, SyntaxError):\n                raise NoAppException(f\"Could not parse the arguments in {app_name!r}.\")\n        else:\n            args = ()\n\n </s> add  </s> remove     except AttributeError as e:\n        raise NoAppException(e.args[0])\n </s> add     except AttributeError:\n        raise NoAppException(\n            f\"Failed to find attribute {name!r} in {module.__name__!r}.\"\n        ) </s> remove             f\"{app_name!r} is not a valid variable name or function expression.\"\n </s> add             f\"Failed to parse {app_name!r} as an attribute name or function call.\" </s> remove         return app_factory(*arguments, script_info=script_info)\n    elif arguments:\n        return app_factory(*arguments)\n    elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n </s> add         kwargs[\"script_info\"] = script_info\n\n    if (\n        not args\n        and len(sig.parameters) == 1\n        and next(iter(sig.parameters.values())).default is inspect.Parameter.empty\n    ):", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         if self._loaded_app is not None:\n <mask>             return self._loaded_app\n <mask> \n <mask>         app = None\n <mask> \n <mask>         if self.create_app is not None:\n <mask>             app = call_factory(self, self.create_app)\n <mask>         else:\n <mask>             if self.app_import_path:\n <mask>                 path, name = (\n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove             if tb.tb_frame.f_code is factory.__code__:\n                # in the factory, it was called successfully\n </s> add             if tb.tb_frame.f_code is f.__code__:\n                # In the function, it was called successfully. </s> remove     name, args = match.groups()\n </s> add     if isinstance(expr, ast.Name):\n        name = expr.id\n        args = kwargs = None\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in expr.keywords}\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            )\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) </s> remove         return app_factory(*arguments, script_info=script_info)\n    elif arguments:\n        return app_factory(*arguments)\n    elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n </s> add         kwargs[\"script_info\"] = script_info\n\n    if (\n        not args\n        and len(sig.parameters) == 1\n        and next(iter(sig.parameters.values())).default is inspect.Parameter.empty\n    ): </s> remove     args_spec = inspect.getfullargspec(app_factory)\n </s> add     sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs </s> remove             f\"{app_name!r} is not a valid variable name or function expression.\"\n </s> add             f\"Failed to parse {app_name!r} as an attribute name or function call.\" </s> remove     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n\n    if not match:\n </s> add     # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         (\"cliapp.app\", \"testapp\", \"testapp\"),\n <mask>         (\"cliapp.factory\", None, \"app\"),\n <mask>         (\"cliapp.factory\", \"create_app\", \"app\"),\n <mask>         (\"cliapp.factory\", \"create_app()\", \"app\"),\n <mask>         # no script_info\n <mask>         (\"cliapp.factory\", 'create_app2(\"foo\", \"bar\")', \"app2_foo_bar\"),\n <mask>         # trailing comma space\n <mask>         (\"cliapp.factory\", 'create_app2(\"foo\", \"bar\", )', \"app2_foo_bar\"),\n <mask>         # strip whitespace\n <mask>         (\"cliapp.factory\", \" create_app () \", \"app\"),\n </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove         # didn't reach the factory\n </s> add         # Didn't reach the function. </s> remove         # explicitly delete tb as it is circular referenced\n </s> add         # Delete tb to break a circular reference. </s> remove             if tb.tb_frame.f_code is factory.__code__:\n                # in the factory, it was called successfully\n </s> add             if tb.tb_frame.f_code is f.__code__:\n                # In the function, it was called successfully. </s> add     # If the attribute is a function, call it with any args and kwargs\n    # to get the real application. </s> remove     name, args = match.groups()\n </s> add     if isinstance(expr, ast.Name):\n        name = expr.id\n        args = kwargs = None\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in expr.keywords}\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            )\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) </s> remove     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n\n    if not match:\n </s> add     # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep replace replace replace keep replace", "code_tokens": " <mask> \n <mask> @pytest.fixture\n <mask> def app(request):\n <mask> \n <mask>     db_fd, temp_db_location = tempfile.mkstemp()\n <mask>     config = {\n <mask>         'DATABASE': temp_db_location,\n </s> fix windows failure to remove temp file </s> remove @pytest.fixture\ndef client(request, app):\n\n    client = app.test_client()\n\n    def teardown():\n        os.close(app.config['DB_FD'])\n        os.unlink(app.config['DATABASE'])\n    request.addfinalizer(teardown)\n </s> add  </s> remove         'DB_FD': db_fd\n </s> add  </s> add     os.close(db_fd)\n    os.unlink(db_path) </s> remove     return client\n </s> add @pytest.fixture\ndef client(app):\n    return app.test_client()", "html_url": "https://github.com/pallets/flask/commit/ffca68fc86718b133668f341ddd8c2635d7e29ec", "file_name": "examples/flaskr/tests/test_flaskr.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     db_fd, temp_db_location = tempfile.mkstemp()\n <mask>     config = {\n <mask>         'DATABASE': temp_db_location,\n <mask>         'TESTING': True,\n <mask>         'DB_FD': db_fd\n <mask>     }\n <mask> \n <mask>     app = create_app(config=config)\n <mask> \n <mask>     with app.app_context():\n </s> fix windows failure to remove temp file </s> remove         'DATABASE': temp_db_location,\n </s> add         'DATABASE': db_path, </s> remove def app(request):\n\n    db_fd, temp_db_location = tempfile.mkstemp()\n </s> add def app():\n    db_fd, db_path = tempfile.mkstemp() </s> remove @pytest.fixture\ndef client(request, app):\n\n    client = app.test_client()\n\n    def teardown():\n        os.close(app.config['DB_FD'])\n        os.unlink(app.config['DATABASE'])\n    request.addfinalizer(teardown)\n </s> add  </s> add     os.close(db_fd)\n    os.unlink(db_path) </s> remove     return client\n </s> add @pytest.fixture\ndef client(app):\n    return app.test_client()", "html_url": "https://github.com/pallets/flask/commit/ffca68fc86718b133668f341ddd8c2635d7e29ec", "file_name": "examples/flaskr/tests/test_flaskr.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         yield app\n <mask> \n <mask> \n <mask> \n <mask> @pytest.fixture\n <mask> def client(app):\n </s> fix windows failure to remove temp file </s> remove @pytest.fixture\ndef client(request, app):\n\n    client = app.test_client()\n\n    def teardown():\n        os.close(app.config['DB_FD'])\n        os.unlink(app.config['DATABASE'])\n    request.addfinalizer(teardown)\n </s> add  </s> remove     return client\n </s> add @pytest.fixture\ndef client(app):\n    return app.test_client() </s> remove def app(request):\n\n    db_fd, temp_db_location = tempfile.mkstemp()\n </s> add def app():\n    db_fd, db_path = tempfile.mkstemp() </s> remove         'DATABASE': temp_db_location,\n </s> add         'DATABASE': db_path, </s> remove         'DB_FD': db_fd\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/ffca68fc86718b133668f341ddd8c2635d7e29ec", "file_name": "examples/flaskr/tests/test_flaskr.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace keep replace keep keep keep", "code_tokens": " <mask>         init_db()\n <mask>         yield app\n <mask> \n <mask> \n <mask> @pytest.fixture\n <mask> def client(request, app):\n <mask> \n <mask>     client = app.test_client()\n <mask> \n <mask>     def teardown():\n <mask>         os.close(app.config['DB_FD'])\n <mask>         os.unlink(app.config['DATABASE'])\n <mask>     request.addfinalizer(teardown)\n <mask> \n <mask>     return client\n <mask> \n <mask> \n <mask> def login(client, username, password):\n </s> fix windows failure to remove temp file </s> add     os.close(db_fd)\n    os.unlink(db_path) </s> remove def app(request):\n\n    db_fd, temp_db_location = tempfile.mkstemp()\n </s> add def app():\n    db_fd, db_path = tempfile.mkstemp() </s> remove         'DATABASE': temp_db_location,\n </s> add         'DATABASE': db_path, </s> remove         'DB_FD': db_fd\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/ffca68fc86718b133668f341ddd8c2635d7e29ec", "file_name": "examples/flaskr/tests/test_flaskr.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> ^^^^^^\n <mask> - Bug in :meth:`Styler._copy` calling overridden methods in subclasses of :class:`Styler` (:issue:`52728`)\n <mask> -\n <mask> \n <mask> Other\n <mask> ^^^^^\n <mask> - Bug in :func:`assert_almost_equal` now throwing assertion error for two unequal sets (:issue:`51727`)\n <mask> - Bug in :func:`assert_frame_equal` checks category dtypes even when asked not to check index type (:issue:`52126`)\n <mask> - Bug in :meth:`DataFrame.reindex` with a ``fill_value`` that should be inferred with a :class:`ExtensionDtype` incorrectly inferring ``object`` dtype (:issue:`52586`)\n <mask> - Bug in :meth:`Series.map` when giving a callable to an empty series, the returned series had ``object`` dtype. It now keeps the original dtype (:issue:`52384`)\n </s> Fix the metadata propagation in Dataframe.std (#52924)\n\n* Fix the metadata propagation both in Dataframe.std\r\n\r\n* Fix the typing problem by forcing propogation only on Series\r\n\r\n* From judge statement  to cast\r\n\r\n* Add whatsnew </s> remove         marks=not_implemented_mark,\n </s> add  </s> remove         return super().std(axis, skipna, ddof, numeric_only, **kwargs)\n </s> add         result = cast(Series, super().std(axis, skipna, ddof, numeric_only, **kwargs))\n        return result.__finalize__(self, method=\"std\")", "html_url": "https://github.com/pandas-dev/pandas/commit/000c3ed75ef63330b18f7751ac005f9a346a6d50", "file_name": "doc/source/whatsnew/v2.1.0.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         ddof: int = 1,\n <mask>         numeric_only: bool = False,\n <mask>         **kwargs,\n <mask>     ):\n <mask>         return super().std(axis, skipna, ddof, numeric_only, **kwargs)\n <mask> \n <mask>     @doc(make_doc(\"skew\", ndim=2))\n <mask>     def skew(\n <mask>         self,\n <mask>         axis: Axis | None = 0,\n </s> Fix the metadata propagation in Dataframe.std (#52924)\n\n* Fix the metadata propagation both in Dataframe.std\r\n\r\n* Fix the typing problem by forcing propogation only on Series\r\n\r\n* From judge statement  to cast\r\n\r\n* Add whatsnew </s> remove         marks=not_implemented_mark,\n </s> add  </s> add Metadata\n^^^^^^^^\n- Fixed metadata propagation in :meth:`DataFrame.std` (:issue:`28283`)\n", "html_url": "https://github.com/pandas-dev/pandas/commit/000c3ed75ef63330b18f7751ac005f9a346a6d50", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         (pd.DataFrame, frame_data, operator.methodcaller(\"sum\")),\n <mask>     ),\n <mask>     pytest.param(\n <mask>         (pd.DataFrame, frame_data, operator.methodcaller(\"std\")),\n <mask>         marks=not_implemented_mark,\n <mask>     ),\n <mask>     pytest.param(\n <mask>         (pd.DataFrame, frame_data, operator.methodcaller(\"mean\")),\n <mask>         marks=not_implemented_mark,\n <mask>     ),\n </s> Fix the metadata propagation in Dataframe.std (#52924)\n\n* Fix the metadata propagation both in Dataframe.std\r\n\r\n* Fix the typing problem by forcing propogation only on Series\r\n\r\n* From judge statement  to cast\r\n\r\n* Add whatsnew </s> remove         return super().std(axis, skipna, ddof, numeric_only, **kwargs)\n </s> add         result = cast(Series, super().std(axis, skipna, ddof, numeric_only, **kwargs))\n        return result.__finalize__(self, method=\"std\") </s> add Metadata\n^^^^^^^^\n- Fixed metadata propagation in :meth:`DataFrame.std` (:issue:`28283`)\n", "html_url": "https://github.com/pandas-dev/pandas/commit/000c3ed75ef63330b18f7751ac005f9a346a6d50", "file_name": "pandas/tests/generic/test_finalize.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> - ``DataFrame.to_csv()`` has dropped the ``engine`` parameter, as was deprecated in 0.17.1 (:issue:`11274`, :issue:`13419`)\n <mask> - ``DataFrame.to_dict()`` has dropped the ``outtype`` parameter in favor of ``orient`` (:issue:`13627`, :issue:`8486`)\n <mask> - ``pd.Categorical`` has dropped the ``levels`` attribute in favour of ``categories`` (:issue:`8376`)\n <mask> \n <mask> - Removal of the legacy time rules (offset aliases), deprecated since 0.17.0 (this has been alias since 0.8.0) (:issue:`13590`)\n <mask> \n <mask>   Previous Behavior:\n </s> CLN: removed setter method of categorical's ordered attribute\n\nxref #9611\n\nAuthor: gfyoung <gfyoung17@gmail.com>\n\nCloses #13671 from gfyoung/cat-set-order-removal and squashes the following commits:\n\n58938e7 [gfyoung] CLN: removed setter method of categorical's ordered attribute </s> remove     def _set_ordered(self, value):\n        \"\"\" Sets the ordered attribute to the boolean value \"\"\"\n        warn(\"Setting 'ordered' directly is deprecated, use 'set_ordered'\",\n             FutureWarning, stacklevel=2)\n        self.set_ordered(value, inplace=True)\n\n </s> add  </s> remove     ordered = property(fget=_get_ordered, fset=_set_ordered)\n </s> add     ordered = property(fget=_get_ordered) </s> remove         # deperecated in v0.16.0\n        with tm.assert_produces_warning(FutureWarning):\n            cat.ordered = False\n            self.assertFalse(cat.ordered)\n        with tm.assert_produces_warning(FutureWarning):\n </s> add         # removed in 0.19.0\n        msg = \"can\\'t set attribute\"\n        with tm.assertRaisesRegexp(AttributeError, msg): </s> remove             self.assertTrue(cat.ordered)\n </s> add         with tm.assertRaisesRegexp(AttributeError, msg):\n            cat.ordered = False", "html_url": "https://github.com/pandas-dev/pandas/commit/006bd0b1c2f3ff183c1834a27305a1a3039011d8", "file_name": "doc/source/whatsnew/v0.19.0.txt"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                           doc=_categories_doc)\n <mask> \n <mask>     _ordered = None\n <mask> \n <mask>     def _set_ordered(self, value):\n <mask>         \"\"\" Sets the ordered attribute to the boolean value \"\"\"\n <mask>         warn(\"Setting 'ordered' directly is deprecated, use 'set_ordered'\",\n <mask>              FutureWarning, stacklevel=2)\n <mask>         self.set_ordered(value, inplace=True)\n <mask> \n <mask>     def set_ordered(self, value, inplace=False):\n <mask>         \"\"\"\n <mask>         Sets the ordered attribute to the boolean value\n <mask> \n <mask>         Parameters\n </s> CLN: removed setter method of categorical's ordered attribute\n\nxref #9611\n\nAuthor: gfyoung <gfyoung17@gmail.com>\n\nCloses #13671 from gfyoung/cat-set-order-removal and squashes the following commits:\n\n58938e7 [gfyoung] CLN: removed setter method of categorical's ordered attribute </s> remove     ordered = property(fget=_get_ordered, fset=_set_ordered)\n </s> add     ordered = property(fget=_get_ordered) </s> add - ``pd.Categorical`` has dropped setting of the ``ordered`` attribute directly in favor of the ``set_ordered`` method (:issue:`13671`) </s> remove         # deperecated in v0.16.0\n        with tm.assert_produces_warning(FutureWarning):\n            cat.ordered = False\n            self.assertFalse(cat.ordered)\n        with tm.assert_produces_warning(FutureWarning):\n </s> add         # removed in 0.19.0\n        msg = \"can\\'t set attribute\"\n        with tm.assertRaisesRegexp(AttributeError, msg): </s> remove             self.assertTrue(cat.ordered)\n </s> add         with tm.assertRaisesRegexp(AttributeError, msg):\n            cat.ordered = False", "html_url": "https://github.com/pandas-dev/pandas/commit/006bd0b1c2f3ff183c1834a27305a1a3039011d8", "file_name": "pandas/core/categorical.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def _get_ordered(self):\n <mask>         \"\"\" Gets the ordered attribute \"\"\"\n <mask>         return self._ordered\n <mask> \n <mask>     ordered = property(fget=_get_ordered, fset=_set_ordered)\n <mask> \n <mask>     def set_categories(self, new_categories, ordered=None, rename=False,\n <mask>                        inplace=False):\n <mask>         \"\"\" Sets the categories to the specified new_categories.\n <mask> \n </s> CLN: removed setter method of categorical's ordered attribute\n\nxref #9611\n\nAuthor: gfyoung <gfyoung17@gmail.com>\n\nCloses #13671 from gfyoung/cat-set-order-removal and squashes the following commits:\n\n58938e7 [gfyoung] CLN: removed setter method of categorical's ordered attribute </s> remove     def _set_ordered(self, value):\n        \"\"\" Sets the ordered attribute to the boolean value \"\"\"\n        warn(\"Setting 'ordered' directly is deprecated, use 'set_ordered'\",\n             FutureWarning, stacklevel=2)\n        self.set_ordered(value, inplace=True)\n\n </s> add  </s> add - ``pd.Categorical`` has dropped setting of the ``ordered`` attribute directly in favor of the ``set_ordered`` method (:issue:`13671`) </s> remove             self.assertTrue(cat.ordered)\n </s> add         with tm.assertRaisesRegexp(AttributeError, msg):\n            cat.ordered = False </s> remove         # deperecated in v0.16.0\n        with tm.assert_produces_warning(FutureWarning):\n            cat.ordered = False\n            self.assertFalse(cat.ordered)\n        with tm.assert_produces_warning(FutureWarning):\n </s> add         # removed in 0.19.0\n        msg = \"can\\'t set attribute\"\n        with tm.assertRaisesRegexp(AttributeError, msg):", "html_url": "https://github.com/pandas-dev/pandas/commit/006bd0b1c2f3ff183c1834a27305a1a3039011d8", "file_name": "pandas/core/categorical.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace replace keep replace keep keep keep", "code_tokens": " <mask>         cat2.set_ordered(False, inplace=True)\n <mask>         self.assertFalse(cat2.ordered)\n <mask> \n <mask>         # deperecated in v0.16.0\n <mask>         with tm.assert_produces_warning(FutureWarning):\n <mask>             cat.ordered = False\n <mask>             self.assertFalse(cat.ordered)\n <mask>         with tm.assert_produces_warning(FutureWarning):\n <mask>             cat.ordered = True\n <mask>             self.assertTrue(cat.ordered)\n <mask> \n <mask>     def test_set_categories(self):\n <mask>         cat = Categorical([\"a\", \"b\", \"c\", \"a\"], ordered=True)\n </s> CLN: removed setter method of categorical's ordered attribute\n\nxref #9611\n\nAuthor: gfyoung <gfyoung17@gmail.com>\n\nCloses #13671 from gfyoung/cat-set-order-removal and squashes the following commits:\n\n58938e7 [gfyoung] CLN: removed setter method of categorical's ordered attribute </s> remove     ordered = property(fget=_get_ordered, fset=_set_ordered)\n </s> add     ordered = property(fget=_get_ordered) </s> remove     def _set_ordered(self, value):\n        \"\"\" Sets the ordered attribute to the boolean value \"\"\"\n        warn(\"Setting 'ordered' directly is deprecated, use 'set_ordered'\",\n             FutureWarning, stacklevel=2)\n        self.set_ordered(value, inplace=True)\n\n </s> add  </s> add - ``pd.Categorical`` has dropped setting of the ``ordered`` attribute directly in favor of the ``set_ordered`` method (:issue:`13671`)", "html_url": "https://github.com/pandas-dev/pandas/commit/006bd0b1c2f3ff183c1834a27305a1a3039011d8", "file_name": "pandas/tests/test_categorical.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     def time_groupby_transform_series2(self):\n <mask>         self.df.groupby('id')['val'].transform(np.mean)\n <mask> \n <mask> class groupby_transform_cythonized(object):\n <mask>     goal_time = 0.2\n <mask> \n <mask>     def setup(self):\n </s> PERF: DataFrame transform\n\ncloses #12737\ncloses #13191\n\nAuthor: Chris <cbartak@gmail.com>\n\nCloses #13192 from chris-b1/transform-perf and squashes the following commits:\n\n0af1e55 [Chris] revert casting logic\nd61d4e0 [Chris] handle duplicate column case\n9d78f65 [Chris] other categorical test name fix\n045d0c7 [Chris] add back some casting\nb66a1c8 [Chris] PERF: DataFrame transform </s> remove         expected = pd.Series(values, index=df.index)\n </s> add         expected = pd.Series(values, index=df.index, name='val') </s> add     def test_series_fast_transform_date(self):\n        # GH 13191\n        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],\n                           'd': pd.date_range('2014-1-1', '2014-1-4')})\n        result = df.groupby('grouping')['d'].transform('first')\n        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),\n                 pd.Timestamp('2014-1-4')]\n        expected = pd.Series(dates, name='d')\n        assert_series_equal(result, expected)\n </s> remove         mask = ids != -1\n\n        out = func().values[ids]\n        if not mask.all():\n            out = np.where(mask, out, np.nan)\n\n        obs = np.zeros(ngroup, dtype='bool')\n        obs[ids[mask]] = True\n        if not obs.all():\n            out = self._try_cast(out, self._selected_obj)\n\n        return Series(out, index=self.obj.index)\n </s> add         cast = (self.size().fillna(0) > 0).any()\n        out = algos.take_1d(func().values, ids)\n        if cast:\n            out = self._try_cast(out, self.obj)\n        return Series(out, index=self.obj.index, name=self.obj.name) </s> remove         return (DataFrame(results, columns=result.columns, index=obj.index)\n                ._convert(datetime=True))\n </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index) </s> remove         expected = Series([pd.Timestamp('2000-01-1')] * 2)\n </s> add         expected = Series([pd.Timestamp('2000-01-1')] * 2, name='B') </s> remove         results = np.empty_like(obj.values, result.values.dtype)\n        for (name, group), (i, row) in zip(self, result.iterrows()):\n            indexer = self._get_index(name)\n            if len(indexer) > 0:\n                results[indexer] = np.tile(row.values, len(\n                    indexer)).reshape(len(indexer), -1)\n </s> add         return self._transform_fast(result, obj)", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "asv_bench/benchmarks/groupby.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> - Improved performance of sparse arithmetic with ``BlockIndex`` when the number of blocks are large, though recommended to use ``IntIndex`` in such cases (:issue:`13082`)\n <mask> - increased performance of ``DataFrame.quantile()`` as it now operates per-block (:issue:`11623`)\n <mask> \n <mask> \n <mask> \n <mask> \n <mask> \n <mask> .. _whatsnew_0182.bug_fixes:\n <mask> \n <mask> Bug Fixes\n </s> PERF: DataFrame transform\n\ncloses #12737\ncloses #13191\n\nAuthor: Chris <cbartak@gmail.com>\n\nCloses #13192 from chris-b1/transform-perf and squashes the following commits:\n\n0af1e55 [Chris] revert casting logic\nd61d4e0 [Chris] handle duplicate column case\n9d78f65 [Chris] other categorical test name fix\n045d0c7 [Chris] add back some casting\nb66a1c8 [Chris] PERF: DataFrame transform </s> remove \n </s> add - Bug in ``SeriesGroupBy.transform`` with datetime values and missing groups (:issue:`13191`) </s> remove         return (DataFrame(results, columns=result.columns, index=obj.index)\n                ._convert(datetime=True))\n </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index) </s> remove         mask = ids != -1\n\n        out = func().values[ids]\n        if not mask.all():\n            out = np.where(mask, out, np.nan)\n\n        obs = np.zeros(ngroup, dtype='bool')\n        obs[ids[mask]] = True\n        if not obs.all():\n            out = self._try_cast(out, self._selected_obj)\n\n        return Series(out, index=self.obj.index)\n </s> add         cast = (self.size().fillna(0) > 0).any()\n        out = algos.take_1d(func().values, ids)\n        if cast:\n            out = self._try_cast(out, self.obj)\n        return Series(out, index=self.obj.index, name=self.obj.name) </s> remove         counts = self.size().fillna(0).values\n        if any(counts == 0):\n            results = self._try_cast(results, obj[result.columns])\n </s> add     def _transform_fast(self, result, obj):\n        \"\"\"\n        Fast transform path for aggregations\n        \"\"\"\n        # if there were groups with no observations (Categorical only?)\n        # try casting data to original dtype\n        cast = (self.size().fillna(0) > 0).any() </s> remove         results = np.empty_like(obj.values, result.values.dtype)\n        for (name, group), (i, row) in zip(self, result.iterrows()):\n            indexer = self._get_index(name)\n            if len(indexer) > 0:\n                results[indexer] = np.tile(row.values, len(\n                    indexer)).reshape(len(indexer), -1)\n </s> add         return self._transform_fast(result, obj) </s> remove         expected = Series([pd.Timestamp('2000-01-1')] * 2)\n </s> add         expected = Series([pd.Timestamp('2000-01-1')] * 2, name='B')", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "doc/source/whatsnew/v0.18.2.txt"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> - Regression in ``Series.quantile`` with nans (also shows up in ``.median()`` and ``.describe()``); furthermore now names the ``Series`` with the quantile (:issue:`13098`, :issue:`13146`)\n <mask> \n <mask> \n <mask> \n <mask> - Bug in ``Series.str.extractall()`` with ``str`` index raises ``ValueError``  (:issue:`13156`)\n <mask> \n <mask> \n <mask> - Bug in ``PeriodIndex`` and ``Period`` subtraction raises ``AttributeError`` (:issue:`13071`)\n </s> PERF: DataFrame transform\n\ncloses #12737\ncloses #13191\n\nAuthor: Chris <cbartak@gmail.com>\n\nCloses #13192 from chris-b1/transform-perf and squashes the following commits:\n\n0af1e55 [Chris] revert casting logic\nd61d4e0 [Chris] handle duplicate column case\n9d78f65 [Chris] other categorical test name fix\n045d0c7 [Chris] add back some casting\nb66a1c8 [Chris] PERF: DataFrame transform </s> remove \n </s> add - Improved performance of ``DataFrameGroupBy.transform`` (:issue:`12737`) </s> remove         counts = self.size().fillna(0).values\n        if any(counts == 0):\n            results = self._try_cast(results, obj[result.columns])\n </s> add     def _transform_fast(self, result, obj):\n        \"\"\"\n        Fast transform path for aggregations\n        \"\"\"\n        # if there were groups with no observations (Categorical only?)\n        # try casting data to original dtype\n        cast = (self.size().fillna(0) > 0).any() </s> remove         results = np.empty_like(obj.values, result.values.dtype)\n        for (name, group), (i, row) in zip(self, result.iterrows()):\n            indexer = self._get_index(name)\n            if len(indexer) > 0:\n                results[indexer] = np.tile(row.values, len(\n                    indexer)).reshape(len(indexer), -1)\n </s> add         return self._transform_fast(result, obj) </s> remove         return (DataFrame(results, columns=result.columns, index=obj.index)\n                ._convert(datetime=True))\n </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index) </s> remove         mask = ids != -1\n\n        out = func().values[ids]\n        if not mask.all():\n            out = np.where(mask, out, np.nan)\n\n        obs = np.zeros(ngroup, dtype='bool')\n        obs[ids[mask]] = True\n        if not obs.all():\n            out = self._try_cast(out, self._selected_obj)\n\n        return Series(out, index=self.obj.index)\n </s> add         cast = (self.size().fillna(0) > 0).any()\n        out = algos.take_1d(func().values, ids)\n        if cast:\n            out = self._try_cast(out, self.obj)\n        return Series(out, index=self.obj.index, name=self.obj.name) </s> remove         expected = Series([pd.Timestamp('2000-01-1')] * 2)\n </s> add         expected = Series([pd.Timestamp('2000-01-1')] * 2, name='B')", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "doc/source/whatsnew/v0.18.2.txt"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         if isinstance(func, compat.string_types):\n <mask>             func = getattr(self, func)\n <mask> \n <mask>         ids, _, ngroup = self.grouper.group_info\n <mask>         mask = ids != -1\n <mask> \n <mask>         out = func().values[ids]\n <mask>         if not mask.all():\n <mask>             out = np.where(mask, out, np.nan)\n <mask> \n <mask>         obs = np.zeros(ngroup, dtype='bool')\n <mask>         obs[ids[mask]] = True\n <mask>         if not obs.all():\n <mask>             out = self._try_cast(out, self._selected_obj)\n <mask> \n <mask>         return Series(out, index=self.obj.index)\n <mask> \n <mask>     def filter(self, func, dropna=True, *args, **kwargs):  # noqa\n <mask>         \"\"\"\n <mask>         Return a copy of a Series excluding elements from groups that\n <mask>         do not satisfy the boolean criterion specified by func.\n </s> PERF: DataFrame transform\n\ncloses #12737\ncloses #13191\n\nAuthor: Chris <cbartak@gmail.com>\n\nCloses #13192 from chris-b1/transform-perf and squashes the following commits:\n\n0af1e55 [Chris] revert casting logic\nd61d4e0 [Chris] handle duplicate column case\n9d78f65 [Chris] other categorical test name fix\n045d0c7 [Chris] add back some casting\nb66a1c8 [Chris] PERF: DataFrame transform </s> remove         return (DataFrame(results, columns=result.columns, index=obj.index)\n                ._convert(datetime=True))\n </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index) </s> remove         results = np.empty_like(obj.values, result.values.dtype)\n        for (name, group), (i, row) in zip(self, result.iterrows()):\n            indexer = self._get_index(name)\n            if len(indexer) > 0:\n                results[indexer] = np.tile(row.values, len(\n                    indexer)).reshape(len(indexer), -1)\n </s> add         return self._transform_fast(result, obj) </s> remove         counts = self.size().fillna(0).values\n        if any(counts == 0):\n            results = self._try_cast(results, obj[result.columns])\n </s> add     def _transform_fast(self, result, obj):\n        \"\"\"\n        Fast transform path for aggregations\n        \"\"\"\n        # if there were groups with no observations (Categorical only?)\n        # try casting data to original dtype\n        cast = (self.size().fillna(0) > 0).any() </s> add     def test_series_fast_transform_date(self):\n        # GH 13191\n        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],\n                           'd': pd.date_range('2014-1-1', '2014-1-4')})\n        result = df.groupby('grouping')['d'].transform('first')\n        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),\n                 pd.Timestamp('2014-1-4')]\n        expected = pd.Series(dates, name='d')\n        assert_series_equal(result, expected)\n </s> remove         expected = pd.Series(values, index=df.index)\n </s> add         expected = pd.Series(values, index=df.index, name='val') </s> remove         expected = Series([pd.Timestamp('2000-01-1')] * 2)\n </s> add         expected = Series([pd.Timestamp('2000-01-1')] * 2, name='B')", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/core/groupby.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace keep replace replace replace", "code_tokens": " <mask>             return self._transform_general(func, *args, **kwargs)\n <mask> \n <mask>         results = np.empty_like(obj.values, result.values.dtype)\n <mask>         for (name, group), (i, row) in zip(self, result.iterrows()):\n <mask>             indexer = self._get_index(name)\n <mask>             if len(indexer) > 0:\n <mask>                 results[indexer] = np.tile(row.values, len(\n <mask>                     indexer)).reshape(len(indexer), -1)\n <mask> \n <mask>         counts = self.size().fillna(0).values\n <mask>         if any(counts == 0):\n <mask>             results = self._try_cast(results, obj[result.columns])\n </s> PERF: DataFrame transform\n\ncloses #12737\ncloses #13191\n\nAuthor: Chris <cbartak@gmail.com>\n\nCloses #13192 from chris-b1/transform-perf and squashes the following commits:\n\n0af1e55 [Chris] revert casting logic\nd61d4e0 [Chris] handle duplicate column case\n9d78f65 [Chris] other categorical test name fix\n045d0c7 [Chris] add back some casting\nb66a1c8 [Chris] PERF: DataFrame transform </s> remove         return (DataFrame(results, columns=result.columns, index=obj.index)\n                ._convert(datetime=True))\n </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index) </s> remove         mask = ids != -1\n\n        out = func().values[ids]\n        if not mask.all():\n            out = np.where(mask, out, np.nan)\n\n        obs = np.zeros(ngroup, dtype='bool')\n        obs[ids[mask]] = True\n        if not obs.all():\n            out = self._try_cast(out, self._selected_obj)\n\n        return Series(out, index=self.obj.index)\n </s> add         cast = (self.size().fillna(0) > 0).any()\n        out = algos.take_1d(func().values, ids)\n        if cast:\n            out = self._try_cast(out, self.obj)\n        return Series(out, index=self.obj.index, name=self.obj.name) </s> remove         expected = pd.Series(values, index=df.index)\n </s> add         expected = pd.Series(values, index=df.index, name='val') </s> add     def test_series_fast_transform_date(self):\n        # GH 13191\n        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],\n                           'd': pd.date_range('2014-1-1', '2014-1-4')})\n        result = df.groupby('grouping')['d'].transform('first')\n        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),\n                 pd.Timestamp('2014-1-4')]\n        expected = pd.Series(dates, name='d')\n        assert_series_equal(result, expected)\n </s> remove         expected = Series([pd.Timestamp('2000-01-1')] * 2)\n </s> add         expected = Series([pd.Timestamp('2000-01-1')] * 2, name='B')", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/core/groupby.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         counts = self.size().fillna(0).values\n <mask>         if any(counts == 0):\n <mask>             results = self._try_cast(results, obj[result.columns])\n <mask> \n <mask>         return (DataFrame(results, columns=result.columns, index=obj.index)\n <mask>                 ._convert(datetime=True))\n <mask> \n <mask>     def _define_paths(self, func, *args, **kwargs):\n <mask>         if isinstance(func, compat.string_types):\n <mask>             fast_path = lambda group: getattr(group, func)(*args, **kwargs)\n <mask>             slow_path = lambda group: group.apply(\n </s> PERF: DataFrame transform\n\ncloses #12737\ncloses #13191\n\nAuthor: Chris <cbartak@gmail.com>\n\nCloses #13192 from chris-b1/transform-perf and squashes the following commits:\n\n0af1e55 [Chris] revert casting logic\nd61d4e0 [Chris] handle duplicate column case\n9d78f65 [Chris] other categorical test name fix\n045d0c7 [Chris] add back some casting\nb66a1c8 [Chris] PERF: DataFrame transform </s> remove         counts = self.size().fillna(0).values\n        if any(counts == 0):\n            results = self._try_cast(results, obj[result.columns])\n </s> add     def _transform_fast(self, result, obj):\n        \"\"\"\n        Fast transform path for aggregations\n        \"\"\"\n        # if there were groups with no observations (Categorical only?)\n        # try casting data to original dtype\n        cast = (self.size().fillna(0) > 0).any() </s> remove         results = np.empty_like(obj.values, result.values.dtype)\n        for (name, group), (i, row) in zip(self, result.iterrows()):\n            indexer = self._get_index(name)\n            if len(indexer) > 0:\n                results[indexer] = np.tile(row.values, len(\n                    indexer)).reshape(len(indexer), -1)\n </s> add         return self._transform_fast(result, obj) </s> remove         mask = ids != -1\n\n        out = func().values[ids]\n        if not mask.all():\n            out = np.where(mask, out, np.nan)\n\n        obs = np.zeros(ngroup, dtype='bool')\n        obs[ids[mask]] = True\n        if not obs.all():\n            out = self._try_cast(out, self._selected_obj)\n\n        return Series(out, index=self.obj.index)\n </s> add         cast = (self.size().fillna(0) > 0).any()\n        out = algos.take_1d(func().values, ids)\n        if cast:\n            out = self._try_cast(out, self.obj)\n        return Series(out, index=self.obj.index, name=self.obj.name) </s> remove         expected = pd.Series(values, index=df.index)\n </s> add         expected = pd.Series(values, index=df.index, name='val') </s> add     def test_series_fast_transform_date(self):\n        # GH 13191\n        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],\n                           'd': pd.date_range('2014-1-1', '2014-1-4')})\n        result = df.groupby('grouping')['d'].transform('first')\n        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),\n                 pd.Timestamp('2014-1-4')]\n        expected = pd.Series(dates, name='d')\n        assert_series_equal(result, expected)\n </s> remove         expected = Series([pd.Timestamp('2000-01-1')] * 2)\n </s> add         expected = Series([pd.Timestamp('2000-01-1')] * 2, name='B')", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/core/groupby.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         df = DataFrame({\"a\": [5, 15, 25]})\n <mask>         c = pd.cut(df.a, bins=[0, 10, 20, 30, 40])\n <mask> \n <mask>         result = df.a.groupby(c).transform(sum)\n <mask>         tm.assert_series_equal(result, df['a'], check_names=False)\n <mask>         self.assertTrue(result.name is None)\n <mask> \n <mask>         tm.assert_series_equal(\n <mask>             df.a.groupby(c).transform(lambda xs: np.sum(xs)), df['a'])\n <mask>         tm.assert_frame_equal(df.groupby(c).transform(sum), df[['a']])\n <mask>         tm.assert_frame_equal(\n </s> PERF: DataFrame transform\n\ncloses #12737\ncloses #13191\n\nAuthor: Chris <cbartak@gmail.com>\n\nCloses #13192 from chris-b1/transform-perf and squashes the following commits:\n\n0af1e55 [Chris] revert casting logic\nd61d4e0 [Chris] handle duplicate column case\n9d78f65 [Chris] other categorical test name fix\n045d0c7 [Chris] add back some casting\nb66a1c8 [Chris] PERF: DataFrame transform </s> remove         tm.assert_series_equal(result, df['a'], check_names=False)\n        self.assertTrue(result.name is None)\n </s> add         tm.assert_series_equal(result, df['a']) </s> add     def test_series_fast_transform_date(self):\n        # GH 13191\n        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],\n                           'd': pd.date_range('2014-1-1', '2014-1-4')})\n        result = df.groupby('grouping')['d'].transform('first')\n        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),\n                 pd.Timestamp('2014-1-4')]\n        expected = pd.Series(dates, name='d')\n        assert_series_equal(result, expected)\n </s> remove         expected = Series([pd.Timestamp('2000-01-1')] * 2)\n </s> add         expected = Series([pd.Timestamp('2000-01-1')] * 2, name='B') </s> remove         expected = pd.Series(values, index=df.index)\n </s> add         expected = pd.Series(values, index=df.index, name='val') </s> remove         mask = ids != -1\n\n        out = func().values[ids]\n        if not mask.all():\n            out = np.where(mask, out, np.nan)\n\n        obs = np.zeros(ngroup, dtype='bool')\n        obs[ids[mask]] = True\n        if not obs.all():\n            out = self._try_cast(out, self._selected_obj)\n\n        return Series(out, index=self.obj.index)\n </s> add         cast = (self.size().fillna(0) > 0).any()\n        out = algos.take_1d(func().values, ids)\n        if cast:\n            out = self._try_cast(out, self.obj)\n        return Series(out, index=self.obj.index, name=self.obj.name) </s> remove         return (DataFrame(results, columns=result.columns, index=obj.index)\n                ._convert(datetime=True))\n </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index)", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/tests/test_categorical.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         df = DataFrame({\"a\": [5, 15, 25, -5]})\n <mask>         c = pd.cut(df.a, bins=[-10, 0, 10, 20, 30, 40])\n <mask> \n <mask>         result = df.a.groupby(c).transform(sum)\n <mask>         tm.assert_series_equal(result, df['a'], check_names=False)\n <mask>         self.assertTrue(result.name is None)\n <mask> \n <mask>         tm.assert_series_equal(\n <mask>             df.a.groupby(c).transform(lambda xs: np.sum(xs)), df['a'])\n <mask>         tm.assert_frame_equal(df.groupby(c).transform(sum), df[['a']])\n <mask>         tm.assert_frame_equal(\n </s> PERF: DataFrame transform\n\ncloses #12737\ncloses #13191\n\nAuthor: Chris <cbartak@gmail.com>\n\nCloses #13192 from chris-b1/transform-perf and squashes the following commits:\n\n0af1e55 [Chris] revert casting logic\nd61d4e0 [Chris] handle duplicate column case\n9d78f65 [Chris] other categorical test name fix\n045d0c7 [Chris] add back some casting\nb66a1c8 [Chris] PERF: DataFrame transform </s> remove         tm.assert_series_equal(result, df['a'], check_names=False)\n        self.assertTrue(result.name is None)\n </s> add         tm.assert_series_equal(result, df['a']) </s> add     def test_series_fast_transform_date(self):\n        # GH 13191\n        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],\n                           'd': pd.date_range('2014-1-1', '2014-1-4')})\n        result = df.groupby('grouping')['d'].transform('first')\n        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),\n                 pd.Timestamp('2014-1-4')]\n        expected = pd.Series(dates, name='d')\n        assert_series_equal(result, expected)\n </s> remove         expected = Series([pd.Timestamp('2000-01-1')] * 2)\n </s> add         expected = Series([pd.Timestamp('2000-01-1')] * 2, name='B') </s> remove         expected = pd.Series(values, index=df.index)\n </s> add         expected = pd.Series(values, index=df.index, name='val') </s> remove         mask = ids != -1\n\n        out = func().values[ids]\n        if not mask.all():\n            out = np.where(mask, out, np.nan)\n\n        obs = np.zeros(ngroup, dtype='bool')\n        obs[ids[mask]] = True\n        if not obs.all():\n            out = self._try_cast(out, self._selected_obj)\n\n        return Series(out, index=self.obj.index)\n </s> add         cast = (self.size().fillna(0) > 0).any()\n        out = algos.take_1d(func().values, ids)\n        if cast:\n            out = self._try_cast(out, self.obj)\n        return Series(out, index=self.obj.index, name=self.obj.name) </s> remove         return (DataFrame(results, columns=result.columns, index=obj.index)\n                ._convert(datetime=True))\n </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index)", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/tests/test_categorical.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         grp = df.groupby('id')['val']\n <mask> \n <mask>         values = np.repeat(grp.mean().values,\n <mask>                            com._ensure_platform_int(grp.count().values))\n <mask>         expected = pd.Series(values, index=df.index)\n <mask>         result = grp.transform(np.mean)\n <mask>         assert_series_equal(result, expected)\n <mask> \n <mask>         result = grp.transform('mean')\n <mask>         assert_series_equal(result, expected)\n </s> PERF: DataFrame transform\n\ncloses #12737\ncloses #13191\n\nAuthor: Chris <cbartak@gmail.com>\n\nCloses #13192 from chris-b1/transform-perf and squashes the following commits:\n\n0af1e55 [Chris] revert casting logic\nd61d4e0 [Chris] handle duplicate column case\n9d78f65 [Chris] other categorical test name fix\n045d0c7 [Chris] add back some casting\nb66a1c8 [Chris] PERF: DataFrame transform </s> add     def test_series_fast_transform_date(self):\n        # GH 13191\n        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],\n                           'd': pd.date_range('2014-1-1', '2014-1-4')})\n        result = df.groupby('grouping')['d'].transform('first')\n        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),\n                 pd.Timestamp('2014-1-4')]\n        expected = pd.Series(dates, name='d')\n        assert_series_equal(result, expected)\n </s> remove         expected = Series([pd.Timestamp('2000-01-1')] * 2)\n </s> add         expected = Series([pd.Timestamp('2000-01-1')] * 2, name='B') </s> remove         tm.assert_series_equal(result, df['a'], check_names=False)\n        self.assertTrue(result.name is None)\n </s> add         tm.assert_series_equal(result, df['a']) </s> remove         tm.assert_series_equal(result, df['a'], check_names=False)\n        self.assertTrue(result.name is None)\n </s> add         tm.assert_series_equal(result, df['a']) </s> remove         mask = ids != -1\n\n        out = func().values[ids]\n        if not mask.all():\n            out = np.where(mask, out, np.nan)\n\n        obs = np.zeros(ngroup, dtype='bool')\n        obs[ids[mask]] = True\n        if not obs.all():\n            out = self._try_cast(out, self._selected_obj)\n\n        return Series(out, index=self.obj.index)\n </s> add         cast = (self.size().fillna(0) > 0).any()\n        out = algos.take_1d(func().values, ids)\n        if cast:\n            out = self._try_cast(out, self.obj)\n        return Series(out, index=self.obj.index, name=self.obj.name) </s> remove         return (DataFrame(results, columns=result.columns, index=obj.index)\n                ._convert(datetime=True))\n </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index)", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/tests/test_groupby.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>         result = self.df.groupby('A')['C'].transform('mean')\n <mask>         expected = self.df.groupby('A')['C'].transform(np.mean)\n <mask>         assert_series_equal(result, expected)\n <mask> \n <mask>     def test_transform_length(self):\n <mask>         # GH 9697\n <mask>         df = pd.DataFrame({'col1': [1, 1, 2, 2], 'col2': [1, 2, 3, np.nan]})\n <mask>         expected = pd.Series([3.0] * 4)\n <mask> \n </s> PERF: DataFrame transform\n\ncloses #12737\ncloses #13191\n\nAuthor: Chris <cbartak@gmail.com>\n\nCloses #13192 from chris-b1/transform-perf and squashes the following commits:\n\n0af1e55 [Chris] revert casting logic\nd61d4e0 [Chris] handle duplicate column case\n9d78f65 [Chris] other categorical test name fix\n045d0c7 [Chris] add back some casting\nb66a1c8 [Chris] PERF: DataFrame transform </s> remove         expected = Series([pd.Timestamp('2000-01-1')] * 2)\n </s> add         expected = Series([pd.Timestamp('2000-01-1')] * 2, name='B') </s> remove         expected = pd.Series(values, index=df.index)\n </s> add         expected = pd.Series(values, index=df.index, name='val') </s> add class groupby_transform_dataframe(object):\n    # GH 12737\n    goal_time = 0.2\n\n    def setup(self):\n        self.df = pd.DataFrame({'group': np.repeat(np.arange(1000), 10),\n                                'B': np.nan,\n                                'C': np.nan})\n        self.df.ix[4::10, 'B':'C'] = 5\n\n    def time_groupby_transform_dataframe(self):\n        self.df.groupby('group').transform('first')\n\n </s> remove         tm.assert_series_equal(result, df['a'], check_names=False)\n        self.assertTrue(result.name is None)\n </s> add         tm.assert_series_equal(result, df['a']) </s> remove         tm.assert_series_equal(result, df['a'], check_names=False)\n        self.assertTrue(result.name is None)\n </s> add         tm.assert_series_equal(result, df['a']) </s> remove         return (DataFrame(results, columns=result.columns, index=obj.index)\n                ._convert(datetime=True))\n </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index)", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/tests/test_groupby.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # 32-bit under 1.9-dev indexing issue\n <mask> \n <mask>         df = DataFrame({\"A\": range(2), \"B\": [pd.Timestamp('2000-01-1')] * 2})\n <mask>         result = df.groupby(\"A\")[\"B\"].transform(min)\n <mask>         expected = Series([pd.Timestamp('2000-01-1')] * 2)\n <mask>         assert_series_equal(result, expected)\n <mask> \n <mask>     def test_groupby_categorical_unequal_len(self):\n <mask>         # GH3011\n <mask>         series = Series([np.nan, np.nan, 1, 1, 2, 2, 3, 3, 4, 4])\n </s> PERF: DataFrame transform\n\ncloses #12737\ncloses #13191\n\nAuthor: Chris <cbartak@gmail.com>\n\nCloses #13192 from chris-b1/transform-perf and squashes the following commits:\n\n0af1e55 [Chris] revert casting logic\nd61d4e0 [Chris] handle duplicate column case\n9d78f65 [Chris] other categorical test name fix\n045d0c7 [Chris] add back some casting\nb66a1c8 [Chris] PERF: DataFrame transform </s> add     def test_series_fast_transform_date(self):\n        # GH 13191\n        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],\n                           'd': pd.date_range('2014-1-1', '2014-1-4')})\n        result = df.groupby('grouping')['d'].transform('first')\n        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),\n                 pd.Timestamp('2014-1-4')]\n        expected = pd.Series(dates, name='d')\n        assert_series_equal(result, expected)\n </s> remove         expected = pd.Series(values, index=df.index)\n </s> add         expected = pd.Series(values, index=df.index, name='val') </s> add class groupby_transform_dataframe(object):\n    # GH 12737\n    goal_time = 0.2\n\n    def setup(self):\n        self.df = pd.DataFrame({'group': np.repeat(np.arange(1000), 10),\n                                'B': np.nan,\n                                'C': np.nan})\n        self.df.ix[4::10, 'B':'C'] = 5\n\n    def time_groupby_transform_dataframe(self):\n        self.df.groupby('group').transform('first')\n\n </s> remove         return (DataFrame(results, columns=result.columns, index=obj.index)\n                ._convert(datetime=True))\n </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index) </s> remove         tm.assert_series_equal(result, df['a'], check_names=False)\n        self.assertTrue(result.name is None)\n </s> add         tm.assert_series_equal(result, df['a']) </s> remove         results = np.empty_like(obj.values, result.values.dtype)\n        for (name, group), (i, row) in zip(self, result.iterrows()):\n            indexer = self._get_index(name)\n            if len(indexer) > 0:\n                results[indexer] = np.tile(row.values, len(\n                    indexer)).reshape(len(indexer), -1)\n </s> add         return self._transform_fast(result, obj)", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/tests/test_groupby.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>    Series.str.normalize\n <mask>    Series.str.pad\n <mask>    Series.str.repeat\n <mask>    Series.str.replace\n <mask>    Series.str.rfind\n <mask>    Series.str.rjust\n <mask>    Series.str.rpartition\n <mask>    Series.str.rstrip\n </s> ENH: Add StringMethods.partition and rpartition </s> add    Series.str.rpartition </s> add     def test_empty_str_methods_to_frame(self):\n        empty_str = empty = Series(dtype=str)\n        empty_df = DataFrame([])\n        tm.assert_frame_equal(empty_df, empty.str.partition('a'))\n        tm.assert_frame_equal(empty_df, empty.str.rpartition('a'))\n </s> add         tm.assert_series_equal(empty_list, empty.str.partition('a', expand=False))\n        tm.assert_series_equal(empty_list, empty.str.rpartition('a', expand=False)) </s> add         # leave as it is to keep extract and get_dummies results\n        # can be merged to _wrap_result_expand in v0.17 </s> add - Added ``StringMethods.partition()`` and ``rpartition()`` which behave as the same as standard ``str`` (:issue:`9773`) </s> add     :meth:`~Series.str.partition`,Equivalent to ``str.partition``\n    :meth:`~Series.str.rpartition`,Equivalent to ``str.rpartition``", "html_url": "https://github.com/pandas-dev/pandas/commit/00c2408ac7837edd8d5d2098f8a95d666dd9857c", "file_name": "doc/source/api.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>    Series.str.replace\n <mask>    Series.str.rfind\n <mask>    Series.str.rjust\n <mask>    Series.str.rstrip\n <mask>    Series.str.slice\n <mask>    Series.str.slice_replace\n <mask>    Series.str.split\n <mask>    Series.str.startswith\n <mask>    Series.str.strip\n </s> ENH: Add StringMethods.partition and rpartition </s> add    Series.str.partition </s> add     def test_empty_str_methods_to_frame(self):\n        empty_str = empty = Series(dtype=str)\n        empty_df = DataFrame([])\n        tm.assert_frame_equal(empty_df, empty.str.partition('a'))\n        tm.assert_frame_equal(empty_df, empty.str.rpartition('a'))\n </s> add         tm.assert_series_equal(empty_list, empty.str.partition('a', expand=False))\n        tm.assert_series_equal(empty_list, empty.str.rpartition('a', expand=False)) </s> add         # leave as it is to keep extract and get_dummies results\n        # can be merged to _wrap_result_expand in v0.17 </s> add - Added ``StringMethods.partition()`` and ``rpartition()`` which behave as the same as standard ``str`` (:issue:`9773`) </s> add     :meth:`~Series.str.partition`,Equivalent to ``str.partition``\n    :meth:`~Series.str.rpartition`,Equivalent to ``str.rpartition``", "html_url": "https://github.com/pandas-dev/pandas/commit/00c2408ac7837edd8d5d2098f8a95d666dd9857c", "file_name": "doc/source/api.rst"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     :meth:`~Series.str.rstrip`,Equivalent to ``str.rstrip``\n <mask>     :meth:`~Series.str.lstrip`,Equivalent to ``str.lstrip``\n <mask>     :meth:`~Series.str.lower`,Equivalent to ``str.lower``\n <mask>     :meth:`~Series.str.upper`,Equivalent to ``str.upper``\n <mask>     :meth:`~Series.str.find`,Equivalent to ``str.find``\n <mask>     :meth:`~Series.str.rfind`,Equivalent to ``str.rfind``\n <mask>     :meth:`~Series.str.capitalize`,Equivalent to ``str.capitalize``\n </s> ENH: Add StringMethods.partition and rpartition </s> add         # leave as it is to keep extract and get_dummies results\n        # can be merged to _wrap_result_expand in v0.17 </s> add - Added ``StringMethods.partition()`` and ``rpartition()`` which behave as the same as standard ``str`` (:issue:`9773`) </s> add     def test_empty_str_methods_to_frame(self):\n        empty_str = empty = Series(dtype=str)\n        empty_df = DataFrame([])\n        tm.assert_frame_equal(empty_df, empty.str.partition('a'))\n        tm.assert_frame_equal(empty_df, empty.str.rpartition('a'))\n </s> add         tm.assert_series_equal(empty_list, empty.str.partition('a', expand=False))\n        tm.assert_series_equal(empty_list, empty.str.rpartition('a', expand=False)) </s> add    Series.str.rpartition </s> add    Series.str.partition", "html_url": "https://github.com/pandas-dev/pandas/commit/00c2408ac7837edd8d5d2098f8a95d666dd9857c", "file_name": "doc/source/text.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> - Added ``StringMethods`` (.str accessor) to ``Index`` (:issue:`9068`)\n <mask> - Added ``StringMethods.normalize()`` which behaves the same as standard :func:`unicodedata.normalizes` (:issue:`10031`)\n <mask> \n <mask> - Allow clip, clip_lower, and clip_upper to accept array-like arguments as thresholds (:issue:`6966`). These methods now have an ``axis`` parameter which determines how the Series or DataFrame will be aligned with the threshold(s).\n <mask> \n <mask>   The ``.str`` accessor is now available for both ``Series`` and ``Index``.\n <mask> \n <mask>   .. ipython:: python\n <mask> \n </s> ENH: Add StringMethods.partition and rpartition </s> add         # leave as it is to keep extract and get_dummies results\n        # can be merged to _wrap_result_expand in v0.17 </s> add     :meth:`~Series.str.partition`,Equivalent to ``str.partition``\n    :meth:`~Series.str.rpartition`,Equivalent to ``str.rpartition`` </s> add     def test_empty_str_methods_to_frame(self):\n        empty_str = empty = Series(dtype=str)\n        empty_df = DataFrame([])\n        tm.assert_frame_equal(empty_df, empty.str.partition('a'))\n        tm.assert_frame_equal(empty_df, empty.str.rpartition('a'))\n </s> add         tm.assert_series_equal(empty_list, empty.str.partition('a', expand=False))\n        tm.assert_series_equal(empty_list, empty.str.rpartition('a', expand=False)) </s> add    Series.str.rpartition </s> add    Series.str.partition", "html_url": "https://github.com/pandas-dev/pandas/commit/00c2408ac7837edd8d5d2098f8a95d666dd9857c", "file_name": "doc/source/whatsnew/v0.16.1.txt"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>             g = self.get(i)\n <mask> \n <mask>     def _wrap_result(self, result):\n <mask>         from pandas.core.series import Series\n <mask>         from pandas.core.frame import DataFrame\n <mask>         from pandas.core.index import Index\n <mask> \n <mask>         if not hasattr(result, 'ndim'):\n </s> ENH: Add StringMethods.partition and rpartition </s> add     def test_empty_str_methods_to_frame(self):\n        empty_str = empty = Series(dtype=str)\n        empty_df = DataFrame([])\n        tm.assert_frame_equal(empty_df, empty.str.partition('a'))\n        tm.assert_frame_equal(empty_df, empty.str.rpartition('a'))\n </s> add - Added ``StringMethods.partition()`` and ``rpartition()`` which behave as the same as standard ``str`` (:issue:`9773`) </s> add         tm.assert_series_equal(empty_list, empty.str.partition('a', expand=False))\n        tm.assert_series_equal(empty_list, empty.str.rpartition('a', expand=False)) </s> add     :meth:`~Series.str.partition`,Equivalent to ``str.partition``\n    :meth:`~Series.str.rpartition`,Equivalent to ``str.rpartition`` </s> add    Series.str.rpartition </s> add    Series.str.partition", "html_url": "https://github.com/pandas-dev/pandas/commit/00c2408ac7837edd8d5d2098f8a95d666dd9857c", "file_name": "pandas/core/strings.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         tm.assert_series_equal(empty_str, empty.str.center(42))\n <mask>         tm.assert_series_equal(empty_list, empty.str.split('a'))\n <mask>         tm.assert_series_equal(empty_str, empty.str.slice(stop=1))\n <mask>         tm.assert_series_equal(empty_str, empty.str.slice(step=1))\n <mask>         tm.assert_series_equal(empty_str, empty.str.strip())\n <mask>         tm.assert_series_equal(empty_str, empty.str.lstrip())\n </s> ENH: Add StringMethods.partition and rpartition </s> add     def test_empty_str_methods_to_frame(self):\n        empty_str = empty = Series(dtype=str)\n        empty_df = DataFrame([])\n        tm.assert_frame_equal(empty_df, empty.str.partition('a'))\n        tm.assert_frame_equal(empty_df, empty.str.rpartition('a'))\n </s> add         # leave as it is to keep extract and get_dummies results\n        # can be merged to _wrap_result_expand in v0.17 </s> add - Added ``StringMethods.partition()`` and ``rpartition()`` which behave as the same as standard ``str`` (:issue:`9773`) </s> add     :meth:`~Series.str.partition`,Equivalent to ``str.partition``\n    :meth:`~Series.str.rpartition`,Equivalent to ``str.rpartition`` </s> add    Series.str.rpartition </s> add    Series.str.partition", "html_url": "https://github.com/pandas-dev/pandas/commit/00c2408ac7837edd8d5d2098f8a95d666dd9857c", "file_name": "pandas/tests/test_strings.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         tm.assert_series_equal(empty_str, empty.str.normalize('NFC'))\n <mask> \n <mask>     def test_ismethods(self):\n <mask>         values = ['A', 'b', 'Xy', '4', '3A', '', 'TT', '55', '-', '  ']\n <mask>         str_s = Series(values)\n <mask>         alnum_e = [True, True, True, True, True, False, True, True, False, False]\n </s> ENH: Add StringMethods.partition and rpartition </s> add         # leave as it is to keep extract and get_dummies results\n        # can be merged to _wrap_result_expand in v0.17 </s> add         tm.assert_series_equal(empty_list, empty.str.partition('a', expand=False))\n        tm.assert_series_equal(empty_list, empty.str.rpartition('a', expand=False)) </s> add - Added ``StringMethods.partition()`` and ``rpartition()`` which behave as the same as standard ``str`` (:issue:`9773`) </s> add     :meth:`~Series.str.partition`,Equivalent to ``str.partition``\n    :meth:`~Series.str.rpartition`,Equivalent to ``str.rpartition`` </s> add    Series.str.rpartition </s> add    Series.str.partition", "html_url": "https://github.com/pandas-dev/pandas/commit/00c2408ac7837edd8d5d2098f8a95d666dd9857c", "file_name": "pandas/tests/test_strings.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> This is a short introduction to pandas, geared mainly for new users.\n <mask> \n <mask> Customarily, we import as follows\n <mask> \n <mask> .. ipython:: python\n <mask> \n </s> DOC: cookbook updates - added idiom section </s> add Idioms\n------\n\n.. _cookbook.idioms:\n\nThese are some neat pandas ``idioms``\n\n`How to do if-then-else?\n<http://stackoverflow.com/questions/17128302/python-pandas-idiom-for-if-then-else>`__\n\n`How to split a frame with a boolean criterion?\n<http://stackoverflow.com/questions/14957116/how-to-split-a-dataframe-according-to-a-boolean-criterion>`__\n\n`How to select from a frame with complex criteria?\n<http://stackoverflow.com/questions/15315452/selecting-with-complex-criteria-from-pandas-dataframe>`__\n </s> add `appending to a csv\n<http://stackoverflow.com/questions/17134942/pandas-dataframe-output-end-of-csv>`__\n </s> add `Using TimeGrouper and another grouping to create subgroups, then apply a custom function\n<https://github.com/pydata/pandas/issues/3791>`__\n", "html_url": "https://github.com/pandas-dev/pandas/commit/010f7a4ab96b3eb149daad59c9c91ea462a7ee37", "file_name": "doc/source/10min.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> This is a great *First Pull Request* (to add interesting links and/or put short code inline\n <mask> for existing links)\n <mask> \n <mask> .. _cookbook.selection:\n <mask> \n <mask> Selection\n <mask> ---------\n <mask> \n </s> DOC: cookbook updates - added idiom section </s> add `appending to a csv\n<http://stackoverflow.com/questions/17134942/pandas-dataframe-output-end-of-csv>`__\n </s> add `Using TimeGrouper and another grouping to create subgroups, then apply a custom function\n<https://github.com/pydata/pandas/issues/3791>`__\n </s> add You can see more complex recipes in the :ref:`Cookbook<cookbook>`\r", "html_url": "https://github.com/pandas-dev/pandas/commit/010f7a4ab96b3eb149daad59c9c91ea462a7ee37", "file_name": "doc/source/cookbook.rst"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> <http://stackoverflow.com/questions/14569223/timegrouper-pandas>`__\n <mask> \n <mask> `Resampling with custom periods\n <mask> <http://stackoverflow.com/questions/15408156/resampling-with-custom-periods>`__\n <mask> \n <mask> `Resample intraday frame without adding new days\n <mask> <http://stackoverflow.com/questions/14898574/resample-intrday-pandas-dataframe-without-add-new-days>`__\n </s> DOC: cookbook updates - added idiom section </s> add `appending to a csv\n<http://stackoverflow.com/questions/17134942/pandas-dataframe-output-end-of-csv>`__\n </s> add Idioms\n------\n\n.. _cookbook.idioms:\n\nThese are some neat pandas ``idioms``\n\n`How to do if-then-else?\n<http://stackoverflow.com/questions/17128302/python-pandas-idiom-for-if-then-else>`__\n\n`How to split a frame with a boolean criterion?\n<http://stackoverflow.com/questions/14957116/how-to-split-a-dataframe-according-to-a-boolean-criterion>`__\n\n`How to select from a frame with complex criteria?\n<http://stackoverflow.com/questions/15315452/selecting-with-complex-criteria-from-pandas-dataframe>`__\n </s> add You can see more complex recipes in the :ref:`Cookbook<cookbook>`\r", "html_url": "https://github.com/pandas-dev/pandas/commit/010f7a4ab96b3eb149daad59c9c91ea462a7ee37", "file_name": "doc/source/cookbook.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> `read_csv in action\n <mask> <http://wesmckinney.com/blog/?p=635>`__\n <mask> \n <mask> `Reading a csv chunk-by-chunk\n <mask> <http://stackoverflow.com/questions/11622652/large-persistent-dataframe-in-pandas/12193309#12193309>`__\n <mask> \n <mask> `Reading the first few lines of a frame\n <mask> <http://stackoverflow.com/questions/15008970/way-to-read-first-few-lines-for-pandas-dataframe>`__\n </s> DOC: cookbook updates - added idiom section </s> add Idioms\n------\n\n.. _cookbook.idioms:\n\nThese are some neat pandas ``idioms``\n\n`How to do if-then-else?\n<http://stackoverflow.com/questions/17128302/python-pandas-idiom-for-if-then-else>`__\n\n`How to split a frame with a boolean criterion?\n<http://stackoverflow.com/questions/14957116/how-to-split-a-dataframe-according-to-a-boolean-criterion>`__\n\n`How to select from a frame with complex criteria?\n<http://stackoverflow.com/questions/15315452/selecting-with-complex-criteria-from-pandas-dataframe>`__\n </s> add `Using TimeGrouper and another grouping to create subgroups, then apply a custom function\n<https://github.com/pydata/pandas/issues/3791>`__\n </s> add You can see more complex recipes in the :ref:`Cookbook<cookbook>`\r", "html_url": "https://github.com/pandas-dev/pandas/commit/010f7a4ab96b3eb149daad59c9c91ea462a7ee37", "file_name": "doc/source/cookbook.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> - :func:`read_html()` no longer ignores all-whitespace ``<tr>`` within ``<thead>`` when considering the ``skiprows`` and ``header`` arguments. Previously, users had to decrease their ``header`` and ``skiprows`` values on such tables to work around the issue. (:issue:`21641`)\n <mask> - :func:`read_excel()` will correctly show the deprecation warning for previously deprecated ``sheetname`` (:issue:`17994`)\n <mask> - :func:`read_csv()` and func:`read_table()` will throw ``UnicodeError`` and not coredump on badly encoded strings (:issue:`22748`)\n <mask> - :func:`read_csv()` will correctly parse timezone-aware datetimes (:issue:`22256`)\n <mask> - :func:`read_sas()` will parse numbers in sas7bdat-files that have width less than 8 bytes correctly. (:issue:`21616`)\n <mask> - :func:`read_sas()` will correctly parse sas7bdat files with many columns (:issue:`22628`)\n <mask> - :func:`read_sas()` will correctly parse sas7bdat files with data page types having also bit 7 set (so page type is 128 + 256 = 384) (:issue:`16615`)\n <mask> - Bug in :meth:`detect_client_encoding` where potential ``IOError`` goes unhandled when importing in a mod_wsgi process due to restricted access to stdout. (:issue:`21552`)\n <mask> - Bug in :func:`to_string()` that broke column alignment when ``index=False`` and width of first column's values is greater than the width of first column's header (:issue:`16839`, :issue:`13032`)\n </s> BUG: Don't over-optimize memory with jagged CSV (#23527)\n\nWith jagged CSV's, we risk being too quick\r\nto dump memory that we need to allocate\r\nbecause previous chunks would have\r\nindicated much larger rows than we can\r\nanticipate in subsequent chunks.\r\n\r\nCloses gh-23509. </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    }\n </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    }\n </s> add         int64_t max_words_cap    # maximum word cap encountered </s> add     def test_read_chunksize_jagged_names(self):\n        # see gh-23509\n        data = \"\\n\".join([\"0\"] * 7 + [\",\".join([\"0\"] * 10)])\n        reader = self.read_csv(StringIO(data), names=range(10), chunksize=4)\n\n        expected = DataFrame()\n\n        for i in range(10):\n            if i == 0:\n                expected[i] = [0] * 8\n            else:\n                expected[i] = [np.nan] * 7 + [0]\n\n        result = pd.concat(reader)\n        tm.assert_frame_equal(result, expected)\n </s> add     int64_t max_words_cap;  // maximum word cap encountered </s> add     self->max_words_cap = sz;", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "doc/source/whatsnew/v0.24.0.txt"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         int64_t *word_starts  # where we are in the stream\n <mask>         int64_t words_len\n <mask>         int64_t words_cap\n <mask> \n <mask>         char *pword_start        # pointer to stream start of current field\n <mask>         int64_t word_start       # position start of current field\n <mask> \n <mask>         int64_t *line_start      # position in words for start of line\n <mask>         int64_t *line_fields     # Number of fields in each line\n </s> BUG: Don't over-optimize memory with jagged CSV (#23527)\n\nWith jagged CSV's, we risk being too quick\r\nto dump memory that we need to allocate\r\nbecause previous chunks would have\r\nindicated much larger rows than we can\r\nanticipate in subsequent chunks.\r\n\r\nCloses gh-23509. </s> add     int64_t max_words_cap;  // maximum word cap encountered </s> add     def test_read_chunksize_jagged_names(self):\n        # see gh-23509\n        data = \"\\n\".join([\"0\"] * 7 + [\",\".join([\"0\"] * 10)])\n        reader = self.read_csv(StringIO(data), names=range(10), chunksize=4)\n\n        expected = DataFrame()\n\n        for i in range(10):\n            if i == 0:\n                expected[i] = [0] * 8\n            else:\n                expected[i] = [np.nan] * 7 + [0]\n\n        result = pd.concat(reader)\n        tm.assert_frame_equal(result, expected)\n </s> add - Bug in :func:`read_csv()` in which memory management was prematurely optimized for the C engine when the data was being read in chunks (:issue:`23509`) </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    }\n </s> remove     int64_t i, cap;\n </s> add     int64_t i, cap, length; </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    }\n", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/_libs/parsers.pyx"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     sz = sz ? sz : 1;\n <mask>     self->words = (char **)malloc(sz * sizeof(char *));\n <mask>     self->word_starts = (int64_t *)malloc(sz * sizeof(int64_t));\n <mask>     self->words_cap = sz;\n <mask>     self->words_len = 0;\n <mask> \n <mask>     // line pointers and metadata\n <mask>     self->line_start = (int64_t *)malloc(sz * sizeof(int64_t));\n <mask> \n </s> BUG: Don't over-optimize memory with jagged CSV (#23527)\n\nWith jagged CSV's, we risk being too quick\r\nto dump memory that we need to allocate\r\nbecause previous chunks would have\r\nindicated much larger rows than we can\r\nanticipate in subsequent chunks.\r\n\r\nCloses gh-23509. </s> remove         (char **)grow_buffer((void *)self->words, self->words_len,\n </s> add         (char **)grow_buffer((void *)self->words, length, </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    }\n </s> add     def test_read_chunksize_jagged_names(self):\n        # see gh-23509\n        data = \"\\n\".join([\"0\"] * 7 + [\",\".join([\"0\"] * 10)])\n        reader = self.read_csv(StringIO(data), names=range(10), chunksize=4)\n\n        expected = DataFrame()\n\n        for i in range(10):\n            if i == 0:\n                expected[i] = [0] * 8\n            else:\n                expected[i] = [np.nan] * 7 + [0]\n\n        result = pd.concat(reader)\n        tm.assert_frame_equal(result, expected)\n </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    }\n </s> add     int64_t max_words_cap;  // maximum word cap encountered </s> add - Bug in :func:`read_csv()` in which memory management was prematurely optimized for the C engine when the data was being read in chunks (:issue:`23509`)", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/_libs/src/parser/tokenizer.c"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     free(self);\n <mask> }\n <mask> \n <mask> static int make_stream_space(parser_t *self, size_t nbytes) {\n <mask>     int64_t i, cap;\n <mask>     int status;\n <mask>     void *orig_ptr, *newptr;\n <mask> \n <mask>     // Can we fit potentially nbytes tokens (+ null terminators) in the stream?\n <mask> \n </s> BUG: Don't over-optimize memory with jagged CSV (#23527)\n\nWith jagged CSV's, we risk being too quick\r\nto dump memory that we need to allocate\r\nbecause previous chunks would have\r\nindicated much larger rows than we can\r\nanticipate in subsequent chunks.\r\n\r\nCloses gh-23509. </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    }\n </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    }\n </s> add     int64_t max_words_cap;  // maximum word cap encountered </s> add         int64_t max_words_cap    # maximum word cap encountered </s> add - Bug in :func:`read_csv()` in which memory management was prematurely optimized for the C engine when the data was being read in chunks (:issue:`23509`) </s> add     self->max_words_cap = sz;", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/_libs/src/parser/tokenizer.c"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     */\n <mask> \n <mask>     cap = self->words_cap;\n <mask>     self->words =\n <mask>         (char **)grow_buffer((void *)self->words, length,\n <mask>                              (int64_t*)&self->words_cap, nbytes,\n <mask>                              sizeof(char *), &status);\n </s> BUG: Don't over-optimize memory with jagged CSV (#23527)\n\nWith jagged CSV's, we risk being too quick\r\nto dump memory that we need to allocate\r\nbecause previous chunks would have\r\nindicated much larger rows than we can\r\nanticipate in subsequent chunks.\r\n\r\nCloses gh-23509. </s> remove         (char **)grow_buffer((void *)self->words, self->words_len,\n </s> add         (char **)grow_buffer((void *)self->words, length, </s> add     self->max_words_cap = sz; </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    }\n </s> add     def test_read_chunksize_jagged_names(self):\n        # see gh-23509\n        data = \"\\n\".join([\"0\"] * 7 + [\",\".join([\"0\"] * 10)])\n        reader = self.read_csv(StringIO(data), names=range(10), chunksize=4)\n\n        expected = DataFrame()\n\n        for i in range(10):\n            if i == 0:\n                expected[i] = [0] * 8\n            else:\n                expected[i] = [np.nan] * 7 + [0]\n\n        result = pd.concat(reader)\n        tm.assert_frame_equal(result, expected)\n </s> add - Bug in :func:`read_csv()` in which memory management was prematurely optimized for the C engine when the data was being read in chunks (:issue:`23509`) </s> add     int64_t max_words_cap;  // maximum word cap encountered", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/_libs/src/parser/tokenizer.c"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     */\n <mask> \n <mask>     cap = self->words_cap;\n <mask>     self->words =\n <mask>         (char **)grow_buffer((void *)self->words, self->words_len,\n <mask>                              (int64_t*)&self->words_cap, nbytes,\n <mask>                              sizeof(char *), &status);\n <mask>     TRACE(\n <mask>         (\"make_stream_space: grow_buffer(self->self->words, %zu, %zu, %zu, \"\n <mask>          \"%d)\\n\",\n </s> BUG: Don't over-optimize memory with jagged CSV (#23527)\n\nWith jagged CSV's, we risk being too quick\r\nto dump memory that we need to allocate\r\nbecause previous chunks would have\r\nindicated much larger rows than we can\r\nanticipate in subsequent chunks.\r\n\r\nCloses gh-23509. </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    }\n </s> add     self->max_words_cap = sz; </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    }\n </s> add     def test_read_chunksize_jagged_names(self):\n        # see gh-23509\n        data = \"\\n\".join([\"0\"] * 7 + [\",\".join([\"0\"] * 10)])\n        reader = self.read_csv(StringIO(data), names=range(10), chunksize=4)\n\n        expected = DataFrame()\n\n        for i in range(10):\n            if i == 0:\n                expected[i] = [0] * 8\n            else:\n                expected[i] = [np.nan] * 7 + [0]\n\n        result = pd.concat(reader)\n        tm.assert_frame_equal(result, expected)\n </s> add - Bug in :func:`read_csv()` in which memory management was prematurely optimized for the C engine when the data was being read in chunks (:issue:`23509`) </s> add     int64_t max_words_cap;  // maximum word cap encountered", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/_libs/src/parser/tokenizer.c"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     int64_t i;\n <mask> \n <mask>     /* trim words, word_starts */\n <mask>     new_cap = _next_pow2(self->words_len) + 1;\n <mask>     if (new_cap < self->words_cap) {\n <mask>         TRACE((\"parser_trim_buffers: new_cap < self->words_cap\\n\"));\n </s> BUG: Don't over-optimize memory with jagged CSV (#23527)\n\nWith jagged CSV's, we risk being too quick\r\nto dump memory that we need to allocate\r\nbecause previous chunks would have\r\nindicated much larger rows than we can\r\nanticipate in subsequent chunks.\r\n\r\nCloses gh-23509. </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    }\n </s> add     self->max_words_cap = sz; </s> add     def test_read_chunksize_jagged_names(self):\n        # see gh-23509\n        data = \"\\n\".join([\"0\"] * 7 + [\",\".join([\"0\"] * 10)])\n        reader = self.read_csv(StringIO(data), names=range(10), chunksize=4)\n\n        expected = DataFrame()\n\n        for i in range(10):\n            if i == 0:\n                expected[i] = [0] * 8\n            else:\n                expected[i] = [np.nan] * 7 + [0]\n\n        result = pd.concat(reader)\n        tm.assert_frame_equal(result, expected)\n </s> remove         (char **)grow_buffer((void *)self->words, self->words_len,\n </s> add         (char **)grow_buffer((void *)self->words, length, </s> remove     int64_t i, cap;\n </s> add     int64_t i, cap, length; </s> add         int64_t max_words_cap    # maximum word cap encountered", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/_libs/src/parser/tokenizer.c"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     int64_t words_len;\n <mask>     int64_t words_cap;\n <mask> \n <mask>     char *pword_start;      // pointer to stream start of current field\n <mask>     int64_t word_start;     // position start of current field\n <mask> \n <mask>     int64_t *line_start;    // position in words for start of line\n <mask>     int64_t *line_fields;   // Number of fields in each line\n </s> BUG: Don't over-optimize memory with jagged CSV (#23527)\n\nWith jagged CSV's, we risk being too quick\r\nto dump memory that we need to allocate\r\nbecause previous chunks would have\r\nindicated much larger rows than we can\r\nanticipate in subsequent chunks.\r\n\r\nCloses gh-23509. </s> add         int64_t max_words_cap    # maximum word cap encountered </s> remove     int64_t i, cap;\n </s> add     int64_t i, cap, length; </s> add     self->max_words_cap = sz; </s> add - Bug in :func:`read_csv()` in which memory management was prematurely optimized for the C engine when the data was being read in chunks (:issue:`23509`) </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    }\n </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    }\n", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/_libs/src/parser/tokenizer.h"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         tm.assert_frame_equal(pd.concat(reader), df)\n <mask> \n <mask>     def test_read_text_list(self):\n <mask>         data = \"\"\"A,B,C\\nfoo,1,2,3\\nbar,4,5,6\"\"\"\n <mask>         as_list = [['A', 'B', 'C'], ['foo', '1', '2', '3'], ['bar',\n <mask>                                                              '4', '5', '6']]\n </s> BUG: Don't over-optimize memory with jagged CSV (#23527)\n\nWith jagged CSV's, we risk being too quick\r\nto dump memory that we need to allocate\r\nbecause previous chunks would have\r\nindicated much larger rows than we can\r\nanticipate in subsequent chunks.\r\n\r\nCloses gh-23509. </s> add     self->max_words_cap = sz; </s> add - Bug in :func:`read_csv()` in which memory management was prematurely optimized for the C engine when the data was being read in chunks (:issue:`23509`) </s> remove         (char **)grow_buffer((void *)self->words, self->words_len,\n </s> add         (char **)grow_buffer((void *)self->words, length, </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    }\n </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    }\n </s> add     int64_t max_words_cap;  // maximum word cap encountered", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/tests/io/parser/common.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     rxor,\n <mask> )\n <mask> \n <mask> if TYPE_CHECKING:\n <mask>     from pandas import DataFrame  # noqa:F401\n <mask> \n <mask> # -----------------------------------------------------------------------------\n <mask> # constants\n <mask> ARITHMETIC_BINOPS: Set[str] = {\n <mask>     \"add\",\n </s> BUG: flex op with DataFrame, Series and ea vs ndarray (#34277) </s> remove             if fill_value is not None:\n                raise NotImplementedError(f\"fill_value {fill_value} not supported.\")\n\n </s> add  </s> add         if isinstance(other, ABCSeries) and fill_value is not None:\n            # TODO: We could allow this in cases where we end up going\n            #  through the DataFrame path\n            raise NotImplementedError(f\"fill_value {fill_value} not supported.\")\n </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> remove     if isinstance(rvalues, np.ndarray):\n        # TODO(EA2D): no need to special-case with 2D EAs\n        # We can operate block-wise\n        if axis == 0:\n            rvalues = rvalues.reshape(-1, 1)\n        else:\n            rvalues = rvalues.reshape(1, -1)\n\n        rvalues = np.broadcast_to(rvalues, left.shape)\n\n        array_op = get_array_op(func)\n        bm = left._mgr.apply(array_op, right=rvalues.T, align_keys=[\"right\"])\n        return type(left)(bm)\n </s> add     assert not isinstance(rvalues, np.ndarray)  # handled by align_series_as_frame </s> add     def test_df_flex_cmp_ea_dtype_with_ndarray_series(self):\n        ii = pd.IntervalIndex.from_breaks([1, 2, 3])\n        df = pd.DataFrame({\"A\": ii, \"B\": ii})\n\n        ser = pd.Series([0, 0])\n        res = df.eq(ser, axis=0)\n\n        expected = pd.DataFrame({\"A\": [False, False], \"B\": [False, False]})\n        tm.assert_frame_equal(res, expected)\n\n        ser2 = pd.Series([1, 2], index=[\"A\", \"B\"])\n        res2 = df.eq(ser2, axis=1)\n        tm.assert_frame_equal(res2, expected)\n </s> add             tm.assert_frame_equal(align(df, val, \"columns\")[1], expected)", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/core/ops/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     # We assume that self.align(other, ...) has already been called\n <mask> \n <mask>     rvalues = right._values\n <mask>     if isinstance(rvalues, np.ndarray):\n <mask>         # TODO(EA2D): no need to special-case with 2D EAs\n <mask>         # We can operate block-wise\n <mask>         if axis == 0:\n <mask>             rvalues = rvalues.reshape(-1, 1)\n <mask>         else:\n <mask>             rvalues = rvalues.reshape(1, -1)\n <mask> \n <mask>         rvalues = np.broadcast_to(rvalues, left.shape)\n <mask> \n <mask>         array_op = get_array_op(func)\n <mask>         bm = left._mgr.apply(array_op, right=rvalues.T, align_keys=[\"right\"])\n <mask>         return type(left)(bm)\n <mask> \n <mask>     if axis == 0:\n <mask>         new_data = dispatch_to_series(left, right, func)\n <mask>     else:\n <mask>         new_data = dispatch_to_series(left, right, func, axis=\"columns\")\n </s> BUG: flex op with DataFrame, Series and ea vs ndarray (#34277) </s> remove             if fill_value is not None:\n                raise NotImplementedError(f\"fill_value {fill_value} not supported.\")\n\n </s> add  </s> add         right = _maybe_align_series_as_frame(left, right, axis) </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> add         if isinstance(other, ABCSeries) and fill_value is not None:\n            # TODO: We could allow this in cases where we end up going\n            #  through the DataFrame path\n            raise NotImplementedError(f\"fill_value {fill_value} not supported.\")\n </s> add     def test_df_flex_cmp_ea_dtype_with_ndarray_series(self):\n        ii = pd.IntervalIndex.from_breaks([1, 2, 3])\n        df = pd.DataFrame({\"A\": ii, \"B\": ii})\n\n        ser = pd.Series([0, 0])\n        res = df.eq(ser, axis=0)\n\n        expected = pd.DataFrame({\"A\": [False, False], \"B\": [False, False]})\n        tm.assert_frame_equal(res, expected)\n\n        ser2 = pd.Series([1, 2], index=[\"A\", \"B\"])\n        res2 = df.eq(ser2, axis=1)\n        tm.assert_frame_equal(res2, expected)\n", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/core/ops/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>             right, join=\"outer\", axis=axis, level=level, copy=False\n <mask>         )\n <mask> \n <mask>     return left, right\n <mask> \n <mask> \n <mask> def _should_reindex_frame_op(\n <mask>     left: \"DataFrame\", right, op, axis, default_axis, fill_value, level\n </s> BUG: flex op with DataFrame, Series and ea vs ndarray (#34277) </s> add         if isinstance(other, ABCSeries) and fill_value is not None:\n            # TODO: We could allow this in cases where we end up going\n            #  through the DataFrame path\n            raise NotImplementedError(f\"fill_value {fill_value} not supported.\")\n </s> remove     if isinstance(rvalues, np.ndarray):\n        # TODO(EA2D): no need to special-case with 2D EAs\n        # We can operate block-wise\n        if axis == 0:\n            rvalues = rvalues.reshape(-1, 1)\n        else:\n            rvalues = rvalues.reshape(1, -1)\n\n        rvalues = np.broadcast_to(rvalues, left.shape)\n\n        array_op = get_array_op(func)\n        bm = left._mgr.apply(array_op, right=rvalues.T, align_keys=[\"right\"])\n        return type(left)(bm)\n </s> add     assert not isinstance(rvalues, np.ndarray)  # handled by align_series_as_frame </s> add     def test_df_flex_cmp_ea_dtype_with_ndarray_series(self):\n        ii = pd.IntervalIndex.from_breaks([1, 2, 3])\n        df = pd.DataFrame({\"A\": ii, \"B\": ii})\n\n        ser = pd.Series([0, 0])\n        res = df.eq(ser, axis=0)\n\n        expected = pd.DataFrame({\"A\": [False, False], \"B\": [False, False]})\n        tm.assert_frame_equal(res, expected)\n\n        ser2 = pd.Series([1, 2], index=[\"A\", \"B\"])\n        res2 = df.eq(ser2, axis=1)\n        tm.assert_frame_equal(res2, expected)\n </s> remove             if fill_value is not None:\n                raise NotImplementedError(f\"fill_value {fill_value} not supported.\")\n\n </s> add  </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> remove     from pandas import DataFrame  # noqa:F401\n </s> add     from pandas import DataFrame, Series  # noqa:F401", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/core/ops/__init__.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             self, other, op, axis, default_axis, fill_value, level\n <mask>         ):\n <mask>             return _frame_arith_method_with_reindex(self, other, op)\n <mask> \n <mask>         # TODO: why are we passing flex=True instead of flex=not special?\n <mask>         #  15 tests fail if we pass flex=not special instead\n <mask>         self, other = _align_method_FRAME(self, other, axis, flex=True, level=level)\n <mask> \n <mask>         if isinstance(other, ABCDataFrame):\n </s> BUG: flex op with DataFrame, Series and ea vs ndarray (#34277) </s> remove             if fill_value is not None:\n                raise NotImplementedError(f\"fill_value {fill_value} not supported.\")\n\n </s> add  </s> add         right = _maybe_align_series_as_frame(left, right, axis) </s> remove     if isinstance(rvalues, np.ndarray):\n        # TODO(EA2D): no need to special-case with 2D EAs\n        # We can operate block-wise\n        if axis == 0:\n            rvalues = rvalues.reshape(-1, 1)\n        else:\n            rvalues = rvalues.reshape(1, -1)\n\n        rvalues = np.broadcast_to(rvalues, left.shape)\n\n        array_op = get_array_op(func)\n        bm = left._mgr.apply(array_op, right=rvalues.T, align_keys=[\"right\"])\n        return type(left)(bm)\n </s> add     assert not isinstance(rvalues, np.ndarray)  # handled by align_series_as_frame </s> remove     from pandas import DataFrame  # noqa:F401\n </s> add     from pandas import DataFrame, Series  # noqa:F401 </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> add     def test_df_flex_cmp_ea_dtype_with_ndarray_series(self):\n        ii = pd.IntervalIndex.from_breaks([1, 2, 3])\n        df = pd.DataFrame({\"A\": ii, \"B\": ii})\n\n        ser = pd.Series([0, 0])\n        res = df.eq(ser, axis=0)\n\n        expected = pd.DataFrame({\"A\": [False, False], \"B\": [False, False]})\n        tm.assert_frame_equal(res, expected)\n\n        ser2 = pd.Series([1, 2], index=[\"A\", \"B\"])\n        res2 = df.eq(ser2, axis=1)\n        tm.assert_frame_equal(res2, expected)\n", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/core/ops/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             # Another DataFrame\n <mask>             new_data = self._combine_frame(other, na_op, fill_value)\n <mask> \n <mask>         elif isinstance(other, ABCSeries):\n <mask>             if fill_value is not None:\n <mask>                 raise NotImplementedError(f\"fill_value {fill_value} not supported.\")\n <mask> \n <mask>             axis = self._get_axis_number(axis) if axis is not None else 1\n <mask>             new_data = _combine_series_frame(self, other, op, axis=axis)\n <mask>         else:\n <mask>             # in this case we always have `np.ndim(other) == 0`\n <mask>             if fill_value is not None:\n </s> BUG: flex op with DataFrame, Series and ea vs ndarray (#34277) </s> add         if isinstance(other, ABCSeries) and fill_value is not None:\n            # TODO: We could allow this in cases where we end up going\n            #  through the DataFrame path\n            raise NotImplementedError(f\"fill_value {fill_value} not supported.\")\n </s> remove     if isinstance(rvalues, np.ndarray):\n        # TODO(EA2D): no need to special-case with 2D EAs\n        # We can operate block-wise\n        if axis == 0:\n            rvalues = rvalues.reshape(-1, 1)\n        else:\n            rvalues = rvalues.reshape(1, -1)\n\n        rvalues = np.broadcast_to(rvalues, left.shape)\n\n        array_op = get_array_op(func)\n        bm = left._mgr.apply(array_op, right=rvalues.T, align_keys=[\"right\"])\n        return type(left)(bm)\n </s> add     assert not isinstance(rvalues, np.ndarray)  # handled by align_series_as_frame </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> remove     from pandas import DataFrame  # noqa:F401\n </s> add     from pandas import DataFrame, Series  # noqa:F401 </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> add     def test_df_flex_cmp_ea_dtype_with_ndarray_series(self):\n        ii = pd.IntervalIndex.from_breaks([1, 2, 3])\n        df = pd.DataFrame({\"A\": ii, \"B\": ii})\n\n        ser = pd.Series([0, 0])\n        res = df.eq(ser, axis=0)\n\n        expected = pd.DataFrame({\"A\": [False, False], \"B\": [False, False]})\n        tm.assert_frame_equal(res, expected)\n\n        ser2 = pd.Series([1, 2], index=[\"A\", \"B\"])\n        res2 = df.eq(ser2, axis=1)\n        tm.assert_frame_equal(res2, expected)\n", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/core/ops/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         expected = pd.Index(\n <mask>             [pd.Timedelta(days=2), pd.Timedelta(days=4), pd.Timestamp(\"2000-01-07\")]\n <mask>         )\n <mask>         expected = tm.box_expected(expected, box_with_array)\n <mask>         if box_with_array is pd.DataFrame:\n <mask>             expected = expected.astype(object)\n <mask>         tm.assert_equal(result, expected)\n <mask> \n <mask>         msg = \"unsupported operand type|cannot subtract a datelike\"\n <mask>         with pytest.raises(TypeError, match=msg):\n <mask>             with tm.assert_produces_warning(PerformanceWarning):\n </s> BUG: flex op with DataFrame, Series and ea vs ndarray (#34277) </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> remove             \"true_divide cannot use operands|\"\n </s> add             \"true_divide'? cannot use operands|\" </s> remove     if isinstance(rvalues, np.ndarray):\n        # TODO(EA2D): no need to special-case with 2D EAs\n        # We can operate block-wise\n        if axis == 0:\n            rvalues = rvalues.reshape(-1, 1)\n        else:\n            rvalues = rvalues.reshape(1, -1)\n\n        rvalues = np.broadcast_to(rvalues, left.shape)\n\n        array_op = get_array_op(func)\n        bm = left._mgr.apply(array_op, right=rvalues.T, align_keys=[\"right\"])\n        return type(left)(bm)\n </s> add     assert not isinstance(rvalues, np.ndarray)  # handled by align_series_as_frame </s> add             tm.assert_frame_equal(align(df, val, \"columns\")[1], expected) </s> add     def test_df_flex_cmp_ea_dtype_with_ndarray_series(self):\n        ii = pd.IntervalIndex.from_breaks([1, 2, 3])\n        df = pd.DataFrame({\"A\": ii, \"B\": ii})\n\n        ser = pd.Series([0, 0])\n        res = df.eq(ser, axis=0)\n\n        expected = pd.DataFrame({\"A\": [False, False], \"B\": [False, False]})\n        tm.assert_frame_equal(res, expected)\n\n        ser2 = pd.Series([1, 2], index=[\"A\", \"B\"])\n        res2 = df.eq(ser2, axis=1)\n        tm.assert_frame_equal(res2, expected)\n </s> remove             tm.assert_series_equal(\n                align(df, val, \"index\")[1], Series([1, 2, 3], index=df.index)\n            )\n            tm.assert_series_equal(\n                align(df, val, \"columns\")[1], Series([1, 2, 3], index=df.columns)\n </s> add             expected = DataFrame({\"X\": val, \"Y\": val, \"Z\": val}, index=df.index)\n            tm.assert_frame_equal(align(df, val, \"index\")[1], expected)\n\n            expected = DataFrame(\n                {\"X\": [1, 1, 1], \"Y\": [2, 2, 2], \"Z\": [3, 3, 3]}, index=df.index", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/tests/arithmetic/test_timedelta64.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         expected = pd.Index(\n <mask>             [pd.Timedelta(0), pd.Timedelta(0), pd.Timestamp(\"2000-01-01\")]\n <mask>         )\n <mask>         expected = tm.box_expected(expected, box_with_array)\n <mask>         if box_with_array is pd.DataFrame:\n <mask>             expected = expected.astype(object)\n <mask>         tm.assert_equal(result, expected)\n <mask> \n <mask> \n <mask> class TestTimedeltaArraylikeMulDivOps:\n <mask>     # Tests for timedelta64[ns]\n </s> BUG: flex op with DataFrame, Series and ea vs ndarray (#34277) </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> add             tm.assert_frame_equal(align(df, val, \"columns\")[1], expected) </s> add     def test_df_flex_cmp_ea_dtype_with_ndarray_series(self):\n        ii = pd.IntervalIndex.from_breaks([1, 2, 3])\n        df = pd.DataFrame({\"A\": ii, \"B\": ii})\n\n        ser = pd.Series([0, 0])\n        res = df.eq(ser, axis=0)\n\n        expected = pd.DataFrame({\"A\": [False, False], \"B\": [False, False]})\n        tm.assert_frame_equal(res, expected)\n\n        ser2 = pd.Series([1, 2], index=[\"A\", \"B\"])\n        res2 = df.eq(ser2, axis=1)\n        tm.assert_frame_equal(res2, expected)\n </s> remove             tm.assert_series_equal(\n                align(df, val, \"index\")[1], Series([1, 2, 3], index=df.index)\n            )\n            tm.assert_series_equal(\n                align(df, val, \"columns\")[1], Series([1, 2, 3], index=df.columns)\n </s> add             expected = DataFrame({\"X\": val, \"Y\": val, \"Z\": val}, index=df.index)\n            tm.assert_frame_equal(align(df, val, \"index\")[1], expected)\n\n            expected = DataFrame(\n                {\"X\": [1, 1, 1], \"Y\": [2, 2, 2], \"Z\": [3, 3, 3]}, index=df.index </s> remove             \"true_divide cannot use operands|\"\n </s> add             \"true_divide'? cannot use operands|\" </s> remove             if fill_value is not None:\n                raise NotImplementedError(f\"fill_value {fill_value} not supported.\")\n\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/tests/arithmetic/test_timedelta64.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         result = tdser / vector\n <mask>         tm.assert_equal(result, expected)\n <mask> \n <mask>         pattern = (\n <mask>             \"true_divide cannot use operands|\"\n <mask>             \"cannot perform __div__|\"\n <mask>             \"cannot perform __truediv__|\"\n <mask>             \"unsupported operand|\"\n <mask>             \"Cannot divide\"\n <mask>         )\n </s> BUG: flex op with DataFrame, Series and ea vs ndarray (#34277) </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> add     def test_df_flex_cmp_ea_dtype_with_ndarray_series(self):\n        ii = pd.IntervalIndex.from_breaks([1, 2, 3])\n        df = pd.DataFrame({\"A\": ii, \"B\": ii})\n\n        ser = pd.Series([0, 0])\n        res = df.eq(ser, axis=0)\n\n        expected = pd.DataFrame({\"A\": [False, False], \"B\": [False, False]})\n        tm.assert_frame_equal(res, expected)\n\n        ser2 = pd.Series([1, 2], index=[\"A\", \"B\"])\n        res2 = df.eq(ser2, axis=1)\n        tm.assert_frame_equal(res2, expected)\n </s> add             tm.assert_frame_equal(align(df, val, \"columns\")[1], expected) </s> remove             tm.assert_series_equal(\n                align(df, val, \"index\")[1], Series([1, 2, 3], index=df.index)\n            )\n            tm.assert_series_equal(\n                align(df, val, \"columns\")[1], Series([1, 2, 3], index=df.columns)\n </s> add             expected = DataFrame({\"X\": val, \"Y\": val, \"Z\": val}, index=df.index)\n            tm.assert_frame_equal(align(df, val, \"index\")[1], expected)\n\n            expected = DataFrame(\n                {\"X\": [1, 1, 1], \"Y\": [2, 2, 2], \"Z\": [3, 3, 3]}, index=df.index </s> remove     if isinstance(rvalues, np.ndarray):\n        # TODO(EA2D): no need to special-case with 2D EAs\n        # We can operate block-wise\n        if axis == 0:\n            rvalues = rvalues.reshape(-1, 1)\n        else:\n            rvalues = rvalues.reshape(1, -1)\n\n        rvalues = np.broadcast_to(rvalues, left.shape)\n\n        array_op = get_array_op(func)\n        bm = left._mgr.apply(array_op, right=rvalues.T, align_keys=[\"right\"])\n        return type(left)(bm)\n </s> add     assert not isinstance(rvalues, np.ndarray)  # handled by align_series_as_frame", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/tests/arithmetic/test_timedelta64.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         result = getattr(empty, opname)(const).dtypes.value_counts()\n <mask>         tm.assert_series_equal(result, pd.Series([2], index=[np.dtype(bool)]))\n <mask> \n <mask> \n <mask> # -------------------------------------------------------------------\n <mask> # Arithmetic\n <mask> \n </s> BUG: flex op with DataFrame, Series and ea vs ndarray (#34277) </s> remove             \"true_divide cannot use operands|\"\n </s> add             \"true_divide'? cannot use operands|\" </s> remove     from pandas import DataFrame  # noqa:F401\n </s> add     from pandas import DataFrame, Series  # noqa:F401 </s> remove     if isinstance(rvalues, np.ndarray):\n        # TODO(EA2D): no need to special-case with 2D EAs\n        # We can operate block-wise\n        if axis == 0:\n            rvalues = rvalues.reshape(-1, 1)\n        else:\n            rvalues = rvalues.reshape(1, -1)\n\n        rvalues = np.broadcast_to(rvalues, left.shape)\n\n        array_op = get_array_op(func)\n        bm = left._mgr.apply(array_op, right=rvalues.T, align_keys=[\"right\"])\n        return type(left)(bm)\n </s> add     assert not isinstance(rvalues, np.ndarray)  # handled by align_series_as_frame </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> remove             if fill_value is not None:\n                raise NotImplementedError(f\"fill_value {fill_value} not supported.\")\n\n </s> add  </s> add         if isinstance(other, ABCSeries) and fill_value is not None:\n            # TODO: We could allow this in cases where we end up going\n            #  through the DataFrame path\n            raise NotImplementedError(f\"fill_value {fill_value} not supported.\")\n", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/tests/frame/test_arithmetic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             np.array([1, 2, 3], dtype=np.int64),\n <mask>             range(1, 4),\n <mask>         ]:\n <mask> \n <mask>             tm.assert_series_equal(\n <mask>                 align(df, val, \"index\")[1], Series([1, 2, 3], index=df.index)\n <mask>             )\n <mask>             tm.assert_series_equal(\n <mask>                 align(df, val, \"columns\")[1], Series([1, 2, 3], index=df.columns)\n <mask>             )\n <mask> \n <mask>         # length mismatch\n <mask>         msg = \"Unable to coerce to Series, length must be 3: given 2\"\n <mask>         for val in [[1, 2], (1, 2), np.array([1, 2]), range(1, 3)]:\n </s> BUG: flex op with DataFrame, Series and ea vs ndarray (#34277) </s> add             tm.assert_frame_equal(align(df, val, \"columns\")[1], expected) </s> add     def test_df_flex_cmp_ea_dtype_with_ndarray_series(self):\n        ii = pd.IntervalIndex.from_breaks([1, 2, 3])\n        df = pd.DataFrame({\"A\": ii, \"B\": ii})\n\n        ser = pd.Series([0, 0])\n        res = df.eq(ser, axis=0)\n\n        expected = pd.DataFrame({\"A\": [False, False], \"B\": [False, False]})\n        tm.assert_frame_equal(res, expected)\n\n        ser2 = pd.Series([1, 2], index=[\"A\", \"B\"])\n        res2 = df.eq(ser2, axis=1)\n        tm.assert_frame_equal(res2, expected)\n </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> remove     if isinstance(rvalues, np.ndarray):\n        # TODO(EA2D): no need to special-case with 2D EAs\n        # We can operate block-wise\n        if axis == 0:\n            rvalues = rvalues.reshape(-1, 1)\n        else:\n            rvalues = rvalues.reshape(1, -1)\n\n        rvalues = np.broadcast_to(rvalues, left.shape)\n\n        array_op = get_array_op(func)\n        bm = left._mgr.apply(array_op, right=rvalues.T, align_keys=[\"right\"])\n        return type(left)(bm)\n </s> add     assert not isinstance(rvalues, np.ndarray)  # handled by align_series_as_frame </s> remove     from pandas import DataFrame  # noqa:F401\n </s> add     from pandas import DataFrame, Series  # noqa:F401", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/tests/frame/test_arithmetic.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>             expected = DataFrame(\n <mask>                 {\"X\": [1, 1, 1], \"Y\": [2, 2, 2], \"Z\": [3, 3, 3]}, index=df.index\n <mask>             )\n <mask> \n <mask>         # length mismatch\n <mask>         msg = \"Unable to coerce to Series, length must be 3: given 2\"\n <mask>         for val in [[1, 2], (1, 2), np.array([1, 2]), range(1, 3)]:\n </s> BUG: flex op with DataFrame, Series and ea vs ndarray (#34277) </s> remove             tm.assert_series_equal(\n                align(df, val, \"index\")[1], Series([1, 2, 3], index=df.index)\n            )\n            tm.assert_series_equal(\n                align(df, val, \"columns\")[1], Series([1, 2, 3], index=df.columns)\n </s> add             expected = DataFrame({\"X\": val, \"Y\": val, \"Z\": val}, index=df.index)\n            tm.assert_frame_equal(align(df, val, \"index\")[1], expected)\n\n            expected = DataFrame(\n                {\"X\": [1, 1, 1], \"Y\": [2, 2, 2], \"Z\": [3, 3, 3]}, index=df.index </s> add     def test_df_flex_cmp_ea_dtype_with_ndarray_series(self):\n        ii = pd.IntervalIndex.from_breaks([1, 2, 3])\n        df = pd.DataFrame({\"A\": ii, \"B\": ii})\n\n        ser = pd.Series([0, 0])\n        res = df.eq(ser, axis=0)\n\n        expected = pd.DataFrame({\"A\": [False, False], \"B\": [False, False]})\n        tm.assert_frame_equal(res, expected)\n\n        ser2 = pd.Series([1, 2], index=[\"A\", \"B\"])\n        res2 = df.eq(ser2, axis=1)\n        tm.assert_frame_equal(res2, expected)\n </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> remove     if isinstance(rvalues, np.ndarray):\n        # TODO(EA2D): no need to special-case with 2D EAs\n        # We can operate block-wise\n        if axis == 0:\n            rvalues = rvalues.reshape(-1, 1)\n        else:\n            rvalues = rvalues.reshape(1, -1)\n\n        rvalues = np.broadcast_to(rvalues, left.shape)\n\n        array_op = get_array_op(func)\n        bm = left._mgr.apply(array_op, right=rvalues.T, align_keys=[\"right\"])\n        return type(left)(bm)\n </s> add     assert not isinstance(rvalues, np.ndarray)  # handled by align_series_as_frame </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object)\n </s> add  </s> remove     from pandas import DataFrame  # noqa:F401\n </s> add     from pandas import DataFrame, Series  # noqa:F401", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/tests/frame/test_arithmetic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> Numeric\n <mask> ^^^^^^^\n <mask> \n <mask> -\n <mask> -\n <mask> \n <mask> Conversion\n <mask> ^^^^^^^^^^\n </s> BUG: fix+test quantile with empty DataFrame, closes #23925 (#27436) </s> remove     def test_quantile_empty(self):\n </s> add     def test_quantile_empty_no_rows(self): </s> add         if len(data.columns) == 0:\n            # GH#23925 _get_numeric_data may have dropped all columns\n            cols = Index([], name=self.columns.name)\n            if is_list_like(q):\n                return self._constructor([], index=q, columns=cols)\n            return self._constructor_sliced([], index=cols, name=q)\n </s> remove Other\n^^^^^\n\n\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/01babb590cb15ef5c6e9ad890ea580a5112e6999", "file_name": "doc/source/whatsnew/v1.0.0.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep", "code_tokens": " <mask> -\n <mask> -\n <mask> \n <mask> \n <mask> Other\n <mask> ^^^^^\n <mask> \n <mask> \n <mask> .. _whatsnew_1000.contributors:\n <mask> \n <mask> Contributors\n <mask> ~~~~~~~~~~~~\n </s> BUG: fix+test quantile with empty DataFrame, closes #23925 (#27436) </s> remove     def test_quantile_empty(self):\n </s> add     def test_quantile_empty_no_rows(self): </s> add         if len(data.columns) == 0:\n            # GH#23925 _get_numeric_data may have dropped all columns\n            cols = Index([], name=self.columns.name)\n            if is_list_like(q):\n                return self._constructor([], index=q, columns=cols)\n            return self._constructor_sliced([], index=cols, name=q)\n </s> remove \n </s> add - Bug in :meth:`DataFrame.quantile` with zero-column :class:`DataFrame` incorrectly raising (:issue:`23925`)", "html_url": "https://github.com/pandas-dev/pandas/commit/01babb590cb15ef5c6e9ad890ea580a5112e6999", "file_name": "doc/source/whatsnew/v1.0.0.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         if is_transposed:\n <mask>             data = data.T\n <mask> \n <mask>         result = data._data.quantile(\n <mask>             qs=q, axis=1, interpolation=interpolation, transposed=is_transposed\n <mask>         )\n <mask> \n <mask>         if result.ndim == 2:\n </s> BUG: fix+test quantile with empty DataFrame, closes #23925 (#27436) </s> remove     def test_quantile_empty(self):\n </s> add     def test_quantile_empty_no_rows(self): </s> remove Other\n^^^^^\n\n\n </s> add  </s> remove \n </s> add - Bug in :meth:`DataFrame.quantile` with zero-column :class:`DataFrame` incorrectly raising (:issue:`23925`)", "html_url": "https://github.com/pandas-dev/pandas/commit/01babb590cb15ef5c6e9ad890ea580a5112e6999", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             [[pd.Timestamp(\"2012-01-02\"), pd.NaT]], index=[0.5], columns=[\"a\", \"b\"]\n <mask>         )\n <mask>         tm.assert_frame_equal(res, exp)\n <mask> \n <mask>     def test_quantile_empty(self):\n <mask> \n <mask>         # floats\n <mask>         df = DataFrame(columns=[\"a\", \"b\"], dtype=\"float64\")\n <mask> \n <mask>         res = df.quantile(0.5)\n </s> BUG: fix+test quantile with empty DataFrame, closes #23925 (#27436) </s> add         if len(data.columns) == 0:\n            # GH#23925 _get_numeric_data may have dropped all columns\n            cols = Index([], name=self.columns.name)\n            if is_list_like(q):\n                return self._constructor([], index=q, columns=cols)\n            return self._constructor_sliced([], index=cols, name=q)\n </s> remove Other\n^^^^^\n\n\n </s> add  </s> remove \n </s> add - Bug in :meth:`DataFrame.quantile` with zero-column :class:`DataFrame` incorrectly raising (:issue:`23925`)", "html_url": "https://github.com/pandas-dev/pandas/commit/01babb590cb15ef5c6e9ad890ea580a5112e6999", "file_name": "pandas/tests/frame/test_quantile.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         if prefix is None:\n <mask>             prefix = ''\n <mask> \n <mask>         result = result.addPrefix(prefix)\n <mask> \n <mask>         return result\n <mask> \n <mask>     def get_dummies(self, item):\n <mask>         \"\"\"\n </s> ENH: added add_prefix / add_suffix methods to DataFrame </s> remove \ndef _prefix_item(item, prefix=None):\n    if prefix is None:\n        return item\n\n    template = '%s%s'\n    return template % (prefix, item)\n\n </s> add  </s> remove     def addPrefix(self, prefix=None):\n        \"\"\"\n        Concatenate prefix string with panel items names.\n\n        Parameters\n        ----------\n        prefix : string\n\n        Returns\n        -------\n        LongPanel\n\n        Note\n        ----\n        does *not* copy values matrix\n        \"\"\"\n        new_items = [_prefix_item(item, prefix) for item in self.items]\n\n        return LongPanel(self.values, columns=new_items,\n                         index=self.index)\n\n\n </s> add  </s> remove         dummies = dummies.addPrefix('FE_')\n </s> add         dummies = dummies.add_prefix('FE_') </s> remove     def test_addPrefix(self):\n        lp = self.panel.addPrefix('foo#')\n </s> add     def test_add_prefix(self):\n        lp = self.panel.add_prefix('foo#') </s> remove             dummies = dummies.addPrefix('%s_' % effect)\n </s> add             dummies = dummies.add_prefix('%s_' % effect) </s> remove         lp = self.panel.addPrefix()\n        assert_panel_equal(lp.to_wide(), self.panel.to_wide())\n\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/01ea9cb140e824e8b3bf45cf03a882d92d4968fb", "file_name": "pandas/core/panel.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             new_values = f(self.values)\n <mask>             return LongPanel(new_values, columns=self.items,\n <mask>                              index=self.index)\n <mask> \n <mask>     def addPrefix(self, prefix=None):\n <mask>         \"\"\"\n <mask>         Concatenate prefix string with panel items names.\n <mask> \n <mask>         Parameters\n <mask>         ----------\n <mask>         prefix : string\n <mask> \n <mask>         Returns\n <mask>         -------\n <mask>         LongPanel\n <mask> \n <mask>         Note\n <mask>         ----\n <mask>         does *not* copy values matrix\n <mask>         \"\"\"\n <mask>         new_items = [_prefix_item(item, prefix) for item in self.items]\n <mask> \n <mask>         return LongPanel(self.values, columns=new_items,\n <mask>                          index=self.index)\n <mask> \n <mask> \n <mask> def _prep_ndarray(values, copy=True):\n <mask>     if not isinstance(values, np.ndarray):\n <mask>         values = np.asarray(values)\n <mask>         # NumPy strings are a pain, convert to object\n <mask>         if issubclass(values.dtype.type, basestring):\n </s> ENH: added add_prefix / add_suffix methods to DataFrame </s> remove \ndef _prefix_item(item, prefix=None):\n    if prefix is None:\n        return item\n\n    template = '%s%s'\n    return template % (prefix, item)\n\n </s> add  </s> remove         result = result.addPrefix(prefix)\n </s> add         result = result.add_prefix(prefix) </s> add     def test_add_prefix_suffix(self):\n        with_prefix = self.frame.add_prefix('foo#')\n        expected = ['foo#%s' % c for c in self.frame.columns]\n        self.assert_(np.array_equal(with_prefix.columns, expected))\n\n        with_suffix = self.frame.add_suffix('#foo')\n        expected = ['%s#foo' % c for c in self.frame.columns]\n        self.assert_(np.array_equal(with_suffix.columns, expected))\n </s> remove         dummies = dummies.addPrefix('FE_')\n </s> add         dummies = dummies.add_prefix('FE_') </s> remove             dummies = dummies.addPrefix('%s_' % effect)\n </s> add             dummies = dummies.add_prefix('%s_' % effect) </s> remove     def test_addPrefix(self):\n        lp = self.panel.addPrefix('foo#')\n </s> add     def test_add_prefix(self):\n        lp = self.panel.add_prefix('foo#')", "html_url": "https://github.com/pandas-dev/pandas/commit/01ea9cb140e824e8b3bf45cf03a882d92d4968fb", "file_name": "pandas/core/panel.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             values = values.copy()\n <mask>     assert(values.ndim == 3)\n <mask>     return values\n <mask> \n <mask> \n <mask> def _prefix_item(item, prefix=None):\n <mask>     if prefix is None:\n <mask>         return item\n <mask> \n <mask>     template = '%s%s'\n <mask>     return template % (prefix, item)\n <mask> \n <mask> def _homogenize_dict(frames, intersect=True, dtype=None):\n <mask>     \"\"\"\n <mask>     Conform set of DataFrame-like objects to either an intersection\n <mask>     of indices / columns or a union.\n <mask> \n </s> ENH: added add_prefix / add_suffix methods to DataFrame </s> remove     def addPrefix(self, prefix=None):\n        \"\"\"\n        Concatenate prefix string with panel items names.\n\n        Parameters\n        ----------\n        prefix : string\n\n        Returns\n        -------\n        LongPanel\n\n        Note\n        ----\n        does *not* copy values matrix\n        \"\"\"\n        new_items = [_prefix_item(item, prefix) for item in self.items]\n\n        return LongPanel(self.values, columns=new_items,\n                         index=self.index)\n\n\n </s> add  </s> remove         result = result.addPrefix(prefix)\n </s> add         result = result.add_prefix(prefix) </s> remove         dummies = dummies.addPrefix('FE_')\n </s> add         dummies = dummies.add_prefix('FE_') </s> remove     def test_addPrefix(self):\n        lp = self.panel.addPrefix('foo#')\n </s> add     def test_add_prefix(self):\n        lp = self.panel.add_prefix('foo#') </s> remove             dummies = dummies.addPrefix('%s_' % effect)\n </s> add             dummies = dummies.add_prefix('%s_' % effect) </s> remove         lp = self.panel.addPrefix()\n        assert_panel_equal(lp.to_wide(), self.panel.to_wide())\n\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/01ea9cb140e824e8b3bf45cf03a882d92d4968fb", "file_name": "pandas/core/panel.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             self.log('-- Excluding dummy for entity: %s' % to_exclude)\n <mask> \n <mask>             dummies = dummies.filter(dummies.items - [to_exclude])\n <mask> \n <mask>         dummies = dummies.addPrefix('FE_')\n <mask>         panel = panel.join(dummies)\n <mask> \n <mask>         return panel\n <mask> \n <mask>     def _add_categorical_dummies(self, panel, cat_mappings):\n </s> ENH: added add_prefix / add_suffix methods to DataFrame </s> remove             dummies = dummies.addPrefix('%s_' % effect)\n </s> add             dummies = dummies.add_prefix('%s_' % effect) </s> remove     def addPrefix(self, prefix=None):\n        \"\"\"\n        Concatenate prefix string with panel items names.\n\n        Parameters\n        ----------\n        prefix : string\n\n        Returns\n        -------\n        LongPanel\n\n        Note\n        ----\n        does *not* copy values matrix\n        \"\"\"\n        new_items = [_prefix_item(item, prefix) for item in self.items]\n\n        return LongPanel(self.values, columns=new_items,\n                         index=self.index)\n\n\n </s> add  </s> add     def test_add_prefix_suffix(self):\n        with_prefix = self.frame.add_prefix('foo#')\n        expected = ['foo#%s' % c for c in self.frame.columns]\n        self.assert_(np.array_equal(with_prefix.columns, expected))\n\n        with_suffix = self.frame.add_suffix('#foo')\n        expected = ['%s#foo' % c for c in self.frame.columns]\n        self.assert_(np.array_equal(with_suffix.columns, expected))\n </s> remove         result = result.addPrefix(prefix)\n </s> add         result = result.add_prefix(prefix) </s> remove     def test_addPrefix(self):\n        lp = self.panel.addPrefix('foo#')\n </s> add     def test_add_prefix(self):\n        lp = self.panel.add_prefix('foo#') </s> remove \ndef _prefix_item(item, prefix=None):\n    if prefix is None:\n        return item\n\n    template = '%s%s'\n    return template % (prefix, item)\n\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/01ea9cb140e824e8b3bf45cf03a882d92d4968fb", "file_name": "pandas/stats/plm.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 dummies = dummies.filter(dummies.items - [mapped_name])\n <mask>                 dropped_dummy = True\n <mask> \n <mask>             dummies = _convertDummies(dummies, cat_mappings.get(effect))\n <mask>             dummies = dummies.addPrefix('%s_' % effect)\n <mask>             panel = panel.join(dummies)\n <mask> \n <mask>         return panel\n <mask> \n <mask>     @property\n </s> ENH: added add_prefix / add_suffix methods to DataFrame </s> remove         dummies = dummies.addPrefix('FE_')\n </s> add         dummies = dummies.add_prefix('FE_') </s> remove         result = result.addPrefix(prefix)\n </s> add         result = result.add_prefix(prefix) </s> remove     def addPrefix(self, prefix=None):\n        \"\"\"\n        Concatenate prefix string with panel items names.\n\n        Parameters\n        ----------\n        prefix : string\n\n        Returns\n        -------\n        LongPanel\n\n        Note\n        ----\n        does *not* copy values matrix\n        \"\"\"\n        new_items = [_prefix_item(item, prefix) for item in self.items]\n\n        return LongPanel(self.values, columns=new_items,\n                         index=self.index)\n\n\n </s> add  </s> remove     def test_addPrefix(self):\n        lp = self.panel.addPrefix('foo#')\n </s> add     def test_add_prefix(self):\n        lp = self.panel.add_prefix('foo#') </s> add     def test_add_prefix_suffix(self):\n        with_prefix = self.frame.add_prefix('foo#')\n        expected = ['foo#%s' % c for c in self.frame.columns]\n        self.assert_(np.array_equal(with_prefix.columns, expected))\n\n        with_suffix = self.frame.add_suffix('#foo')\n        expected = ['%s#foo' % c for c in self.frame.columns]\n        self.assert_(np.array_equal(with_suffix.columns, expected))\n </s> remove         lp = self.panel.addPrefix()\n        assert_panel_equal(lp.to_wide(), self.panel.to_wide())\n\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/01ea9cb140e824e8b3bf45cf03a882d92d4968fb", "file_name": "pandas/stats/plm.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         renamed = self.frame.T.rename(index={'C' : 'foo', 'D' : 'bar'})\n <mask>         self.assert_(np.array_equal(renamed.index, ['A', 'B', 'foo', 'bar']))\n <mask> \n <mask>     #----------------------------------------------------------------------\n <mask>     # Time series related\n <mask> \n <mask>     def test_diff(self):\n <mask>         the_diff = self.tsframe.diff(1)\n <mask> \n </s> ENH: added add_prefix / add_suffix methods to DataFrame </s> remove     def addPrefix(self, prefix=None):\n        \"\"\"\n        Concatenate prefix string with panel items names.\n\n        Parameters\n        ----------\n        prefix : string\n\n        Returns\n        -------\n        LongPanel\n\n        Note\n        ----\n        does *not* copy values matrix\n        \"\"\"\n        new_items = [_prefix_item(item, prefix) for item in self.items]\n\n        return LongPanel(self.values, columns=new_items,\n                         index=self.index)\n\n\n </s> add  </s> remove     def test_addPrefix(self):\n        lp = self.panel.addPrefix('foo#')\n </s> add     def test_add_prefix(self):\n        lp = self.panel.add_prefix('foo#') </s> remove         result = result.addPrefix(prefix)\n </s> add         result = result.add_prefix(prefix) </s> remove         lp = self.panel.addPrefix()\n        assert_panel_equal(lp.to_wide(), self.panel.to_wide())\n\n </s> add  </s> remove         dummies = dummies.addPrefix('FE_')\n </s> add         dummies = dummies.add_prefix('FE_') </s> remove             dummies = dummies.addPrefix('%s_' % effect)\n </s> add             dummies = dummies.add_prefix('%s_' % effect)", "html_url": "https://github.com/pandas-dev/pandas/commit/01ea9cb140e824e8b3bf45cf03a882d92d4968fb", "file_name": "pandas/tests/test_frame.py"}
{"docstring_tokens": "keep replace replace keep keep replace replace replace keep keep keep", "code_tokens": " <mask> \n <mask>     def test_addPrefix(self):\n <mask>         lp = self.panel.addPrefix('foo#')\n <mask>         self.assertEqual(lp.items[0], 'foo#ItemA')\n <mask> \n <mask>         lp = self.panel.addPrefix()\n <mask>         assert_panel_equal(lp.to_wide(), self.panel.to_wide())\n <mask> \n <mask>     def test_pivot(self):\n <mask>         from pandas.core.reshape import _slow_pivot\n <mask> \n </s> ENH: added add_prefix / add_suffix methods to DataFrame </s> remove         result = result.addPrefix(prefix)\n </s> add         result = result.add_prefix(prefix) </s> add     def test_add_prefix_suffix(self):\n        with_prefix = self.frame.add_prefix('foo#')\n        expected = ['foo#%s' % c for c in self.frame.columns]\n        self.assert_(np.array_equal(with_prefix.columns, expected))\n\n        with_suffix = self.frame.add_suffix('#foo')\n        expected = ['%s#foo' % c for c in self.frame.columns]\n        self.assert_(np.array_equal(with_suffix.columns, expected))\n </s> remove         dummies = dummies.addPrefix('FE_')\n </s> add         dummies = dummies.add_prefix('FE_') </s> remove \ndef _prefix_item(item, prefix=None):\n    if prefix is None:\n        return item\n\n    template = '%s%s'\n    return template % (prefix, item)\n\n </s> add  </s> remove     def addPrefix(self, prefix=None):\n        \"\"\"\n        Concatenate prefix string with panel items names.\n\n        Parameters\n        ----------\n        prefix : string\n\n        Returns\n        -------\n        LongPanel\n\n        Note\n        ----\n        does *not* copy values matrix\n        \"\"\"\n        new_items = [_prefix_item(item, prefix) for item in self.items]\n\n        return LongPanel(self.values, columns=new_items,\n                         index=self.index)\n\n\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/01ea9cb140e824e8b3bf45cf03a882d92d4968fb", "file_name": "pandas/tests/test_panel.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> - Bug in :func:`assert_frame_equal` checks category dtypes even when asked not to check index type (:issue:`52126`)\n <mask> - Bug in :meth:`DataFrame.reindex` with a ``fill_value`` that should be inferred with a :class:`ExtensionDtype` incorrectly inferring ``object`` dtype (:issue:`52586`)\n <mask> - Bug in :meth:`Series.map` when giving a callable to an empty series, the returned series had ``object`` dtype. It now keeps the original dtype (:issue:`52384`)\n <mask> - Bug in :meth:`Series.memory_usage` when ``deep=True`` throw an error with Series of objects and the returned value is incorrect, as it does not take into account GC corrections (:issue:`51858`)\n <mask> -\n <mask> \n <mask> .. ***DO NOT USE THIS SECTION***\n <mask> \n <mask> -\n <mask> \n </s> BUG: Fix pandas._libs.json __name__ (#52903) </s> add     def test_ujson__name__(self):\n        # GH 52898\n        assert ujson.__name__ == \"pandas._libs.json\"\n </s> remove                                        .m_name = \"_libjson\",\n </s> add                                        .m_name = \"pandas._libs.json\",", "html_url": "https://github.com/pandas-dev/pandas/commit/0223c0cfd130df7c4c2d7017b84fe2c75e226d38", "file_name": "doc/source/whatsnew/v2.1.0.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> static int module_clear(PyObject *m);\n <mask> static void module_free(void *module);\n <mask> \n <mask> static struct PyModuleDef moduledef = {.m_base = PyModuleDef_HEAD_INIT,\n <mask>                                        .m_name = \"_libjson\",\n <mask>                                        .m_methods = ujsonMethods,\n <mask>                                        .m_size = sizeof(modulestate),\n <mask>                                        .m_traverse = module_traverse,\n <mask>                                        .m_clear = module_clear,\n <mask>                                        .m_free = module_free};\n </s> BUG: Fix pandas._libs.json __name__ (#52903) </s> add     def test_ujson__name__(self):\n        # GH 52898\n        assert ujson.__name__ == \"pandas._libs.json\"\n </s> remove -\n </s> add - Fixed incorrect ``__name__`` attribute of ``pandas._libs.json`` (:issue:`52898`)", "html_url": "https://github.com/pandas-dev/pandas/commit/0223c0cfd130df7c4c2d7017b84fe2c75e226d38", "file_name": "pandas/_libs/src/ujson/python/ujson.c"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         assert ujson.decode(ujson.encode(test_object)) == {\"a\": 1, \"b\": 2, \"d\": 4}\n <mask> \n <mask> \n <mask> class TestNumpyJSONTests:\n <mask>     @pytest.mark.parametrize(\"bool_input\", [True, False])\n <mask>     def test_bool(self, bool_input):\n </s> BUG: Fix pandas._libs.json __name__ (#52903) </s> remove                                        .m_name = \"_libjson\",\n </s> add                                        .m_name = \"pandas._libs.json\", </s> remove -\n </s> add - Fixed incorrect ``__name__`` attribute of ``pandas._libs.json`` (:issue:`52898`)", "html_url": "https://github.com/pandas-dev/pandas/commit/0223c0cfd130df7c4c2d7017b84fe2c75e226d38", "file_name": "pandas/tests/io/json/test_ujson.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>           packages:\n <mask>           - python-gtk2\n <mask>     - dist: trusty\n <mask>       env:\n <mask>         - JOB=\"3.6, lint, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true LINT=true\n <mask>     - dist: trusty\n <mask>       env:\n <mask>         - JOB=\"3.7, NumPy dev\" ENV_FILE=\"ci/deps/travis-37-numpydev.yaml\" PATTERN=\"not slow and not network\" TEST_ARGS=\"-W error\" PANDAS_TESTING_MODE=\"deprecate\"\n <mask>       addons:\n <mask>         apt:\n </s> CI: Linting with azure instead of travis (#22854) </s> remove   - ipython\n  - isort\n  - jinja2\n  - lxml\n </s> add  </s> remove   - flake8>=3.5\n  - flake8-comprehensions\n  - flake8-rst>=0.6.0\n </s> add  </s> remove   - seaborn\n </s> add  </s> remove     - cpplint\n </s> add  </s> add   - asv </s> remove   - ci/code_checks.sh\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": ".travis.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>   - echo \"script start\"\n <mask>   - source activate pandas-dev\n <mask>   - ci/run_build_docs.sh\n <mask>   - ci/run_tests.sh\n <mask>   - ci/code_checks.sh\n <mask> \n <mask> after_script:\n <mask>   - echo \"after_script start\"\n <mask>   - source activate pandas-dev && pushd /tmp && python -c \"import pandas; pandas.show_versions();\" && popd\n <mask>   - if [ -e test-data-single.xml ]; then\n </s> CI: Linting with azure instead of travis (#22854) </s> remove   - ipython\n  - isort\n  - jinja2\n  - lxml\n </s> add  </s> remove   - flake8>=3.5\n  - flake8-comprehensions\n  - flake8-rst>=0.6.0\n </s> add  </s> remove   - seaborn\n </s> add  </s> remove     - cpplint\n </s> add  </s> add   - asv </s> remove         - JOB=\"3.6, lint, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true LINT=true\n </s> add         - JOB=\"3.6, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": ".travis.yml"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep replace replace replace replace keep keep keep", "code_tokens": " <mask>   - beautifulsoup4\n <mask>   - cython>=0.28.2\n <mask>   - dask\n <mask>   - fastparquet\n <mask>   - flake8>=3.5\n <mask>   - flake8-comprehensions\n <mask>   - flake8-rst>=0.6.0\n <mask>   - gcsfs\n <mask>   - geopandas\n <mask>   - html5lib\n <mask>   - ipython\n <mask>   - isort\n <mask>   - jinja2\n <mask>   - lxml\n <mask>   - matplotlib\n <mask>   - nomkl\n <mask>   - numexpr\n </s> CI: Linting with azure instead of travis (#22854) </s> add   - asv </s> remove   - seaborn\n </s> add  </s> remove     - cpplint\n </s> add  </s> remove   - ci/code_checks.sh\n </s> add  </s> remove         - JOB=\"3.6, lint, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true LINT=true\n </s> add         - JOB=\"3.6, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "ci/deps/travis-36.yaml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>   - pytz\n <mask>   - s3fs\n <mask>   - scikit-learn\n <mask>   - scipy\n <mask>   - seaborn\n <mask>   - sqlalchemy\n <mask>   - statsmodels\n <mask>   - xarray\n <mask>   - xlrd\n <mask>   - xlsxwriter\n </s> CI: Linting with azure instead of travis (#22854) </s> add   - asv </s> remove   - ipython\n  - isort\n  - jinja2\n  - lxml\n </s> add  </s> remove   - flake8>=3.5\n  - flake8-comprehensions\n  - flake8-rst>=0.6.0\n </s> add  </s> remove     - cpplint\n </s> add  </s> remove   - ci/code_checks.sh\n </s> add  </s> remove         - JOB=\"3.6, lint, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true LINT=true\n </s> add         - JOB=\"3.6, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "ci/deps/travis-36.yaml"}
{"docstring_tokens": "keep keep keep keep replace keep keep", "code_tokens": " <mask>   - hypothesis>=3.58.0\n <mask>   - pip:\n <mask>     - brotlipy\n <mask>     - coverage\n <mask>     - cpplint\n <mask>     - pandas-datareader\n <mask>     - python-dateutil\n </s> CI: Linting with azure instead of travis (#22854) </s> remove   - ipython\n  - isort\n  - jinja2\n  - lxml\n </s> add  </s> remove   - flake8>=3.5\n  - flake8-comprehensions\n  - flake8-rst>=0.6.0\n </s> add  </s> remove   - seaborn\n </s> add  </s> add   - asv </s> remove   - ci/code_checks.sh\n </s> add  </s> remove         - JOB=\"3.6, lint, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true LINT=true\n </s> add         - JOB=\"3.6, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "ci/deps/travis-36.yaml"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>   - pytz\n <mask> \n <mask>   # development\n <mask>   - cython>=0.28.2\n <mask>   - flake8\n <mask>   - flake8-comprehensions\n <mask>   - flake8-rst>=0.6.0\n </s> CI: Linting with azure instead of travis (#22854) </s> remove   - flake8>=3.5\n  - flake8-comprehensions\n  - flake8-rst>=0.6.0\n </s> add  </s> add asv </s> remove   - seaborn\n </s> add  </s> remove   - ipython\n  - isort\n  - jinja2\n  - lxml\n </s> add  </s> remove     - cpplint\n </s> add  </s> remove   - ci/code_checks.sh\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "environment.yml"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             ``'replace'``\n <mask>                 If table exists, drop it, recreate it, and insert data.\n <mask>             ``'append'``\n <mask>                 If table exists, insert data. Create if does not exist.\n <mask>         private_key : str, optional\n <mask>             Service account private key in JSON format. Can be file path\n <mask>             or string contents. This is useful for remote server\n <mask>             authentication (eg. Jupyter/IPython notebook on remote host).\n <mask>         auth_local_webserver : bool, default False\n <mask>             Use the `local webserver flow`_ instead of the `console flow`_\n <mask>             when getting user credentials.\n <mask> \n <mask>             .. _local webserver flow:\n </s> CI: Linting with azure instead of travis (#22854) </s> remove     private_key : str, optional\n        Service account private key in JSON format. Can be file path\n        or string contents. This is useful for remote server\n        authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add  </s> add     verbose : None, deprecated\n        Deprecated in pandas-gbq version 0.4.0. Use the `logging module to\n        adjust verbosity instead\n        <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__. </s> remove \nParameters\n----------\nother : Series, DataFrame, or ndarray, optional\n    if not supplied then will default to self and produce pairwise output\npairwise : bool, default None\n    If False then only matching columns between self and other will be used and\n    the output will be a DataFrame.\n    If True then all pairwise combinations will be calculated and the output\n    will be a MultiIndex DataFrame in the case of DataFrame inputs.\n    In the case of missing elements, only complete pairwise observations will\n    be used.\nbias : bool, default False\n   Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndex DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        bias : bool, default False\n           Use a standard estimation bias correction </s> remove     Parameters\n    ----------\n    other : Series, DataFrame, or ndarray, optional\n        if not supplied then will default to self and produce pairwise output\n    pairwise : bool, default None\n        If False then only matching columns between self and other will be used\n        and the output will be a DataFrame.\n        If True then all pairwise combinations will be calculated and the\n        output will be a MultiIndexed DataFrame in the case of DataFrame\n        inputs. In the case of missing elements, only complete pairwise\n        observations will be used.\n    ddof : int, default 1\n        Delta Degrees of Freedom.  The divisor used in calculations\n        is ``N - ddof``, where ``N`` represents the number of elements.\"\"\")\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndexed DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        ddof : int, default 1\n            Delta Degrees of Freedom.  The divisor used in calculations\n            is ``N - ddof``, where ``N`` represents the number of elements.\n    \"\"\" </s> remove     verbose : None, deprecated\n        Deprecated in pandas-gbq version 0.4.0. Use the `logging module to\n        adjust verbosity instead\n        <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__.\n </s> add  </s> remove     lines : boolean, default False\n        Read the file as a json object per line.\n </s> add     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes.", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     major_axis : Index or array-like\n <mask>         axis=1\n <mask>     minor_axis : Index or array-like\n <mask>         axis=2\n <mask>     dtype : dtype, default None\n <mask>         Data type to force, otherwise infer\n <mask>     copy : boolean, default False\n <mask>         Copy data from inputs. Only affects DataFrame / 2d ndarray input\n <mask>     \"\"\"\n <mask> \n <mask>     @property\n </s> CI: Linting with azure instead of travis (#22854) </s> add     dtype : dtype, default None\n        Data type to force, otherwise infer </s> remove \nParameters\n----------\nother : Series, DataFrame, or ndarray, optional\n    if not supplied then will default to self and produce pairwise output\npairwise : bool, default None\n    If False then only matching columns between self and other will be used and\n    the output will be a DataFrame.\n    If True then all pairwise combinations will be calculated and the output\n    will be a MultiIndex DataFrame in the case of DataFrame inputs.\n    In the case of missing elements, only complete pairwise observations will\n    be used.\nbias : bool, default False\n   Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndex DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        bias : bool, default False\n           Use a standard estimation bias correction </s> remove     Parameters\n    ----------\n    other : Series, DataFrame, or ndarray, optional\n        if not supplied then will default to self and produce pairwise output\n    pairwise : bool, default None\n        If False then only matching columns between self and other will be used\n        and the output will be a DataFrame.\n        If True then all pairwise combinations will be calculated and the\n        output will be a MultiIndexed DataFrame in the case of DataFrame\n        inputs. In the case of missing elements, only complete pairwise\n        observations will be used.\n    ddof : int, default 1\n        Delta Degrees of Freedom.  The divisor used in calculations\n        is ``N - ddof``, where ``N`` represents the number of elements.\"\"\")\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndexed DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        ddof : int, default 1\n            Delta Degrees of Freedom.  The divisor used in calculations\n            is ``N - ddof``, where ``N`` represents the number of elements.\n    \"\"\" </s> remove     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes.\n </s> add     lines : boolean, default False\n        Read the file as a json object per line. </s> add         Returns\n        -------\n        same type as input </s> remove     private_key : str, optional\n        Service account private key in JSON format. Can be file path\n        or string contents. This is useful for remote server\n        authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/panel.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     copy : boolean, default False\n <mask>         Copy data from inputs. Only affects DataFrame / 2d ndarray input\n <mask>     \"\"\"\n <mask> \n <mask>     @property\n <mask>     def _constructor(self):\n </s> CI: Linting with azure instead of travis (#22854) </s> remove     dtype : dtype, default None\n        Data type to force, otherwise infer\n </s> add  </s> remove \nParameters\n----------\nother : Series, DataFrame, or ndarray, optional\n    if not supplied then will default to self and produce pairwise output\npairwise : bool, default None\n    If False then only matching columns between self and other will be used and\n    the output will be a DataFrame.\n    If True then all pairwise combinations will be calculated and the output\n    will be a MultiIndex DataFrame in the case of DataFrame inputs.\n    In the case of missing elements, only complete pairwise observations will\n    be used.\nbias : bool, default False\n   Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndex DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        bias : bool, default False\n           Use a standard estimation bias correction </s> remove     Parameters\n    ----------\n    other : Series, DataFrame, or ndarray, optional\n        if not supplied then will default to self and produce pairwise output\n    pairwise : bool, default None\n        If False then only matching columns between self and other will be used\n        and the output will be a DataFrame.\n        If True then all pairwise combinations will be calculated and the\n        output will be a MultiIndexed DataFrame in the case of DataFrame\n        inputs. In the case of missing elements, only complete pairwise\n        observations will be used.\n    ddof : int, default 1\n        Delta Degrees of Freedom.  The divisor used in calculations\n        is ``N - ddof``, where ``N`` represents the number of elements.\"\"\")\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndexed DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        ddof : int, default 1\n            Delta Degrees of Freedom.  The divisor used in calculations\n            is ``N - ddof``, where ``N`` represents the number of elements.\n    \"\"\" </s> remove     private_key : str, optional\n        Service account private key in JSON format. Can be file path\n        or string contents. This is useful for remote server\n        authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add  </s> add         Returns\n        -------\n        same type as input </s> remove \nParameters\n----------\nbias : bool, default False\n    Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        bias : bool, default False\n            Use a standard estimation bias correction", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/panel.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     -------\n <mask>     timedelta64 or numpy.array of timedelta64\n <mask>         Output type returned if parsing succeeded.\n <mask> \n <mask>     See also\n <mask>     --------\n <mask>     DataFrame.astype : Cast argument to a specified dtype.\n <mask>     to_datetime : Convert argument to datetime.\n <mask> \n <mask>     Examples\n </s> CI: Linting with azure instead of travis (#22854) </s> remove Returns\n-------\nsame type as input\n\nSee Also\n--------\npandas.Series.%(name)s\npandas.DataFrame.%(name)s\n </s> add         See Also\n        --------\n        Series.%(name)s\n        DataFrame.%(name)s </s> add         Returns\n        -------\n        same type as input </s> remove     lines : boolean, default False\n        Read the file as a json object per line.\n </s> add     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes. </s> remove \nParameters\n----------\nother : Series, DataFrame, or ndarray, optional\n    if not supplied then will default to self and produce pairwise output\npairwise : bool, default None\n    If False then only matching columns between self and other will be used and\n    the output will be a DataFrame.\n    If True then all pairwise combinations will be calculated and the output\n    will be a MultiIndex DataFrame in the case of DataFrame inputs.\n    In the case of missing elements, only complete pairwise observations will\n    be used.\nbias : bool, default False\n   Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndex DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        bias : bool, default False\n           Use a standard estimation bias correction </s> remove     Parameters\n    ----------\n    other : Series, DataFrame, or ndarray, optional\n        if not supplied then will default to self and produce pairwise output\n    pairwise : bool, default None\n        If False then only matching columns between self and other will be used\n        and the output will be a DataFrame.\n        If True then all pairwise combinations will be calculated and the\n        output will be a MultiIndexed DataFrame in the case of DataFrame\n        inputs. In the case of missing elements, only complete pairwise\n        observations will be used.\n    ddof : int, default 1\n        Delta Degrees of Freedom.  The divisor used in calculations\n        is ``N - ddof``, where ``N`` represents the number of elements.\"\"\")\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndexed DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        ddof : int, default 1\n            Delta Degrees of Freedom.  The divisor used in calculations\n            is ``N - ddof``, where ``N`` represents the number of elements.\n    \"\"\" </s> add     verbose : None, deprecated\n        Deprecated in pandas-gbq version 0.4.0. Use the `logging module to\n        adjust verbosity instead\n        <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__.", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/tools/timedeltas.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> _shared_docs = dict(**_shared_docs)\n <mask> _doc_template = \"\"\"\n <mask> \n <mask>         See Also\n <mask>         --------\n <mask>         Series.%(name)s\n <mask>         DataFrame.%(name)s\n </s> CI: Linting with azure instead of travis (#22854) </s> remove Returns\n-------\nsame type as input\n\nSee Also\n--------\npandas.Series.%(name)s\npandas.DataFrame.%(name)s\n </s> add         See Also\n        --------\n        Series.%(name)s\n        DataFrame.%(name)s </s> remove     See also\n </s> add     See Also </s> remove \nParameters\n----------\nbias : bool, default False\n    Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        bias : bool, default False\n            Use a standard estimation bias correction </s> remove     pip_content = '\\n'.join(filter(None, map(conda_package_to_pip, deps)))\n </s> add     pip_deps = []\n    for dep in deps:\n        if isinstance(dep, str):\n            conda_dep = conda_package_to_pip(dep)\n            if conda_dep:\n                pip_deps.append(conda_dep)\n        elif isinstance(dep, dict) and len(dep) == 1 and 'pip' in dep:\n            pip_deps += dep['pip']\n        else:\n            raise ValueError('Unexpected dependency {}'.format(dep))\n\n    pip_content = '\\n'.join(pip_deps) </s> remove     _shared_docs['cov'] = dedent(\"\"\"\n    Calculate the %(name)s sample covariance.\n </s> add     _shared_docs['cov'] = \"\"\"\n        Calculate the %(name)s sample covariance. </s> add     argparser.add_argument('--azure',\n                           action='store_true',\n                           help='show the output in azure-pipelines format')", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/window.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> _shared_docs = dict(**_shared_docs)\n <mask> _doc_template = \"\"\"\n <mask> \n <mask> Returns\n <mask> -------\n <mask> same type as input\n <mask> \n <mask> See Also\n <mask> --------\n <mask> pandas.Series.%(name)s\n <mask> pandas.DataFrame.%(name)s\n <mask> \"\"\"\n <mask> \n <mask> \n <mask> class _Window(PandasObject, SelectionMixin):\n <mask>     _attributes = ['window', 'min_periods', 'center', 'win_type',\n </s> CI: Linting with azure instead of travis (#22854) </s> add         Returns\n        -------\n        same type as input </s> remove     See also\n </s> add     See Also </s> remove     pip_content = '\\n'.join(filter(None, map(conda_package_to_pip, deps)))\n </s> add     pip_deps = []\n    for dep in deps:\n        if isinstance(dep, str):\n            conda_dep = conda_package_to_pip(dep)\n            if conda_dep:\n                pip_deps.append(conda_dep)\n        elif isinstance(dep, dict) and len(dep) == 1 and 'pip' in dep:\n            pip_deps += dep['pip']\n        else:\n            raise ValueError('Unexpected dependency {}'.format(dep))\n\n    pip_content = '\\n'.join(pip_deps) </s> remove \nParameters\n----------\nbias : bool, default False\n    Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        bias : bool, default False\n            Use a standard estimation bias correction </s> add     dtype : dtype, default None\n        Data type to force, otherwise infer </s> remove     dtype : dtype, default None\n        Data type to force, otherwise infer\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/window.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         return self._apply(f, 'quantile', quantile=quantile,\n <mask>                            **kwargs)\n <mask> \n <mask>     _shared_docs['cov'] = dedent(\"\"\"\n <mask>     Calculate the %(name)s sample covariance.\n <mask> \n <mask>     Parameters\n <mask>     ----------\n <mask>     other : Series, DataFrame, or ndarray, optional\n <mask>         if not supplied then will default to self and produce pairwise output\n </s> CI: Linting with azure instead of travis (#22854) </s> remove     Parameters\n    ----------\n    other : Series, DataFrame, or ndarray, optional\n        if not supplied then will default to self and produce pairwise output\n    pairwise : bool, default None\n        If False then only matching columns between self and other will be used\n        and the output will be a DataFrame.\n        If True then all pairwise combinations will be calculated and the\n        output will be a MultiIndexed DataFrame in the case of DataFrame\n        inputs. In the case of missing elements, only complete pairwise\n        observations will be used.\n    ddof : int, default 1\n        Delta Degrees of Freedom.  The divisor used in calculations\n        is ``N - ddof``, where ``N`` represents the number of elements.\"\"\")\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndexed DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        ddof : int, default 1\n            Delta Degrees of Freedom.  The divisor used in calculations\n            is ``N - ddof``, where ``N`` represents the number of elements.\n    \"\"\" </s> remove \nParameters\n----------\nother : Series, DataFrame, or ndarray, optional\n    if not supplied then will default to self and produce pairwise output\npairwise : bool, default None\n    If False then only matching columns between self and other will be used and\n    the output will be a DataFrame.\n    If True then all pairwise combinations will be calculated and the output\n    will be a MultiIndex DataFrame in the case of DataFrame inputs.\n    In the case of missing elements, only complete pairwise observations will\n    be used.\nbias : bool, default False\n   Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndex DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        bias : bool, default False\n           Use a standard estimation bias correction </s> remove \nParameters\n----------\nbias : bool, default False\n    Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        bias : bool, default False\n            Use a standard estimation bias correction </s> remove     lines : boolean, default False\n        Read the file as a json object per line.\n </s> add     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes. </s> remove     pip_content = '\\n'.join(filter(None, map(conda_package_to_pip, deps)))\n </s> add     pip_deps = []\n    for dep in deps:\n        if isinstance(dep, str):\n            conda_dep = conda_package_to_pip(dep)\n            if conda_dep:\n                pip_deps.append(conda_dep)\n        elif isinstance(dep, dict) and len(dep) == 1 and 'pip' in dep:\n            pip_deps += dep['pip']\n        else:\n            raise ValueError('Unexpected dependency {}'.format(dep))\n\n    pip_content = '\\n'.join(pip_deps) </s> remove         private_key : str, optional\n            Service account private key in JSON format. Can be file path\n            or string contents. This is useful for remote server\n            authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/window.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     _shared_docs['cov'] = dedent(\"\"\"\n <mask>     Calculate the %(name)s sample covariance.\n <mask> \n <mask>     Parameters\n <mask>     ----------\n <mask>     other : Series, DataFrame, or ndarray, optional\n <mask>         if not supplied then will default to self and produce pairwise output\n <mask>     pairwise : bool, default None\n <mask>         If False then only matching columns between self and other will be used\n <mask>         and the output will be a DataFrame.\n <mask>         If True then all pairwise combinations will be calculated and the\n <mask>         output will be a MultiIndexed DataFrame in the case of DataFrame\n <mask>         inputs. In the case of missing elements, only complete pairwise\n <mask>         observations will be used.\n <mask>     ddof : int, default 1\n <mask>         Delta Degrees of Freedom.  The divisor used in calculations\n <mask>         is ``N - ddof``, where ``N`` represents the number of elements.\"\"\")\n <mask> \n <mask>     def cov(self, other=None, pairwise=None, ddof=1, **kwargs):\n <mask>         if other is None:\n <mask>             other = self._selected_obj\n <mask>             # only default unset\n </s> CI: Linting with azure instead of travis (#22854) </s> remove \nParameters\n----------\nother : Series, DataFrame, or ndarray, optional\n    if not supplied then will default to self and produce pairwise output\npairwise : bool, default None\n    If False then only matching columns between self and other will be used and\n    the output will be a DataFrame.\n    If True then all pairwise combinations will be calculated and the output\n    will be a MultiIndex DataFrame in the case of DataFrame inputs.\n    In the case of missing elements, only complete pairwise observations will\n    be used.\nbias : bool, default False\n   Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndex DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        bias : bool, default False\n           Use a standard estimation bias correction </s> remove     _shared_docs['cov'] = dedent(\"\"\"\n    Calculate the %(name)s sample covariance.\n </s> add     _shared_docs['cov'] = \"\"\"\n        Calculate the %(name)s sample covariance. </s> remove     lines : boolean, default False\n        Read the file as a json object per line.\n </s> add     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes. </s> remove         private_key : str, optional\n            Service account private key in JSON format. Can be file path\n            or string contents. This is useful for remote server\n            authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add  </s> remove     private_key : str, optional\n        Service account private key in JSON format. Can be file path\n        or string contents. This is useful for remote server\n        authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add  </s> add     verbose : None, deprecated\n        Deprecated in pandas-gbq version 0.4.0. Use the `logging module to\n        adjust verbosity instead\n        <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__.", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/window.py"}
{"docstring_tokens": "keep replace replace replace replace replace keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep", "code_tokens": " <mask> _bias_template = \"\"\"\n <mask> \n <mask> Parameters\n <mask> ----------\n <mask> bias : bool, default False\n <mask>     Use a standard estimation bias correction\n <mask> \"\"\"\n <mask> \n <mask> _pairwise_template = \"\"\"\n <mask> \n <mask> Parameters\n <mask> ----------\n <mask> other : Series, DataFrame, or ndarray, optional\n <mask>     if not supplied then will default to self and produce pairwise output\n <mask> pairwise : bool, default None\n <mask>     If False then only matching columns between self and other will be used and\n <mask>     the output will be a DataFrame.\n <mask>     If True then all pairwise combinations will be calculated and the output\n <mask>     will be a MultiIndex DataFrame in the case of DataFrame inputs.\n <mask>     In the case of missing elements, only complete pairwise observations will\n <mask>     be used.\n <mask> bias : bool, default False\n <mask>    Use a standard estimation bias correction\n <mask> \"\"\"\n <mask> \n </s> CI: Linting with azure instead of travis (#22854) </s> remove     Parameters\n    ----------\n    other : Series, DataFrame, or ndarray, optional\n        if not supplied then will default to self and produce pairwise output\n    pairwise : bool, default None\n        If False then only matching columns between self and other will be used\n        and the output will be a DataFrame.\n        If True then all pairwise combinations will be calculated and the\n        output will be a MultiIndexed DataFrame in the case of DataFrame\n        inputs. In the case of missing elements, only complete pairwise\n        observations will be used.\n    ddof : int, default 1\n        Delta Degrees of Freedom.  The divisor used in calculations\n        is ``N - ddof``, where ``N`` represents the number of elements.\"\"\")\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndexed DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        ddof : int, default 1\n            Delta Degrees of Freedom.  The divisor used in calculations\n            is ``N - ddof``, where ``N`` represents the number of elements.\n    \"\"\" </s> remove     _shared_docs['cov'] = dedent(\"\"\"\n    Calculate the %(name)s sample covariance.\n </s> add     _shared_docs['cov'] = \"\"\"\n        Calculate the %(name)s sample covariance. </s> remove         private_key : str, optional\n            Service account private key in JSON format. Can be file path\n            or string contents. This is useful for remote server\n            authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add  </s> remove     lines : boolean, default False\n        Read the file as a json object per line.\n </s> add     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes. </s> remove     private_key : str, optional\n        Service account private key in JSON format. Can be file path\n        or string contents. This is useful for remote server\n        authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/window.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         DataFrame.\n <mask>     reauth : boolean, default False\n <mask>         Force Google BigQuery to re-authenticate the user. This is useful\n <mask>         if multiple accounts are used.\n <mask>     private_key : str, optional\n <mask>         Service account private key in JSON format. Can be file path\n <mask>         or string contents. This is useful for remote server\n <mask>         authentication (eg. Jupyter/IPython notebook on remote host).\n <mask>     auth_local_webserver : boolean, default False\n <mask>         Use the `local webserver flow`_ instead of the `console flow`_\n <mask>         when getting user credentials.\n <mask> \n <mask>         .. _local webserver flow:\n </s> CI: Linting with azure instead of travis (#22854) </s> remove         private_key : str, optional\n            Service account private key in JSON format. Can be file path\n            or string contents. This is useful for remote server\n            authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add  </s> add     verbose : None, deprecated\n        Deprecated in pandas-gbq version 0.4.0. Use the `logging module to\n        adjust verbosity instead\n        <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__. </s> remove     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes.\n </s> add     lines : boolean, default False\n        Read the file as a json object per line. </s> remove     lines : boolean, default False\n        Read the file as a json object per line.\n </s> add     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes. </s> remove     Parameters\n    ----------\n    other : Series, DataFrame, or ndarray, optional\n        if not supplied then will default to self and produce pairwise output\n    pairwise : bool, default None\n        If False then only matching columns between self and other will be used\n        and the output will be a DataFrame.\n        If True then all pairwise combinations will be calculated and the\n        output will be a MultiIndexed DataFrame in the case of DataFrame\n        inputs. In the case of missing elements, only complete pairwise\n        observations will be used.\n    ddof : int, default 1\n        Delta Degrees of Freedom.  The divisor used in calculations\n        is ``N - ddof``, where ``N`` represents the number of elements.\"\"\")\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndexed DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        ddof : int, default 1\n            Delta Degrees of Freedom.  The divisor used in calculations\n            is ``N - ddof``, where ``N`` represents the number of elements.\n    \"\"\" </s> remove \nParameters\n----------\nother : Series, DataFrame, or ndarray, optional\n    if not supplied then will default to self and produce pairwise output\npairwise : bool, default None\n    If False then only matching columns between self and other will be used and\n    the output will be a DataFrame.\n    If True then all pairwise combinations will be calculated and the output\n    will be a MultiIndex DataFrame in the case of DataFrame inputs.\n    In the case of missing elements, only complete pairwise observations will\n    be used.\nbias : bool, default False\n   Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndex DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        bias : bool, default False\n           Use a standard estimation bias correction", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/io/gbq.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         *New in version 0.8.0 of pandas-gbq*.\n <mask> \n <mask>         .. versionadded:: 0.24.0\n <mask>     verbose : None, deprecated\n <mask>         Deprecated in pandas-gbq version 0.4.0. Use the `logging module to\n <mask>         adjust verbosity instead\n <mask>         <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__.\n <mask>     private_key : str, deprecated\n <mask>         Deprecated in pandas-gbq version 0.8.0. Use the ``credentials``\n <mask>         parameter and\n <mask>         :func:`google.oauth2.service_account.Credentials.from_service_account_info`\n <mask>         or\n </s> CI: Linting with azure instead of travis (#22854) </s> add     verbose : None, deprecated\n        Deprecated in pandas-gbq version 0.4.0. Use the `logging module to\n        adjust verbosity instead\n        <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__. </s> remove         private_key : str, optional\n            Service account private key in JSON format. Can be file path\n            or string contents. This is useful for remote server\n            authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add  </s> remove     private_key : str, optional\n        Service account private key in JSON format. Can be file path\n        or string contents. This is useful for remote server\n        authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add  </s> remove \nParameters\n----------\nother : Series, DataFrame, or ndarray, optional\n    if not supplied then will default to self and produce pairwise output\npairwise : bool, default None\n    If False then only matching columns between self and other will be used and\n    the output will be a DataFrame.\n    If True then all pairwise combinations will be calculated and the output\n    will be a MultiIndex DataFrame in the case of DataFrame inputs.\n    In the case of missing elements, only complete pairwise observations will\n    be used.\nbias : bool, default False\n   Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndex DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        bias : bool, default False\n           Use a standard estimation bias correction </s> remove     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes.\n </s> add     lines : boolean, default False\n        Read the file as a json object per line. </s> remove     lines : boolean, default False\n        Read the file as a json object per line.\n </s> add     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes.", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/io/gbq.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         Service account private key in JSON format. Can be file path\n <mask>         or string contents. This is useful for remote server\n <mask>         authentication (eg. Jupyter/IPython notebook on remote host).\n <mask> \n <mask>     Returns\n <mask>     -------\n <mask>     df: DataFrame\n <mask>         DataFrame representing results of query.\n <mask> \n </s> CI: Linting with azure instead of travis (#22854) </s> remove     private_key : str, optional\n        Service account private key in JSON format. Can be file path\n        or string contents. This is useful for remote server\n        authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add  </s> remove         private_key : str, optional\n            Service account private key in JSON format. Can be file path\n            or string contents. This is useful for remote server\n            authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add  </s> remove     Parameters\n    ----------\n    other : Series, DataFrame, or ndarray, optional\n        if not supplied then will default to self and produce pairwise output\n    pairwise : bool, default None\n        If False then only matching columns between self and other will be used\n        and the output will be a DataFrame.\n        If True then all pairwise combinations will be calculated and the\n        output will be a MultiIndexed DataFrame in the case of DataFrame\n        inputs. In the case of missing elements, only complete pairwise\n        observations will be used.\n    ddof : int, default 1\n        Delta Degrees of Freedom.  The divisor used in calculations\n        is ``N - ddof``, where ``N`` represents the number of elements.\"\"\")\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndexed DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        ddof : int, default 1\n            Delta Degrees of Freedom.  The divisor used in calculations\n            is ``N - ddof``, where ``N`` represents the number of elements.\n    \"\"\" </s> remove \nParameters\n----------\nother : Series, DataFrame, or ndarray, optional\n    if not supplied then will default to self and produce pairwise output\npairwise : bool, default None\n    If False then only matching columns between self and other will be used and\n    the output will be a DataFrame.\n    If True then all pairwise combinations will be calculated and the output\n    will be a MultiIndex DataFrame in the case of DataFrame inputs.\n    In the case of missing elements, only complete pairwise observations will\n    be used.\nbias : bool, default False\n   Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndex DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        bias : bool, default False\n           Use a standard estimation bias correction </s> add         Returns\n        -------\n        same type as input </s> remove     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes.\n </s> add     lines : boolean, default False\n        Read the file as a json object per line.", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/io/gbq.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep replace replace", "code_tokens": " <mask>         The timestamp unit to detect if converting dates. The default behaviour\n <mask>         is to try and detect the correct precision, but if this is not desired\n <mask>         then pass one of 's', 'ms', 'us' or 'ns' to force parsing only seconds,\n <mask>         milliseconds, microseconds or nanoseconds respectively.\n <mask>     lines : boolean, default False\n <mask>         Read the file as a json object per line.\n <mask> \n <mask>         .. versionadded:: 0.19.0\n <mask> \n <mask>     encoding : str, default is 'utf-8'\n <mask>         The encoding to use to decode py3 bytes.\n </s> CI: Linting with azure instead of travis (#22854) </s> remove     Parameters\n    ----------\n    other : Series, DataFrame, or ndarray, optional\n        if not supplied then will default to self and produce pairwise output\n    pairwise : bool, default None\n        If False then only matching columns between self and other will be used\n        and the output will be a DataFrame.\n        If True then all pairwise combinations will be calculated and the\n        output will be a MultiIndexed DataFrame in the case of DataFrame\n        inputs. In the case of missing elements, only complete pairwise\n        observations will be used.\n    ddof : int, default 1\n        Delta Degrees of Freedom.  The divisor used in calculations\n        is ``N - ddof``, where ``N`` represents the number of elements.\"\"\")\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndexed DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        ddof : int, default 1\n            Delta Degrees of Freedom.  The divisor used in calculations\n            is ``N - ddof``, where ``N`` represents the number of elements.\n    \"\"\" </s> remove     private_key : str, optional\n        Service account private key in JSON format. Can be file path\n        or string contents. This is useful for remote server\n        authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add  </s> remove \nParameters\n----------\nother : Series, DataFrame, or ndarray, optional\n    if not supplied then will default to self and produce pairwise output\npairwise : bool, default None\n    If False then only matching columns between self and other will be used and\n    the output will be a DataFrame.\n    If True then all pairwise combinations will be calculated and the output\n    will be a MultiIndex DataFrame in the case of DataFrame inputs.\n    In the case of missing elements, only complete pairwise observations will\n    be used.\nbias : bool, default False\n   Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndex DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        bias : bool, default False\n           Use a standard estimation bias correction </s> remove         private_key : str, optional\n            Service account private key in JSON format. Can be file path\n            or string contents. This is useful for remote server\n            authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add  </s> remove     verbose : None, deprecated\n        Deprecated in pandas-gbq version 0.4.0. Use the `logging module to\n        adjust verbosity instead\n        <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__.\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/io/json/json.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> python-dateutil>=2.5.0\n <mask> pytz\n <mask> cython>=0.28.2\n <mask> flake8\n <mask> flake8-comprehensions\n <mask> flake8-rst>=0.6.0\n </s> CI: Linting with azure instead of travis (#22854) </s> add   - asv </s> remove   - flake8>=3.5\n  - flake8-comprehensions\n  - flake8-rst>=0.6.0\n </s> add  </s> remove   - seaborn\n </s> add  </s> remove   - ipython\n  - isort\n  - jinja2\n  - lxml\n </s> add  </s> remove         sys.stderr.write('`requirements-dev.txt` has to be generated with '\n                         '`{}` after `environment.yml` is modified.\\n'.format(\n                             sys.argv[0]))\n </s> add         msg = ('`requirements-dev.txt` has to be generated with `{}` after '\n               '`environment.yml` is modified.\\n'.format(sys.argv[0]))\n        if args.azure:\n            msg = ('##vso[task.logissue type=error;'\n                   'sourcepath=requirements-dev.txt]{}'.format(msg))\n        sys.stderr.write(msg) </s> remove Returns\n-------\nsame type as input\n\nSee Also\n--------\npandas.Series.%(name)s\npandas.DataFrame.%(name)s\n </s> add         See Also\n        --------\n        Series.%(name)s\n        DataFrame.%(name)s", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "requirements-dev.txt"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask> statsmodels\n <mask> xarray\n <mask> xlrd\n <mask> xlsxwriter\n <mask> xlwt </s> CI: Linting with azure instead of travis (#22854) </s> remove   - seaborn\n </s> add  </s> remove         sys.stderr.write('`requirements-dev.txt` has to be generated with '\n                         '`{}` after `environment.yml` is modified.\\n'.format(\n                             sys.argv[0]))\n </s> add         msg = ('`requirements-dev.txt` has to be generated with `{}` after '\n               '`environment.yml` is modified.\\n'.format(sys.argv[0]))\n        if args.azure:\n            msg = ('##vso[task.logissue type=error;'\n                   'sourcepath=requirements-dev.txt]{}'.format(msg))\n        sys.stderr.write(msg) </s> remove Returns\n-------\nsame type as input\n\nSee Also\n--------\npandas.Series.%(name)s\npandas.DataFrame.%(name)s\n </s> add         See Also\n        --------\n        Series.%(name)s\n        DataFrame.%(name)s </s> remove   - ci/code_checks.sh\n </s> add  </s> remove   - flake8>=3.5\n  - flake8-comprehensions\n  - flake8-rst>=0.6.0\n </s> add  </s> remove   - ipython\n  - isort\n  - jinja2\n  - lxml\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "requirements-dev.txt"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     with open(conda_fname) as conda_fd:\n <mask>         deps = yaml.safe_load(conda_fd)['dependencies']\n <mask> \n <mask>     pip_content = '\\n'.join(filter(None, map(conda_package_to_pip, deps)))\n <mask> \n <mask>     if compare:\n <mask>         with open(pip_fname) as pip_fd:\n <mask>             return pip_content != pip_fd.read()\n <mask>     else:\n </s> CI: Linting with azure instead of travis (#22854) </s> remove         sys.stderr.write('`requirements-dev.txt` has to be generated with '\n                         '`{}` after `environment.yml` is modified.\\n'.format(\n                             sys.argv[0]))\n </s> add         msg = ('`requirements-dev.txt` has to be generated with `{}` after '\n               '`environment.yml` is modified.\\n'.format(sys.argv[0]))\n        if args.azure:\n            msg = ('##vso[task.logissue type=error;'\n                   'sourcepath=requirements-dev.txt]{}'.format(msg))\n        sys.stderr.write(msg) </s> add         Returns\n        -------\n        same type as input </s> remove Returns\n-------\nsame type as input\n\nSee Also\n--------\npandas.Series.%(name)s\npandas.DataFrame.%(name)s\n </s> add         See Also\n        --------\n        Series.%(name)s\n        DataFrame.%(name)s </s> remove \nParameters\n----------\nbias : bool, default False\n    Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        bias : bool, default False\n            Use a standard estimation bias correction </s> remove     _shared_docs['cov'] = dedent(\"\"\"\n    Calculate the %(name)s sample covariance.\n </s> add     _shared_docs['cov'] = \"\"\"\n        Calculate the %(name)s sample covariance. </s> remove     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes.\n </s> add     lines : boolean, default False\n        Read the file as a json object per line.", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "scripts/generate_pip_deps_from_conda.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     argparser.add_argument('--compare',\n <mask>                            action='store_true',\n <mask>                            help='compare whether the two files are equivalent')\n <mask>     args = argparser.parse_args()\n <mask> \n <mask>     repo_path = os.path.dirname(os.path.abspath(os.path.dirname(__file__)))\n <mask>     res = main(os.path.join(repo_path, 'environment.yml'),\n <mask>                os.path.join(repo_path, 'requirements-dev.txt'),\n </s> CI: Linting with azure instead of travis (#22854) </s> remove         sys.stderr.write('`requirements-dev.txt` has to be generated with '\n                         '`{}` after `environment.yml` is modified.\\n'.format(\n                             sys.argv[0]))\n </s> add         msg = ('`requirements-dev.txt` has to be generated with `{}` after '\n               '`environment.yml` is modified.\\n'.format(sys.argv[0]))\n        if args.azure:\n            msg = ('##vso[task.logissue type=error;'\n                   'sourcepath=requirements-dev.txt]{}'.format(msg))\n        sys.stderr.write(msg) </s> remove     _shared_docs['cov'] = dedent(\"\"\"\n    Calculate the %(name)s sample covariance.\n </s> add     _shared_docs['cov'] = \"\"\"\n        Calculate the %(name)s sample covariance. </s> remove     pip_content = '\\n'.join(filter(None, map(conda_package_to_pip, deps)))\n </s> add     pip_deps = []\n    for dep in deps:\n        if isinstance(dep, str):\n            conda_dep = conda_package_to_pip(dep)\n            if conda_dep:\n                pip_deps.append(conda_dep)\n        elif isinstance(dep, dict) and len(dep) == 1 and 'pip' in dep:\n            pip_deps += dep['pip']\n        else:\n            raise ValueError('Unexpected dependency {}'.format(dep))\n\n    pip_content = '\\n'.join(pip_deps) </s> remove Returns\n-------\nsame type as input\n\nSee Also\n--------\npandas.Series.%(name)s\npandas.DataFrame.%(name)s\n </s> add         See Also\n        --------\n        Series.%(name)s\n        DataFrame.%(name)s </s> add         Returns\n        -------\n        same type as input </s> remove \nParameters\n----------\nbias : bool, default False\n    Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        bias : bool, default False\n            Use a standard estimation bias correction", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "scripts/generate_pip_deps_from_conda.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep", "code_tokens": " <mask>     res = main(os.path.join(repo_path, 'environment.yml'),\n <mask>                os.path.join(repo_path, 'requirements-dev.txt'),\n <mask>                compare=args.compare)\n <mask>     if res:\n <mask>         sys.stderr.write('`requirements-dev.txt` has to be generated with '\n <mask>                          '`{}` after `environment.yml` is modified.\\n'.format(\n <mask>                              sys.argv[0]))\n <mask>     sys.exit(res)\n </s> CI: Linting with azure instead of travis (#22854) </s> add     argparser.add_argument('--azure',\n                           action='store_true',\n                           help='show the output in azure-pipelines format') </s> remove     pip_content = '\\n'.join(filter(None, map(conda_package_to_pip, deps)))\n </s> add     pip_deps = []\n    for dep in deps:\n        if isinstance(dep, str):\n            conda_dep = conda_package_to_pip(dep)\n            if conda_dep:\n                pip_deps.append(conda_dep)\n        elif isinstance(dep, dict) and len(dep) == 1 and 'pip' in dep:\n            pip_deps += dep['pip']\n        else:\n            raise ValueError('Unexpected dependency {}'.format(dep))\n\n    pip_content = '\\n'.join(pip_deps) </s> remove     Parameters\n    ----------\n    other : Series, DataFrame, or ndarray, optional\n        if not supplied then will default to self and produce pairwise output\n    pairwise : bool, default None\n        If False then only matching columns between self and other will be used\n        and the output will be a DataFrame.\n        If True then all pairwise combinations will be calculated and the\n        output will be a MultiIndexed DataFrame in the case of DataFrame\n        inputs. In the case of missing elements, only complete pairwise\n        observations will be used.\n    ddof : int, default 1\n        Delta Degrees of Freedom.  The divisor used in calculations\n        is ``N - ddof``, where ``N`` represents the number of elements.\"\"\")\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndexed DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        ddof : int, default 1\n            Delta Degrees of Freedom.  The divisor used in calculations\n            is ``N - ddof``, where ``N`` represents the number of elements.\n    \"\"\" </s> remove     private_key : str, optional\n        Service account private key in JSON format. Can be file path\n        or string contents. This is useful for remote server\n        authentication (eg. Jupyter/IPython notebook on remote host).\n </s> add  </s> remove \nParameters\n----------\nother : Series, DataFrame, or ndarray, optional\n    if not supplied then will default to self and produce pairwise output\npairwise : bool, default None\n    If False then only matching columns between self and other will be used and\n    the output will be a DataFrame.\n    If True then all pairwise combinations will be calculated and the output\n    will be a MultiIndex DataFrame in the case of DataFrame inputs.\n    In the case of missing elements, only complete pairwise observations will\n    be used.\nbias : bool, default False\n   Use a standard estimation bias correction\n </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndex DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        bias : bool, default False\n           Use a standard estimation bias correction </s> remove     lines : boolean, default False\n        Read the file as a json object per line.\n </s> add     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes.", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "scripts/generate_pip_deps_from_conda.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> )\n <mask> from pandas.core.window.numba_ import generate_numba_apply_func\n <mask> \n <mask> if TYPE_CHECKING:\n <mask>     from pandas import Series\n <mask> \n <mask> \n <mask> def calculate_center_offset(window) -> int:\n <mask>     \"\"\"\n <mask>     Calculate an offset necessary to have the window label to be centered.\n </s> REF: make window _apply_blockwise actually blockwise (#35861) </s> add     def _insert_on_column(self, result: \"DataFrame\", obj: \"DataFrame\"): </s> add         from pandas import Series\n </s> remove                 df[name] = extra_col\n        return df\n </s> add                 result[name] = extra_col\n            elif name in result.index.names:\n                pass\n            elif name in self._selected_obj.columns:\n                # insert in the same location as we had in _selected_obj\n                old_cols = self._selected_obj.columns\n                new_cols = result.columns\n                old_loc = old_cols.get_loc(name)\n                overlap = new_cols.intersection(old_cols[:old_loc])\n                new_loc = len(overlap)\n                result.insert(new_loc, name, extra_col)\n            else:\n                # insert at the end\n                result[name] = extra_col </s> remove         df = concat(final, axis=1).reindex(columns=columns, copy=False)\n </s> add         df = concat(results, axis=1).reindex(columns=columns, copy=False)\n        self._insert_on_column(df, obj)\n        return df </s> remove         elif not len(final):\n </s> add         elif not len(results): </s> remove             if name not in df.columns and name not in df.index.names:\n                new_loc = len(df.columns)\n                df.insert(new_loc, name, extra_col)\n            elif name in df.columns:\n </s> add             if name in result.columns:", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace replace replace keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask>         kept_blocks = [blk for i, blk in enumerate(orig_blocks) if i not in skipped]\n <mask> \n <mask>         final = []\n <mask>         for result, block in zip(results, kept_blocks):\n <mask> \n <mask>             result = type(obj)(result, index=obj.index, columns=block.columns)\n <mask>             final.append(result)\n <mask> \n <mask>         exclude = exclude or []\n <mask>         columns = [c for c in self._selected_obj.columns if c not in exclude]\n <mask>         if not columns and not len(final) and exclude:\n <mask>             raise DataError(\"No numeric types to aggregate\")\n <mask>         elif not len(final):\n <mask>             return obj.astype(\"float64\")\n <mask> \n </s> REF: make window _apply_blockwise actually blockwise (#35861) </s> remove         elif not len(final):\n </s> add         elif not len(results): </s> remove             if name not in df.columns and name not in df.index.names:\n                new_loc = len(df.columns)\n                df.insert(new_loc, name, extra_col)\n            elif name in df.columns:\n </s> add             if name in result.columns: </s> remove         df = concat(final, axis=1).reindex(columns=columns, copy=False)\n </s> add         df = concat(results, axis=1).reindex(columns=columns, copy=False)\n        self._insert_on_column(df, obj)\n        return df </s> remove             result = homogeneous_func(values)\n            results.append(result)\n </s> add             res_blocks.extend(nbs)\n\n        if not len(res_blocks) and skipped:\n            raise DataError(\"No numeric types to aggregate\")\n        elif not len(res_blocks):\n            return obj.astype(\"float64\") </s> add         from pandas import Series\n", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep replace keep keep replace keep keep keep", "code_tokens": " <mask>             raise DataError(\"No numeric types to aggregate\")\n <mask>         elif not len(final):\n <mask>             return obj.astype(\"float64\")\n <mask> \n <mask>         df = concat(final, axis=1).reindex(columns=columns, copy=False)\n <mask> \n <mask>         # if we have an 'on' column we want to put it back into\n <mask>         # the results in the same location\n </s> REF: make window _apply_blockwise actually blockwise (#35861) </s> add     def _insert_on_column(self, result: \"DataFrame\", obj: \"DataFrame\"): </s> add         from pandas import Series\n </s> remove         if not columns and not len(final) and exclude:\n </s> add         if not columns and not len(results) and exclude: </s> remove             if name not in df.columns and name not in df.index.names:\n                new_loc = len(df.columns)\n                df.insert(new_loc, name, extra_col)\n            elif name in df.columns:\n </s> add             if name in result.columns: </s> remove         kept_blocks = [blk for i, blk in enumerate(orig_blocks) if i not in skipped]\n\n        final = []\n        for result, block in zip(results, kept_blocks):\n\n            result = type(obj)(result, index=obj.index, columns=block.columns)\n            final.append(result)\n\n        exclude = exclude or []\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         return df\n <mask> \n <mask>         # if we have an 'on' column we want to put it back into\n <mask>         # the results in the same location\n <mask>         from pandas import Series\n <mask> \n <mask>         if self.on is not None and not self._on.equals(obj.index):\n </s> REF: make window _apply_blockwise actually blockwise (#35861) </s> add         from pandas import Series\n </s> remove         df = concat(final, axis=1).reindex(columns=columns, copy=False)\n </s> add         df = concat(results, axis=1).reindex(columns=columns, copy=False)\n        self._insert_on_column(df, obj)\n        return df </s> remove         elif not len(final):\n </s> add         elif not len(results): </s> remove     from pandas import Series\n </s> add     from pandas import DataFrame, Series\n    from pandas.core.internals import Block  # noqa:F401 </s> remove             if name not in df.columns and name not in df.index.names:\n                new_loc = len(df.columns)\n                df.insert(new_loc, name, extra_col)\n            elif name in df.columns:\n </s> add             if name in result.columns: </s> remove         if not columns and not len(final) and exclude:\n </s> add         if not columns and not len(results) and exclude:", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>         # if we have an 'on' column we want to put it back into\n <mask>         # the results in the same location\n <mask>         if self.on is not None and not self._on.equals(obj.index):\n <mask>             name = self._on.name\n <mask>             extra_col = Series(self._on, index=obj.index, name=name)\n <mask>             if name in result.columns:\n <mask>                 # TODO: sure we want to overwrite results?\n <mask>                 result[name] = extra_col\n </s> REF: make window _apply_blockwise actually blockwise (#35861) </s> remove             if name not in df.columns and name not in df.index.names:\n                new_loc = len(df.columns)\n                df.insert(new_loc, name, extra_col)\n            elif name in df.columns:\n </s> add             if name in result.columns: </s> remove         df = concat(final, axis=1).reindex(columns=columns, copy=False)\n </s> add         df = concat(results, axis=1).reindex(columns=columns, copy=False)\n        self._insert_on_column(df, obj)\n        return df </s> add     def _insert_on_column(self, result: \"DataFrame\", obj: \"DataFrame\"): </s> remove                 df[name] = extra_col\n        return df\n </s> add                 result[name] = extra_col\n            elif name in result.index.names:\n                pass\n            elif name in self._selected_obj.columns:\n                # insert in the same location as we had in _selected_obj\n                old_cols = self._selected_obj.columns\n                new_cols = result.columns\n                old_loc = old_cols.get_loc(name)\n                overlap = new_cols.intersection(old_cols[:old_loc])\n                new_loc = len(overlap)\n                result.insert(new_loc, name, extra_col)\n            else:\n                # insert at the end\n                result[name] = extra_col </s> remove         elif not len(final):\n </s> add         elif not len(results): </s> remove         kept_blocks = [blk for i, blk in enumerate(orig_blocks) if i not in skipped]\n\n        final = []\n        for result, block in zip(results, kept_blocks):\n\n            result = type(obj)(result, index=obj.index, columns=block.columns)\n            final.append(result)\n\n        exclude = exclude or []\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep replace replace replace replace keep replace replace keep keep keep", "code_tokens": " <mask>             extra_col = Series(self._on, index=obj.index, name=name)\n <mask>             if name not in df.columns and name not in df.index.names:\n <mask>                 new_loc = len(df.columns)\n <mask>                 df.insert(new_loc, name, extra_col)\n <mask>             elif name in df.columns:\n <mask>                 # TODO: sure we want to overwrite results?\n <mask>                 df[name] = extra_col\n <mask>         return df\n <mask> \n <mask>     def _center_window(self, result, window) -> np.ndarray:\n <mask>         \"\"\"\n </s> REF: make window _apply_blockwise actually blockwise (#35861) </s> add         from pandas import Series\n </s> remove         df = concat(final, axis=1).reindex(columns=columns, copy=False)\n </s> add         df = concat(results, axis=1).reindex(columns=columns, copy=False)\n        self._insert_on_column(df, obj)\n        return df </s> remove         kept_blocks = [blk for i, blk in enumerate(orig_blocks) if i not in skipped]\n\n        final = []\n        for result, block in zip(results, kept_blocks):\n\n            result = type(obj)(result, index=obj.index, columns=block.columns)\n            final.append(result)\n\n        exclude = exclude or []\n </s> add  </s> remove         elif not len(final):\n </s> add         elif not len(results): </s> remove         if not columns and not len(final) and exclude:\n </s> add         if not columns and not len(results) and exclude:", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         # This isn't quite blockwise, since `blocks` is actually a collection\n <mask>         #  of homogenenous DataFrames.\n <mask>         blocks, obj = self._create_blocks(self._selected_obj)\n <mask> \n <mask>         skipped: List[int] = []\n <mask>         res_blocks: List[\"Block\"] = []\n <mask>         for i, blk in enumerate(mgr.blocks):\n <mask>             try:\n </s> REF: make window _apply_blockwise actually blockwise (#35861) </s> remove         results: List[ArrayLike] = []\n        for i, b in enumerate(blocks):\n </s> add         res_blocks: List[\"Block\"] = []\n        for i, blk in enumerate(mgr.blocks): </s> remove                 values = self._prep_values(b.values)\n </s> add                 nbs = blk.apply(hfunc) </s> remove         kept_blocks = [blk for i, blk in enumerate(orig_blocks) if i not in skipped]\n\n        final = []\n        for result, block in zip(results, kept_blocks):\n\n            result = type(obj)(result, index=obj.index, columns=block.columns)\n            final.append(result)\n\n        exclude = exclude or []\n </s> add  </s> add         from pandas import Series\n </s> remove             if name not in df.columns and name not in df.index.names:\n                new_loc = len(df.columns)\n                df.insert(new_loc, name, extra_col)\n            elif name in df.columns:\n </s> add             if name in result.columns: </s> remove                 df[name] = extra_col\n        return df\n </s> add                 result[name] = extra_col\n            elif name in result.index.names:\n                pass\n            elif name in self._selected_obj.columns:\n                # insert in the same location as we had in _selected_obj\n                old_cols = self._selected_obj.columns\n                new_cols = result.columns\n                old_loc = old_cols.get_loc(name)\n                overlap = new_cols.intersection(old_cols[:old_loc])\n                new_loc = len(overlap)\n                result.insert(new_loc, name, extra_col)\n            else:\n                # insert at the end\n                result[name] = extra_col", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace keep keep keep", "code_tokens": " <mask>         blocks, obj = self._create_blocks(self._selected_obj)\n <mask> \n <mask>         skipped: List[int] = []\n <mask>         results: List[ArrayLike] = []\n <mask>         for i, b in enumerate(blocks):\n <mask>             try:\n <mask>                 values = self._prep_values(b.values)\n <mask> \n <mask>             except (TypeError, NotImplementedError):\n <mask>                 skipped.append(i)\n </s> REF: make window _apply_blockwise actually blockwise (#35861) </s> add         mgr = obj._mgr\n\n        def hfunc(bvalues: ArrayLike) -> ArrayLike:\n            # TODO(EA2D): getattr unnecessary with 2D EAs\n            values = self._prep_values(getattr(bvalues, \"T\", bvalues))\n            res_values = homogeneous_func(values)\n            return getattr(res_values, \"T\", res_values) </s> remove             result = homogeneous_func(values)\n            results.append(result)\n </s> add             res_blocks.extend(nbs)\n\n        if not len(res_blocks) and skipped:\n            raise DataError(\"No numeric types to aggregate\")\n        elif not len(res_blocks):\n            return obj.astype(\"float64\") </s> remove         kept_blocks = [blk for i, blk in enumerate(orig_blocks) if i not in skipped]\n\n        final = []\n        for result, block in zip(results, kept_blocks):\n\n            result = type(obj)(result, index=obj.index, columns=block.columns)\n            final.append(result)\n\n        exclude = exclude or []\n </s> add  </s> remove         if not columns and not len(final) and exclude:\n </s> add         if not columns and not len(results) and exclude: </s> remove                 df[name] = extra_col\n        return df\n </s> add                 result[name] = extra_col\n            elif name in result.index.names:\n                pass\n            elif name in self._selected_obj.columns:\n                # insert in the same location as we had in _selected_obj\n                old_cols = self._selected_obj.columns\n                new_cols = result.columns\n                old_loc = old_cols.get_loc(name)\n                overlap = new_cols.intersection(old_cols[:old_loc])\n                new_loc = len(overlap)\n                result.insert(new_loc, name, extra_col)\n            else:\n                # insert at the end\n                result[name] = extra_col", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             except (TypeError, NotImplementedError):\n <mask>                 skipped.append(i)\n <mask>                 continue\n <mask> \n <mask>             result = homogeneous_func(values)\n <mask>             results.append(result)\n <mask> \n <mask>         return self._wrap_results(results, obj, skipped)\n <mask> \n <mask>     def _apply(\n <mask>         self,\n </s> REF: make window _apply_blockwise actually blockwise (#35861) </s> remove         return self._wrap_results(results, obj, skipped)\n </s> add         new_cols = mgr.reset_dropped_locs(res_blocks, skipped)\n        new_mgr = type(mgr).from_blocks(res_blocks, [new_cols, obj.index])\n        out = obj._constructor(new_mgr)\n        self._insert_on_column(out, obj)\n        return out </s> remove                 values = self._prep_values(b.values)\n </s> add                 nbs = blk.apply(hfunc) </s> remove         results: List[ArrayLike] = []\n        for i, b in enumerate(blocks):\n </s> add         res_blocks: List[\"Block\"] = []\n        for i, blk in enumerate(mgr.blocks): </s> add         mgr = obj._mgr\n\n        def hfunc(bvalues: ArrayLike) -> ArrayLike:\n            # TODO(EA2D): getattr unnecessary with 2D EAs\n            values = self._prep_values(getattr(bvalues, \"T\", bvalues))\n            res_values = homogeneous_func(values)\n            return getattr(res_values, \"T\", res_values) </s> remove         kept_blocks = [blk for i, blk in enumerate(orig_blocks) if i not in skipped]\n\n        final = []\n        for result, block in zip(results, kept_blocks):\n\n            result = type(obj)(result, index=obj.index, columns=block.columns)\n            final.append(result)\n\n        exclude = exclude or []\n </s> add  </s> remove                 df[name] = extra_col\n        return df\n </s> add                 result[name] = extra_col\n            elif name in result.index.names:\n                pass\n            elif name in self._selected_obj.columns:\n                # insert in the same location as we had in _selected_obj\n                old_cols = self._selected_obj.columns\n                new_cols = result.columns\n                old_loc = old_cols.get_loc(name)\n                overlap = new_cols.intersection(old_cols[:old_loc])\n                new_loc = len(overlap)\n                result.insert(new_loc, name, extra_col)\n            else:\n                # insert at the end\n                result[name] = extra_col", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>             result = homogeneous_func(values)\n <mask>             results.append(result)\n <mask> \n <mask>         return self._wrap_results(results, obj, skipped)\n <mask> \n <mask>     def _apply(\n <mask>         self,\n <mask>         func: Callable,\n <mask>         center: bool,\n </s> REF: make window _apply_blockwise actually blockwise (#35861) </s> remove             result = homogeneous_func(values)\n            results.append(result)\n </s> add             res_blocks.extend(nbs)\n\n        if not len(res_blocks) and skipped:\n            raise DataError(\"No numeric types to aggregate\")\n        elif not len(res_blocks):\n            return obj.astype(\"float64\") </s> add         mgr = obj._mgr\n\n        def hfunc(bvalues: ArrayLike) -> ArrayLike:\n            # TODO(EA2D): getattr unnecessary with 2D EAs\n            values = self._prep_values(getattr(bvalues, \"T\", bvalues))\n            res_values = homogeneous_func(values)\n            return getattr(res_values, \"T\", res_values) </s> remove         kept_blocks = [blk for i, blk in enumerate(orig_blocks) if i not in skipped]\n\n        final = []\n        for result, block in zip(results, kept_blocks):\n\n            result = type(obj)(result, index=obj.index, columns=block.columns)\n            final.append(result)\n\n        exclude = exclude or []\n </s> add  </s> remove                 df[name] = extra_col\n        return df\n </s> add                 result[name] = extra_col\n            elif name in result.index.names:\n                pass\n            elif name in self._selected_obj.columns:\n                # insert in the same location as we had in _selected_obj\n                old_cols = self._selected_obj.columns\n                new_cols = result.columns\n                old_loc = old_cols.get_loc(name)\n                overlap = new_cols.intersection(old_cols[:old_loc])\n                new_loc = len(overlap)\n                result.insert(new_loc, name, extra_col)\n            else:\n                # insert at the end\n                result[name] = extra_col </s> remove         df = concat(final, axis=1).reindex(columns=columns, copy=False)\n </s> add         df = concat(results, axis=1).reindex(columns=columns, copy=False)\n        self._insert_on_column(df, obj)\n        return df </s> remove         if not columns and not len(final) and exclude:\n </s> add         if not columns and not len(results) and exclude:", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> - Bug in :meth:`Series.corr` and :meth:`Series.cov` raising ``AttributeError`` for masked dtypes (:issue:`51422`)\n <mask> - Bug in :meth:`Series.mean`, :meth:`DataFrame.mean` with object-dtype values containing strings that can be converted to numbers (e.g. \"2\") returning incorrect numeric results; these now raise ``TypeError`` (:issue:`36703`, :issue:`44008`)\n <mask> - Bug in :meth:`DataFrame.corrwith` raising ``NotImplementedError`` for pyarrow-backed dtypes (:issue:`52314`)\n <mask> - Bug in :meth:`DataFrame.size` and :meth:`Series.size` returning 64-bit integer instead of int (:issue:`52897`)\n <mask> - Bug in :meth:`Series.corr` and :meth:`Series.cov` raising ``AttributeError`` for masked dtypes (:issue:`51422`)\n <mask> - Bug in :meth:`Series.median` and :meth:`DataFrame.median` with object-dtype values containing strings that can be converted to numbers (e.g. \"2\") returning incorrect numeric results; these now raise ``TypeError`` (:issue:`34671`)\n <mask> \n <mask> \n <mask> Conversion\n <mask> ^^^^^^^^^^\n </s> BUG: Change default of bool_only to False (#53283) </s> remove -\n </s> add  </s> remove bool_only : bool, default None\n    Include only boolean columns. If None, will attempt to use everything,\n    then use only boolean data. Not implemented for Series.\n </s> add bool_only : bool, default False\n    Include only boolean columns. Not implemented for Series. </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False,", "html_url": "https://github.com/pandas-dev/pandas/commit/030cf5d6fd3287567a4e8b2d71a2576eb9b64a1c", "file_name": "doc/source/whatsnew/v2.1.0.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> - Bug in :meth:`DataFrame.corrwith` raising ``NotImplementedError`` for pyarrow-backed dtypes (:issue:`52314`)\n <mask> - Bug in :meth:`DataFrame.size` and :meth:`Series.size` returning 64-bit integer instead of int (:issue:`52897`)\n <mask> - Bug in :meth:`Series.corr` and :meth:`Series.cov` raising ``AttributeError`` for masked dtypes (:issue:`51422`)\n <mask> - Bug in :meth:`Series.median` and :meth:`DataFrame.median` with object-dtype values containing strings that can be converted to numbers (e.g. \"2\") returning incorrect numeric results; these now raise ``TypeError`` (:issue:`34671`)\n <mask> -\n <mask> \n <mask> \n <mask> Conversion\n <mask> ^^^^^^^^^^\n <mask> - Bug in :func:`DataFrame.style.to_latex` and :func:`DataFrame.style.to_html` if the DataFrame contains integers with more digits than can be represented by floating point double precision (:issue:`52272`)\n </s> BUG: Change default of bool_only to False (#53283) </s> add - Bug in :meth:`Series.any`, :meth:`Series.all`, :meth:`DataFrame.any`, and :meth:`DataFrame.all` had the default value of ``bool_only`` set to ``None`` instead of ``False``; this change should have no impact on users (:issue:`53258`) </s> remove bool_only : bool, default None\n    Include only boolean columns. If None, will attempt to use everything,\n    then use only boolean data. Not implemented for Series.\n </s> add bool_only : bool, default False\n    Include only boolean columns. Not implemented for Series. </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False,", "html_url": "https://github.com/pandas-dev/pandas/commit/030cf5d6fd3287567a4e8b2d71a2576eb9b64a1c", "file_name": "doc/source/whatsnew/v2.1.0.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def any(  # type: ignore[override]\n <mask>         self,\n <mask>         *,\n <mask>         axis: Axis = 0,\n <mask>         bool_only=None,\n <mask>         skipna: bool = True,\n <mask>         **kwargs,\n <mask>     ) -> Series:\n <mask>         # error: Incompatible return value type (got \"Union[Series, bool]\",\n <mask>         # expected \"Series\")\n </s> BUG: Change default of bool_only to False (#53283) </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove bool_only : bool, default None\n    Include only boolean columns. If None, will attempt to use everything,\n    then use only boolean data. Not implemented for Series.\n </s> add bool_only : bool, default False\n    Include only boolean columns. Not implemented for Series. </s> add - Bug in :meth:`Series.any`, :meth:`Series.all`, :meth:`DataFrame.any`, and :meth:`DataFrame.all` had the default value of ``bool_only`` set to ``None`` instead of ``False``; this change should have no impact on users (:issue:`53258`) </s> remove -\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/030cf5d6fd3287567a4e8b2d71a2576eb9b64a1c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @doc(make_doc(\"all\", ndim=2))\n <mask>     def all(\n <mask>         self,\n <mask>         axis: Axis = 0,\n <mask>         bool_only=None,\n <mask>         skipna: bool = True,\n <mask>         **kwargs,\n <mask>     ) -> Series:\n <mask>         # error: Incompatible return value type (got \"Union[Series, bool]\",\n <mask>         # expected \"Series\")\n </s> BUG: Change default of bool_only to False (#53283) </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove bool_only : bool, default None\n    Include only boolean columns. If None, will attempt to use everything,\n    then use only boolean data. Not implemented for Series.\n </s> add bool_only : bool, default False\n    Include only boolean columns. Not implemented for Series. </s> add - Bug in :meth:`Series.any`, :meth:`Series.all`, :meth:`DataFrame.any`, and :meth:`DataFrame.all` had the default value of ``bool_only`` set to ``None`` instead of ``False``; this change should have no impact on users (:issue:`53258`) </s> remove -\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/030cf5d6fd3287567a4e8b2d71a2576eb9b64a1c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     * 1 / 'columns' : reduce the columns, return a Series whose index is the\n <mask>       original index.\n <mask>     * None : reduce all axes, return a scalar.\n <mask> \n <mask> bool_only : bool, default None\n <mask>     Include only boolean columns. If None, will attempt to use everything,\n <mask>     then use only boolean data. Not implemented for Series.\n <mask> skipna : bool, default True\n <mask>     Exclude NA/null values. If the entire row/column is NA and skipna is\n <mask>     True, then the result will be {empty_value}, as for an empty row/column.\n <mask>     If skipna is False, then NA are treated as True, because these are not\n <mask>     equal to zero.\n </s> BUG: Change default of bool_only to False (#53283) </s> add - Bug in :meth:`Series.any`, :meth:`Series.all`, :meth:`DataFrame.any`, and :meth:`DataFrame.all` had the default value of ``bool_only`` set to ``None`` instead of ``False``; this change should have no impact on users (:issue:`53258`) </s> remove -\n </s> add  </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False,", "html_url": "https://github.com/pandas-dev/pandas/commit/030cf5d6fd3287567a4e8b2d71a2576eb9b64a1c", "file_name": "pandas/core/generic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def any(  # type: ignore[override]\n <mask>         self,\n <mask>         *,\n <mask>         axis: Axis = 0,\n <mask>         bool_only=None,\n <mask>         skipna: bool = True,\n <mask>         **kwargs,\n <mask>     ) -> bool:\n <mask>         nv.validate_logical_func((), kwargs, fname=\"any\")\n <mask>         validate_bool_kwarg(skipna, \"skipna\", none_allowed=False)\n </s> BUG: Change default of bool_only to False (#53283) </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove bool_only : bool, default None\n    Include only boolean columns. If None, will attempt to use everything,\n    then use only boolean data. Not implemented for Series.\n </s> add bool_only : bool, default False\n    Include only boolean columns. Not implemented for Series. </s> remove -\n </s> add  </s> add - Bug in :meth:`Series.any`, :meth:`Series.all`, :meth:`DataFrame.any`, and :meth:`DataFrame.all` had the default value of ``bool_only`` set to ``None`` instead of ``False``; this change should have no impact on users (:issue:`53258`)", "html_url": "https://github.com/pandas-dev/pandas/commit/030cf5d6fd3287567a4e8b2d71a2576eb9b64a1c", "file_name": "pandas/core/series.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @Appender(make_doc(\"all\", ndim=1))\n <mask>     def all(\n <mask>         self,\n <mask>         axis: Axis = 0,\n <mask>         bool_only=None,\n <mask>         skipna: bool = True,\n <mask>         **kwargs,\n <mask>     ) -> bool:\n <mask>         nv.validate_logical_func((), kwargs, fname=\"all\")\n <mask>         validate_bool_kwarg(skipna, \"skipna\", none_allowed=False)\n </s> BUG: Change default of bool_only to False (#53283) </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove         bool_only=None,\n </s> add         bool_only: bool = False, </s> remove bool_only : bool, default None\n    Include only boolean columns. If None, will attempt to use everything,\n    then use only boolean data. Not implemented for Series.\n </s> add bool_only : bool, default False\n    Include only boolean columns. Not implemented for Series. </s> remove -\n </s> add  </s> add - Bug in :meth:`Series.any`, :meth:`Series.all`, :meth:`DataFrame.any`, and :meth:`DataFrame.all` had the default value of ``bool_only`` set to ``None`` instead of ``False``; this change should have no impact on users (:issue:`53258`)", "html_url": "https://github.com/pandas-dev/pandas/commit/030cf5d6fd3287567a4e8b2d71a2576eb9b64a1c", "file_name": "pandas/core/series.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace keep keep keep keep", "code_tokens": " <mask> changes in this branch specific to one bug or feature so it is clear\n <mask> what the branch brings to *pandas*. You can have many shiny-new-features\n <mask> and switch in between them using the git checkout command.\n <mask> \n <mask> To update this branch, you need to retrieve the changes from the master branch::\n <mask> \n <mask>     git fetch upstream\n <mask>     git rebase upstream/master\n <mask> \n <mask> This will replay your commits on top of the latest pandas git master.  If this\n <mask> leads to merge conflicts, you must resolve these before submitting your pull\n <mask> request.  If you have uncommitted changes, you will need to ``stash`` them prior\n </s> DOC: update contributing guide regarding updating a pull request (merge master) (#19990) </s> remove This will replay your commits on top of the latest pandas git master.  If this\nleads to merge conflicts, you must resolve these before submitting your pull\nrequest.  If you have uncommitted changes, you will need to ``stash`` them prior\nto updating.  This will effectively store your changes and they can be reapplied\nafter updating.\n </s> add When you want to update the feature branch with changes in master after\nyou created the branch, check the section on\n:ref:`updating a PR <contributing.update-pr>`. </s> remove Combining commits\n-----------------\n\nIf you have multiple commits, you may want to combine them into one commit, often\nreferred to as \"squashing\" or \"rebasing\".  This is a common request by package maintainers\nwhen submitting a pull request as it maintains a more compact commit history.  To rebase\nyour commits::\n\n    git rebase -i HEAD~#\n\nWhere # is the number of commits you want to combine.  Then you can pick the relevant\ncommit message and discard others.\n\nTo squash to the master branch do::\n\n    git rebase -i master\n\nUse the ``s`` option on a commit to ``squash``, meaning to keep the commit messages,\nor ``f`` to ``fixup``, meaning to merge the commit messages.\n\nThen you will need to push the branch (see below) forcefully to replace the current\ncommits with the new ones::\n\n    git push origin shiny-new-feature -f\n\n\n </s> add  </s> remove     git push -f origin shiny-new-feature\n </s> add Updating your pull request\n--------------------------\n\nBased on the review you get on your pull request, you will probably need to make\nsome changes to the code. In that case, you can make them in your branch, \nadd a new commit to that branch, push it to GitHub, and the pull request will be\nautomatically updated.  Pushing them to GitHub again is done by::\n\n    git push origin shiny-new-feature </s> remove the code. If you need to make more changes, you can make them in\nyour branch, push them to GitHub, and the pull request will be automatically\nupdated.  Pushing them to GitHub again is done by::\n </s> add the code. \n\n.. _contributing.update-pr:", "html_url": "https://github.com/pandas-dev/pandas/commit/0368927fd26e261e87125479a96e59da8985f5f5", "file_name": "doc/source/contributing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     git fetch upstream\n <mask>     git rebase upstream/master\n <mask> \n <mask> This will replay your commits on top of the latest pandas git master.  If this\n <mask> leads to merge conflicts, you must resolve these before submitting your pull\n <mask> request.  If you have uncommitted changes, you will need to ``stash`` them prior\n <mask> to updating.  This will effectively store your changes and they can be reapplied\n <mask> after updating.\n <mask> \n <mask> .. _contributing.documentation:\n <mask> \n <mask> Contributing to the documentation\n <mask> =================================\n </s> DOC: update contributing guide regarding updating a pull request (merge master) (#19990) </s> remove     git fetch upstream\n    git rebase upstream/master\n </s> add     git checkout master\n    git pull upstream master --ff-only </s> remove the code. If you need to make more changes, you can make them in\nyour branch, push them to GitHub, and the pull request will be automatically\nupdated.  Pushing them to GitHub again is done by::\n </s> add the code. \n\n.. _contributing.update-pr: </s> remove     git push -f origin shiny-new-feature\n </s> add Updating your pull request\n--------------------------\n\nBased on the review you get on your pull request, you will probably need to make\nsome changes to the code. In that case, you can make them in your branch, \nadd a new commit to that branch, push it to GitHub, and the pull request will be\nautomatically updated.  Pushing them to GitHub again is done by::\n\n    git push origin shiny-new-feature </s> remove To update this branch, you need to retrieve the changes from the master branch::\n </s> add When creating this branch, make sure your master branch is up to date with\nthe latest upstream master version. To update your local master branch, you\ncan do:: </s> remove Combining commits\n-----------------\n\nIf you have multiple commits, you may want to combine them into one commit, often\nreferred to as \"squashing\" or \"rebasing\".  This is a common request by package maintainers\nwhen submitting a pull request as it maintains a more compact commit history.  To rebase\nyour commits::\n\n    git rebase -i HEAD~#\n\nWhere # is the number of commits you want to combine.  Then you can pick the relevant\ncommit message and discard others.\n\nTo squash to the master branch do::\n\n    git rebase -i master\n\nUse the ``s`` option on a commit to ``squash``, meaning to keep the commit messages,\nor ``f`` to ``fixup``, meaning to merge the commit messages.\n\nThen you will need to push the branch (see below) forcefully to replace the current\ncommits with the new ones::\n\n    git push origin shiny-new-feature -f\n\n\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/0368927fd26e261e87125479a96e59da8985f5f5", "file_name": "doc/source/contributing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> Now you can commit your changes in your local repository::\n <mask> \n <mask>     git commit -m\n <mask> \n <mask> Combining commits\n <mask> -----------------\n <mask> \n <mask> If you have multiple commits, you may want to combine them into one commit, often\n <mask> referred to as \"squashing\" or \"rebasing\".  This is a common request by package maintainers\n <mask> when submitting a pull request as it maintains a more compact commit history.  To rebase\n <mask> your commits::\n <mask> \n <mask>     git rebase -i HEAD~#\n <mask> \n <mask> Where # is the number of commits you want to combine.  Then you can pick the relevant\n <mask> commit message and discard others.\n <mask> \n <mask> To squash to the master branch do::\n <mask> \n <mask>     git rebase -i master\n <mask> \n <mask> Use the ``s`` option on a commit to ``squash``, meaning to keep the commit messages,\n <mask> or ``f`` to ``fixup``, meaning to merge the commit messages.\n <mask> \n <mask> Then you will need to push the branch (see below) forcefully to replace the current\n <mask> commits with the new ones::\n <mask> \n <mask>     git push origin shiny-new-feature -f\n <mask> \n <mask> \n <mask> Pushing your changes\n <mask> --------------------\n <mask> \n <mask> When you want your changes to appear publicly on your GitHub page, push your\n <mask> forked feature branch's commits::\n </s> DOC: update contributing guide regarding updating a pull request (merge master) (#19990) </s> remove     git push -f origin shiny-new-feature\n </s> add Updating your pull request\n--------------------------\n\nBased on the review you get on your pull request, you will probably need to make\nsome changes to the code. In that case, you can make them in your branch, \nadd a new commit to that branch, push it to GitHub, and the pull request will be\nautomatically updated.  Pushing them to GitHub again is done by::\n\n    git push origin shiny-new-feature </s> remove To update this branch, you need to retrieve the changes from the master branch::\n </s> add When creating this branch, make sure your master branch is up to date with\nthe latest upstream master version. To update your local master branch, you\ncan do:: </s> remove This will replay your commits on top of the latest pandas git master.  If this\nleads to merge conflicts, you must resolve these before submitting your pull\nrequest.  If you have uncommitted changes, you will need to ``stash`` them prior\nto updating.  This will effectively store your changes and they can be reapplied\nafter updating.\n </s> add When you want to update the feature branch with changes in master after\nyou created the branch, check the section on\n:ref:`updating a PR <contributing.update-pr>`. </s> remove     git fetch upstream\n    git rebase upstream/master\n </s> add     git checkout master\n    git pull upstream master --ff-only </s> remove the code. If you need to make more changes, you can make them in\nyour branch, push them to GitHub, and the pull request will be automatically\nupdated.  Pushing them to GitHub again is done by::\n </s> add the code. \n\n.. _contributing.update-pr:", "html_url": "https://github.com/pandas-dev/pandas/commit/0368927fd26e261e87125479a96e59da8985f5f5", "file_name": "doc/source/contributing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep replace keep keep", "code_tokens": " <mask> #. Write a description of your changes in the ``Preview Discussion`` tab\n <mask> #. Click ``Send Pull Request``.\n <mask> \n <mask> This request then goes to the repository maintainers, and they will review\n <mask> the code. If you need to make more changes, you can make them in\n <mask> your branch, push them to GitHub, and the pull request will be automatically\n <mask> updated.  Pushing them to GitHub again is done by::\n <mask> \n <mask>     git push -f origin shiny-new-feature\n <mask> \n <mask> This will automatically update your pull request with the latest code and restart the\n </s> DOC: update contributing guide regarding updating a pull request (merge master) (#19990) </s> remove     git fetch upstream\n    git rebase upstream/master\n </s> add     git checkout master\n    git pull upstream master --ff-only </s> remove This will replay your commits on top of the latest pandas git master.  If this\nleads to merge conflicts, you must resolve these before submitting your pull\nrequest.  If you have uncommitted changes, you will need to ``stash`` them prior\nto updating.  This will effectively store your changes and they can be reapplied\nafter updating.\n </s> add When you want to update the feature branch with changes in master after\nyou created the branch, check the section on\n:ref:`updating a PR <contributing.update-pr>`. </s> remove To update this branch, you need to retrieve the changes from the master branch::\n </s> add When creating this branch, make sure your master branch is up to date with\nthe latest upstream master version. To update your local master branch, you\ncan do:: </s> remove Combining commits\n-----------------\n\nIf you have multiple commits, you may want to combine them into one commit, often\nreferred to as \"squashing\" or \"rebasing\".  This is a common request by package maintainers\nwhen submitting a pull request as it maintains a more compact commit history.  To rebase\nyour commits::\n\n    git rebase -i HEAD~#\n\nWhere # is the number of commits you want to combine.  Then you can pick the relevant\ncommit message and discard others.\n\nTo squash to the master branch do::\n\n    git rebase -i master\n\nUse the ``s`` option on a commit to ``squash``, meaning to keep the commit messages,\nor ``f`` to ``fixup``, meaning to merge the commit messages.\n\nThen you will need to push the branch (see below) forcefully to replace the current\ncommits with the new ones::\n\n    git push origin shiny-new-feature -f\n\n\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/0368927fd26e261e87125479a96e59da8985f5f5", "file_name": "doc/source/contributing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     min_fname_arg_count = 0\n <mask>     max_length = len(compat_args) + min_fname_arg_count\n <mask>     actual_length = len(args) + min_fname_arg_count\n <mask>     msg = (\n <mask>         r\"{fname}\\(\\) takes at most {max_length} \"\n <mask>         r\"argument \\({actual_length} given\\)\".format(\n <mask>             fname=_fname, max_length=max_length, actual_length=actual_length\n <mask>         )\n <mask>     )\n <mask> \n <mask>     with pytest.raises(TypeError, match=msg):\n <mask>         validate_args(_fname, args, min_fname_arg_count, compat_args)\n <mask> \n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"arguments \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"arguments \\({actual_length} given\\)\" </s> remove             \"`requirements-dev.txt` has to be generated with `{}` after \"\n            \"`environment.yml` is modified.\\n\".format(sys.argv[0])\n </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\" </s> remove         msg = \"'{arg}' is not a valid function for 'Window' object\".format(arg=arg)\n </s> add         msg = f\"'{arg}' is not a valid function for 'Window' object\" </s> remove         msg = \"'{}' has no attribute '{}'\".format(obj_name, invalid_attr_name)\n </s> add         msg = f\"'{obj_name}' has no attribute '{invalid_attr_name}'\" </s> remove         msg = 'No module can be imported from \"{}\"'.format(invalid_name)\n </s> add         msg = f'No module can be imported from \"{invalid_name}\"' </s> remove         title_line = \"{side} {title}{adj} {side}\".format(\n            side=char * side_len, title=title, adj=adj\n        )\n </s> add         title_line = f\"{char * side_len} {title}{adj} {char * side_len}\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tests/util/test_validate_args.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     min_fname_arg_count = 2\n <mask>     max_length = len(compat_args) + min_fname_arg_count\n <mask>     actual_length = len(args) + min_fname_arg_count\n <mask>     msg = (\n <mask>         r\"{fname}\\(\\) takes at most {max_length} \"\n <mask>         r\"arguments \\({actual_length} given\\)\".format(\n <mask>             fname=_fname, max_length=max_length, actual_length=actual_length\n <mask>         )\n <mask>     )\n <mask> \n <mask>     with pytest.raises(TypeError, match=msg):\n <mask>         validate_args(_fname, args, min_fname_arg_count, compat_args)\n <mask> \n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"argument \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"argument \\({actual_length} given\\)\" </s> remove             \"`requirements-dev.txt` has to be generated with `{}` after \"\n            \"`environment.yml` is modified.\\n\".format(sys.argv[0])\n </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\" </s> remove         msg = \"'{arg}' is not a valid function for 'Window' object\".format(arg=arg)\n </s> add         msg = f\"'{arg}' is not a valid function for 'Window' object\" </s> remove         msg = \"'{}' has no attribute '{}'\".format(obj_name, invalid_attr_name)\n </s> add         msg = f\"'{obj_name}' has no attribute '{invalid_attr_name}'\" </s> remove         title_line = \"{side} {title}{adj} {side}\".format(\n            side=char * side_len, title=title, adj=adj\n        )\n </s> add         title_line = f\"{char * side_len} {title}{adj} {char * side_len}\" </s> remove         msg = 'No module can be imported from \"{}\"'.format(invalid_name)\n </s> add         msg = f'No module can be imported from \"{invalid_name}\"'", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tests/util/test_validate_args.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> @pytest.mark.parametrize(\"i\", range(1, 3))\n <mask> def test_not_all_defaults(i):\n <mask>     bad_arg = \"foo\"\n <mask>     msg = (\n <mask>         \"the '{arg}' parameter is not supported \"\n <mask>         r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname)\n <mask>     )\n <mask> \n <mask>     compat_args = {\"foo\": 2, \"bar\": -1, \"baz\": 3}\n <mask>     arg_vals = (1, -1, 3)\n <mask> \n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         r\"the '{arg}' parameter is not supported \"\n        r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname)\n </s> add         fr\"the '{bad_arg}' parameter is not supported \"\n        fr\"in the pandas implementation of {_fname}\\(\\)\" </s> remove             \"`requirements-dev.txt` has to be generated with `{}` after \"\n            \"`environment.yml` is modified.\\n\".format(sys.argv[0])\n </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\" </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"argument \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"argument \\({actual_length} given\\)\" </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"arguments \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"arguments \\({actual_length} given\\)\" </s> remove                 \"sourcepath=requirements-dev.txt]{}\".format(msg)\n </s> add                 f\"sourcepath=requirements-dev.txt]{msg}\" </s> remove         msg = \"'{arg}' is not a valid function for 'Window' object\".format(arg=arg)\n </s> add         msg = f\"'{arg}' is not a valid function for 'Window' object\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tests/util/test_validate_args.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> @pytest.mark.parametrize(\"i\", range(1, 3))\n <mask> def test_not_all_none(i):\n <mask>     bad_arg = \"foo\"\n <mask>     msg = (\n <mask>         r\"the '{arg}' parameter is not supported \"\n <mask>         r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname)\n <mask>     )\n <mask> \n <mask>     compat_args = {\"foo\": 1, \"bar\": \"s\", \"baz\": None}\n <mask> \n <mask>     kwarg_keys = (\"foo\", \"bar\", \"baz\")\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         \"the '{arg}' parameter is not supported \"\n        r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname)\n </s> add         f\"the '{bad_arg}' parameter is not supported \"\n        fr\"in the pandas implementation of {_fname}\\(\\)\" </s> remove             \"`requirements-dev.txt` has to be generated with `{}` after \"\n            \"`environment.yml` is modified.\\n\".format(sys.argv[0])\n </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\" </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"argument \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"argument \\({actual_length} given\\)\" </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"arguments \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"arguments \\({actual_length} given\\)\" </s> remove                 \"sourcepath=requirements-dev.txt]{}\".format(msg)\n </s> add                 f\"sourcepath=requirements-dev.txt]{msg}\" </s> remove         msg = \"'{arg}' is not a valid function for 'Window' object\".format(arg=arg)\n </s> add         msg = f\"'{arg}' is not a valid function for 'Window' object\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tests/util/test_validate_kwargs.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def test_agg_function_support(self, arg):\n <mask>         df = pd.DataFrame({\"A\": np.arange(5)})\n <mask>         roll = df.rolling(2, win_type=\"triang\")\n <mask> \n <mask>         msg = \"'{arg}' is not a valid function for 'Window' object\".format(arg=arg)\n <mask>         with pytest.raises(AttributeError, match=msg):\n <mask>             roll.agg(arg)\n <mask> \n <mask>         with pytest.raises(AttributeError, match=msg):\n <mask>             roll.agg([arg])\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         msg = \"'{}' has no attribute '{}'\".format(obj_name, invalid_attr_name)\n </s> add         msg = f\"'{obj_name}' has no attribute '{invalid_attr_name}'\" </s> remove         msg = 'No module can be imported from \"{}\"'.format(invalid_name)\n </s> add         msg = f'No module can be imported from \"{invalid_name}\"' </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"arguments \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"arguments \\({actual_length} given\\)\" </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"argument \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"argument \\({actual_length} given\\)\" </s> remove             \"`requirements-dev.txt` has to be generated with `{}` after \"\n            \"`environment.yml` is modified.\\n\".format(sys.argv[0])\n </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\" </s> remove         \"the '{arg}' parameter is not supported \"\n        r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname)\n </s> add         f\"the '{bad_arg}' parameter is not supported \"\n        fr\"in the pandas implementation of {_fname}\\(\\)\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tests/window/test_window.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep replace keep", "code_tokens": " <mask> \n <mask>     def __repr__(self) -> str:\n <mask>         info = \"\"\n <mask>         if self.year is not None:\n <mask>             info += \"year={year}, \".format(year=self.year)\n <mask>         info += \"month={mon}, day={day}, \".format(mon=self.month, day=self.day)\n <mask> \n <mask>         if self.offset is not None:\n <mask>             info += \"offset={offset}\".format(offset=self.offset)\n <mask> \n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove             info += \"observance={obs}\".format(obs=self.observance)\n </s> add             info += f\"observance={self.observance}\" </s> remove         repr = \"Holiday: {name} ({info})\".format(name=self.name, info=info)\n </s> add         repr = f\"Holiday: {self.name} ({info})\" </s> remove         url += \"{}#L{}\".format(self.source_file_name, self.source_file_def_line)\n </s> add         url += f\"{self.source_file_name}#L{self.source_file_def_line}\" </s> remove                 \"Holiday Calendar {name} does not have any \"\n                \"rules specified\".format(name=self.name)\n </s> add                 f\"Holiday Calendar {self.name} does not have any rules specified\" </s> remove         return \"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\".format(\n            full_line=full_line, title_line=title_line\n        )\n </s> add         return f\"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tseries/holiday.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if self.offset is not None:\n <mask>             info += \"offset={offset}\".format(offset=self.offset)\n <mask> \n <mask>         if self.observance is not None:\n <mask>             info += \"observance={obs}\".format(obs=self.observance)\n <mask> \n <mask>         repr = \"Holiday: {name} ({info})\".format(name=self.name, info=info)\n <mask>         return repr\n <mask> \n <mask>     def dates(self, start_date, end_date, return_name=False):\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         repr = \"Holiday: {name} ({info})\".format(name=self.name, info=info)\n </s> add         repr = f\"Holiday: {self.name} ({info})\" </s> remove             info += \"offset={offset}\".format(offset=self.offset)\n </s> add             info += f\"offset={self.offset}\" </s> remove             info += \"year={year}, \".format(year=self.year)\n        info += \"month={mon}, day={day}, \".format(mon=self.month, day=self.day)\n </s> add             info += f\"year={self.year}, \"\n        info += f\"month={self.month}, day={self.day}, \" </s> remove                 \"Holiday Calendar {name} does not have any \"\n                \"rules specified\".format(name=self.name)\n </s> add                 f\"Holiday Calendar {self.name} does not have any rules specified\" </s> remove         return \"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\".format(\n            full_line=full_line, title_line=title_line\n        )\n </s> add         return f\"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\" </s> remove         url += \"{}#L{}\".format(self.source_file_name, self.source_file_def_line)\n </s> add         url += f\"{self.source_file_name}#L{self.source_file_def_line}\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tseries/holiday.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         if self.observance is not None:\n <mask>             info += \"observance={obs}\".format(obs=self.observance)\n <mask> \n <mask>         repr = \"Holiday: {name} ({info})\".format(name=self.name, info=info)\n <mask>         return repr\n <mask> \n <mask>     def dates(self, start_date, end_date, return_name=False):\n <mask>         \"\"\"\n <mask>         Calculate holidays observed between start date and end date\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove             info += \"observance={obs}\".format(obs=self.observance)\n </s> add             info += f\"observance={self.observance}\" </s> remove             info += \"offset={offset}\".format(offset=self.offset)\n </s> add             info += f\"offset={self.offset}\" </s> remove                 \"Holiday Calendar {name} does not have any \"\n                \"rules specified\".format(name=self.name)\n </s> add                 f\"Holiday Calendar {self.name} does not have any rules specified\" </s> remove             info += \"year={year}, \".format(year=self.year)\n        info += \"month={mon}, day={day}, \".format(mon=self.month, day=self.day)\n </s> add             info += f\"year={self.year}, \"\n        info += f\"month={self.month}, day={self.day}, \" </s> remove         return \"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\".format(\n            full_line=full_line, title_line=title_line\n        )\n </s> add         return f\"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\" </s> remove         url += \"{}#L{}\".format(self.source_file_name, self.source_file_def_line)\n </s> add         url += f\"{self.source_file_name}#L{self.source_file_def_line}\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tseries/holiday.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             DatetimeIndex of holidays\n <mask>         \"\"\"\n <mask>         if self.rules is None:\n <mask>             raise Exception(\n <mask>                 \"Holiday Calendar {name} does not have any \"\n <mask>                 \"rules specified\".format(name=self.name)\n <mask>             )\n <mask> \n <mask>         if start is None:\n <mask>             start = AbstractHolidayCalendar.start_date\n <mask> \n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         repr = \"Holiday: {name} ({info})\".format(name=self.name, info=info)\n </s> add         repr = f\"Holiday: {self.name} ({info})\" </s> remove             info += \"observance={obs}\".format(obs=self.observance)\n </s> add             info += f\"observance={self.observance}\" </s> remove             info += \"offset={offset}\".format(offset=self.offset)\n </s> add             info += f\"offset={self.offset}\" </s> remove             info += \"year={year}, \".format(year=self.year)\n        info += \"month={mon}, day={day}, \".format(mon=self.month, day=self.day)\n </s> add             info += f\"year={self.year}, \"\n        info += f\"month={self.month}, day={self.day}, \" </s> remove         return \"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\".format(\n            full_line=full_line, title_line=title_line\n        )\n </s> add         return f\"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\" </s> remove         \"the '{arg}' parameter is not supported \"\n        r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname)\n </s> add         f\"the '{bad_arg}' parameter is not supported \"\n        fr\"in the pandas implementation of {_fname}\\(\\)\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tseries/holiday.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     files = [\n <mask>         x\n <mask>         for x in root.xpath(\"//a/text()\")\n <mask>         if x.startswith(\"pandas-{}\".format(version)) and not dest.joinpath(x).exists()\n <mask>     ]\n <mask> \n <mask>     N = len(files)\n <mask> \n <mask>     for i, filename in enumerate(files, 1):\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         print(\n            \"Downloaded {link} to {out} [{i}/{N}]\".format(link=link, out=out, i=i, N=N)\n        )\n </s> add         print(f\"Downloaded {link} to {out} [{i}/{N}]\") </s> remove             func_name = \"pandas.{}.{}\".format(class_.__name__, member[0])\n </s> add             func_name = f\"pandas.{class_.__name__}.{member[0]}\" </s> remove             full_directive = \".. {}\".format(directive)\n </s> add             full_directive = f\".. {directive}\" </s> remove         repr = \"Holiday: {name} ({info})\".format(name=self.name, info=info)\n </s> add         repr = f\"Holiday: {self.name} ({info})\" </s> remove             if \"import {}\".format(wrong_import) in examples_source_code:\n </s> add             if f\"import {wrong_import}\" in examples_source_code: </s> remove                     times_happening=\" ({} times)\".format(err.count)\n                    if err.count > 1\n                    else \"\",\n </s> add                     times_happening=f\" ({err.count} times)\" if err.count > 1 else \"\",", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/download_wheels.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     for i, filename in enumerate(files, 1):\n <mask>         out = str(dest.joinpath(filename))\n <mask>         link = urllib.request.urljoin(base, filename)\n <mask>         urllib.request.urlretrieve(link, out)\n <mask>         print(\n <mask>             \"Downloaded {link} to {out} [{i}/{N}]\".format(link=link, out=out, i=i, N=N)\n <mask>         )\n <mask> \n <mask> \n <mask> def main(args=None):\n <mask>     args = parse_args(args)\n <mask>     fetch(args.version)\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         if x.startswith(\"pandas-{}\".format(version)) and not dest.joinpath(x).exists()\n </s> add         if x.startswith(f\"pandas-{version}\") and not dest.joinpath(x).exists() </s> remove             full_directive = \".. {}\".format(directive)\n </s> add             full_directive = f\".. {directive}\" </s> remove             \"`requirements-dev.txt` has to be generated with `{}` after \"\n            \"`environment.yml` is modified.\\n\".format(sys.argv[0])\n </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\" </s> remove             func_name = \"pandas.{}.{}\".format(class_.__name__, member[0])\n </s> add             func_name = f\"pandas.{class_.__name__}.{member[0]}\" </s> remove         msg = \"'{}' has no attribute '{}'\".format(obj_name, invalid_attr_name)\n </s> add         msg = f\"'{obj_name}' has no attribute '{invalid_attr_name}'\" </s> remove         msg = \"'{arg}' is not a valid function for 'Window' object\".format(arg=arg)\n </s> add         msg = f\"'{arg}' is not a valid function for 'Window' object\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/download_wheels.py"}
{"docstring_tokens": "keep replace replace keep keep keep keep replace keep", "code_tokens": " <mask>         msg = (\n <mask>             \"`requirements-dev.txt` has to be generated with `{}` after \"\n <mask>             \"`environment.yml` is modified.\\n\".format(sys.argv[0])\n <mask>         )\n <mask>         if args.azure:\n <mask>             msg = (\n <mask>                 \"##vso[task.logissue type=error;\"\n <mask>                 \"sourcepath=requirements-dev.txt]{}\".format(msg)\n <mask>             )\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         msg = \"'{}' has no attribute '{}'\".format(obj_name, invalid_attr_name)\n </s> add         msg = f\"'{obj_name}' has no attribute '{invalid_attr_name}'\" </s> remove         msg = 'No module can be imported from \"{}\"'.format(invalid_name)\n </s> add         msg = f'No module can be imported from \"{invalid_name}\"' </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"arguments \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"arguments \\({actual_length} given\\)\" </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"argument \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"argument \\({actual_length} given\\)\" </s> remove         \"the '{arg}' parameter is not supported \"\n        r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname)\n </s> add         f\"the '{bad_arg}' parameter is not supported \"\n        fr\"in the pandas implementation of {_fname}\\(\\)\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/generate_pip_deps_from_conda.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         assert d.obj is expected_obj\n <mask> \n <mask>     @pytest.mark.parametrize(\"invalid_name\", [\"panda\", \"panda.DataFrame\"])\n <mask>     def test_raises_for_invalid_module_name(self, invalid_name):\n <mask>         msg = 'No module can be imported from \"{}\"'.format(invalid_name)\n <mask>         with pytest.raises(ImportError, match=msg):\n <mask>             validate_docstrings.Docstring(invalid_name)\n <mask> \n <mask>     @pytest.mark.parametrize(\n <mask>         \"invalid_name\", [\"pandas.BadClassName\", \"pandas.Series.bad_method_name\"]\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         msg = \"'{}' has no attribute '{}'\".format(obj_name, invalid_attr_name)\n </s> add         msg = f\"'{obj_name}' has no attribute '{invalid_attr_name}'\" </s> remove             \"`requirements-dev.txt` has to be generated with `{}` after \"\n            \"`environment.yml` is modified.\\n\".format(sys.argv[0])\n </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\" </s> remove         msg = \"'{arg}' is not a valid function for 'Window' object\".format(arg=arg)\n </s> add         msg = f\"'{arg}' is not a valid function for 'Window' object\" </s> remove         \"It can be {}\".format(str(format_opts)[1:-1]),\n </s> add         f\"It can be {str(format_opts)[1:-1]}\", </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"argument \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"argument \\({actual_length} given\\)\" </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"arguments \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"arguments \\({actual_length} given\\)\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/tests/test_validate_docstrings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     )\n <mask>     def test_raises_for_invalid_attribute_name(self, invalid_name):\n <mask>         name_components = invalid_name.split(\".\")\n <mask>         obj_name, invalid_attr_name = name_components[-2], name_components[-1]\n <mask>         msg = \"'{}' has no attribute '{}'\".format(obj_name, invalid_attr_name)\n <mask>         with pytest.raises(AttributeError, match=msg):\n <mask>             validate_docstrings.Docstring(invalid_name)\n <mask> \n <mask>     @pytest.mark.parametrize(\n <mask>         \"name\", [\"pandas.Series.str.isdecimal\", \"pandas.Series.str.islower\"]\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         msg = 'No module can be imported from \"{}\"'.format(invalid_name)\n </s> add         msg = f'No module can be imported from \"{invalid_name}\"' </s> remove         msg = \"'{arg}' is not a valid function for 'Window' object\".format(arg=arg)\n </s> add         msg = f\"'{arg}' is not a valid function for 'Window' object\" </s> remove             \"`requirements-dev.txt` has to be generated with `{}` after \"\n            \"`environment.yml` is modified.\\n\".format(sys.argv[0])\n </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\" </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"arguments \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"arguments \\({actual_length} given\\)\" </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"argument \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"argument \\({actual_length} given\\)\" </s> remove         \"the '{arg}' parameter is not supported \"\n        r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname)\n </s> add         f\"the '{bad_arg}' parameter is not supported \"\n        fr\"in the pandas implementation of {_fname}\\(\\)\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/tests/test_validate_docstrings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     @property\n <mask>     def github_url(self):\n <mask>         url = \"https://github.com/pandas-dev/pandas/blob/master/\"\n <mask>         url += \"{}#L{}\".format(self.source_file_name, self.source_file_def_line)\n <mask>         return url\n <mask> \n <mask>     @property\n <mask>     def start_blank_lines(self):\n <mask>         i = None\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove             info += \"observance={obs}\".format(obs=self.observance)\n </s> add             info += f\"observance={self.observance}\" </s> remove         repr = \"Holiday: {name} ({info})\".format(name=self.name, info=info)\n </s> add         repr = f\"Holiday: {self.name} ({info})\" </s> remove             info += \"year={year}, \".format(year=self.year)\n        info += \"month={mon}, day={day}, \".format(mon=self.month, day=self.day)\n </s> add             info += f\"year={self.year}, \"\n        info += f\"month={self.month}, day={self.day}, \" </s> remove             info += \"offset={offset}\".format(offset=self.offset)\n </s> add             info += f\"offset={self.offset}\" </s> remove         return \"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\".format(\n            full_line=full_line, title_line=title_line\n        )\n </s> add         return f\"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\" </s> remove             full_directive = \".. {}\".format(directive)\n </s> add             full_directive = f\".. {directive}\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def parameter_desc(self, param):\n <mask>         desc = self.doc_parameters[param][1]\n <mask>         # Find and strip out any sphinx directives\n <mask>         for directive in DIRECTIVES:\n <mask>             full_directive = \".. {}\".format(directive)\n <mask>             if full_directive in desc:\n <mask>                 # Only retain any description before the directive\n <mask>                 desc = desc[: desc.index(full_directive)]\n <mask>         return desc\n <mask> \n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove             func_name = \"pandas.{}.{}\".format(class_.__name__, member[0])\n </s> add             func_name = f\"pandas.{class_.__name__}.{member[0]}\" </s> remove                 \"Holiday Calendar {name} does not have any \"\n                \"rules specified\".format(name=self.name)\n </s> add                 f\"Holiday Calendar {self.name} does not have any rules specified\" </s> remove         sys.stderr.write(header(\"Docstring ({})\".format(func_name)))\n        sys.stderr.write(\"{}\\n\".format(result[\"docstring\"]))\n </s> add         sys.stderr.write(header(f\"Docstring ({func_name})\"))\n        sys.stderr.write(f\"{result['docstring']}\\n\") </s> remove         if x.startswith(\"pandas-{}\".format(version)) and not dest.joinpath(x).exists()\n </s> add         if x.startswith(f\"pandas-{version}\") and not dest.joinpath(x).exists() </s> remove         print(\n            \"Downloaded {link} to {out} [{i}/{N}]\".format(link=link, out=out, i=i, N=N)\n        )\n </s> add         print(f\"Downloaded {link} to {out} [{i}/{N}]\") </s> remove         repr = \"Holiday: {name} ({info})\".format(name=self.name, info=info)\n </s> add         repr = f\"Holiday: {self.name} ({info})\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep keep keep keep replace", "code_tokens": " <mask>                     \"EX03\",\n <mask>                     error_code=err.error_code,\n <mask>                     error_message=err.message,\n <mask>                     times_happening=\" ({} times)\".format(err.count)\n <mask>                     if err.count > 1\n <mask>                     else \"\",\n <mask>                 )\n <mask>             )\n <mask>         examples_source_code = \"\".join(doc.examples_source_code)\n <mask>         for wrong_import in (\"numpy\", \"pandas\"):\n <mask>             if \"import {}\".format(wrong_import) in examples_source_code:\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove             func_name = \"pandas.{}.{}\".format(class_.__name__, member[0])\n </s> add             func_name = f\"pandas.{class_.__name__}.{member[0]}\" </s> remove         title_line = \"{side} {title}{adj} {side}\".format(\n            side=char * side_len, title=title, adj=adj\n        )\n </s> add         title_line = f\"{char * side_len} {title}{adj} {char * side_len}\" </s> remove         if x.startswith(\"pandas-{}\".format(version)) and not dest.joinpath(x).exists()\n </s> add         if x.startswith(f\"pandas-{version}\") and not dest.joinpath(x).exists() </s> remove                 sys.stderr.write(\"\\t{}\\n\".format(wrn_desc))\n </s> add                 sys.stderr.write(f\"\\t{wrn_desc}\\n\") </s> remove             full_directive = \".. {}\".format(directive)\n </s> add             full_directive = f\".. {directive}\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     # functions from introspecting Series and DataFrame\n <mask>     api_item_names = set(list(zip(*api_items))[0])\n <mask>     for class_ in (pandas.Series, pandas.DataFrame):\n <mask>         for member in inspect.getmembers(class_):\n <mask>             func_name = \"pandas.{}.{}\".format(class_.__name__, member[0])\n <mask>             if not member[0].startswith(\"_\") and func_name not in api_item_names:\n <mask>                 if prefix and not func_name.startswith(prefix):\n <mask>                     continue\n <mask>                 doc_info = validate_one(func_name)\n <mask>                 if ignore_deprecated and doc_info[\"deprecated\"]:\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         if x.startswith(\"pandas-{}\".format(version)) and not dest.joinpath(x).exists()\n </s> add         if x.startswith(f\"pandas-{version}\") and not dest.joinpath(x).exists() </s> remove             full_directive = \".. {}\".format(directive)\n </s> add             full_directive = f\".. {directive}\" </s> remove         repr = \"Holiday: {name} ({info})\".format(name=self.name, info=info)\n </s> add         repr = f\"Holiday: {self.name} ({info})\" </s> remove         return \"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\".format(\n            full_line=full_line, title_line=title_line\n        )\n </s> add         return f\"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\" </s> remove         sys.stderr.write(header(\"Docstring ({})\".format(func_name)))\n        sys.stderr.write(\"{}\\n\".format(result[\"docstring\"]))\n </s> add         sys.stderr.write(header(f\"Docstring ({func_name})\"))\n        sys.stderr.write(f\"{result['docstring']}\\n\") </s> remove                 sys.stderr.write(\"\\t{}\\n\".format(err_desc))\n </s> add                 sys.stderr.write(f\"\\t{err_desc}\\n\")", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep replace replace replace keep keep keep keep", "code_tokens": " <mask>         full_line = char * width\n <mask>         side_len = (width - len(title) - 2) // 2\n <mask>         adj = \"\" if len(title) % 2 == 0 else \" \"\n <mask>         title_line = \"{side} {title}{adj} {side}\".format(\n <mask>             side=char * side_len, title=title, adj=adj\n <mask>         )\n <mask> \n <mask>         return \"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\".format(\n <mask>             full_line=full_line, title_line=title_line\n <mask>         )\n <mask> \n <mask>     exit_status = 0\n <mask>     if func_name is None:\n <mask>         result = validate_all(prefix, ignore_deprecated)\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"arguments \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"arguments \\({actual_length} given\\)\" </s> remove             info += \"year={year}, \".format(year=self.year)\n        info += \"month={mon}, day={day}, \".format(mon=self.month, day=self.day)\n </s> add             info += f\"year={self.year}, \"\n        info += f\"month={self.month}, day={self.day}, \" </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"argument \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        )\n </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"argument \\({actual_length} given\\)\" </s> remove             func_name = \"pandas.{}.{}\".format(class_.__name__, member[0])\n </s> add             func_name = f\"pandas.{class_.__name__}.{member[0]}\" </s> remove             \"`requirements-dev.txt` has to be generated with `{}` after \"\n            \"`environment.yml` is modified.\\n\".format(sys.argv[0])\n </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep replace replace keep keep replace keep keep keep keep", "code_tokens": " <mask>         result = validate_one(func_name)\n <mask>         sys.stderr.write(header(\"Docstring ({})\".format(func_name)))\n <mask>         sys.stderr.write(\"{}\\n\".format(result[\"docstring\"]))\n <mask>         sys.stderr.write(header(\"Validation\"))\n <mask>         if result[\"errors\"]:\n <mask>             sys.stderr.write(\"{} Errors found:\\n\".format(len(result[\"errors\"])))\n <mask>             for err_code, err_desc in result[\"errors\"]:\n <mask>                 # Failing examples are printed at the end\n <mask>                 if err_code == \"EX02\":\n <mask>                     sys.stderr.write(\"\\tExamples do not pass tests\\n\")\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove                 sys.stderr.write(\"\\t{}\\n\".format(err_desc))\n </s> add                 sys.stderr.write(f\"\\t{err_desc}\\n\") </s> remove             sys.stderr.write(\"{} Warnings found:\\n\".format(len(result[\"warnings\"])))\n </s> add             sys.stderr.write(f\"{len(result['warnings'])} Warnings found:\\n\") </s> remove                 sys.stderr.write(\"\\t{}\\n\".format(wrn_desc))\n </s> add                 sys.stderr.write(f\"\\t{wrn_desc}\\n\") </s> remove             func_name = \"pandas.{}.{}\".format(class_.__name__, member[0])\n </s> add             func_name = f\"pandas.{class_.__name__}.{member[0]}\" </s> remove             sys.stderr.write('Docstring for \"{}\" correct. :)\\n'.format(func_name))\n </s> add             sys.stderr.write(f'Docstring for \"{func_name}\" correct. :)\\n')", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep replace keep replace", "code_tokens": " <mask>                 if err_code == \"EX02\":\n <mask>                     sys.stderr.write(\"\\tExamples do not pass tests\\n\")\n <mask>                     continue\n <mask>                 sys.stderr.write(\"\\t{}\\n\".format(err_desc))\n <mask>         if result[\"warnings\"]:\n <mask>             sys.stderr.write(\"{} Warnings found:\\n\".format(len(result[\"warnings\"])))\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove             sys.stderr.write(\"{} Errors found:\\n\".format(len(result[\"errors\"])))\n </s> add             sys.stderr.write(f\"{len(result['errors'])} Errors found:\\n\") </s> remove                 sys.stderr.write(\"\\t{}\\n\".format(wrn_desc))\n </s> add                 sys.stderr.write(f\"\\t{wrn_desc}\\n\") </s> remove             sys.stderr.write('Docstring for \"{}\" correct. :)\\n'.format(func_name))\n </s> add             sys.stderr.write(f'Docstring for \"{func_name}\" correct. :)\\n') </s> remove             func_name = \"pandas.{}.{}\".format(class_.__name__, member[0])\n </s> add             func_name = f\"pandas.{class_.__name__}.{member[0]}\" </s> remove         sys.stderr.write(header(\"Docstring ({})\".format(func_name)))\n        sys.stderr.write(\"{}\\n\".format(result[\"docstring\"]))\n </s> add         sys.stderr.write(header(f\"Docstring ({func_name})\"))\n        sys.stderr.write(f\"{result['docstring']}\\n\")", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace keep keep keep", "code_tokens": " <mask>         if result[\"warnings\"]:\n <mask>             sys.stderr.write(\"{} Warnings found:\\n\".format(len(result[\"warnings\"])))\n <mask>             for wrn_code, wrn_desc in result[\"warnings\"]:\n <mask>                 sys.stderr.write(\"\\t{}\\n\".format(wrn_desc))\n <mask> \n <mask>         if not result[\"errors\"]:\n <mask>             sys.stderr.write('Docstring for \"{}\" correct. :)\\n'.format(func_name))\n <mask> \n <mask>         if result[\"examples_errors\"]:\n <mask>             sys.stderr.write(header(\"Doctests\"))\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove             sys.stderr.write(\"{} Warnings found:\\n\".format(len(result[\"warnings\"])))\n </s> add             sys.stderr.write(f\"{len(result['warnings'])} Warnings found:\\n\") </s> remove                 sys.stderr.write(\"\\t{}\\n\".format(err_desc))\n </s> add                 sys.stderr.write(f\"\\t{err_desc}\\n\") </s> remove             sys.stderr.write(\"{} Errors found:\\n\".format(len(result[\"errors\"])))\n </s> add             sys.stderr.write(f\"{len(result['errors'])} Errors found:\\n\") </s> remove         sys.stderr.write(header(\"Docstring ({})\".format(func_name)))\n        sys.stderr.write(\"{}\\n\".format(result[\"docstring\"]))\n </s> add         sys.stderr.write(header(f\"Docstring ({func_name})\"))\n        sys.stderr.write(f\"{result['docstring']}\\n\") </s> remove                     times_happening=\" ({} times)\".format(err.count)\n                    if err.count > 1\n                    else \"\",\n </s> add                     times_happening=f\" ({err.count} times)\" if err.count > 1 else \"\",", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         default=\"default\",\n <mask>         choices=format_opts,\n <mask>         help=\"format of the output when validating \"\n <mask>         \"multiple docstrings (ignored when validating one).\"\n <mask>         \"It can be {}\".format(str(format_opts)[1:-1]),\n <mask>     )\n <mask>     argparser.add_argument(\n <mask>         \"--prefix\",\n <mask>         default=None,\n <mask>         help=\"pattern for the \"\n </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         r\"the '{arg}' parameter is not supported \"\n        r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname)\n </s> add         fr\"the '{bad_arg}' parameter is not supported \"\n        fr\"in the pandas implementation of {_fname}\\(\\)\" </s> remove         \"the '{arg}' parameter is not supported \"\n        r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname)\n </s> add         f\"the '{bad_arg}' parameter is not supported \"\n        fr\"in the pandas implementation of {_fname}\\(\\)\" </s> remove         msg = 'No module can be imported from \"{}\"'.format(invalid_name)\n </s> add         msg = f'No module can be imported from \"{invalid_name}\"' </s> remove             \"`requirements-dev.txt` has to be generated with `{}` after \"\n            \"`environment.yml` is modified.\\n\".format(sys.argv[0])\n </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\" </s> remove                 \"Holiday Calendar {name} does not have any \"\n                \"rules specified\".format(name=self.name)\n </s> add                 f\"Holiday Calendar {self.name} does not have any rules specified\" </s> remove         sys.stderr.write(header(\"Docstring ({})\".format(func_name)))\n        sys.stderr.write(\"{}\\n\".format(result[\"docstring\"]))\n </s> add         sys.stderr.write(header(f\"Docstring ({func_name})\"))\n        sys.stderr.write(f\"{result['docstring']}\\n\")", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     def _filter_data(self):\n <mask>         \"\"\"\n <mask> \n <mask>         \"\"\"\n <mask>         data, cat_mapping = self._convert_x()\n <mask>         x_names = data.keys()\n <mask> \n <mask>         if isinstance(data, LongPanel):\n <mask>             data = data.toWide()\n <mask> \n <mask>         elif not isinstance(data, WidePanel):\n </s> PanelOLS will accept LongPanel arguments\n\ngit-svn-id: http://pandas.googlecode.com/svn/trunk@66 d5231056-7de3-11de-ac95-d976489f1ece </s> add             cat_mapping = {}\r </s> remove         elif not isinstance(data, WidePanel):\n            data = WidePanel.fromDict(data)\n </s> add         else:\r\n            data, cat_mapping = self._convert_x(data)\r\n\r\n            if not isinstance(data, WidePanel):\r\n                data = WidePanel.fromDict(data)\r\n\r\n        x_names = data.items\r </s> remove     def _convert_x(self):\n </s> add     def _convert_x(self, x):\r </s> remove         for key, value in self._x_orig.iteritems():\n </s> add         for key, value in x.iteritems():\r", "html_url": "https://github.com/pandas-dev/pandas/commit/03c74e4492da468a7b118575c1a0291392d6e64b", "file_name": "pandas/stats/plm.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         data = self._x_orig\n <mask> \n <mask>         if isinstance(data, LongPanel):\n <mask>             data = data.toWide()\n <mask> \n <mask>         else:\n <mask>             data, cat_mapping = self._convert_x(data)\n <mask> \n <mask>             if not isinstance(data, WidePanel):\n </s> PanelOLS will accept LongPanel arguments\n\ngit-svn-id: http://pandas.googlecode.com/svn/trunk@66 d5231056-7de3-11de-ac95-d976489f1ece </s> remove         data, cat_mapping = self._convert_x()\n        x_names = data.keys()\n </s> add         data = self._x_orig\r </s> remove         elif not isinstance(data, WidePanel):\n            data = WidePanel.fromDict(data)\n </s> add         else:\r\n            data, cat_mapping = self._convert_x(data)\r\n\r\n            if not isinstance(data, WidePanel):\r\n                data = WidePanel.fromDict(data)\r\n\r\n        x_names = data.items\r </s> remove         for key, value in self._x_orig.iteritems():\n </s> add         for key, value in x.iteritems():\r </s> remove     def _convert_x(self):\n </s> add     def _convert_x(self, x):\r", "html_url": "https://github.com/pandas-dev/pandas/commit/03c74e4492da468a7b118575c1a0291392d6e64b", "file_name": "pandas/stats/plm.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         if isinstance(data, LongPanel):\n <mask>             data = data.toWide()\n <mask> \n <mask>         elif not isinstance(data, WidePanel):\n <mask>             data = WidePanel.fromDict(data)\n <mask> \n <mask>         if self._weights is not None:\n <mask>             data['__weights__'] = self._weights\n <mask> \n <mask>         # Filter x's without y (so we can make a prediction)\n </s> PanelOLS will accept LongPanel arguments\n\ngit-svn-id: http://pandas.googlecode.com/svn/trunk@66 d5231056-7de3-11de-ac95-d976489f1ece </s> remove         data, cat_mapping = self._convert_x()\n        x_names = data.keys()\n </s> add         data = self._x_orig\r </s> add             cat_mapping = {}\r </s> remove     def _convert_x(self):\n </s> add     def _convert_x(self, x):\r </s> remove         for key, value in self._x_orig.iteritems():\n </s> add         for key, value in x.iteritems():\r", "html_url": "https://github.com/pandas-dev/pandas/commit/03c74e4492da468a7b118575c1a0291392d6e64b", "file_name": "pandas/stats/plm.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         weights = data_long['__weights__'] if self._weights else None\n <mask> \n <mask>         return x, x_filt, y, weights, weights_filt, cat_mapping\n <mask> \n <mask>     def _convert_x(self):\n <mask> \n <mask>         # Converts non-numeric data in x to floats. x_converted is the\n <mask>         # DataMatrix with converted values, and x_conversion is a dict that\n <mask>         # provides the reverse mapping.  For example, if 'A' was converted to 0\n <mask>         # for x named 'variety', then x_conversion['variety'][0] is 'A'.\n </s> PanelOLS will accept LongPanel arguments\n\ngit-svn-id: http://pandas.googlecode.com/svn/trunk@66 d5231056-7de3-11de-ac95-d976489f1ece </s> remove         for key, value in self._x_orig.iteritems():\n </s> add         for key, value in x.iteritems():\r </s> remove         elif not isinstance(data, WidePanel):\n            data = WidePanel.fromDict(data)\n </s> add         else:\r\n            data, cat_mapping = self._convert_x(data)\r\n\r\n            if not isinstance(data, WidePanel):\r\n                data = WidePanel.fromDict(data)\r\n\r\n        x_names = data.items\r </s> remove         data, cat_mapping = self._convert_x()\n        x_names = data.keys()\n </s> add         data = self._x_orig\r </s> add             cat_mapping = {}\r", "html_url": "https://github.com/pandas-dev/pandas/commit/03c74e4492da468a7b118575c1a0291392d6e64b", "file_name": "pandas/stats/plm.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # provides the reverse mapping.  For example, if 'A' was converted to 0\n <mask>         # for x named 'variety', then x_conversion['variety'][0] is 'A'.\n <mask>         x_converted = {}\n <mask>         x_conversion = {}\n <mask>         for key, value in self._x_orig.iteritems():\n <mask>             df = value\n <mask>             if _is_numeric(df):\n <mask>                 x_converted[key] = df\n <mask>             else:\n <mask>                 values = df.values\n </s> PanelOLS will accept LongPanel arguments\n\ngit-svn-id: http://pandas.googlecode.com/svn/trunk@66 d5231056-7de3-11de-ac95-d976489f1ece </s> remove     def _convert_x(self):\n </s> add     def _convert_x(self, x):\r </s> add             cat_mapping = {}\r </s> remove         elif not isinstance(data, WidePanel):\n            data = WidePanel.fromDict(data)\n </s> add         else:\r\n            data, cat_mapping = self._convert_x(data)\r\n\r\n            if not isinstance(data, WidePanel):\r\n                data = WidePanel.fromDict(data)\r\n\r\n        x_names = data.items\r </s> remove         data, cat_mapping = self._convert_x()\n        x_names = data.keys()\n </s> add         data = self._x_orig\r", "html_url": "https://github.com/pandas-dev/pandas/commit/03c74e4492da468a7b118575c1a0291392d6e64b", "file_name": "pandas/stats/plm.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     weekofyear,\"The week ordinal of the year\"\n <mask>     week,\"The week ordinal of the year\"\n <mask>     dayofweek,\"The number of the day of the week with Monday=0, Sunday=6\"\n <mask>     weekday,\"The number of the day of the week with Monday=0, Sunday=6\"\n <mask>     isocalendar,\"The ISO 8601 year, week and day of the date\"\n <mask>     quarter,\"Quarter of the date: Jan-Mar = 1, Apr-Jun = 2, etc.\"\n <mask>     days_in_month,\"The number of days in the month of the datetime\"\n <mask>     is_month_start,\"Logical indicating if first day of month (defined by frequency)\"\n <mask>     is_month_end,\"Logical indicating if last day of month (defined by frequency)\"\n <mask>     is_quarter_start,\"Logical indicating if first day of quarter (defined by frequency)\"\n </s> CLN: Change isocalendar to be a method (#33533)\n\nFor consistency with `Timestamp.isocalendar`, this should rather be a\r\nmethod.\r\n\r\nFollowup of #33220, see the discussions following the merge </s> remove - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` accessor that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`).\n </s> add - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` method that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`). </s> remove     @property\n </s> add  </s> remove     @property\n </s> add  </s> remove         >>> ser.dt.isocalendar\n </s> add         >>> ser.dt.isocalendar() </s> remove         >>> idx.isocalendar\n </s> add         >>> idx.isocalendar() </s> remove         >>> ser.dt.isocalendar.week\n </s> add         >>> ser.dt.isocalendar().week", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "doc/source/user_guide/timeseries.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. ipython:: python\n <mask> \n <mask>    idx = pd.date_range(start='2019-12-29', freq='D', periods=4)\n <mask>    idx.to_series().dt.isocalendar\n <mask> \n <mask> .. _timeseries.offsets:\n <mask> \n <mask> DateOffset objects\n <mask> ------------------\n </s> CLN: Change isocalendar to be a method (#33533)\n\nFor consistency with `Timestamp.isocalendar`, this should rather be a\r\nmethod.\r\n\r\nFollowup of #33220, see the discussions following the merge </s> remove         >>> idx.isocalendar\n </s> add         >>> idx.isocalendar() </s> remove     _other_ops = [\"date\", \"time\", \"timetz\", \"isocalendar\"]\n </s> add     _other_ops = [\"date\", \"time\", \"timetz\"] </s> add             \"isocalendar\", </s> remove         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar\n </s> add         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar() </s> remove - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` accessor that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`).\n </s> add - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` method that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`). </s> remove         >>> ser.dt.isocalendar\n </s> add         >>> ser.dt.isocalendar()", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "doc/source/user_guide/timeseries.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> - Positional slicing on a :class:`IntervalIndex` now supports slices with ``step > 1`` (:issue:`31658`)\n <mask> - :class:`Series.str` now has a `fullmatch` method that matches a regular expression against the entire string in each row of the series, similar to `re.fullmatch` (:issue:`32806`).\n <mask> - :meth:`DataFrame.sample` will now also allow array-like and BitGenerator objects to be passed to ``random_state`` as seeds (:issue:`32503`)\n <mask> - :meth:`MultiIndex.union` will now raise `RuntimeWarning` if the object inside are unsortable, pass `sort=False` to suppress this warning (:issue:`33015`)\n <mask> - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` accessor that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`).\n <mask> - The :meth:`DataFrame.to_feather` method now supports additional keyword\n <mask>   arguments (e.g. to set the compression) that are added in pyarrow 0.17\n <mask>   (:issue:`33422`).\n <mask> - :meth:`DataFrame.to_csv`, :meth:`DataFrame.to_pickle`,\n <mask>   and :meth:`DataFrame.to_json` now support passing a dict of\n </s> CLN: Change isocalendar to be a method (#33533)\n\nFor consistency with `Timestamp.isocalendar`, this should rather be a\r\nmethod.\r\n\r\nFollowup of #33220, see the discussions following the merge </s> remove     @property\n </s> add  </s> remove     @property\n </s> add  </s> remove     isocalendar,\"The ISO 8601 year, week and day of the date\"\n </s> add  </s> remove    idx.to_series().dt.isocalendar\n </s> add    idx.to_series().dt.isocalendar() </s> remove         >>> ser.dt.isocalendar.week\n </s> add         >>> ser.dt.isocalendar().week </s> remove         >>> ser.dt.isocalendar\n </s> add         >>> ser.dt.isocalendar()", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "doc/source/whatsnew/v1.1.0.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"daysinmonth\",\n <mask>         \"microsecond\",\n <mask>         \"nanosecond\",\n <mask>     ]\n <mask>     _other_ops = [\"date\", \"time\", \"timetz\", \"isocalendar\"]\n <mask>     _datetimelike_ops = _field_ops + _object_ops + _bool_ops + _other_ops\n <mask>     _datetimelike_methods = [\n <mask>         \"to_period\",\n <mask>         \"tz_localize\",\n <mask>         \"tz_convert\",\n </s> CLN: Change isocalendar to be a method (#33533)\n\nFor consistency with `Timestamp.isocalendar`, this should rather be a\r\nmethod.\r\n\r\nFollowup of #33220, see the discussions following the merge </s> add             \"isocalendar\", </s> remove         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar\n </s> add         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar() </s> remove    idx.to_series().dt.isocalendar\n </s> add    idx.to_series().dt.isocalendar() </s> remove         >>> ser.dt.isocalendar\n </s> add         >>> ser.dt.isocalendar() </s> remove     @property\n </s> add  </s> remove         >>> idx.isocalendar\n </s> add         >>> idx.isocalendar()", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/core/arrays/datetimes.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             timestamps = self.asi8\n <mask> \n <mask>         return tslib.ints_to_pydatetime(timestamps, box=\"date\")\n <mask> \n <mask>     @property\n <mask>     def isocalendar(self):\n <mask>         \"\"\"\n <mask>         Returns a DataFrame with the year, week, and day calculated according to\n <mask>         the ISO 8601 standard.\n <mask> \n </s> CLN: Change isocalendar to be a method (#33533)\n\nFor consistency with `Timestamp.isocalendar`, this should rather be a\r\nmethod.\r\n\r\nFollowup of #33220, see the discussions following the merge </s> remove     @property\n </s> add  </s> remove - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` accessor that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`).\n </s> add - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` method that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`). </s> remove     isocalendar,\"The ISO 8601 year, week and day of the date\"\n </s> add  </s> remove         return self._get_values().isocalendar.set_index(self._parent.index)\n </s> add         return self._get_values().isocalendar().set_index(self._parent.index) </s> remove         >>> ser.dt.isocalendar.week\n </s> add         >>> ser.dt.isocalendar().week </s> remove         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar\n </s> add         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar()", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/core/arrays/datetimes.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         Examples\n <mask>         --------\n <mask>         >>> idx = pd.date_range(start='2019-12-29', freq='D', periods=4)\n <mask>         >>> idx.isocalendar\n <mask>            year  week  day\n <mask>         0  2019    52    7\n <mask>         1  2020     1    1\n <mask>         2  2020     1    2\n <mask>         3  2020     1    3\n </s> CLN: Change isocalendar to be a method (#33533)\n\nFor consistency with `Timestamp.isocalendar`, this should rather be a\r\nmethod.\r\n\r\nFollowup of #33220, see the discussions following the merge </s> remove         >>> idx.isocalendar.week\n </s> add         >>> idx.isocalendar().week </s> remove         >>> ser.dt.isocalendar\n </s> add         >>> ser.dt.isocalendar() </s> remove         >>> ser.dt.isocalendar.week\n </s> add         >>> ser.dt.isocalendar().week </s> remove    idx.to_series().dt.isocalendar\n </s> add    idx.to_series().dt.isocalendar() </s> remove         return self._get_values().isocalendar.set_index(self._parent.index)\n </s> add         return self._get_values().isocalendar().set_index(self._parent.index) </s> remove     isocalendar,\"The ISO 8601 year, week and day of the date\"\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/core/arrays/datetimes.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         0  2019    52    7\n <mask>         1  2020     1    1\n <mask>         2  2020     1    2\n <mask>         3  2020     1    3\n <mask>         >>> idx.isocalendar.week\n <mask>         0    52\n <mask>         1     1\n <mask>         2     1\n <mask>         3     1\n <mask>         Name: week, dtype: UInt32\n </s> CLN: Change isocalendar to be a method (#33533)\n\nFor consistency with `Timestamp.isocalendar`, this should rather be a\r\nmethod.\r\n\r\nFollowup of #33220, see the discussions following the merge </s> remove         >>> idx.isocalendar\n </s> add         >>> idx.isocalendar() </s> remove         >>> ser.dt.isocalendar.week\n </s> add         >>> ser.dt.isocalendar().week </s> remove         return self._get_values().isocalendar.set_index(self._parent.index)\n </s> add         return self._get_values().isocalendar().set_index(self._parent.index) </s> remove         >>> ser.dt.isocalendar\n </s> add         >>> ser.dt.isocalendar() </s> remove     @property\n </s> add  </s> remove     @property\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/core/arrays/datetimes.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @property\n <mask>     def freq(self):\n <mask>         return self._get_values().inferred_freq\n <mask> \n <mask>     @property\n <mask>     def isocalendar(self):\n <mask>         \"\"\"\n <mask>         Returns a DataFrame with the year, week, and day calculated according to\n <mask>         the ISO 8601 standard.\n <mask> \n </s> CLN: Change isocalendar to be a method (#33533)\n\nFor consistency with `Timestamp.isocalendar`, this should rather be a\r\nmethod.\r\n\r\nFollowup of #33220, see the discussions following the merge </s> remove     @property\n </s> add  </s> remove - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` accessor that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`).\n </s> add - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` method that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`). </s> remove     isocalendar,\"The ISO 8601 year, week and day of the date\"\n </s> add  </s> remove         return self._get_values().isocalendar.set_index(self._parent.index)\n </s> add         return self._get_values().isocalendar().set_index(self._parent.index) </s> remove         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar\n </s> add         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar() </s> remove         >>> ser.dt.isocalendar.week\n </s> add         >>> ser.dt.isocalendar().week", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/core/indexes/accessors.py"}
{"docstring_tokens": "keep keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         --------\n <mask>         >>> ser = pd.to_datetime(pd.Series([\"2010-01-01\", pd.NaT]))\n <mask>         >>> ser.dt.isocalendar\n <mask>            year  week  day\n <mask>         0  2009    53     5\n <mask>         1  <NA>  <NA>  <NA>\n <mask>         >>> ser.dt.isocalendar.week\n <mask>         0      53\n <mask>         1    <NA>\n <mask>         Name: week, dtype: UInt32\n <mask>         \"\"\"\n </s> CLN: Change isocalendar to be a method (#33533)\n\nFor consistency with `Timestamp.isocalendar`, this should rather be a\r\nmethod.\r\n\r\nFollowup of #33220, see the discussions following the merge </s> remove         return self._get_values().isocalendar.set_index(self._parent.index)\n </s> add         return self._get_values().isocalendar().set_index(self._parent.index) </s> remove         >>> idx.isocalendar\n </s> add         >>> idx.isocalendar() </s> remove         >>> idx.isocalendar.week\n </s> add         >>> idx.isocalendar().week </s> remove     isocalendar,\"The ISO 8601 year, week and day of the date\"\n </s> add  </s> remove     @property\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/core/indexes/accessors.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         0      53\n <mask>         1    <NA>\n <mask>         Name: week, dtype: UInt32\n <mask>         \"\"\"\n <mask>         return self._get_values().isocalendar.set_index(self._parent.index)\n <mask> \n <mask> \n <mask> @delegate_names(\n <mask>     delegate=TimedeltaArray, accessors=TimedeltaArray._datetimelike_ops, typ=\"property\"\n <mask> )\n </s> CLN: Change isocalendar to be a method (#33533)\n\nFor consistency with `Timestamp.isocalendar`, this should rather be a\r\nmethod.\r\n\r\nFollowup of #33220, see the discussions following the merge </s> remove         >>> ser.dt.isocalendar.week\n </s> add         >>> ser.dt.isocalendar().week </s> remove         >>> idx.isocalendar.week\n </s> add         >>> idx.isocalendar().week </s> remove         >>> ser.dt.isocalendar\n </s> add         >>> ser.dt.isocalendar() </s> remove         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar\n </s> add         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar() </s> remove     @property\n </s> add  </s> remove     @property\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/core/indexes/accessors.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>             \"floor\",\n <mask>             \"ceil\",\n <mask>             \"day_name\",\n <mask>             \"month_name\",\n <mask>         ]\n <mask>         ok_for_td = TimedeltaIndex._datetimelike_ops\n <mask>         ok_for_td_methods = [\n <mask>             \"components\",\n </s> CLN: Change isocalendar to be a method (#33533)\n\nFor consistency with `Timestamp.isocalendar`, this should rather be a\r\nmethod.\r\n\r\nFollowup of #33220, see the discussions following the merge </s> remove     _other_ops = [\"date\", \"time\", \"timetz\", \"isocalendar\"]\n </s> add     _other_ops = [\"date\", \"time\", \"timetz\"] </s> remove         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar\n </s> add         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar() </s> remove    idx.to_series().dt.isocalendar\n </s> add    idx.to_series().dt.isocalendar() </s> remove         >>> ser.dt.isocalendar\n </s> add         >>> ser.dt.isocalendar() </s> remove     @property\n </s> add  </s> remove         >>> idx.isocalendar\n </s> add         >>> idx.isocalendar()", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/tests/series/test_datetime_values.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>             [[\"2010-01-01\", pd.NaT], [[2009, 53, 5], [np.NaN, np.NaN, np.NaN]]],\n <mask>         ],\n <mask>     )\n <mask>     def test_isocalendar(self, input_series, expected_output):\n <mask>         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar\n <mask>         expected_frame = pd.DataFrame(\n <mask>             expected_output, columns=[\"year\", \"week\", \"day\"], dtype=\"UInt32\"\n <mask>         )\n <mask>         tm.assert_frame_equal(result, expected_frame)\n </s> CLN: Change isocalendar to be a method (#33533)\n\nFor consistency with `Timestamp.isocalendar`, this should rather be a\r\nmethod.\r\n\r\nFollowup of #33220, see the discussions following the merge </s> remove         return self._get_values().isocalendar.set_index(self._parent.index)\n </s> add         return self._get_values().isocalendar().set_index(self._parent.index) </s> remove     @property\n </s> add  </s> remove     _other_ops = [\"date\", \"time\", \"timetz\", \"isocalendar\"]\n </s> add     _other_ops = [\"date\", \"time\", \"timetz\"] </s> remove     @property\n </s> add  </s> add             \"isocalendar\", </s> remove    idx.to_series().dt.isocalendar\n </s> add    idx.to_series().dt.isocalendar()", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/tests/series/test_datetime_values.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     #----------------------------------------------------------------------\n <mask>     # Reindexing and alignment\n <mask> \n <mask>     def align(self, other, join='outer', axis=None, level=None, copy=True):\n <mask>         \"\"\"\n <mask>         Align two DataFrame object on their index and columns with the\n <mask>         specified join method for each axis Index\n <mask> \n <mask>         Parameters\n </s> Added fill_value argument to Series/DataFrame.align </s> remove     def align(self, other, join='outer', level=None, copy=True):\n </s> add     def align(self, other, join='outer', level=None, copy=True,\n              fill_value=None): </s> add         copy : boolean, default True\n            Always returns new objects. If copy=False and no reindexing is\n            required then original objects are returned.\n        fill_value : object, default None\n            Fills na's if not None </s> remove         return left_result, right_result\n </s> add         return left_result.fillna(fill_value), right_result.fillna(fill_value) </s> remove                      copy=True):\n </s> add                      copy=True, fill_value=None): </s> remove                       copy=True):\n </s> add                       copy=True, fill_value=None): </s> remove         return left, right\n </s> add         return left.fillna(fill_value), right.fillna(fill_value)", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             Align on index (0), columns (1), or both (None)\n <mask>         level : int or name\n <mask>             Broadcast across a level, matching Index values on the\n <mask>             passed MultiIndex level\n <mask> \n <mask>         Returns\n <mask>         -------\n <mask>         (left, right) : (DataFrame, type of other)\n <mask>             Aligned objects\n </s> Added fill_value argument to Series/DataFrame.align </s> add         fill_value : object, default None\n            Fills na's if not None </s> remove     def align(self, other, join='outer', axis=None, level=None, copy=True):\n </s> add     def align(self, other, join='outer', axis=None, level=None, copy=True,\n              fill_value=None): </s> remove     def align(self, other, join='outer', level=None, copy=True):\n </s> add     def align(self, other, join='outer', level=None, copy=True,\n              fill_value=None): </s> remove         return left_result, right_result\n </s> add         return left_result.fillna(fill_value), right_result.fillna(fill_value) </s> remove         af, bf = self.frame.align(other, axis=0)\n        self.assert_(bf.columns.equals(other.columns))\n </s> add         af, bf = self.frame.align(other, axis=0, fill_value=-1)\n        self.assert_(bf.columns.equals(other.columns))        \n        #test fill value\n        join_idx = self.frame.index.join(other.index)\n        diff_a = self.frame.index.diff(join_idx)\n        diff_b = other.index.diff(join_idx)\n        diff_a_vals = af.reindex(diff_a).values\n        diff_b_vals = bf.reindex(diff_b).values\n        self.assert_((diff_a_vals == -1).all()) </s> remove         return left, right\n </s> add         return left.fillna(fill_value), right.fillna(fill_value)", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         else:  # pragma: no cover\n <mask>             raise TypeError('unsupported type: %s' % type(other))\n <mask> \n <mask>     def _align_frame(self, other, join='outer', axis=None, level=None,\n <mask>                      copy=True):\n <mask>         # defaults\n <mask>         join_index, join_columns = None, None\n <mask>         ilidx, iridx = None, None\n <mask>         clidx, cridx = None, None\n <mask> \n </s> Added fill_value argument to Series/DataFrame.align </s> remove                       copy=True):\n </s> add                       copy=True, fill_value=None): </s> remove         return left, right\n </s> add         return left.fillna(fill_value), right.fillna(fill_value) </s> remove         return left, right\n </s> add         return left.fillna(fill_value), right.fillna(fill_value) </s> remove         af, bf = self.frame.align(other, axis=0)\n        self.assert_(bf.columns.equals(other.columns))\n </s> add         af, bf = self.frame.align(other, axis=0, fill_value=-1)\n        self.assert_(bf.columns.equals(other.columns))        \n        #test fill value\n        join_idx = self.frame.index.join(other.index)\n        diff_a = self.frame.index.diff(join_idx)\n        diff_b = other.index.diff(join_idx)\n        diff_a_vals = af.reindex(diff_a).values\n        diff_b_vals = bf.reindex(diff_b).values\n        self.assert_((diff_a_vals == -1).all()) </s> remove     def align(self, other, join='outer', axis=None, level=None, copy=True):\n </s> add     def align(self, other, join='outer', axis=None, level=None, copy=True,\n              fill_value=None): </s> remove         return left_result, right_result\n </s> add         return left_result.fillna(fill_value), right_result.fillna(fill_value)", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep replace keep keep keep keep", "code_tokens": " <mask>         left = self._reindex_with_indexers(join_index, ilidx,\n <mask>                                            join_columns, clidx, copy)\n <mask>         right = other._reindex_with_indexers(join_index, iridx,\n <mask>                                              join_columns, cridx, copy)\n <mask>         return left, right\n <mask> \n <mask>     def _align_series(self, other, join='outer', axis=None, level=None,\n <mask>                       copy=True):\n <mask>         fdata = self._data\n <mask>         if axis == 0:\n <mask>             join_index = self.index\n <mask>             lidx, ridx = None, None\n </s> Added fill_value argument to Series/DataFrame.align </s> remove         return left, right\n </s> add         return left.fillna(fill_value), right.fillna(fill_value) </s> remove                      copy=True):\n </s> add                      copy=True, fill_value=None): </s> remove         return left_result, right_result\n </s> add         return left_result.fillna(fill_value), right_result.fillna(fill_value) </s> remove         af, bf = self.frame.align(other, axis=0)\n        self.assert_(bf.columns.equals(other.columns))\n </s> add         af, bf = self.frame.align(other, axis=0, fill_value=-1)\n        self.assert_(bf.columns.equals(other.columns))        \n        #test fill value\n        join_idx = self.frame.index.join(other.index)\n        diff_a = self.frame.index.diff(join_idx)\n        diff_b = other.index.diff(join_idx)\n        diff_a_vals = af.reindex(diff_a).values\n        diff_b_vals = bf.reindex(diff_b).values\n        self.assert_((diff_a_vals == -1).all()) </s> remove     def align(self, other, join='outer', level=None, copy=True):\n </s> add     def align(self, other, join='outer', level=None, copy=True,\n              fill_value=None):", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             fdata = fdata.copy()\n <mask> \n <mask>         left_result = DataFrame(fdata)\n <mask>         right_result = other if ridx is None else other.reindex(join_index)\n <mask>         return left_result, right_result\n <mask> \n <mask>     def reindex(self, index=None, columns=None, method=None, level=None,\n <mask>                 copy=True):\n <mask>         \"\"\"Conform DataFrame to new index with optional filling logic, placing\n <mask>         NA/NaN in locations having no value in the previous index. A new object\n </s> Added fill_value argument to Series/DataFrame.align </s> remove                       copy=True):\n </s> add                       copy=True, fill_value=None): </s> remove         return left, right\n </s> add         return left.fillna(fill_value), right.fillna(fill_value) </s> remove     def align(self, other, join='outer', axis=None, level=None, copy=True):\n </s> add     def align(self, other, join='outer', axis=None, level=None, copy=True,\n              fill_value=None): </s> remove         af, bf = self.frame.align(other, axis=0)\n        self.assert_(bf.columns.equals(other.columns))\n </s> add         af, bf = self.frame.align(other, axis=0, fill_value=-1)\n        self.assert_(bf.columns.equals(other.columns))        \n        #test fill value\n        join_idx = self.frame.index.join(other.index)\n        diff_a = self.frame.index.diff(join_idx)\n        diff_b = other.index.diff(join_idx)\n        diff_a_vals = af.reindex(diff_a).values\n        diff_b_vals = bf.reindex(diff_b).values\n        self.assert_((diff_a_vals == -1).all()) </s> remove     def align(self, other, join='outer', level=None, copy=True):\n </s> add     def align(self, other, join='outer', level=None, copy=True,\n              fill_value=None): </s> remove                      copy=True):\n </s> add                      copy=True, fill_value=None):", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         except Exception:\n <mask>             mapped = lib.map_infer(self.values, func)\n <mask>             return Series(mapped, index=self.index, name=self.name)\n <mask> \n <mask>     def align(self, other, join='outer', level=None, copy=True):\n <mask>         \"\"\"\n <mask>         Align two Series object with the specified join method\n <mask> \n <mask>         Parameters\n <mask>         ----------\n </s> Added fill_value argument to Series/DataFrame.align </s> remove     def align(self, other, join='outer', axis=None, level=None, copy=True):\n </s> add     def align(self, other, join='outer', axis=None, level=None, copy=True,\n              fill_value=None): </s> remove         return left_result, right_result\n </s> add         return left_result.fillna(fill_value), right_result.fillna(fill_value) </s> remove         return left, right\n </s> add         return left.fillna(fill_value), right.fillna(fill_value) </s> remove                       copy=True):\n </s> add                       copy=True, fill_value=None): </s> add         fill_value : object, default None\n            Fills na's if not None </s> remove                      copy=True):\n </s> add                      copy=True, fill_value=None):", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/series.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>             Always return new objects. If copy=False and no reindexing is\n <mask>             required, the same object will be returned (for better performance)\n <mask> \n <mask>         Returns\n <mask>         -------\n <mask>         (left, right) : (Series, Series)\n <mask>             Aligned Series\n </s> Added fill_value argument to Series/DataFrame.align </s> add         copy : boolean, default True\n            Always returns new objects. If copy=False and no reindexing is\n            required then original objects are returned.\n        fill_value : object, default None\n            Fills na's if not None </s> remove         return left_result, right_result\n </s> add         return left_result.fillna(fill_value), right_result.fillna(fill_value) </s> remove     def align(self, other, join='outer', level=None, copy=True):\n </s> add     def align(self, other, join='outer', level=None, copy=True,\n              fill_value=None): </s> remove     def align(self, other, join='outer', axis=None, level=None, copy=True):\n </s> add     def align(self, other, join='outer', axis=None, level=None, copy=True,\n              fill_value=None): </s> remove         return left, right\n </s> add         return left.fillna(fill_value), right.fillna(fill_value) </s> remove         return left, right\n </s> add         return left.fillna(fill_value), right.fillna(fill_value)", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/series.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                                                  return_indexers=True)\n <mask> \n <mask>         left = self._reindex_indexer(join_index, lidx, copy)\n <mask>         right = other._reindex_indexer(join_index, ridx, copy)\n <mask>         return left, right\n <mask> \n <mask>     def _reindex_indexer(self, new_index, indexer, copy):\n <mask>         if indexer is not None:\n <mask>             new_values = com.take_1d(self.values, indexer)\n <mask>         else:\n </s> Added fill_value argument to Series/DataFrame.align </s> remove         return left, right\n </s> add         return left.fillna(fill_value), right.fillna(fill_value) </s> remove                       copy=True):\n </s> add                       copy=True, fill_value=None): </s> remove                      copy=True):\n </s> add                      copy=True, fill_value=None): </s> remove         return left_result, right_result\n </s> add         return left_result.fillna(fill_value), right_result.fillna(fill_value) </s> remove         af, bf = self.frame.align(other, axis=0)\n        self.assert_(bf.columns.equals(other.columns))\n </s> add         af, bf = self.frame.align(other, axis=0, fill_value=-1)\n        self.assert_(bf.columns.equals(other.columns))        \n        #test fill value\n        join_idx = self.frame.index.join(other.index)\n        diff_a = self.frame.index.diff(join_idx)\n        diff_b = other.index.diff(join_idx)\n        diff_a_vals = af.reindex(diff_a).values\n        diff_b_vals = bf.reindex(diff_b).values\n        self.assert_((diff_a_vals == -1).all()) </s> remove     def align(self, other, join='outer', level=None, copy=True):\n </s> add     def align(self, other, join='outer', level=None, copy=True,\n              fill_value=None):", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/series.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         self.assert_(af._data is self.frame._data)\n <mask> \n <mask>         # axis = 0\n <mask>         other = self.frame.ix[:-5, :3]\n <mask>         af, bf = self.frame.align(other, axis=0)\n <mask>         self.assert_(bf.columns.equals(other.columns))\n <mask> \n <mask>         af, bf = self.frame.align(other, join='right', axis=0)\n <mask>         self.assert_(bf.columns.equals(other.columns))\n <mask>         self.assert_(bf.index.equals(other.index))\n <mask>         self.assert_(af.index.equals(other.index))\n </s> Added fill_value argument to Series/DataFrame.align </s> remove                      copy=True):\n </s> add                      copy=True, fill_value=None): </s> remove         return left_result, right_result\n </s> add         return left_result.fillna(fill_value), right_result.fillna(fill_value) </s> remove                       copy=True):\n </s> add                       copy=True, fill_value=None): </s> remove         return left, right\n </s> add         return left.fillna(fill_value), right.fillna(fill_value) </s> remove         return left, right\n </s> add         return left.fillna(fill_value), right.fillna(fill_value) </s> remove     def align(self, other, join='outer', level=None, copy=True):\n </s> add     def align(self, other, join='outer', level=None, copy=True,\n              fill_value=None):", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/tests/test_frame.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             try:\n <mask>                 result = libreduction.compute_reduction(\n <mask>                     values, self.f, axis=self.axis, dummy=dummy, labels=labels\n <mask>                 )\n <mask>                 return self.obj._constructor_sliced(result, index=labels)\n <mask>             except Exception:\n <mask>                 pass\n <mask> \n <mask>         # compute the result using the series generator\n <mask>         self.apply_series_generator()\n <mask> \n </s> BUG: Fix TypeError raised in libreduction (#28643) </s> add             else:\n                return self.obj._constructor_sliced(result, index=labels) </s> remove     msg = (\n        r'\\(\"unsupported operand type\\(s\\) for \\+: '\n        \"'Timestamp' and 'float'\\\"\"\n        r\", 'occurred at index 0'\\)\"\n    )\n </s> add     msg = r'\\(\"unsupported operand type\\(s\\) for \\+: ' \"'Timestamp' and 'float'\\\", 0\"", "html_url": "https://github.com/pandas-dev/pandas/commit/0436570f05c3b6e7bbb7c7d8fc8fa2f28a0420a8", "file_name": "pandas/core/apply.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>                     raise\n <mask>             except ZeroDivisionError:\n <mask>                 # reached via numexpr; fall back to python implementation\n <mask>                 pass\n <mask> \n <mask>         # compute the result using the series generator\n <mask>         self.apply_series_generator()\n <mask> \n <mask>         # wrap results\n </s> BUG: Fix TypeError raised in libreduction (#28643) </s> remove                 return self.obj._constructor_sliced(result, index=labels)\n            except Exception:\n </s> add             except ValueError as err:\n                if \"Function does not reduce\" not in str(err):\n                    # catch only ValueError raised intentionally in libreduction\n                    raise\n            except TypeError:\n                # e.g. test_apply_ignore_failures we just ignore\n                if not self.ignore_failures:\n                    raise\n            except ZeroDivisionError:\n                # reached via numexpr; fall back to python implementation </s> remove     msg = (\n        r'\\(\"unsupported operand type\\(s\\) for \\+: '\n        \"'Timestamp' and 'float'\\\"\"\n        r\", 'occurred at index 0'\\)\"\n    )\n </s> add     msg = r'\\(\"unsupported operand type\\(s\\) for \\+: ' \"'Timestamp' and 'float'\\\", 0\"", "html_url": "https://github.com/pandas-dev/pandas/commit/0436570f05c3b6e7bbb7c7d8fc8fa2f28a0420a8", "file_name": "pandas/core/apply.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     assert_frame_equal(result, expected)\n <mask> \n <mask>     # won't work with axis = 1\n <mask>     grouped = df.groupby({\"A\": 0, \"C\": 0, \"D\": 1, \"E\": 1}, axis=1)\n <mask>     msg = (\n <mask>         r'\\(\"unsupported operand type\\(s\\) for \\+: '\n <mask>         \"'Timestamp' and 'float'\\\"\"\n <mask>         r\", 'occurred at index 0'\\)\"\n <mask>     )\n <mask>     with pytest.raises(TypeError, match=msg):\n <mask>         grouped.agg(lambda x: x.sum(0, numeric_only=False))\n <mask> \n <mask> \n <mask> def test_omit_nuisance_python_multiple(three_group):\n </s> BUG: Fix TypeError raised in libreduction (#28643) </s> remove                 return self.obj._constructor_sliced(result, index=labels)\n            except Exception:\n </s> add             except ValueError as err:\n                if \"Function does not reduce\" not in str(err):\n                    # catch only ValueError raised intentionally in libreduction\n                    raise\n            except TypeError:\n                # e.g. test_apply_ignore_failures we just ignore\n                if not self.ignore_failures:\n                    raise\n            except ZeroDivisionError:\n                # reached via numexpr; fall back to python implementation </s> add             else:\n                return self.obj._constructor_sliced(result, index=labels)", "html_url": "https://github.com/pandas-dev/pandas/commit/0436570f05c3b6e7bbb7c7d8fc8fa2f28a0420a8", "file_name": "pandas/tests/groupby/test_groupby.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     sum_x,\n <mask>                     neg_ct,\n <mask>                     compensation_add,\n <mask>                     num_consecutive_same_value,\n <mask>                     prev_value,\n <mask>                 )\n <mask>         else:\n <mask>             for j in range(start[i - 1], s):\n <mask>                 val = values[j]\n <mask>                 nobs, sum_x, neg_ct, compensation_remove = remove_mean(\n </s> CI: fix numba typing (#53730)\n\n* fix numba typing\r\n\r\n* type ignore\r\n\r\n---------\r\n\r\nCo-authored-by: Patrick Hoefler <61934744+phofl@users.noreply.github.com> </s> remove                     prev_value,\n </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> remove                     prev_value,\n </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> remove                     prev_value,\n </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues]", "html_url": "https://github.com/pandas-dev/pandas/commit/047da251c83c513617e437fec82133fbf690cb77", "file_name": "pandas/core/_numba/kernels/mean_.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     sum_x,\n <mask>                     neg_ct,\n <mask>                     compensation_add,\n <mask>                     num_consecutive_same_value,\n <mask>                     prev_value,\n <mask>                 )\n <mask> \n <mask>         if nobs >= min_periods and nobs > 0:\n <mask>             result = sum_x / nobs\n <mask>             if num_consecutive_same_value >= nobs:\n </s> CI: fix numba typing (#53730)\n\n* fix numba typing\r\n\r\n* type ignore\r\n\r\n---------\r\n\r\nCo-authored-by: Patrick Hoefler <61934744+phofl@users.noreply.github.com> </s> remove                     prev_value,\n </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> remove                     prev_value,\n </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> remove                     prev_value,\n </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues]", "html_url": "https://github.com/pandas-dev/pandas/commit/047da251c83c513617e437fec82133fbf690cb77", "file_name": "pandas/core/_numba/kernels/mean_.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     mean_x,\n <mask>                     ssqdm_x,\n <mask>                     compensation_add,\n <mask>                     num_consecutive_same_value,\n <mask>                     prev_value,\n <mask>                 )\n <mask>         else:\n <mask>             for j in range(start[i - 1], s):\n <mask>                 val = values[j]\n <mask>                 nobs, mean_x, ssqdm_x, compensation_remove = remove_var(\n </s> CI: fix numba typing (#53730)\n\n* fix numba typing\r\n\r\n* type ignore\r\n\r\n---------\r\n\r\nCo-authored-by: Patrick Hoefler <61934744+phofl@users.noreply.github.com> </s> remove                     prev_value,\n </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> remove                     prev_value,\n </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> remove                     prev_value,\n </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues]", "html_url": "https://github.com/pandas-dev/pandas/commit/047da251c83c513617e437fec82133fbf690cb77", "file_name": "pandas/core/_numba/kernels/var_.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     mean_x,\n <mask>                     ssqdm_x,\n <mask>                     compensation_add,\n <mask>                     num_consecutive_same_value,\n <mask>                     prev_value,\n <mask>                 )\n <mask> \n <mask>         if nobs >= min_periods and nobs > ddof:\n <mask>             if nobs == 1 or num_consecutive_same_value >= nobs:\n <mask>                 result = 0.0\n </s> CI: fix numba typing (#53730)\n\n* fix numba typing\r\n\r\n* type ignore\r\n\r\n---------\r\n\r\nCo-authored-by: Patrick Hoefler <61934744+phofl@users.noreply.github.com> </s> remove                     prev_value,\n </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> remove                     prev_value,\n </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> remove                     prev_value,\n </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues]", "html_url": "https://github.com/pandas-dev/pandas/commit/047da251c83c513617e437fec82133fbf690cb77", "file_name": "pandas/core/_numba/kernels/var_.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> # ----------------------------------------------------------------\n <mask> # Common arguments\n <mask> # ----------------------------------------------------------------\n <mask> @pytest.fixture(params=[0, 1, \"index\", \"columns\"], ids=lambda x: f\"axis {repr(x)}\")\n <mask> def axis(request):\n <mask>     \"\"\"\n <mask>     Fixture for returning the axis numbers of a DataFrame.\n <mask>     \"\"\"\n <mask>     return request.param\n </s> [ArrayManager] Fix window operations with axis=1 (#40251) </s> remove     expected = Series(\n        expData, index=days.rename(\"DateCol\")._with_freq(None), name=\"metric\"\n    )\n </s> add     index = days.rename(\"DateCol\")\n    if not using_array_manager:\n        # INFO(ArrayManager) preserves the frequence of the index\n        index = index._with_freq(None)\n    expected = Series(expData, index=index, name=\"metric\") </s> remove def test_rolling_window_as_string():\n </s> add def test_rolling_window_as_string(using_array_manager): </s> remove         new_mgr = mgr.apply(hfunc, ignore_failures=True)\n </s> add         def hfunc2d(values: ArrayLike) -> ArrayLike:\n            values = self._prep_values(values)\n            return homogeneous_func(values)\n\n        if isinstance(mgr, ArrayManager) and self.axis == 1:\n            new_mgr = mgr.apply_2d(hfunc2d, ignore_failures=True)\n        else:\n            new_mgr = mgr.apply(hfunc, ignore_failures=True) </s> add from pandas.core.internals import ArrayManager", "html_url": "https://github.com/pandas-dev/pandas/commit/04a0b86a9f7b80d91a8cf5f09953459096b2137e", "file_name": "pandas/conftest.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> from pandas.core.indexes.api import (\n <mask>     Index,\n <mask>     MultiIndex,\n <mask> )\n <mask> from pandas.core.reshape.concat import concat\n <mask> from pandas.core.util.numba_ import (\n <mask>     NUMBA_FUNC_CACHE,\n <mask>     maybe_use_numba,\n <mask> )\n </s> [ArrayManager] Fix window operations with axis=1 (#40251) </s> remove     expected = Series(\n        expData, index=days.rename(\"DateCol\")._with_freq(None), name=\"metric\"\n    )\n </s> add     index = days.rename(\"DateCol\")\n    if not using_array_manager:\n        # INFO(ArrayManager) preserves the frequence of the index\n        index = index._with_freq(None)\n    expected = Series(expData, index=index, name=\"metric\") </s> remove def test_rolling_window_as_string():\n </s> add def test_rolling_window_as_string(using_array_manager): </s> remove         new_mgr = mgr.apply(hfunc, ignore_failures=True)\n </s> add         def hfunc2d(values: ArrayLike) -> ArrayLike:\n            values = self._prep_values(values)\n            return homogeneous_func(values)\n\n        if isinstance(mgr, ArrayManager) and self.axis == 1:\n            new_mgr = mgr.apply_2d(hfunc2d, ignore_failures=True)\n        else:\n            new_mgr = mgr.apply(hfunc, ignore_failures=True) </s> remove @pytest.fixture(params=[0, 1, \"index\", \"columns\"], ids=lambda x: f\"axis {repr(x)}\")\n </s> add @pytest.fixture(params=[0, 1, \"index\", \"columns\"], ids=lambda x: f\"axis={repr(x)}\")", "html_url": "https://github.com/pandas-dev/pandas/commit/04a0b86a9f7b80d91a8cf5f09953459096b2137e", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             values = self._prep_values(getattr(bvalues, \"T\", bvalues))\n <mask>             res_values = homogeneous_func(values)\n <mask>             return getattr(res_values, \"T\", res_values)\n <mask> \n <mask>         new_mgr = mgr.apply(hfunc, ignore_failures=True)\n <mask>         out = obj._constructor(new_mgr)\n <mask> \n <mask>         if out.shape[1] == 0 and obj.shape[1] > 0:\n <mask>             raise DataError(\"No numeric types to aggregate\")\n <mask>         elif out.shape[1] == 0:\n </s> [ArrayManager] Fix window operations with axis=1 (#40251) </s> remove     expected = Series(\n        expData, index=days.rename(\"DateCol\")._with_freq(None), name=\"metric\"\n    )\n </s> add     index = days.rename(\"DateCol\")\n    if not using_array_manager:\n        # INFO(ArrayManager) preserves the frequence of the index\n        index = index._with_freq(None)\n    expected = Series(expData, index=index, name=\"metric\") </s> remove def test_rolling_window_as_string():\n </s> add def test_rolling_window_as_string(using_array_manager): </s> remove @pytest.fixture(params=[0, 1, \"index\", \"columns\"], ids=lambda x: f\"axis {repr(x)}\")\n </s> add @pytest.fixture(params=[0, 1, \"index\", \"columns\"], ids=lambda x: f\"axis={repr(x)}\") </s> add from pandas.core.internals import ArrayManager", "html_url": "https://github.com/pandas-dev/pandas/commit/04a0b86a9f7b80d91a8cf5f09953459096b2137e", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     )\n <mask>     tm.assert_frame_equal(result, expected)\n <mask> \n <mask> \n <mask> def test_rolling_window_as_string():\n <mask>     # see gh-22590\n <mask>     date_today = datetime.now()\n <mask>     days = date_range(date_today, date_today + timedelta(365), freq=\"D\")\n <mask> \n <mask>     npr = np.random.RandomState(seed=421)\n </s> [ArrayManager] Fix window operations with axis=1 (#40251) </s> remove     expected = Series(\n        expData, index=days.rename(\"DateCol\")._with_freq(None), name=\"metric\"\n    )\n </s> add     index = days.rename(\"DateCol\")\n    if not using_array_manager:\n        # INFO(ArrayManager) preserves the frequence of the index\n        index = index._with_freq(None)\n    expected = Series(expData, index=index, name=\"metric\") </s> remove         new_mgr = mgr.apply(hfunc, ignore_failures=True)\n </s> add         def hfunc2d(values: ArrayLike) -> ArrayLike:\n            values = self._prep_values(values)\n            return homogeneous_func(values)\n\n        if isinstance(mgr, ArrayManager) and self.axis == 1:\n            new_mgr = mgr.apply_2d(hfunc2d, ignore_failures=True)\n        else:\n            new_mgr = mgr.apply(hfunc, ignore_failures=True) </s> remove @pytest.fixture(params=[0, 1, \"index\", \"columns\"], ids=lambda x: f\"axis {repr(x)}\")\n </s> add @pytest.fixture(params=[0, 1, \"index\", \"columns\"], ids=lambda x: f\"axis={repr(x)}\") </s> add from pandas.core.internals import ArrayManager", "html_url": "https://github.com/pandas-dev/pandas/commit/04a0b86a9f7b80d91a8cf5f09953459096b2137e", "file_name": "pandas/tests/window/test_rolling.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         + [93.0] * 3\n <mask>         + [95.0] * 20\n <mask>     )\n <mask> \n <mask>     expected = Series(\n <mask>         expData, index=days.rename(\"DateCol\")._with_freq(None), name=\"metric\"\n <mask>     )\n <mask>     tm.assert_series_equal(result, expected)\n <mask> \n <mask> \n <mask> def test_min_periods1():\n <mask>     # GH#6795\n </s> [ArrayManager] Fix window operations with axis=1 (#40251) </s> remove def test_rolling_window_as_string():\n </s> add def test_rolling_window_as_string(using_array_manager): </s> add from pandas.core.internals import ArrayManager </s> remove @pytest.fixture(params=[0, 1, \"index\", \"columns\"], ids=lambda x: f\"axis {repr(x)}\")\n </s> add @pytest.fixture(params=[0, 1, \"index\", \"columns\"], ids=lambda x: f\"axis={repr(x)}\") </s> remove         new_mgr = mgr.apply(hfunc, ignore_failures=True)\n </s> add         def hfunc2d(values: ArrayLike) -> ArrayLike:\n            values = self._prep_values(values)\n            return homogeneous_func(values)\n\n        if isinstance(mgr, ArrayManager) and self.axis == 1:\n            new_mgr = mgr.apply_2d(hfunc2d, ignore_failures=True)\n        else:\n            new_mgr = mgr.apply(hfunc, ignore_failures=True)", "html_url": "https://github.com/pandas-dev/pandas/commit/04a0b86a9f7b80d91a8cf5f09953459096b2137e", "file_name": "pandas/tests/window/test_rolling.py"}
{"docstring_tokens": "keep keep keep replace keep replace replace replace replace keep keep", "code_tokens": " <mask>    s3\n <mask>    s3.str.replace(\"^.a|dog\", \"XX-XX \", case=False, regex=True)\n <mask> \n <mask> .. warning::\n <mask> \n <mask>     Some caution must be taken when dealing with regular expressions! The current behavior\n <mask>     is to treat single character patterns as literal strings, even when ``regex`` is set\n <mask>     to ``True``. This behavior is deprecated and will be removed in a future version so\n <mask>     that the ``regex`` keyword is always respected.\n <mask> \n <mask> .. versionchanged:: 1.2.0\n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove .. versionchanged:: 1.2.0\n </s> add    s4 = pd.Series([\"a.b\", \".\", \"b\", np.nan, \"\"], dtype=\"string\")\n   s4\n   s4.str.replace(\".\", \"a\", regex=True) </s> remove @pytest.mark.parametrize(\"regex\", [True, False, None])\n </s> add @pytest.mark.parametrize(\"regex\", [True, False]) </s> remove     # https://github.com/pandas-dev/pandas/pull/24809\n\n    # The current behavior is to treat single character patterns as literal strings,\n    # even when ``regex`` is set to ``True``.\n\n </s> add     # https://github.com/pandas-dev/pandas/pull/24809, enforced in 2.0\n    # GH 24804 </s> remove         # The current behavior is to treat single character patterns as literal strings,\n        # even when ``regex`` is set to ``True``.\n        if isinstance(pat, str) and len(pat) == 1:\n            regex = False\n\n        if regex is None:\n            regex = True\n\n </s> add  </s> add - Change the default argument of ``regex`` for :meth:`Series.str.replace` from ``True`` to ``False``. Additionally, a single character ``pat`` with ``regex=True`` is now treated as a regular expression instead of a string literal. (:issue:`36695`, :issue:`24804`)", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "doc/source/user_guide/text.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     is to treat single character patterns as literal strings, even when ``regex`` is set\n <mask>     to ``True``. This behavior is deprecated and will be removed in a future version so\n <mask>     that the ``regex`` keyword is always respected.\n <mask> \n <mask> .. versionchanged:: 1.2.0\n <mask> \n <mask> If you want literal replacement of a string (equivalent to :meth:`str.replace`), you\n <mask> can set the optional ``regex`` parameter to ``False``, rather than escaping each\n <mask> character. In this case both ``pat`` and ``repl`` must be strings:\n <mask> \n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove     Some caution must be taken when dealing with regular expressions! The current behavior\n    is to treat single character patterns as literal strings, even when ``regex`` is set\n    to ``True``. This behavior is deprecated and will be removed in a future version so\n    that the ``regex`` keyword is always respected.\n </s> add .. versionchanged:: 2.0\n\nSingle character pattern with ``regex=True`` will also be treated as regular expressions:\n\n.. ipython:: python </s> remove .. warning::\n </s> add  </s> remove         # The current behavior is to treat single character patterns as literal strings,\n        # even when ``regex`` is set to ``True``.\n        if isinstance(pat, str) and len(pat) == 1:\n            regex = False\n\n        if regex is None:\n            regex = True\n\n </s> add  </s> add - Change the default argument of ``regex`` for :meth:`Series.str.replace` from ``True`` to ``False``. Additionally, a single character ``pat`` with ``regex=True`` is now treated as a regular expression instead of a string literal. (:issue:`36695`, :issue:`24804`) </s> remove     # https://github.com/pandas-dev/pandas/pull/24809\n\n    # The current behavior is to treat single character patterns as literal strings,\n    # even when ``regex`` is set to ``True``.\n\n </s> add     # https://github.com/pandas-dev/pandas/pull/24809, enforced in 2.0\n    # GH 24804 </s> remove @pytest.mark.parametrize(\"regex\", [True, False, None])\n </s> add @pytest.mark.parametrize(\"regex\", [True, False])", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "doc/source/user_guide/text.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> - Changed behavior of :class:`Timestamp` constructor with a ``np.datetime64`` object and a ``tz`` passed to interpret the input as a wall-time as opposed to a UTC time (:issue:`42288`)\n <mask> - Changed behavior of :class:`Index` constructor when passed a ``SparseArray`` or ``SparseDtype`` to retain that dtype instead of casting to ``numpy.ndarray`` (:issue:`43930`)\n <mask> - Changed behavior of :class:`Index`, :class:`Series`, :class:`DataFrame` constructors with floating-dtype data and a :class:`DatetimeTZDtype`, the data are now interpreted as UTC-times instead of wall-times, consistent with how integer-dtype data are treated (:issue:`45573`)\n <mask> - Removed the deprecated ``base`` and ``loffset`` arguments from :meth:`pandas.DataFrame.resample`, :meth:`pandas.Series.resample` and :class:`pandas.Grouper`. Use ``offset`` or ``origin`` instead (:issue:`31809`)\n <mask> - Changed behavior of :meth:`DataFrame.any` and :meth:`DataFrame.all` with ``bool_only=True``; object-dtype columns with all-bool values will no longer be included, manually cast to ``bool`` dtype first (:issue:`46188`)\n <mask> - Changed behavior of comparison of a :class:`Timestamp` with a ``datetime.date`` object; these now compare as un-equal and raise on inequality comparisons, matching the ``datetime.datetime`` behavior (:issue:`36131`)\n <mask> - Enforced deprecation of silently dropping columns that raised a ``TypeError`` in :class:`Series.transform` and :class:`DataFrame.transform` when used with a list or dictionary (:issue:`43740`)\n <mask> - Change behavior of :meth:`DataFrame.apply` with list-like so that any partial failure will raise an error (:issue:`43740`)\n <mask> \n <mask> .. ---------------------------------------------------------------------------\n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove             .. versionadded:: 0.23.0\n\n </s> add  </s> remove         regex : bool, default True\n </s> add         regex : bool, default False </s> remove     Some caution must be taken when dealing with regular expressions! The current behavior\n    is to treat single character patterns as literal strings, even when ``regex`` is set\n    to ``True``. This behavior is deprecated and will be removed in a future version so\n    that the ``regex`` keyword is always respected.\n </s> add .. versionchanged:: 2.0\n\nSingle character pattern with ``regex=True`` will also be treated as regular expressions:\n\n.. ipython:: python </s> remove .. warning::\n </s> add  </s> remove .. versionchanged:: 1.2.0\n </s> add    s4 = pd.Series([\"a.b\", \".\", \"b\", np.nan, \"\"], dtype=\"string\")\n   s4\n   s4.str.replace(\".\", \"a\", regex=True) </s> remove         if regex is None:\n            if isinstance(pat, str) and any(c in pat for c in \".+*|^$?[](){}\\\\\"):\n                # warn only in cases where regex behavior would differ from literal\n                msg = (\n                    \"The default value of regex will change from True to False \"\n                    \"in a future version.\"\n                )\n                if len(pat) == 1:\n                    msg += (\n                        \" In addition, single character regular expressions will \"\n                        \"*not* be treated as literal strings when regex=True.\"\n                    )\n                warnings.warn(msg, FutureWarning, stacklevel=find_stack_level())\n\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "doc/source/whatsnew/v2.0.0.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         repl: str | Callable,\n <mask>         n: int = -1,\n <mask>         case: bool | None = None,\n <mask>         flags: int = 0,\n <mask>         regex: bool | None = None,\n <mask>     ):\n <mask>         r\"\"\"\n <mask>         Replace each occurrence of pattern/regex in the Series/Index.\n <mask> \n <mask>         Equivalent to :meth:`str.replace` or :func:`re.sub`, depending on\n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove     if regex is None:\n        msg = re.escape(\n            \"The default value of regex will change from True to False in a future \"\n            \"version. In addition, single character regular expressions will *not* \"\n            \"be treated as literal strings when regex=True.\"\n        )\n        with tm.assert_produces_warning(\n            FutureWarning,\n            match=msg,\n        ):\n            result = s.str.replace(\".\", \"a\", regex=regex)\n </s> add     result = s.str.replace(\".\", \"a\", regex=regex)\n    if regex:\n        expected = Series([\"aaa\", \"a\", \"a\", np.nan, \"\"], dtype=any_string_dtype) </s> remove     msg = (\n        \"The default value of regex will change from True to False in a \"\n        \"future version\\\\.$\"\n    )\n\n    with tm.assert_produces_warning(\n        FutureWarning,\n        match=msg,\n        raise_on_extra_warnings=any_string_dtype != \"string[pyarrow]\",\n    ):\n        result = s.str.replace(\"^.$\", \"a\")\n </s> add     result = s.str.replace(\"^.$\", \"a\", regex=True) </s> remove         result = ser.str.replace(pat, \", \")\n </s> add         result = ser.str.replace(pat, \", \", regex=True) </s> remove         result = ser.str.replace(pat, repl, n=2)\n </s> add         result = ser.str.replace(pat, repl, n=2, regex=True) </s> remove .. versionchanged:: 1.2.0\n </s> add    s4 = pd.Series([\"a.b\", \".\", \"b\", np.nan, \"\"], dtype=\"string\")\n   s4\n   s4.str.replace(\".\", \"a\", regex=True) </s> remove         result = s.str.replace(\".\", \"a\", regex=regex)\n\n    expected = Series([\"aab\", \"a\", \"b\", np.nan, \"\"], dtype=any_string_dtype)\n </s> add         expected = Series([\"aab\", \"a\", \"b\", np.nan, \"\"], dtype=any_string_dtype)", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/core/strings/accessor.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         flags : int, default 0 (no flags)\n <mask>             Regex module flags, e.g. re.IGNORECASE. Cannot be set if `pat` is a compiled\n <mask>             regex.\n <mask>         regex : bool, default True\n <mask>             Determines if the passed-in pattern is a regular expression:\n <mask> \n <mask>             - If True, assumes the passed-in pattern is a regular expression.\n <mask>             - If False, treats the pattern as a literal string\n <mask>             - Cannot be set to False if `pat` is a compiled regex or `repl` is\n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove             .. versionadded:: 0.23.0\n\n </s> add  </s> add - Change the default argument of ``regex`` for :meth:`Series.str.replace` from ``True`` to ``False``. Additionally, a single character ``pat`` with ``regex=True`` is now treated as a regular expression instead of a string literal. (:issue:`36695`, :issue:`24804`) </s> remove     Some caution must be taken when dealing with regular expressions! The current behavior\n    is to treat single character patterns as literal strings, even when ``regex`` is set\n    to ``True``. This behavior is deprecated and will be removed in a future version so\n    that the ``regex`` keyword is always respected.\n </s> add .. versionchanged:: 2.0\n\nSingle character pattern with ``regex=True`` will also be treated as regular expressions:\n\n.. ipython:: python </s> remove         if regex is None:\n            if isinstance(pat, str) and any(c in pat for c in \".+*|^$?[](){}\\\\\"):\n                # warn only in cases where regex behavior would differ from literal\n                msg = (\n                    \"The default value of regex will change from True to False \"\n                    \"in a future version.\"\n                )\n                if len(pat) == 1:\n                    msg += (\n                        \" In addition, single character regular expressions will \"\n                        \"*not* be treated as literal strings when regex=True.\"\n                    )\n                warnings.warn(msg, FutureWarning, stacklevel=find_stack_level())\n\n </s> add  </s> remove .. versionchanged:: 1.2.0\n </s> add    s4 = pd.Series([\"a.b\", \".\", \"b\", np.nan, \"\"], dtype=\"string\")\n   s4\n   s4.str.replace(\".\", \"a\", regex=True) </s> remove         # The current behavior is to treat single character patterns as literal strings,\n        # even when ``regex`` is set to ``True``.\n        if isinstance(pat, str) and len(pat) == 1:\n            regex = False\n\n        if regex is None:\n            regex = True\n\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/core/strings/accessor.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             - If False, treats the pattern as a literal string\n <mask>             - Cannot be set to False if `pat` is a compiled regex or `repl` is\n <mask>               a callable.\n <mask> \n <mask>             .. versionadded:: 0.23.0\n <mask> \n <mask>         Returns\n <mask>         -------\n <mask>         Series or Index of object\n <mask>             A copy of the object with all matching occurrences of `pat` replaced by\n <mask>             `repl`.\n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove         regex : bool, default True\n </s> add         regex : bool, default False </s> add - Change the default argument of ``regex`` for :meth:`Series.str.replace` from ``True`` to ``False``. Additionally, a single character ``pat`` with ``regex=True`` is now treated as a regular expression instead of a string literal. (:issue:`36695`, :issue:`24804`) </s> remove     Some caution must be taken when dealing with regular expressions! The current behavior\n    is to treat single character patterns as literal strings, even when ``regex`` is set\n    to ``True``. This behavior is deprecated and will be removed in a future version so\n    that the ``regex`` keyword is always respected.\n </s> add .. versionchanged:: 2.0\n\nSingle character pattern with ``regex=True`` will also be treated as regular expressions:\n\n.. ipython:: python </s> remove         if regex is None:\n            if isinstance(pat, str) and any(c in pat for c in \".+*|^$?[](){}\\\\\"):\n                # warn only in cases where regex behavior would differ from literal\n                msg = (\n                    \"The default value of regex will change from True to False \"\n                    \"in a future version.\"\n                )\n                if len(pat) == 1:\n                    msg += (\n                        \" In addition, single character regular expressions will \"\n                        \"*not* be treated as literal strings when regex=True.\"\n                    )\n                warnings.warn(msg, FutureWarning, stacklevel=find_stack_level())\n\n </s> add  </s> remove .. versionchanged:: 1.2.0\n </s> add    s4 = pd.Series([\"a.b\", \".\", \"b\", np.nan, \"\"], dtype=\"string\")\n   s4\n   s4.str.replace(\".\", \"a\", regex=True) </s> remove .. warning::\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/core/strings/accessor.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         1    bar\n <mask>         2    NaN\n <mask>         dtype: object\n <mask>         \"\"\"\n <mask>         if regex is None:\n <mask>             if isinstance(pat, str) and any(c in pat for c in \".+*|^$?[](){}\\\\\"):\n <mask>                 # warn only in cases where regex behavior would differ from literal\n <mask>                 msg = (\n <mask>                     \"The default value of regex will change from True to False \"\n <mask>                     \"in a future version.\"\n <mask>                 )\n <mask>                 if len(pat) == 1:\n <mask>                     msg += (\n <mask>                         \" In addition, single character regular expressions will \"\n <mask>                         \"*not* be treated as literal strings when regex=True.\"\n <mask>                     )\n <mask>                 warnings.warn(msg, FutureWarning, stacklevel=find_stack_level())\n <mask> \n <mask>         # Check whether repl is valid (GH 13438, GH 15055)\n <mask>         if not (isinstance(repl, str) or callable(repl)):\n <mask>             raise TypeError(\"repl must be a string or callable\")\n <mask> \n <mask>         is_compiled_re = is_re(pat)\n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove     if regex is None:\n        msg = re.escape(\n            \"The default value of regex will change from True to False in a future \"\n            \"version. In addition, single character regular expressions will *not* \"\n            \"be treated as literal strings when regex=True.\"\n        )\n        with tm.assert_produces_warning(\n            FutureWarning,\n            match=msg,\n        ):\n            result = s.str.replace(\".\", \"a\", regex=regex)\n </s> add     result = s.str.replace(\".\", \"a\", regex=regex)\n    if regex:\n        expected = Series([\"aaa\", \"a\", \"a\", np.nan, \"\"], dtype=any_string_dtype) </s> remove         # The current behavior is to treat single character patterns as literal strings,\n        # even when ``regex`` is set to ``True``.\n        if isinstance(pat, str) and len(pat) == 1:\n            regex = False\n\n        if regex is None:\n            regex = True\n\n </s> add  </s> remove     # https://github.com/pandas-dev/pandas/pull/24809\n\n    # The current behavior is to treat single character patterns as literal strings,\n    # even when ``regex`` is set to ``True``.\n\n </s> add     # https://github.com/pandas-dev/pandas/pull/24809, enforced in 2.0\n    # GH 24804 </s> remove     msg = (\n        \"The default value of regex will change from True to False in a \"\n        \"future version\\\\.$\"\n    )\n\n    with tm.assert_produces_warning(\n        FutureWarning,\n        match=msg,\n        raise_on_extra_warnings=any_string_dtype != \"string[pyarrow]\",\n    ):\n        result = s.str.replace(\"^.$\", \"a\")\n </s> add     result = s.str.replace(\"^.$\", \"a\", regex=True) </s> remove def test_replace_regex_default_warning(any_string_dtype):\n </s> add def test_replace_regex(any_string_dtype): </s> remove         regex : bool, default True\n </s> add         regex : bool, default False", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/core/strings/accessor.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             )\n <mask>         elif callable(repl):\n <mask>             raise ValueError(\"Cannot use a callable replacement when regex=False\")\n <mask> \n <mask>         # The current behavior is to treat single character patterns as literal strings,\n <mask>         # even when ``regex`` is set to ``True``.\n <mask>         if isinstance(pat, str) and len(pat) == 1:\n <mask>             regex = False\n <mask> \n <mask>         if regex is None:\n <mask>             regex = True\n <mask> \n <mask>         if case is None:\n <mask>             case = True\n <mask> \n <mask>         result = self._data.array._str_replace(\n <mask>             pat, repl, n=n, case=case, flags=flags, regex=regex\n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove         if regex is None:\n            if isinstance(pat, str) and any(c in pat for c in \".+*|^$?[](){}\\\\\"):\n                # warn only in cases where regex behavior would differ from literal\n                msg = (\n                    \"The default value of regex will change from True to False \"\n                    \"in a future version.\"\n                )\n                if len(pat) == 1:\n                    msg += (\n                        \" In addition, single character regular expressions will \"\n                        \"*not* be treated as literal strings when regex=True.\"\n                    )\n                warnings.warn(msg, FutureWarning, stacklevel=find_stack_level())\n\n </s> add  </s> remove     # https://github.com/pandas-dev/pandas/pull/24809\n\n    # The current behavior is to treat single character patterns as literal strings,\n    # even when ``regex`` is set to ``True``.\n\n </s> add     # https://github.com/pandas-dev/pandas/pull/24809, enforced in 2.0\n    # GH 24804 </s> remove     if regex is None:\n        msg = re.escape(\n            \"The default value of regex will change from True to False in a future \"\n            \"version. In addition, single character regular expressions will *not* \"\n            \"be treated as literal strings when regex=True.\"\n        )\n        with tm.assert_produces_warning(\n            FutureWarning,\n            match=msg,\n        ):\n            result = s.str.replace(\".\", \"a\", regex=regex)\n </s> add     result = s.str.replace(\".\", \"a\", regex=regex)\n    if regex:\n        expected = Series([\"aaa\", \"a\", \"a\", np.nan, \"\"], dtype=any_string_dtype) </s> remove @pytest.mark.parametrize(\"regex\", [True, False, None])\n </s> add @pytest.mark.parametrize(\"regex\", [True, False]) </s> remove .. versionchanged:: 1.2.0\n </s> add    s4 = pd.Series([\"a.b\", \".\", \"b\", np.nan, \"\"], dtype=\"string\")\n   s4\n   s4.str.replace(\".\", \"a\", regex=True) </s> remove .. warning::\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/core/strings/accessor.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     with pytest.raises(TypeError, match=msg):\n <mask>         with tm.maybe_produces_warning(\n <mask>             PerformanceWarning, any_string_dtype == \"string[pyarrow]\"\n <mask>         ):\n <mask>             values.str.replace(\"a\", repl)\n <mask> \n <mask> \n <mask> def test_replace_callable_named_groups(any_string_dtype):\n <mask>     # test regex named groups\n <mask>     ser = Series([\"Foo Bar Baz\", np.nan], dtype=any_string_dtype)\n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove         result = ser.str.replace(pat, repl, n=2)\n </s> add         result = ser.str.replace(pat, repl, n=2, regex=True) </s> remove         ser.str.replace(pat, \"\", case=True)\n </s> add         ser.str.replace(pat, \"\", case=True, regex=True) </s> remove         result = ser.str.replace(pat, \", \")\n </s> add         result = ser.str.replace(pat, \", \", regex=True) </s> remove         ser.str.replace(pat, \"\", flags=re.IGNORECASE)\n </s> add         ser.str.replace(pat, \"\", flags=re.IGNORECASE, regex=True) </s> remove def test_replace_regex_default_warning(any_string_dtype):\n </s> add def test_replace_regex(any_string_dtype): </s> remove         ser.str.replace(pat, \"\", case=False)\n </s> add         ser.str.replace(pat, \"\", case=False, regex=True)", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     pat = re.compile(r\"(?<=\\w),(?=\\w)\", flags=re.UNICODE)\n <mask>     with tm.maybe_produces_warning(\n <mask>         PerformanceWarning, any_string_dtype == \"string[pyarrow]\"\n <mask>     ):\n <mask>         result = ser.str.replace(pat, \", \")\n <mask>     tm.assert_series_equal(result, expected)\n <mask> \n <mask> \n <mask> def test_replace_compiled_regex_raises(any_string_dtype):\n <mask>     # case and flags provided to str.replace will have no effect\n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove         result = ser.str.replace(pat, repl, n=2)\n </s> add         result = ser.str.replace(pat, repl, n=2, regex=True) </s> remove             values.str.replace(\"a\", repl)\n </s> add             values.str.replace(\"a\", repl, regex=True) </s> remove         ser.str.replace(pat, \"\", flags=re.IGNORECASE)\n </s> add         ser.str.replace(pat, \"\", flags=re.IGNORECASE, regex=True) </s> remove         # The current behavior is to treat single character patterns as literal strings,\n        # even when ``regex`` is set to ``True``.\n        if isinstance(pat, str) and len(pat) == 1:\n            regex = False\n\n        if regex is None:\n            regex = True\n\n </s> add  </s> remove     msg = (\n        \"The default value of regex will change from True to False in a \"\n        \"future version\\\\.$\"\n    )\n\n    with tm.assert_produces_warning(\n        FutureWarning,\n        match=msg,\n        raise_on_extra_warnings=any_string_dtype != \"string[pyarrow]\",\n    ):\n        result = s.str.replace(\"^.$\", \"a\")\n </s> add     result = s.str.replace(\"^.$\", \"a\", regex=True) </s> remove         result = s.str.replace(\".\", \"a\", regex=regex)\n\n    expected = Series([\"aab\", \"a\", \"b\", np.nan, \"\"], dtype=any_string_dtype)\n </s> add         expected = Series([\"aab\", \"a\", \"b\", np.nan, \"\"], dtype=any_string_dtype)", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask>     msg = \"case and flags cannot be set when pat is a compiled regex\"\n <mask> \n <mask>     with pytest.raises(ValueError, match=msg):\n <mask>         ser.str.replace(pat, \"\", flags=re.IGNORECASE)\n <mask> \n <mask>     with pytest.raises(ValueError, match=msg):\n <mask>         ser.str.replace(pat, \"\", case=False)\n <mask> \n <mask>     with pytest.raises(ValueError, match=msg):\n <mask>         ser.str.replace(pat, \"\", flags=re.IGNORECASE)\n <mask> \n <mask>     with pytest.raises(ValueError, match=msg):\n <mask>         ser.str.replace(pat, \"\", case=False)\n <mask> \n <mask>     with pytest.raises(ValueError, match=msg):\n <mask>         ser.str.replace(pat, \"\", case=True)\n <mask> \n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove         ser.str.replace(pat, \"\", case=True)\n </s> add         ser.str.replace(pat, \"\", case=True, regex=True) </s> remove         result = ser.str.replace(pat, \", \")\n </s> add         result = ser.str.replace(pat, \", \", regex=True) </s> remove         result = ser.str.replace(pat, repl, n=2)\n </s> add         result = ser.str.replace(pat, repl, n=2, regex=True) </s> remove             values.str.replace(\"a\", repl)\n </s> add             values.str.replace(\"a\", repl, regex=True) </s> remove             .. versionadded:: 0.23.0\n\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     with pytest.raises(ValueError, match=msg):\n <mask>         ser.str.replace(pat, \"\", case=False)\n <mask> \n <mask>     with pytest.raises(ValueError, match=msg):\n <mask>         ser.str.replace(pat, \"\", case=True)\n <mask> \n <mask> \n <mask> def test_replace_compiled_regex_callable(any_string_dtype):\n <mask>     # test with callable\n <mask>     ser = Series([\"fooBAD__barBAD\", np.nan], dtype=any_string_dtype)\n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove         ser.str.replace(pat, \"\", case=False)\n </s> add         ser.str.replace(pat, \"\", case=False, regex=True) </s> remove         ser.str.replace(pat, \"\", flags=re.IGNORECASE)\n </s> add         ser.str.replace(pat, \"\", flags=re.IGNORECASE, regex=True) </s> remove             values.str.replace(\"a\", repl)\n </s> add             values.str.replace(\"a\", repl, regex=True) </s> remove         result = ser.str.replace(pat, repl, n=2)\n </s> add         result = ser.str.replace(pat, repl, n=2, regex=True) </s> remove         result = ser.str.replace(pat, \", \")\n </s> add         result = ser.str.replace(pat, \", \", regex=True) </s> remove def test_replace_regex_default_warning(any_string_dtype):\n </s> add def test_replace_regex(any_string_dtype):", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     pat = re.compile(\"[a-z][A-Z]{2}\")\n <mask>     with tm.maybe_produces_warning(\n <mask>         PerformanceWarning, any_string_dtype == \"string[pyarrow]\"\n <mask>     ):\n <mask>         result = ser.str.replace(pat, repl, n=2)\n <mask>     expected = Series([\"foObaD__baRbaD\", np.nan], dtype=any_string_dtype)\n <mask>     tm.assert_series_equal(result, expected)\n <mask> \n <mask> \n <mask> @pytest.mark.parametrize(\n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove         result = ser.str.replace(pat, \", \")\n </s> add         result = ser.str.replace(pat, \", \", regex=True) </s> remove             values.str.replace(\"a\", repl)\n </s> add             values.str.replace(\"a\", repl, regex=True) </s> remove         result = s.str.replace(\".\", \"a\", regex=regex)\n\n    expected = Series([\"aab\", \"a\", \"b\", np.nan, \"\"], dtype=any_string_dtype)\n </s> add         expected = Series([\"aab\", \"a\", \"b\", np.nan, \"\"], dtype=any_string_dtype) </s> remove     msg = (\n        \"The default value of regex will change from True to False in a \"\n        \"future version\\\\.$\"\n    )\n\n    with tm.assert_produces_warning(\n        FutureWarning,\n        match=msg,\n        raise_on_extra_warnings=any_string_dtype != \"string[pyarrow]\",\n    ):\n        result = s.str.replace(\"^.$\", \"a\")\n </s> add     result = s.str.replace(\"^.$\", \"a\", regex=True) </s> remove     if regex is None:\n        msg = re.escape(\n            \"The default value of regex will change from True to False in a future \"\n            \"version. In addition, single character regular expressions will *not* \"\n            \"be treated as literal strings when regex=True.\"\n        )\n        with tm.assert_produces_warning(\n            FutureWarning,\n            match=msg,\n        ):\n            result = s.str.replace(\".\", \"a\", regex=regex)\n </s> add     result = s.str.replace(\".\", \"a\", regex=regex)\n    if regex:\n        expected = Series([\"aaa\", \"a\", \"a\", np.nan, \"\"], dtype=any_string_dtype) </s> remove         ser.str.replace(pat, \"\", case=True)\n </s> add         ser.str.replace(pat, \"\", case=True, regex=True)", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep replace keep keep replace replace replace replace replace replace replace replace replace replace replace keep keep", "code_tokens": " <mask> \n <mask> def test_replace_regex_default_warning(any_string_dtype):\n <mask>     # https://github.com/pandas-dev/pandas/pull/24809\n <mask>     s = Series([\"a\", \"b\", \"ac\", np.nan, \"\"], dtype=any_string_dtype)\n <mask>     msg = (\n <mask>         \"The default value of regex will change from True to False in a \"\n <mask>         \"future version\\\\.$\"\n <mask>     )\n <mask> \n <mask>     with tm.assert_produces_warning(\n <mask>         FutureWarning,\n <mask>         match=msg,\n <mask>         raise_on_extra_warnings=any_string_dtype != \"string[pyarrow]\",\n <mask>     ):\n <mask>         result = s.str.replace(\"^.$\", \"a\")\n <mask>     expected = Series([\"a\", \"a\", \"ac\", np.nan, \"\"], dtype=any_string_dtype)\n <mask>     tm.assert_series_equal(result, expected)\n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove     if regex is None:\n        msg = re.escape(\n            \"The default value of regex will change from True to False in a future \"\n            \"version. In addition, single character regular expressions will *not* \"\n            \"be treated as literal strings when regex=True.\"\n        )\n        with tm.assert_produces_warning(\n            FutureWarning,\n            match=msg,\n        ):\n            result = s.str.replace(\".\", \"a\", regex=regex)\n </s> add     result = s.str.replace(\".\", \"a\", regex=regex)\n    if regex:\n        expected = Series([\"aaa\", \"a\", \"a\", np.nan, \"\"], dtype=any_string_dtype) </s> remove @pytest.mark.parametrize(\"regex\", [True, False, None])\n </s> add @pytest.mark.parametrize(\"regex\", [True, False]) </s> remove         result = s.str.replace(\".\", \"a\", regex=regex)\n\n    expected = Series([\"aab\", \"a\", \"b\", np.nan, \"\"], dtype=any_string_dtype)\n </s> add         expected = Series([\"aab\", \"a\", \"b\", np.nan, \"\"], dtype=any_string_dtype) </s> remove     # https://github.com/pandas-dev/pandas/pull/24809\n\n    # The current behavior is to treat single character patterns as literal strings,\n    # even when ``regex`` is set to ``True``.\n\n </s> add     # https://github.com/pandas-dev/pandas/pull/24809, enforced in 2.0\n    # GH 24804 </s> remove         if regex is None:\n            if isinstance(pat, str) and any(c in pat for c in \".+*|^$?[](){}\\\\\"):\n                # warn only in cases where regex behavior would differ from literal\n                msg = (\n                    \"The default value of regex will change from True to False \"\n                    \"in a future version.\"\n                )\n                if len(pat) == 1:\n                    msg += (\n                        \" In addition, single character regular expressions will \"\n                        \"*not* be treated as literal strings when regex=True.\"\n                    )\n                warnings.warn(msg, FutureWarning, stacklevel=find_stack_level())\n\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     expected = Series([\"a\", \"a\", \"ac\", np.nan, \"\"], dtype=any_string_dtype)\n <mask>     tm.assert_series_equal(result, expected)\n <mask> \n <mask> \n <mask> @pytest.mark.parametrize(\"regex\", [True, False, None])\n <mask> def test_replace_regex_single_character(regex, any_string_dtype):\n <mask>     # https://github.com/pandas-dev/pandas/pull/24809\n <mask> \n <mask>     # The current behavior is to treat single character patterns as literal strings,\n <mask>     # even when ``regex`` is set to ``True``.\n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove     # https://github.com/pandas-dev/pandas/pull/24809\n\n    # The current behavior is to treat single character patterns as literal strings,\n    # even when ``regex`` is set to ``True``.\n\n </s> add     # https://github.com/pandas-dev/pandas/pull/24809, enforced in 2.0\n    # GH 24804 </s> remove     msg = (\n        \"The default value of regex will change from True to False in a \"\n        \"future version\\\\.$\"\n    )\n\n    with tm.assert_produces_warning(\n        FutureWarning,\n        match=msg,\n        raise_on_extra_warnings=any_string_dtype != \"string[pyarrow]\",\n    ):\n        result = s.str.replace(\"^.$\", \"a\")\n </s> add     result = s.str.replace(\"^.$\", \"a\", regex=True) </s> remove def test_replace_regex_default_warning(any_string_dtype):\n </s> add def test_replace_regex(any_string_dtype): </s> remove         # The current behavior is to treat single character patterns as literal strings,\n        # even when ``regex`` is set to ``True``.\n        if isinstance(pat, str) and len(pat) == 1:\n            regex = False\n\n        if regex is None:\n            regex = True\n\n </s> add  </s> remove     if regex is None:\n        msg = re.escape(\n            \"The default value of regex will change from True to False in a future \"\n            \"version. In addition, single character regular expressions will *not* \"\n            \"be treated as literal strings when regex=True.\"\n        )\n        with tm.assert_produces_warning(\n            FutureWarning,\n            match=msg,\n        ):\n            result = s.str.replace(\".\", \"a\", regex=regex)\n </s> add     result = s.str.replace(\".\", \"a\", regex=regex)\n    if regex:\n        expected = Series([\"aaa\", \"a\", \"a\", np.nan, \"\"], dtype=any_string_dtype) </s> remove .. warning::\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace keep keep replace replace replace replace replace replace replace replace replace replace replace", "code_tokens": " <mask> @pytest.mark.parametrize(\"regex\", [True, False, None])\n <mask> def test_replace_regex_single_character(regex, any_string_dtype):\n <mask>     # https://github.com/pandas-dev/pandas/pull/24809\n <mask> \n <mask>     # The current behavior is to treat single character patterns as literal strings,\n <mask>     # even when ``regex`` is set to ``True``.\n <mask> \n <mask>     s = Series([\"a.b\", \".\", \"b\", np.nan, \"\"], dtype=any_string_dtype)\n <mask> \n <mask>     if regex is None:\n <mask>         msg = re.escape(\n <mask>             \"The default value of regex will change from True to False in a future \"\n <mask>             \"version. In addition, single character regular expressions will *not* \"\n <mask>             \"be treated as literal strings when regex=True.\"\n <mask>         )\n <mask>         with tm.assert_produces_warning(\n <mask>             FutureWarning,\n <mask>             match=msg,\n <mask>         ):\n <mask>             result = s.str.replace(\".\", \"a\", regex=regex)\n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove @pytest.mark.parametrize(\"regex\", [True, False, None])\n </s> add @pytest.mark.parametrize(\"regex\", [True, False]) </s> remove     msg = (\n        \"The default value of regex will change from True to False in a \"\n        \"future version\\\\.$\"\n    )\n\n    with tm.assert_produces_warning(\n        FutureWarning,\n        match=msg,\n        raise_on_extra_warnings=any_string_dtype != \"string[pyarrow]\",\n    ):\n        result = s.str.replace(\"^.$\", \"a\")\n </s> add     result = s.str.replace(\"^.$\", \"a\", regex=True) </s> remove         if regex is None:\n            if isinstance(pat, str) and any(c in pat for c in \".+*|^$?[](){}\\\\\"):\n                # warn only in cases where regex behavior would differ from literal\n                msg = (\n                    \"The default value of regex will change from True to False \"\n                    \"in a future version.\"\n                )\n                if len(pat) == 1:\n                    msg += (\n                        \" In addition, single character regular expressions will \"\n                        \"*not* be treated as literal strings when regex=True.\"\n                    )\n                warnings.warn(msg, FutureWarning, stacklevel=find_stack_level())\n\n </s> add  </s> remove         # The current behavior is to treat single character patterns as literal strings,\n        # even when ``regex`` is set to ``True``.\n        if isinstance(pat, str) and len(pat) == 1:\n            regex = False\n\n        if regex is None:\n            regex = True\n\n </s> add  </s> remove def test_replace_regex_default_warning(any_string_dtype):\n </s> add def test_replace_regex(any_string_dtype):", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             match=msg,\n <mask>         ):\n <mask>             result = s.str.replace(\".\", \"a\", regex=regex)\n <mask>     else:\n <mask>         result = s.str.replace(\".\", \"a\", regex=regex)\n <mask> \n <mask>     expected = Series([\"aab\", \"a\", \"b\", np.nan, \"\"], dtype=any_string_dtype)\n <mask>     tm.assert_series_equal(result, expected)\n <mask> \n <mask> \n <mask> # --------------------------------------------------------------------------------------\n <mask> # str.match\n </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove     if regex is None:\n        msg = re.escape(\n            \"The default value of regex will change from True to False in a future \"\n            \"version. In addition, single character regular expressions will *not* \"\n            \"be treated as literal strings when regex=True.\"\n        )\n        with tm.assert_produces_warning(\n            FutureWarning,\n            match=msg,\n        ):\n            result = s.str.replace(\".\", \"a\", regex=regex)\n </s> add     result = s.str.replace(\".\", \"a\", regex=regex)\n    if regex:\n        expected = Series([\"aaa\", \"a\", \"a\", np.nan, \"\"], dtype=any_string_dtype) </s> remove     msg = (\n        \"The default value of regex will change from True to False in a \"\n        \"future version\\\\.$\"\n    )\n\n    with tm.assert_produces_warning(\n        FutureWarning,\n        match=msg,\n        raise_on_extra_warnings=any_string_dtype != \"string[pyarrow]\",\n    ):\n        result = s.str.replace(\"^.$\", \"a\")\n </s> add     result = s.str.replace(\"^.$\", \"a\", regex=True) </s> remove @pytest.mark.parametrize(\"regex\", [True, False, None])\n </s> add @pytest.mark.parametrize(\"regex\", [True, False]) </s> remove         result = ser.str.replace(pat, repl, n=2)\n </s> add         result = ser.str.replace(pat, repl, n=2, regex=True) </s> remove def test_replace_regex_default_warning(any_string_dtype):\n </s> add def test_replace_regex(any_string_dtype): </s> remove         result = ser.str.replace(pat, \", \")\n </s> add         result = ser.str.replace(pat, \", \", regex=True)", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     #----------------------------------------------------------------------\n <mask>     # Plotting\n <mask> \n <mask>     def plot(self, kind='line', subplots=False, sharex=True, sharey=False, use_index=True,\n <mask>              figsize=None, grid=True, legend=True, rot=30, ax=None, **kwds):\n <mask>         \"\"\"\n <mask>         Make line plot of DataFrame's series with the index on the x-axis using\n <mask>         matplotlib / pylab.\n <mask> \n <mask>         Parameters\n </s> ENH: refactoring/mpl tweaking post PR #348 </s> remove         plt.draw_if_interactive()\n </s> add         if N < 10:\n            fontsize = 12\n        else:\n            fontsize = 10\n\n        ax.set_xticks(xinds + 0.25)\n        ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n\n        if legend and not subplots:\n            fig = ax.get_figure()\n            fig.legend([r[0] for r in rects], labels, loc='upper center',\n                       fancybox=True, ncol=6, mode='expand')\n\n        import matplotlib.pyplot as plt\n        plt.subplots_adjust(top=0.8) </s> remove         if legend and not subplots:\n            if kind == 'line':\n                ax.legend(loc='best')\n </s> add         plt.draw_if_interactive()\n\n    def _bar_plot(self, axes, subplots=False, use_index=True, grid=True,\n                  rot=30, legend=True, **kwds):\n        N, K = self.shape\n        xinds = np.arange(N) + 0.25\n        colors = 'rgbyk'\n        rects = []\n        labels = []\n\n        if not subplots:\n            ax = axes[0]\n\n        for i, col in enumerate(_try_sort(self.columns)):\n            empty = self[col].count() == 0\n            y = self[col].values if not empty else np.zeros(len(self))\n            if subplots:\n                ax = axes[i]\n                ax.bar(xinds, y, 0.5,\n                       bottom=np.zeros(N), linewidth=1, **kwds)\n                ax.set_title(col) </s> remove                 ax.legend([r[0] for r in rects],labels,loc='best')\n </s> add                 rects.append(ax.bar(xinds + i * 0.5/K, y, 0.5/K,\n                                    bottom=np.zeros(N),\n                                    color=colors[i % len(colors)], **kwds))\n                labels.append(col) </s> add         kind : {'line', 'bar'} </s> remove             if N < 10:\n                fontsize = 12\n            else:\n                fontsize = 10\n\n            ax.set_xticks(xinds + 0.25)\n            ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n </s> add             if legend and not subplots:\n                ax.legend(loc='best')\n        elif kind == 'bar':\n            self._bar_plot(axes, subplots=subplots, grid=grid, rot=rot,\n                           legend=legend) </s> add     def test_plot_bar(self):\n        df = DataFrame(np.random.randn(6, 4),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=['one', 'two', 'three', 'four'])\n\n        _check_plot_works(df.plot, kind='bar')\n        _check_plot_works(df.plot, kind='bar', legend=False)\n        _check_plot_works(df.plot, kind='bar', subplots=True)\n\n        df = DataFrame(np.random.randn(6, 15),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=range(15))\n        _check_plot_works(df.plot, kind='bar')\n", "html_url": "https://github.com/pandas-dev/pandas/commit/0518b54bfc2bf6ae4a657183b65c714f4187609c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         sharey : boolean, default False\n <mask>             In case subplots=True, share y axis\n <mask>         use_index : boolean, default True\n <mask>             Use index as ticks for x axis\n <mask>         kwds : keywords\n <mask>             Options to pass to Axis.plot\n <mask> \n <mask>         Notes\n <mask>         -----\n <mask>         This method doesn't make much sense for cross-sections,\n </s> ENH: refactoring/mpl tweaking post PR #348 </s> remove             if N < 10:\n                fontsize = 12\n            else:\n                fontsize = 10\n\n            ax.set_xticks(xinds + 0.25)\n            ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n </s> add             if legend and not subplots:\n                ax.legend(loc='best')\n        elif kind == 'bar':\n            self._bar_plot(axes, subplots=subplots, grid=grid, rot=rot,\n                           legend=legend) </s> remove         if legend and not subplots:\n            if kind == 'line':\n                ax.legend(loc='best')\n </s> add         plt.draw_if_interactive()\n\n    def _bar_plot(self, axes, subplots=False, use_index=True, grid=True,\n                  rot=30, legend=True, **kwds):\n        N, K = self.shape\n        xinds = np.arange(N) + 0.25\n        colors = 'rgbyk'\n        rects = []\n        labels = []\n\n        if not subplots:\n            ax = axes[0]\n\n        for i, col in enumerate(_try_sort(self.columns)):\n            empty = self[col].count() == 0\n            y = self[col].values if not empty else np.zeros(len(self))\n            if subplots:\n                ax = axes[i]\n                ax.bar(xinds, y, 0.5,\n                       bottom=np.zeros(N), linewidth=1, **kwds)\n                ax.set_title(col) </s> remove         plt.draw_if_interactive()\n </s> add         if N < 10:\n            fontsize = 12\n        else:\n            fontsize = 10\n\n        ax.set_xticks(xinds + 0.25)\n        ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n\n        if legend and not subplots:\n            fig = ax.get_figure()\n            fig.legend([r[0] for r in rects], labels, loc='upper center',\n                       fancybox=True, ncol=6, mode='expand')\n\n        import matplotlib.pyplot as plt\n        plt.subplots_adjust(top=0.8) </s> add                 axes = [ax] </s> remove     def plot(self, kind='line', subplots=False, sharex=True, sharey=False, use_index=True,\n             figsize=None, grid=True, legend=True, rot=30, ax=None, **kwds):\n </s> add     def plot(self, subplots=False, sharex=True, sharey=False, use_index=True,\n             figsize=None, grid=True, legend=True, rot=30, ax=None,\n             kind='line', **kwds): </s> add     def test_plot_bar(self):\n        df = DataFrame(np.random.randn(6, 4),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=['one', 'two', 'three', 'four'])\n\n        _check_plot_works(df.plot, kind='bar')\n        _check_plot_works(df.plot, kind='bar', legend=False)\n        _check_plot_works(df.plot, kind='bar', subplots=True)\n\n        df = DataFrame(np.random.randn(6, 15),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=range(15))\n        _check_plot_works(df.plot, kind='bar')\n", "html_url": "https://github.com/pandas-dev/pandas/commit/0518b54bfc2bf6ae4a657183b65c714f4187609c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>                 fig = plt.figure(figsize=figsize)\n <mask>                 ax = fig.add_subplot(111)\n <mask>             else:\n <mask>                 fig = ax.get_figure()\n <mask> \n <mask>         if kind == 'line':\n <mask>             if use_index:\n <mask>                 x = self.index\n </s> ENH: refactoring/mpl tweaking post PR #348 </s> remove         plt.draw_if_interactive()\n </s> add         if N < 10:\n            fontsize = 12\n        else:\n            fontsize = 10\n\n        ax.set_xticks(xinds + 0.25)\n        ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n\n        if legend and not subplots:\n            fig = ax.get_figure()\n            fig.legend([r[0] for r in rects], labels, loc='upper center',\n                       fancybox=True, ncol=6, mode='expand')\n\n        import matplotlib.pyplot as plt\n        plt.subplots_adjust(top=0.8) </s> remove         if legend and not subplots:\n            if kind == 'line':\n                ax.legend(loc='best')\n </s> add         plt.draw_if_interactive()\n\n    def _bar_plot(self, axes, subplots=False, use_index=True, grid=True,\n                  rot=30, legend=True, **kwds):\n        N, K = self.shape\n        xinds = np.arange(N) + 0.25\n        colors = 'rgbyk'\n        rects = []\n        labels = []\n\n        if not subplots:\n            ax = axes[0]\n\n        for i, col in enumerate(_try_sort(self.columns)):\n            empty = self[col].count() == 0\n            y = self[col].values if not empty else np.zeros(len(self))\n            if subplots:\n                ax = axes[i]\n                ax.bar(xinds, y, 0.5,\n                       bottom=np.zeros(N), linewidth=1, **kwds)\n                ax.set_title(col) </s> remove         elif kind == 'bar':\n            N = len(self)\n            M = len(self.columns)\n            xinds = np.arange(N) + 0.25\n            colors = ['red', 'green', 'blue', 'yellow', 'black']\n            rects = []\n            labels = []\n            for i, col in enumerate(_try_sort(self.columns)):\n                empty = self[col].count() == 0\n                y = self[col].values if not empty else np.zeros(x.shape)\n                if subplots:\n                    ax = axes[i]\n                    ax.bar(xinds, y, 0.5,\n                           bottom=np.zeros(N), linewidth=1, **kwds)\n                    ax.set_title(col)\n                else:\n                    rects.append(ax.bar(xinds+i*0.5/M,y,0.5/M,bottom=np.zeros(N),color=colors[i % len(colors)], **kwds))\n                    labels.append(col)\n </s> add  </s> remove             if N < 10:\n                fontsize = 12\n            else:\n                fontsize = 10\n\n            ax.set_xticks(xinds + 0.25)\n            ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n </s> add             if legend and not subplots:\n                ax.legend(loc='best')\n        elif kind == 'bar':\n            self._bar_plot(axes, subplots=subplots, grid=grid, rot=rot,\n                           legend=legend) </s> remove                 ax.legend([r[0] for r in rects],labels,loc='best')\n </s> add                 rects.append(ax.bar(xinds + i * 0.5/K, y, 0.5/K,\n                                    bottom=np.zeros(N),\n                                    color=colors[i % len(colors)], **kwds))\n                labels.append(col) </s> add     def test_plot_bar(self):\n        df = DataFrame(np.random.randn(6, 4),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=['one', 'two', 'three', 'four'])\n\n        _check_plot_works(df.plot, kind='bar')\n        _check_plot_works(df.plot, kind='bar', legend=False)\n        _check_plot_works(df.plot, kind='bar', subplots=True)\n\n        df = DataFrame(np.random.randn(6, 15),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=range(15))\n        _check_plot_works(df.plot, kind='bar')\n", "html_url": "https://github.com/pandas-dev/pandas/commit/0518b54bfc2bf6ae4a657183b65c714f4187609c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep replace replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>                 else:\n <mask>                     ax.plot(x, y, label=str(col), **kwds)\n <mask> \n <mask>                 ax.grid(grid)\n <mask>         elif kind == 'bar':\n <mask>             N = len(self)\n <mask>             M = len(self.columns)\n <mask>             xinds = np.arange(N) + 0.25\n <mask>             colors = ['red', 'green', 'blue', 'yellow', 'black']\n <mask>             rects = []\n <mask>             labels = []\n <mask>             for i, col in enumerate(_try_sort(self.columns)):\n <mask>                 empty = self[col].count() == 0\n <mask>                 y = self[col].values if not empty else np.zeros(x.shape)\n <mask>                 if subplots:\n <mask>                     ax = axes[i]\n <mask>                     ax.bar(xinds, y, 0.5,\n <mask>                            bottom=np.zeros(N), linewidth=1, **kwds)\n <mask>                     ax.set_title(col)\n <mask>                 else:\n <mask>                     rects.append(ax.bar(xinds+i*0.5/M,y,0.5/M,bottom=np.zeros(N),color=colors[i % len(colors)], **kwds))\n <mask>                     labels.append(col)\n <mask> \n <mask>             if N < 10:\n <mask>                 fontsize = 12\n <mask>             else:\n <mask>                 fontsize = 10\n <mask> \n <mask>             ax.set_xticks(xinds + 0.25)\n <mask>             ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n <mask> \n <mask>         # try to make things prettier\n <mask>         try:\n </s> ENH: refactoring/mpl tweaking post PR #348 </s> remove         if legend and not subplots:\n            if kind == 'line':\n                ax.legend(loc='best')\n </s> add         plt.draw_if_interactive()\n\n    def _bar_plot(self, axes, subplots=False, use_index=True, grid=True,\n                  rot=30, legend=True, **kwds):\n        N, K = self.shape\n        xinds = np.arange(N) + 0.25\n        colors = 'rgbyk'\n        rects = []\n        labels = []\n\n        if not subplots:\n            ax = axes[0]\n\n        for i, col in enumerate(_try_sort(self.columns)):\n            empty = self[col].count() == 0\n            y = self[col].values if not empty else np.zeros(len(self))\n            if subplots:\n                ax = axes[i]\n                ax.bar(xinds, y, 0.5,\n                       bottom=np.zeros(N), linewidth=1, **kwds)\n                ax.set_title(col) </s> remove         plt.draw_if_interactive()\n </s> add         if N < 10:\n            fontsize = 12\n        else:\n            fontsize = 10\n\n        ax.set_xticks(xinds + 0.25)\n        ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n\n        if legend and not subplots:\n            fig = ax.get_figure()\n            fig.legend([r[0] for r in rects], labels, loc='upper center',\n                       fancybox=True, ncol=6, mode='expand')\n\n        import matplotlib.pyplot as plt\n        plt.subplots_adjust(top=0.8) </s> add                 axes = [ax] </s> remove                 ax.legend([r[0] for r in rects],labels,loc='best')\n </s> add                 rects.append(ax.bar(xinds + i * 0.5/K, y, 0.5/K,\n                                    bottom=np.zeros(N),\n                                    color=colors[i % len(colors)], **kwds))\n                labels.append(col) </s> add     def test_plot_bar(self):\n        df = DataFrame(np.random.randn(6, 4),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=['one', 'two', 'three', 'four'])\n\n        _check_plot_works(df.plot, kind='bar')\n        _check_plot_works(df.plot, kind='bar', legend=False)\n        _check_plot_works(df.plot, kind='bar', subplots=True)\n\n        df = DataFrame(np.random.randn(6, 15),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=range(15))\n        _check_plot_works(df.plot, kind='bar')\n", "html_url": "https://github.com/pandas-dev/pandas/commit/0518b54bfc2bf6ae4a657183b65c714f4187609c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep replace replace replace keep replace", "code_tokens": " <mask>             pass\n <mask> \n <mask>         if legend and not subplots:\n <mask>             if kind == 'line':\n <mask>                 ax.legend(loc='best')\n <mask>             else:\n <mask>                 ax.legend([r[0] for r in rects],labels,loc='best')\n </s> ENH: refactoring/mpl tweaking post PR #348 </s> remove         plt.draw_if_interactive()\n </s> add         if N < 10:\n            fontsize = 12\n        else:\n            fontsize = 10\n\n        ax.set_xticks(xinds + 0.25)\n        ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n\n        if legend and not subplots:\n            fig = ax.get_figure()\n            fig.legend([r[0] for r in rects], labels, loc='upper center',\n                       fancybox=True, ncol=6, mode='expand')\n\n        import matplotlib.pyplot as plt\n        plt.subplots_adjust(top=0.8) </s> remove             if N < 10:\n                fontsize = 12\n            else:\n                fontsize = 10\n\n            ax.set_xticks(xinds + 0.25)\n            ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n </s> add             if legend and not subplots:\n                ax.legend(loc='best')\n        elif kind == 'bar':\n            self._bar_plot(axes, subplots=subplots, grid=grid, rot=rot,\n                           legend=legend) </s> add                 axes = [ax] </s> remove         elif kind == 'bar':\n            N = len(self)\n            M = len(self.columns)\n            xinds = np.arange(N) + 0.25\n            colors = ['red', 'green', 'blue', 'yellow', 'black']\n            rects = []\n            labels = []\n            for i, col in enumerate(_try_sort(self.columns)):\n                empty = self[col].count() == 0\n                y = self[col].values if not empty else np.zeros(x.shape)\n                if subplots:\n                    ax = axes[i]\n                    ax.bar(xinds, y, 0.5,\n                           bottom=np.zeros(N), linewidth=1, **kwds)\n                    ax.set_title(col)\n                else:\n                    rects.append(ax.bar(xinds+i*0.5/M,y,0.5/M,bottom=np.zeros(N),color=colors[i % len(colors)], **kwds))\n                    labels.append(col)\n </s> add  </s> add         kind : {'line', 'bar'}", "html_url": "https://github.com/pandas-dev/pandas/commit/0518b54bfc2bf6ae4a657183b65c714f4187609c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 ax.legend(loc='best')\n <mask>             else:\n <mask>                 ax.legend([r[0] for r in rects],labels,loc='best')\n <mask> \n <mask>         plt.draw_if_interactive()\n <mask> \n <mask>     def hist(self, grid=True, **kwds):\n <mask>         \"\"\"\n <mask>         Draw Histogram the DataFrame's series using matplotlib / pylab.\n <mask> \n </s> ENH: refactoring/mpl tweaking post PR #348 </s> remove     def plot(self, kind='line', subplots=False, sharex=True, sharey=False, use_index=True,\n             figsize=None, grid=True, legend=True, rot=30, ax=None, **kwds):\n </s> add     def plot(self, subplots=False, sharex=True, sharey=False, use_index=True,\n             figsize=None, grid=True, legend=True, rot=30, ax=None,\n             kind='line', **kwds): </s> remove                 ax.legend([r[0] for r in rects],labels,loc='best')\n </s> add                 rects.append(ax.bar(xinds + i * 0.5/K, y, 0.5/K,\n                                    bottom=np.zeros(N),\n                                    color=colors[i % len(colors)], **kwds))\n                labels.append(col) </s> remove         if legend and not subplots:\n            if kind == 'line':\n                ax.legend(loc='best')\n </s> add         plt.draw_if_interactive()\n\n    def _bar_plot(self, axes, subplots=False, use_index=True, grid=True,\n                  rot=30, legend=True, **kwds):\n        N, K = self.shape\n        xinds = np.arange(N) + 0.25\n        colors = 'rgbyk'\n        rects = []\n        labels = []\n\n        if not subplots:\n            ax = axes[0]\n\n        for i, col in enumerate(_try_sort(self.columns)):\n            empty = self[col].count() == 0\n            y = self[col].values if not empty else np.zeros(len(self))\n            if subplots:\n                ax = axes[i]\n                ax.bar(xinds, y, 0.5,\n                       bottom=np.zeros(N), linewidth=1, **kwds)\n                ax.set_title(col) </s> remove         elif kind == 'bar':\n            N = len(self)\n            M = len(self.columns)\n            xinds = np.arange(N) + 0.25\n            colors = ['red', 'green', 'blue', 'yellow', 'black']\n            rects = []\n            labels = []\n            for i, col in enumerate(_try_sort(self.columns)):\n                empty = self[col].count() == 0\n                y = self[col].values if not empty else np.zeros(x.shape)\n                if subplots:\n                    ax = axes[i]\n                    ax.bar(xinds, y, 0.5,\n                           bottom=np.zeros(N), linewidth=1, **kwds)\n                    ax.set_title(col)\n                else:\n                    rects.append(ax.bar(xinds+i*0.5/M,y,0.5/M,bottom=np.zeros(N),color=colors[i % len(colors)], **kwds))\n                    labels.append(col)\n </s> add  </s> remove             if N < 10:\n                fontsize = 12\n            else:\n                fontsize = 10\n\n            ax.set_xticks(xinds + 0.25)\n            ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n </s> add             if legend and not subplots:\n                ax.legend(loc='best')\n        elif kind == 'bar':\n            self._bar_plot(axes, subplots=subplots, grid=grid, rot=rot,\n                           legend=legend) </s> add     def test_plot_bar(self):\n        df = DataFrame(np.random.randn(6, 4),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=['one', 'two', 'three', 'four'])\n\n        _check_plot_works(df.plot, kind='bar')\n        _check_plot_works(df.plot, kind='bar', legend=False)\n        _check_plot_works(df.plot, kind='bar', subplots=True)\n\n        df = DataFrame(np.random.randn(6, 15),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=range(15))\n        _check_plot_works(df.plot, kind='bar')\n", "html_url": "https://github.com/pandas-dev/pandas/commit/0518b54bfc2bf6ae4a657183b65c714f4187609c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         _check_plot_works(df.plot, subplots=True)\n <mask>         _check_plot_works(df.plot, subplots=True, use_index=False)\n <mask> \n <mask>     def test_hist(self):\n <mask>         df = DataFrame(np.random.randn(100, 4))\n <mask>         _check_plot_works(df.hist)\n <mask>         _check_plot_works(df.hist, grid=False)\n <mask> \n <mask>     def test_plot_int_columns(self):\n </s> ENH: refactoring/mpl tweaking post PR #348 </s> add         kind : {'line', 'bar'} </s> remove         if legend and not subplots:\n            if kind == 'line':\n                ax.legend(loc='best')\n </s> add         plt.draw_if_interactive()\n\n    def _bar_plot(self, axes, subplots=False, use_index=True, grid=True,\n                  rot=30, legend=True, **kwds):\n        N, K = self.shape\n        xinds = np.arange(N) + 0.25\n        colors = 'rgbyk'\n        rects = []\n        labels = []\n\n        if not subplots:\n            ax = axes[0]\n\n        for i, col in enumerate(_try_sort(self.columns)):\n            empty = self[col].count() == 0\n            y = self[col].values if not empty else np.zeros(len(self))\n            if subplots:\n                ax = axes[i]\n                ax.bar(xinds, y, 0.5,\n                       bottom=np.zeros(N), linewidth=1, **kwds)\n                ax.set_title(col) </s> remove         plt.draw_if_interactive()\n </s> add         if N < 10:\n            fontsize = 12\n        else:\n            fontsize = 10\n\n        ax.set_xticks(xinds + 0.25)\n        ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n\n        if legend and not subplots:\n            fig = ax.get_figure()\n            fig.legend([r[0] for r in rects], labels, loc='upper center',\n                       fancybox=True, ncol=6, mode='expand')\n\n        import matplotlib.pyplot as plt\n        plt.subplots_adjust(top=0.8) </s> remove     def plot(self, kind='line', subplots=False, sharex=True, sharey=False, use_index=True,\n             figsize=None, grid=True, legend=True, rot=30, ax=None, **kwds):\n </s> add     def plot(self, subplots=False, sharex=True, sharey=False, use_index=True,\n             figsize=None, grid=True, legend=True, rot=30, ax=None,\n             kind='line', **kwds): </s> remove                 ax.legend([r[0] for r in rects],labels,loc='best')\n </s> add                 rects.append(ax.bar(xinds + i * 0.5/K, y, 0.5/K,\n                                    bottom=np.zeros(N),\n                                    color=colors[i % len(colors)], **kwds))\n                labels.append(col) </s> add                 axes = [ax]", "html_url": "https://github.com/pandas-dev/pandas/commit/0518b54bfc2bf6ae4a657183b65c714f4187609c", "file_name": "pandas/tests/test_graphics.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>   has an improved ``KeyError`` message, and will not fail on duplicate column names with ``drop=True``. (:issue:`22484`)\n <mask> - Slicing a single row of a DataFrame with multiple ExtensionArrays of the same type now preserves the dtype, rather than coercing to object (:issue:`22784`)\n <mask> - :class:`DateOffset` attribute `_cacheable` and method `_should_cache` have been removed (:issue:`23118`)\n <mask> \n <mask> .. _whatsnew_0240.deprecations:\n <mask> \n <mask> Deprecations\n <mask> ~~~~~~~~~~~~\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove         return isna(self).any()\n </s> add         return bool(isna(self).any()) </s> remove         return self._isnan.any()\n </s> add         return bool(self._isnan.any()) </s> remove         assert index.hasnans\n </s> add         assert index.hasnans is True </s> remove             assert not idx_unique.hasnans\n </s> add             assert idx_unique.hasnans is False </s> remove             return self._isnan.any()\n </s> add             return bool(self._isnan.any())", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "doc/source/whatsnew/v0.24.0.txt"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     @property  # NB: override with cache_readonly in immutable subclasses\n <mask>     def hasnans(self):\n <mask>         \"\"\" return if I have any nans; enables various perf speedups \"\"\"\n <mask>         return self._isnan.any()\n <mask> \n <mask>     def _maybe_mask_results(self, result, fill_value=None, convert=None):\n <mask>         \"\"\"\n <mask>         Parameters\n <mask>         ----------\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove             return self._isnan.any()\n </s> add             return bool(self._isnan.any()) </s> remove         return isna(self).any()\n </s> add         return bool(isna(self).any()) </s> add - :meth:`Index.hasnans` and :meth:`Series.hasnans` now always return a python boolean. Previously, a python or a numpy boolean could be returned, depending on circumstances (:issue:`23294`). </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove                 assert not idx.hasnans\n </s> add                 assert idx.hasnans is False </s> remove     assert not idx.hasnans\n </s> add     assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/core/arrays/datetimelike.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     @cache_readonly\n <mask>     def hasnans(self):\n <mask>         \"\"\" return if I have any nans; enables various perf speedups \"\"\"\n <mask>         return isna(self).any()\n <mask> \n <mask>     def _reduce(self, op, name, axis=0, skipna=True, numeric_only=None,\n <mask>                 filter_type=None, **kwds):\n <mask>         \"\"\" perform the reduction type operation if we can \"\"\"\n <mask>         func = getattr(self, name, None)\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove             return self._isnan.any()\n </s> add             return bool(self._isnan.any()) </s> remove         return self._isnan.any()\n </s> add         return bool(self._isnan.any()) </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> add - :meth:`Index.hasnans` and :meth:`Series.hasnans` now always return a python boolean. Previously, a python or a numpy boolean could be returned, depending on circumstances (:issue:`23294`). </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove                 assert not idx.hasnans\n </s> add                 assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/core/base.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @cache_readonly\n <mask>     def hasnans(self):\n <mask>         \"\"\" return if I have any nans; enables various perf speedups \"\"\"\n <mask>         if self._can_hold_na:\n <mask>             return self._isnan.any()\n <mask>         else:\n <mask>             return False\n <mask> \n <mask>     def isna(self):\n <mask>         \"\"\"\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove         return self._isnan.any()\n </s> add         return bool(self._isnan.any()) </s> remove         return isna(self).any()\n </s> add         return bool(isna(self).any()) </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> add - :meth:`Index.hasnans` and :meth:`Series.hasnans` now always return a python boolean. Previously, a python or a numpy boolean could be returned, depending on circumstances (:issue:`23294`). </s> remove                 assert not idx.hasnans\n </s> add                 assert idx.hasnans is False </s> remove         assert not index.hasnans\n </s> add         assert index.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/core/indexes/base.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # We test against `idx_unique`, so first we make sure it's unique\n <mask>         # and doesn't contain nans.\n <mask>         assert idx_unique.is_unique is True\n <mask>         try:\n <mask>             assert not idx_unique.hasnans\n <mask>         except NotImplementedError:\n <mask>             pass\n <mask> \n <mask>         for dropna in [False, True]:\n <mask>             result = idx._get_unique_index(dropna=dropna)\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove     assert not index.hasnans\n </s> add     assert index.hasnans is False </s> remove                 assert not idx.hasnans\n </s> add                 assert idx.hasnans is False </s> remove         assert not index.hasnans\n </s> add         assert index.hasnans is False </s> remove         assert index.hasnans\n </s> add         assert index.hasnans is True", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/common.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>                 # cases in indices doesn't include NaN\n <mask>                 expected = np.array([False] * len(idx), dtype=bool)\n <mask>                 tm.assert_numpy_array_equal(idx._isnan, expected)\n <mask>                 assert not idx.hasnans\n <mask> \n <mask>                 idx = index.copy()\n <mask>                 values = np.asarray(idx.values)\n <mask> \n <mask>                 if len(index) == 0:\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove     assert not index.hasnans\n </s> add     assert index.hasnans is False </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove             assert idx.hasnans\n </s> add             assert idx.hasnans is True </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove     assert index.hasnans\n </s> add     assert index.hasnans is True </s> remove     assert not ser.hasnans\n </s> add     assert ser.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/common.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>                 expected = np.array([False] * len(idx), dtype=bool)\n <mask>                 expected[1] = True\n <mask>                 tm.assert_numpy_array_equal(idx._isnan, expected)\n <mask>                 assert idx.hasnans\n <mask> \n <mask>     def test_fillna(self):\n <mask>         # GH 11343\n <mask>         for name, index in self.indices.items():\n <mask>             if len(index) == 0:\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove                 assert not idx.hasnans\n </s> add                 assert idx.hasnans is False </s> remove             assert idx.hasnans\n </s> add             assert idx.hasnans is True </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove     assert index.hasnans\n </s> add     assert index.hasnans is True </s> remove     assert not index.hasnans\n </s> add     assert index.hasnans is False </s> remove         assert index.hasnans\n </s> add         assert index.hasnans is True", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/common.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>                 expected = np.array([False] * len(idx), dtype=bool)\n <mask>                 expected[1] = True\n <mask>                 tm.assert_numpy_array_equal(idx._isnan, expected)\n <mask>                 assert idx.hasnans\n <mask> \n <mask>     def test_nulls(self):\n <mask>         # this is really a smoke test for the methods\n <mask>         # as these are adequately tested for function elsewhere\n <mask> \n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove             assert idx.hasnans\n </s> add             assert idx.hasnans is True </s> remove     assert index.hasnans\n </s> add     assert index.hasnans is True </s> remove                 assert not idx.hasnans\n </s> add                 assert idx.hasnans is False </s> remove             assert not idx_unique.hasnans\n </s> add             assert idx_unique.hasnans is False </s> remove     assert not index.hasnans\n </s> add     assert index.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/common.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         idx = pd.DatetimeIndex(['2011-01-01', '2011-01-02'], tz=tz)\n <mask>         assert idx._can_hold_na\n <mask> \n <mask>         tm.assert_numpy_array_equal(idx._isnan, np.array([False, False]))\n <mask>         assert not idx.hasnans\n <mask>         tm.assert_numpy_array_equal(idx._nan_idxs,\n <mask>                                     np.array([], dtype=np.intp))\n <mask> \n <mask>         idx = pd.DatetimeIndex(['2011-01-01', 'NaT'], tz=tz)\n <mask>         assert idx._can_hold_na\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True </s> remove     assert not idx.hasnans\n </s> add     assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/datetimes/test_ops.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         idx = pd.DatetimeIndex(['2011-01-01', 'NaT'], tz=tz)\n <mask>         assert idx._can_hold_na\n <mask> \n <mask>         tm.assert_numpy_array_equal(idx._isnan, np.array([False, True]))\n <mask>         assert idx.hasnans\n <mask>         tm.assert_numpy_array_equal(idx._nan_idxs,\n <mask>                                     np.array([1], dtype=np.intp))\n <mask> \n <mask>     def test_equals(self):\n <mask>         # GH 13107\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False </s> remove             assert idx.hasnans\n </s> add             assert idx.hasnans is True", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/datetimes/test_ops.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         tm.assert_index_equal(result, expected)\n <mask> \n <mask>     def test_with_nans(self, closed):\n <mask>         index = self.create_index(closed=closed)\n <mask>         assert not index.hasnans\n <mask> \n <mask>         result = index.isna()\n <mask>         expected = np.repeat(False, len(index))\n <mask>         tm.assert_numpy_array_equal(result, expected)\n <mask> \n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove         assert index.hasnans\n </s> add         assert index.hasnans is True </s> remove     assert not index.hasnans\n </s> add     assert index.hasnans is False </s> remove     assert index.hasnans\n </s> add     assert index.hasnans is True </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove             assert idx.hasnans\n </s> add             assert idx.hasnans is True </s> remove                 assert not idx.hasnans\n </s> add                 assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/interval/test_interval.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         expected = np.repeat(True, len(index))\n <mask>         tm.assert_numpy_array_equal(result, expected)\n <mask> \n <mask>         index = self.create_index_with_nan(closed=closed)\n <mask>         assert index.hasnans\n <mask> \n <mask>         result = index.isna()\n <mask>         expected = np.array([False, True] + [False] * (len(index) - 2))\n <mask>         tm.assert_numpy_array_equal(result, expected)\n <mask> \n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove         assert not index.hasnans\n </s> add         assert index.hasnans is False </s> remove     assert not index.hasnans\n </s> add     assert index.hasnans is False </s> remove     assert index.hasnans\n </s> add     assert index.hasnans is True </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove             assert idx.hasnans\n </s> add             assert idx.hasnans is True </s> remove                 assert not idx.hasnans\n </s> add                 assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/interval/test_interval.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>             expected = np.array([False] * len(idx), dtype=bool)\n <mask>             expected[1] = True\n <mask>             tm.assert_numpy_array_equal(idx._isnan, expected)\n <mask>             assert idx.hasnans\n <mask> \n <mask> \n <mask> def test_dropna():\n <mask>     # GH 6194\n <mask>     idx = pd.MultiIndex.from_arrays([[1, np.nan, 3, np.nan, 5],\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove     assert index.hasnans\n </s> add     assert index.hasnans is True </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove                 assert not idx.hasnans\n </s> add                 assert idx.hasnans is False </s> remove     assert not index.hasnans\n </s> add     assert index.hasnans is False </s> remove         assert index.hasnans\n </s> add         assert index.hasnans is True", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/multi/test_missing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     # cases in indices doesn't include NaN\n <mask>     expected = np.array([False] * len(index), dtype=bool)\n <mask>     tm.assert_numpy_array_equal(index._isnan, expected)\n <mask>     assert not index.hasnans\n <mask> \n <mask>     index = idx.copy()\n <mask>     values = index.values\n <mask>     values[1] = np.nan\n <mask> \n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove                 assert not idx.hasnans\n </s> add                 assert idx.hasnans is False </s> remove     assert index.hasnans\n </s> add     assert index.hasnans is True </s> remove         assert index.hasnans\n </s> add         assert index.hasnans is True </s> remove         assert not index.hasnans\n </s> add         assert index.hasnans is False </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove             assert idx.hasnans\n </s> add             assert idx.hasnans is True", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/multi/test_missing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     expected = np.array([False] * len(index), dtype=bool)\n <mask>     expected[1] = True\n <mask>     tm.assert_numpy_array_equal(index._isnan, expected)\n <mask>     assert index.hasnans\n <mask> \n <mask> \n <mask> def test_nan_stays_float():\n <mask> \n <mask>     # GH 7031\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove     assert not index.hasnans\n </s> add     assert index.hasnans is False </s> remove             assert idx.hasnans\n </s> add             assert idx.hasnans is True </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove         assert index.hasnans\n </s> add         assert index.hasnans is True </s> remove         assert not index.hasnans\n </s> add         assert index.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/multi/test_missing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         idx = pd.PeriodIndex(['2011-01-01', '2011-01-02'], freq='D')\n <mask>         assert idx._can_hold_na\n <mask> \n <mask>         tm.assert_numpy_array_equal(idx._isnan, np.array([False, False]))\n <mask>         assert not idx.hasnans\n <mask>         tm.assert_numpy_array_equal(idx._nan_idxs,\n <mask>                                     np.array([], dtype=np.intp))\n <mask> \n <mask>         idx = pd.PeriodIndex(['2011-01-01', 'NaT'], freq='D')\n <mask>         assert idx._can_hold_na\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True </s> remove     assert not idx.hasnans\n </s> add     assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/period/test_ops.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         idx = pd.PeriodIndex(['2011-01-01', 'NaT'], freq='D')\n <mask>         assert idx._can_hold_na\n <mask> \n <mask>         tm.assert_numpy_array_equal(idx._isnan, np.array([False, True]))\n <mask>         assert idx.hasnans\n <mask>         tm.assert_numpy_array_equal(idx._nan_idxs,\n <mask>                                     np.array([1], dtype=np.intp))\n <mask> \n <mask>     @pytest.mark.parametrize('freq', ['D', 'M'])\n <mask>     def test_equals(self, freq):\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False </s> remove     assert not idx.hasnans\n </s> add     assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/period/test_ops.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         idx = pd.TimedeltaIndex(['1 days', '2 days'])\n <mask>         assert idx._can_hold_na\n <mask> \n <mask>         tm.assert_numpy_array_equal(idx._isnan, np.array([False, False]))\n <mask>         assert not idx.hasnans\n <mask>         tm.assert_numpy_array_equal(idx._nan_idxs,\n <mask>                                     np.array([], dtype=np.intp))\n <mask> \n <mask>         idx = pd.TimedeltaIndex(['1 days', 'NaT'])\n <mask>         assert idx._can_hold_na\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True </s> remove     assert not idx.hasnans\n </s> add     assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/timedeltas/test_ops.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         idx = pd.TimedeltaIndex(['1 days', 'NaT'])\n <mask>         assert idx._can_hold_na\n <mask> \n <mask>         tm.assert_numpy_array_equal(idx._isnan, np.array([False, True]))\n <mask>         assert idx.hasnans\n <mask>         tm.assert_numpy_array_equal(idx._nan_idxs,\n <mask>                                     np.array([1], dtype=np.intp))\n <mask> \n <mask>     def test_equals(self):\n <mask>         # GH 13107\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False </s> remove             assert idx.hasnans\n </s> add             assert idx.hasnans is True", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/timedeltas/test_ops.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep replace", "code_tokens": " <mask> \n <mask> def test_hasnans_unchached_for_series():\n <mask>     # GH#19700\n <mask>     idx = pd.Index([0, 1])\n <mask>     assert not idx.hasnans\n <mask>     assert 'hasnans' in idx._cache\n <mask>     ser = idx.to_series()\n <mask>     assert not ser.hasnans\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove     assert ser.hasnans\n </s> add     assert ser.hasnans is True </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove             assert idx.hasnans\n </s> add             assert idx.hasnans is True </s> remove                 assert not idx.hasnans\n </s> add                 assert idx.hasnans is False </s> remove         assert idx.hasnans\n </s> add         assert idx.hasnans is True", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/series/test_internals.py"}
{"docstring_tokens": "keep keep keep keep replace keep", "code_tokens": " <mask>     ser = idx.to_series()\n <mask>     assert not ser.hasnans\n <mask>     assert not hasattr(ser, '_cache')\n <mask>     ser.iloc[-1] = np.nan\n <mask>     assert ser.hasnans\n <mask>     assert pd.Series.hasnans.__doc__ == pd.Index.hasnans.__doc__\n </s> API/TST: make hasnans always return python booleans (#23349) </s> remove     assert not ser.hasnans\n </s> add     assert ser.hasnans is False </s> remove     assert not idx.hasnans\n </s> add     assert idx.hasnans is False </s> remove     assert not index.hasnans\n </s> add     assert index.hasnans is False </s> remove                 assert not idx.hasnans\n </s> add                 assert idx.hasnans is False </s> remove                 assert idx.hasnans\n </s> add                 assert idx.hasnans is True </s> remove         assert not idx.hasnans\n </s> add         assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/series/test_internals.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def time_tz(self, tz, freq):\n <mask>         self.ts.tz\n <mask> \n <mask>     def time_offset(self, tz, freq):\n <mask>         self.ts.offset\n <mask> \n <mask>     def time_dayofweek(self, tz, freq):\n <mask>         self.ts.dayofweek\n <mask> \n <mask>     def time_weekday_name(self, tz, freq):\n <mask>         self.ts.weekday_name\n </s> Followup Cleanup DTI test_arithmetic, ASV (#19149) </s> remove     def test_series_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = Series(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([2, 3, 4], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + 1\n            assert_series_equal(res, exp)\n\n            res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n            assert_series_equal(res, exp)\n\n            s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                           pd.Timedelta('3 days')], dtype=dtype)\n            exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                             pd.Timedelta('6 days')])\n            assert_series_equal(pd.Timedelta('3 days') + s, exp)\n            assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n        s = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + s, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(s + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    def test_frame_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = DataFrame(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n            assert_frame_equal(res, exp)\n\n            res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n            assert_frame_equal(res, exp)\n\n </s> add     def test_series_radd_str(self):\n        ser = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + ser, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(ser + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_more(self, dtype):\n        res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([2, 3, 4], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + 1\n        assert_series_equal(res, exp)\n\n        res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n        assert_series_equal(res, exp)\n\n        s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                       pd.Timedelta('3 days')], dtype=dtype)\n        exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                         pd.Timedelta('6 days')])\n        assert_series_equal(pd.Timedelta('3 days') + s, exp)\n        assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_str_invalid(self, dtype, data):\n        ser = Series(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + ser\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_str_invalid(self, dtype, data):\n        df = DataFrame(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + df\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_more(self, dtype):\n        res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n        assert_frame_equal(res, exp)\n\n        res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n        assert_frame_equal(res, exp)\n\n    def test_frame_radd_str(self): </s> remove             nat_series_dtype_timestamp / 1.0\n </s> add             dt64_series / one </s> remove         pytest.param(Timedelta('5m4s'),\n                     marks=pytest.mark.xfail(reason=\"Timedelta.__floordiv__ \"\n                                                    \"bug GH#18846\")),\n </s> add         Timedelta('5m4s'), </s> remove             nat_series_dtype_timestamp / 1\n </s> add             one / dt64_series </s> add     @pytest.mark.parametrize('dt64_series', [\n        Series([Timestamp('19900315'), Timestamp('19900315')]),\n        Series([NaT, Timestamp('19900315')]),\n        Series([NaT, NaT], dtype='datetime64[ns]')])\n    @pytest.mark.parametrize('one', [1, 1.0, np.array(1)])\n    def test_dt64_mul_div_numeric_invalid(self, one, dt64_series): </s> add                 assert_series_equal(result, expected)", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "asv_bench/benchmarks/timestamp.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace", "code_tokens": " <mask>     exp = klass([Timestamp('2000-01-31 00:15:00', tz='US/Central'),\n <mask>                  Timestamp('2000-02-29', tz='US/Central')], name='a')\n <mask>     assert_func(result, exp)\n <mask>     assert_func(result2, exp)\n <mask> \n <mask>     # array of offsets - valid for Series only\n <mask>     if klass is Series:\n <mask>         with tm.assert_produces_warning(PerformanceWarning):\n <mask>             s = klass([Timestamp('2000-1-1'), Timestamp('2000-2-1')])\n <mask>             result = s + Series([pd.offsets.DateOffset(years=1),\n <mask>                                  pd.offsets.MonthEnd()])\n <mask>             exp = klass([Timestamp('2001-1-1'), Timestamp('2000-2-29')\n <mask>                          ])\n <mask>             assert_func(result, exp)\n <mask> \n <mask>             # same offset\n <mask>             result = s + Series([pd.offsets.DateOffset(years=1),\n <mask>                                  pd.offsets.DateOffset(years=1)])\n <mask>             exp = klass([Timestamp('2001-1-1'), Timestamp('2001-2-1')])\n <mask>             assert_func(result, exp)\n <mask> \n <mask>     s = klass([Timestamp('2000-01-05 00:15:00'),\n <mask>                Timestamp('2000-01-31 00:23:00'),\n <mask>                Timestamp('2000-01-01'),\n <mask>                Timestamp('2000-03-31'),\n <mask>                Timestamp('2000-02-29'),\n <mask>                Timestamp('2000-12-31'),\n <mask>                Timestamp('2000-05-15'),\n <mask>                Timestamp('2001-06-15')])\n <mask> \n <mask>     # DateOffset relativedelta fastpath\n <mask>     relative_kwargs = [('years', 2), ('months', 5), ('days', 3),\n <mask>                        ('hours', 5), ('minutes', 10), ('seconds', 2),\n <mask>                        ('microseconds', 5)]\n <mask>     for i, kwd in enumerate(relative_kwargs):\n <mask>         op = pd.DateOffset(**dict([kwd]))\n <mask>         assert_func(klass([x + op for x in s]), s + op)\n <mask>         assert_func(klass([x - op for x in s]), s - op)\n <mask>         op = pd.DateOffset(**dict(relative_kwargs[:i + 1]))\n <mask>         assert_func(klass([x + op for x in s]), s + op)\n <mask>         assert_func(klass([x - op for x in s]), s - op)\n <mask> \n <mask>     # assert these are equal on a piecewise basis\n <mask>     offsets = ['YearBegin', ('YearBegin', {'month': 5}),\n <mask>                'YearEnd', ('YearEnd', {'month': 5}),\n <mask>                'MonthBegin', 'MonthEnd',\n <mask>                'SemiMonthEnd', 'SemiMonthBegin',\n <mask>                'Week', ('Week', {'weekday': 3}),\n <mask>                'BusinessDay', 'BDay', 'QuarterEnd', 'QuarterBegin',\n <mask>                'CustomBusinessDay', 'CDay', 'CBMonthEnd',\n <mask>                'CBMonthBegin', 'BMonthBegin', 'BMonthEnd',\n <mask>                'BusinessHour', 'BYearBegin', 'BYearEnd',\n <mask>                'BQuarterBegin', ('LastWeekOfMonth', {'weekday': 2}),\n <mask>                ('FY5253Quarter', {'qtr_with_extra_week': 1,\n <mask>                                   'startingMonth': 1,\n <mask>                                   'weekday': 2,\n <mask>                                   'variation': 'nearest'}),\n <mask>                ('FY5253', {'weekday': 0,\n <mask>                            'startingMonth': 2,\n <mask>                            'variation':\n <mask>                            'nearest'}),\n <mask>                ('WeekOfMonth', {'weekday': 2,\n <mask>                                 'week': 2}),\n <mask>                'Easter', ('DateOffset', {'day': 4}),\n <mask>                ('DateOffset', {'month': 5})]\n <mask> \n <mask>     with warnings.catch_warnings(record=True):\n <mask>         for normalize in (True, False):\n <mask>             for do in offsets:\n <mask>                 if isinstance(do, tuple):\n <mask>                     do, kwargs = do\n <mask>                 else:\n <mask>                     do = do\n <mask>                     kwargs = {}\n <mask> \n <mask>                     for n in [0, 5]:\n <mask>                         if (do in ['WeekOfMonth', 'LastWeekOfMonth',\n <mask>                                    'FY5253Quarter', 'FY5253'] and n == 0):\n <mask>                             continue\n <mask>                     op = getattr(pd.offsets, do)(n,\n <mask>                                                  normalize=normalize,\n <mask>                                                  **kwargs)\n <mask>                     assert_func(klass([x + op for x in s]), s + op)\n <mask>                     assert_func(klass([x - op for x in s]), s - op)\n <mask>                     assert_func(klass([op + x for x in s]), op + s)\n </s> Followup Cleanup DTI test_arithmetic, ASV (#19149) </s> remove     def test_series_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = Series(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([2, 3, 4], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + 1\n            assert_series_equal(res, exp)\n\n            res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n            assert_series_equal(res, exp)\n\n            s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                           pd.Timedelta('3 days')], dtype=dtype)\n            exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                             pd.Timedelta('6 days')])\n            assert_series_equal(pd.Timedelta('3 days') + s, exp)\n            assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n        s = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + s, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(s + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    def test_frame_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = DataFrame(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n            assert_frame_equal(res, exp)\n\n            res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n            assert_frame_equal(res, exp)\n\n </s> add     def test_series_radd_str(self):\n        ser = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + ser, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(ser + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_more(self, dtype):\n        res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([2, 3, 4], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + 1\n        assert_series_equal(res, exp)\n\n        res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n        assert_series_equal(res, exp)\n\n        s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                       pd.Timedelta('3 days')], dtype=dtype)\n        exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                         pd.Timedelta('6 days')])\n        assert_series_equal(pd.Timedelta('3 days') + s, exp)\n        assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_str_invalid(self, dtype, data):\n        ser = Series(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + ser\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_str_invalid(self, dtype, data):\n        df = DataFrame(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + df\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_more(self, dtype):\n        res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n        assert_frame_equal(res, exp)\n\n        res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n        assert_frame_equal(res, exp)\n\n    def test_frame_radd_str(self): </s> add                 assert_series_equal(result, expected) </s> remove             nat_series_dtype_timestamp / 1.0\n </s> add             dt64_series / one </s> remove             nat_series_dtype_timestamp / 1\n </s> add             one / dt64_series </s> remove             datetime_series * 1\n        with pytest.raises(TypeError):\n            nat_series_dtype_timestamp * 1\n </s> add             dt64_series * one </s> remove             datetime_series * 1.0\n        with pytest.raises(TypeError):\n            nat_series_dtype_timestamp * 1.0\n </s> add             one * dt64_series", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "pandas/tests/indexes/datetimes/test_arithmetic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             td1 ** scalar_td\n <mask> \n <mask>     @pytest.mark.parametrize('scalar_td', [\n <mask>         timedelta(minutes=5, seconds=4),\n <mask>         pytest.param(Timedelta('5m4s'),\n <mask>                      marks=pytest.mark.xfail(reason=\"Timedelta.__floordiv__ \"\n <mask>                                                     \"bug GH#18846\")),\n <mask>         Timedelta('5m4s').to_timedelta64()])\n <mask>     def test_timedelta_rfloordiv(self, scalar_td):\n <mask>         # GH#18831\n <mask>         td1 = Series([timedelta(minutes=5, seconds=3)] * 3)\n <mask>         td1.iloc[2] = np.nan\n </s> Followup Cleanup DTI test_arithmetic, ASV (#19149) </s> remove     def test_series_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = Series(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([2, 3, 4], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + 1\n            assert_series_equal(res, exp)\n\n            res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n            assert_series_equal(res, exp)\n\n            s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                           pd.Timedelta('3 days')], dtype=dtype)\n            exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                             pd.Timedelta('6 days')])\n            assert_series_equal(pd.Timedelta('3 days') + s, exp)\n            assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n        s = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + s, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(s + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    def test_frame_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = DataFrame(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n            assert_frame_equal(res, exp)\n\n            res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n            assert_frame_equal(res, exp)\n\n </s> add     def test_series_radd_str(self):\n        ser = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + ser, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(ser + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_more(self, dtype):\n        res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([2, 3, 4], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + 1\n        assert_series_equal(res, exp)\n\n        res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n        assert_series_equal(res, exp)\n\n        s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                       pd.Timedelta('3 days')], dtype=dtype)\n        exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                         pd.Timedelta('6 days')])\n        assert_series_equal(pd.Timedelta('3 days') + s, exp)\n        assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_str_invalid(self, dtype, data):\n        ser = Series(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + ser\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_str_invalid(self, dtype, data):\n        df = DataFrame(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + df\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_more(self, dtype):\n        res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n        assert_frame_equal(res, exp)\n\n        res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n        assert_frame_equal(res, exp)\n\n    def test_frame_radd_str(self): </s> add     @pytest.mark.parametrize('dt64_series', [\n        Series([Timestamp('19900315'), Timestamp('19900315')]),\n        Series([NaT, Timestamp('19900315')]),\n        Series([NaT, NaT], dtype='datetime64[ns]')])\n    @pytest.mark.parametrize('one', [1, 1.0, np.array(1)])\n    def test_dt64_mul_div_numeric_invalid(self, one, dt64_series): </s> remove             nat_series_dtype_timestamp / 1.0\n </s> add             dt64_series / one </s> remove             nat_series_dtype_timestamp / 1\n </s> add             one / dt64_series </s> remove     def time_offset(self, tz, freq):\n        self.ts.offset\n\n </s> add  </s> add                 assert_series_equal(result, expected)", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "pandas/tests/series/test_operators.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>                             nat_series_dtype_timestamp)\n <mask> \n <mask>         # multiplication\n <mask>         with pytest.raises(TypeError):\n <mask>             dt64_series * one\n <mask>         with pytest.raises(TypeError):\n <mask>             one * dt64_series\n <mask> \n </s> Followup Cleanup DTI test_arithmetic, ASV (#19149) </s> remove             datetime_series * 1\n        with pytest.raises(TypeError):\n            nat_series_dtype_timestamp * 1\n </s> add             dt64_series * one </s> remove             datetime_series * 1.0\n        with pytest.raises(TypeError):\n            nat_series_dtype_timestamp * 1.0\n </s> add             one * dt64_series </s> remove             nat_series_dtype_timestamp / 1.0\n </s> add             dt64_series / one </s> remove             nat_series_dtype_timestamp / 1\n </s> add             one / dt64_series </s> remove     def test_series_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = Series(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([2, 3, 4], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + 1\n            assert_series_equal(res, exp)\n\n            res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n            assert_series_equal(res, exp)\n\n            s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                           pd.Timedelta('3 days')], dtype=dtype)\n            exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                             pd.Timedelta('6 days')])\n            assert_series_equal(pd.Timedelta('3 days') + s, exp)\n            assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n        s = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + s, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(s + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    def test_frame_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = DataFrame(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n            assert_frame_equal(res, exp)\n\n            res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n            assert_frame_equal(res, exp)\n\n </s> add     def test_series_radd_str(self):\n        ser = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + ser, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(ser + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_more(self, dtype):\n        res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([2, 3, 4], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + 1\n        assert_series_equal(res, exp)\n\n        res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n        assert_series_equal(res, exp)\n\n        s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                       pd.Timedelta('3 days')], dtype=dtype)\n        exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                         pd.Timedelta('6 days')])\n        assert_series_equal(pd.Timedelta('3 days') + s, exp)\n        assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_str_invalid(self, dtype, data):\n        ser = Series(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + ser\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_str_invalid(self, dtype, data):\n        df = DataFrame(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + df\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_more(self, dtype):\n        res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n        assert_frame_equal(res, exp)\n\n        res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n        assert_frame_equal(res, exp)\n\n    def test_frame_radd_str(self): </s> remove \n    # array of offsets - valid for Series only\n    if klass is Series:\n        with tm.assert_produces_warning(PerformanceWarning):\n            s = klass([Timestamp('2000-1-1'), Timestamp('2000-2-1')])\n            result = s + Series([pd.offsets.DateOffset(years=1),\n                                 pd.offsets.MonthEnd()])\n            exp = klass([Timestamp('2001-1-1'), Timestamp('2000-2-29')\n                         ])\n            assert_func(result, exp)\n\n            # same offset\n            result = s + Series([pd.offsets.DateOffset(years=1),\n                                 pd.offsets.DateOffset(years=1)])\n            exp = klass([Timestamp('2001-1-1'), Timestamp('2001-2-1')])\n            assert_func(result, exp)\n\n    s = klass([Timestamp('2000-01-05 00:15:00'),\n               Timestamp('2000-01-31 00:23:00'),\n               Timestamp('2000-01-01'),\n               Timestamp('2000-03-31'),\n               Timestamp('2000-02-29'),\n               Timestamp('2000-12-31'),\n               Timestamp('2000-05-15'),\n               Timestamp('2001-06-15')])\n\n    # DateOffset relativedelta fastpath\n    relative_kwargs = [('years', 2), ('months', 5), ('days', 3),\n                       ('hours', 5), ('minutes', 10), ('seconds', 2),\n                       ('microseconds', 5)]\n    for i, kwd in enumerate(relative_kwargs):\n        op = pd.DateOffset(**dict([kwd]))\n        assert_func(klass([x + op for x in s]), s + op)\n        assert_func(klass([x - op for x in s]), s - op)\n        op = pd.DateOffset(**dict(relative_kwargs[:i + 1]))\n        assert_func(klass([x + op for x in s]), s + op)\n        assert_func(klass([x - op for x in s]), s - op)\n\n    # assert these are equal on a piecewise basis\n    offsets = ['YearBegin', ('YearBegin', {'month': 5}),\n               'YearEnd', ('YearEnd', {'month': 5}),\n               'MonthBegin', 'MonthEnd',\n               'SemiMonthEnd', 'SemiMonthBegin',\n               'Week', ('Week', {'weekday': 3}),\n               'BusinessDay', 'BDay', 'QuarterEnd', 'QuarterBegin',\n               'CustomBusinessDay', 'CDay', 'CBMonthEnd',\n               'CBMonthBegin', 'BMonthBegin', 'BMonthEnd',\n               'BusinessHour', 'BYearBegin', 'BYearEnd',\n               'BQuarterBegin', ('LastWeekOfMonth', {'weekday': 2}),\n               ('FY5253Quarter', {'qtr_with_extra_week': 1,\n                                  'startingMonth': 1,\n                                  'weekday': 2,\n                                  'variation': 'nearest'}),\n               ('FY5253', {'weekday': 0,\n                           'startingMonth': 2,\n                           'variation':\n                           'nearest'}),\n               ('WeekOfMonth', {'weekday': 2,\n                                'week': 2}),\n               'Easter', ('DateOffset', {'day': 4}),\n               ('DateOffset', {'month': 5})]\n\n    with warnings.catch_warnings(record=True):\n        for normalize in (True, False):\n            for do in offsets:\n                if isinstance(do, tuple):\n                    do, kwargs = do\n                else:\n                    do = do\n                    kwargs = {}\n\n                    for n in [0, 5]:\n                        if (do in ['WeekOfMonth', 'LastWeekOfMonth',\n                                   'FY5253Quarter', 'FY5253'] and n == 0):\n                            continue\n                    op = getattr(pd.offsets, do)(n,\n                                                 normalize=normalize,\n                                                 **kwargs)\n                    assert_func(klass([x + op for x in s]), s + op)\n                    assert_func(klass([x - op for x in s]), s - op)\n                    assert_func(klass([op + x for x in s]), op + s)\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "pandas/tests/series/test_operators.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep replace replace replace", "code_tokens": " <mask>                             nat_series_dtype_timestamp)\n <mask> \n <mask>         # multiplication\n <mask>         with pytest.raises(TypeError):\n <mask>             datetime_series * 1\n <mask>         with pytest.raises(TypeError):\n <mask>             nat_series_dtype_timestamp * 1\n <mask>         with pytest.raises(TypeError):\n <mask>             datetime_series * 1.0\n <mask>         with pytest.raises(TypeError):\n <mask>             nat_series_dtype_timestamp * 1.0\n </s> Followup Cleanup DTI test_arithmetic, ASV (#19149) </s> add     @pytest.mark.parametrize('dt64_series', [\n        Series([Timestamp('19900315'), Timestamp('19900315')]),\n        Series([NaT, Timestamp('19900315')]),\n        Series([NaT, NaT], dtype='datetime64[ns]')])\n    @pytest.mark.parametrize('one', [1, 1.0, np.array(1)])\n    def test_dt64_mul_div_numeric_invalid(self, one, dt64_series): </s> remove             nat_series_dtype_timestamp / 1.0\n </s> add             dt64_series / one </s> remove             nat_series_dtype_timestamp / 1\n </s> add             one / dt64_series </s> remove     def test_series_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = Series(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([2, 3, 4], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + 1\n            assert_series_equal(res, exp)\n\n            res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n            assert_series_equal(res, exp)\n\n            s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                           pd.Timedelta('3 days')], dtype=dtype)\n            exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                             pd.Timedelta('6 days')])\n            assert_series_equal(pd.Timedelta('3 days') + s, exp)\n            assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n        s = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + s, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(s + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    def test_frame_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = DataFrame(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n            assert_frame_equal(res, exp)\n\n            res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n            assert_frame_equal(res, exp)\n\n </s> add     def test_series_radd_str(self):\n        ser = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + ser, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(ser + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_more(self, dtype):\n        res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([2, 3, 4], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + 1\n        assert_series_equal(res, exp)\n\n        res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n        assert_series_equal(res, exp)\n\n        s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                       pd.Timedelta('3 days')], dtype=dtype)\n        exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                         pd.Timedelta('6 days')])\n        assert_series_equal(pd.Timedelta('3 days') + s, exp)\n        assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_str_invalid(self, dtype, data):\n        ser = Series(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + ser\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_str_invalid(self, dtype, data):\n        df = DataFrame(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + df\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_more(self, dtype):\n        res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n        assert_frame_equal(res, exp)\n\n        res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n        assert_frame_equal(res, exp)\n\n    def test_frame_radd_str(self): </s> remove \n    # array of offsets - valid for Series only\n    if klass is Series:\n        with tm.assert_produces_warning(PerformanceWarning):\n            s = klass([Timestamp('2000-1-1'), Timestamp('2000-2-1')])\n            result = s + Series([pd.offsets.DateOffset(years=1),\n                                 pd.offsets.MonthEnd()])\n            exp = klass([Timestamp('2001-1-1'), Timestamp('2000-2-29')\n                         ])\n            assert_func(result, exp)\n\n            # same offset\n            result = s + Series([pd.offsets.DateOffset(years=1),\n                                 pd.offsets.DateOffset(years=1)])\n            exp = klass([Timestamp('2001-1-1'), Timestamp('2001-2-1')])\n            assert_func(result, exp)\n\n    s = klass([Timestamp('2000-01-05 00:15:00'),\n               Timestamp('2000-01-31 00:23:00'),\n               Timestamp('2000-01-01'),\n               Timestamp('2000-03-31'),\n               Timestamp('2000-02-29'),\n               Timestamp('2000-12-31'),\n               Timestamp('2000-05-15'),\n               Timestamp('2001-06-15')])\n\n    # DateOffset relativedelta fastpath\n    relative_kwargs = [('years', 2), ('months', 5), ('days', 3),\n                       ('hours', 5), ('minutes', 10), ('seconds', 2),\n                       ('microseconds', 5)]\n    for i, kwd in enumerate(relative_kwargs):\n        op = pd.DateOffset(**dict([kwd]))\n        assert_func(klass([x + op for x in s]), s + op)\n        assert_func(klass([x - op for x in s]), s - op)\n        op = pd.DateOffset(**dict(relative_kwargs[:i + 1]))\n        assert_func(klass([x + op for x in s]), s + op)\n        assert_func(klass([x - op for x in s]), s - op)\n\n    # assert these are equal on a piecewise basis\n    offsets = ['YearBegin', ('YearBegin', {'month': 5}),\n               'YearEnd', ('YearEnd', {'month': 5}),\n               'MonthBegin', 'MonthEnd',\n               'SemiMonthEnd', 'SemiMonthBegin',\n               'Week', ('Week', {'weekday': 3}),\n               'BusinessDay', 'BDay', 'QuarterEnd', 'QuarterBegin',\n               'CustomBusinessDay', 'CDay', 'CBMonthEnd',\n               'CBMonthBegin', 'BMonthBegin', 'BMonthEnd',\n               'BusinessHour', 'BYearBegin', 'BYearEnd',\n               'BQuarterBegin', ('LastWeekOfMonth', {'weekday': 2}),\n               ('FY5253Quarter', {'qtr_with_extra_week': 1,\n                                  'startingMonth': 1,\n                                  'weekday': 2,\n                                  'variation': 'nearest'}),\n               ('FY5253', {'weekday': 0,\n                           'startingMonth': 2,\n                           'variation':\n                           'nearest'}),\n               ('WeekOfMonth', {'weekday': 2,\n                                'week': 2}),\n               'Easter', ('DateOffset', {'day': 4}),\n               ('DateOffset', {'month': 5})]\n\n    with warnings.catch_warnings(record=True):\n        for normalize in (True, False):\n            for do in offsets:\n                if isinstance(do, tuple):\n                    do, kwargs = do\n                else:\n                    do = do\n                    kwargs = {}\n\n                    for n in [0, 5]:\n                        if (do in ['WeekOfMonth', 'LastWeekOfMonth',\n                                   'FY5253Quarter', 'FY5253'] and n == 0):\n                            continue\n                    op = getattr(pd.offsets, do)(n,\n                                                 normalize=normalize,\n                                                 **kwargs)\n                    assert_func(klass([x + op for x in s]), s + op)\n                    assert_func(klass([x - op for x in s]), s - op)\n                    assert_func(klass([op + x for x in s]), op + s)\n </s> add ", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "pandas/tests/series/test_operators.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep keep", "code_tokens": " <mask> \n <mask>         # division\n <mask>         with pytest.raises(TypeError):\n <mask>             nat_series_dtype_timestamp / 1.0\n <mask>         with pytest.raises(TypeError):\n <mask>             nat_series_dtype_timestamp / 1\n <mask> \n <mask>     def test_dt64series_arith_overflow(self):\n <mask>         # GH#12534, fixed by #19024\n </s> Followup Cleanup DTI test_arithmetic, ASV (#19149) </s> remove             datetime_series * 1.0\n        with pytest.raises(TypeError):\n            nat_series_dtype_timestamp * 1.0\n </s> add             one * dt64_series </s> remove             datetime_series * 1\n        with pytest.raises(TypeError):\n            nat_series_dtype_timestamp * 1\n </s> add             dt64_series * one </s> add     @pytest.mark.parametrize('dt64_series', [\n        Series([Timestamp('19900315'), Timestamp('19900315')]),\n        Series([NaT, Timestamp('19900315')]),\n        Series([NaT, NaT], dtype='datetime64[ns]')])\n    @pytest.mark.parametrize('one', [1, 1.0, np.array(1)])\n    def test_dt64_mul_div_numeric_invalid(self, one, dt64_series): </s> add                 assert_series_equal(result, expected) </s> remove     def test_series_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = Series(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([2, 3, 4], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + 1\n            assert_series_equal(res, exp)\n\n            res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n            assert_series_equal(res, exp)\n\n            s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                           pd.Timedelta('3 days')], dtype=dtype)\n            exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                             pd.Timedelta('6 days')])\n            assert_series_equal(pd.Timedelta('3 days') + s, exp)\n            assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n        s = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + s, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(s + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    def test_frame_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = DataFrame(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n            assert_frame_equal(res, exp)\n\n            res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n            assert_frame_equal(res, exp)\n\n </s> add     def test_series_radd_str(self):\n        ser = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + ser, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(ser + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_more(self, dtype):\n        res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([2, 3, 4], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + 1\n        assert_series_equal(res, exp)\n\n        res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n        assert_series_equal(res, exp)\n\n        s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                       pd.Timedelta('3 days')], dtype=dtype)\n        exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                         pd.Timedelta('6 days')])\n        assert_series_equal(pd.Timedelta('3 days') + s, exp)\n        assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_str_invalid(self, dtype, data):\n        ser = Series(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + ser\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_str_invalid(self, dtype, data):\n        df = DataFrame(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + df\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_more(self, dtype):\n        res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n        assert_frame_equal(res, exp)\n\n        res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n        assert_frame_equal(res, exp)\n\n    def test_frame_radd_str(self):", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "pandas/tests/series/test_operators.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>                 expected = s1.apply(\n <mask>                     lambda x: Timedelta(np.timedelta64(m, unit)) / x)\n <mask>                 result = np.timedelta64(m, unit) / s1\n <mask> \n <mask>         # astype\n <mask>         s = Series(date_range('20130101', periods=3))\n <mask>         result = s.astype(object)\n </s> Followup Cleanup DTI test_arithmetic, ASV (#19149) </s> remove \n    # array of offsets - valid for Series only\n    if klass is Series:\n        with tm.assert_produces_warning(PerformanceWarning):\n            s = klass([Timestamp('2000-1-1'), Timestamp('2000-2-1')])\n            result = s + Series([pd.offsets.DateOffset(years=1),\n                                 pd.offsets.MonthEnd()])\n            exp = klass([Timestamp('2001-1-1'), Timestamp('2000-2-29')\n                         ])\n            assert_func(result, exp)\n\n            # same offset\n            result = s + Series([pd.offsets.DateOffset(years=1),\n                                 pd.offsets.DateOffset(years=1)])\n            exp = klass([Timestamp('2001-1-1'), Timestamp('2001-2-1')])\n            assert_func(result, exp)\n\n    s = klass([Timestamp('2000-01-05 00:15:00'),\n               Timestamp('2000-01-31 00:23:00'),\n               Timestamp('2000-01-01'),\n               Timestamp('2000-03-31'),\n               Timestamp('2000-02-29'),\n               Timestamp('2000-12-31'),\n               Timestamp('2000-05-15'),\n               Timestamp('2001-06-15')])\n\n    # DateOffset relativedelta fastpath\n    relative_kwargs = [('years', 2), ('months', 5), ('days', 3),\n                       ('hours', 5), ('minutes', 10), ('seconds', 2),\n                       ('microseconds', 5)]\n    for i, kwd in enumerate(relative_kwargs):\n        op = pd.DateOffset(**dict([kwd]))\n        assert_func(klass([x + op for x in s]), s + op)\n        assert_func(klass([x - op for x in s]), s - op)\n        op = pd.DateOffset(**dict(relative_kwargs[:i + 1]))\n        assert_func(klass([x + op for x in s]), s + op)\n        assert_func(klass([x - op for x in s]), s - op)\n\n    # assert these are equal on a piecewise basis\n    offsets = ['YearBegin', ('YearBegin', {'month': 5}),\n               'YearEnd', ('YearEnd', {'month': 5}),\n               'MonthBegin', 'MonthEnd',\n               'SemiMonthEnd', 'SemiMonthBegin',\n               'Week', ('Week', {'weekday': 3}),\n               'BusinessDay', 'BDay', 'QuarterEnd', 'QuarterBegin',\n               'CustomBusinessDay', 'CDay', 'CBMonthEnd',\n               'CBMonthBegin', 'BMonthBegin', 'BMonthEnd',\n               'BusinessHour', 'BYearBegin', 'BYearEnd',\n               'BQuarterBegin', ('LastWeekOfMonth', {'weekday': 2}),\n               ('FY5253Quarter', {'qtr_with_extra_week': 1,\n                                  'startingMonth': 1,\n                                  'weekday': 2,\n                                  'variation': 'nearest'}),\n               ('FY5253', {'weekday': 0,\n                           'startingMonth': 2,\n                           'variation':\n                           'nearest'}),\n               ('WeekOfMonth', {'weekday': 2,\n                                'week': 2}),\n               'Easter', ('DateOffset', {'day': 4}),\n               ('DateOffset', {'month': 5})]\n\n    with warnings.catch_warnings(record=True):\n        for normalize in (True, False):\n            for do in offsets:\n                if isinstance(do, tuple):\n                    do, kwargs = do\n                else:\n                    do = do\n                    kwargs = {}\n\n                    for n in [0, 5]:\n                        if (do in ['WeekOfMonth', 'LastWeekOfMonth',\n                                   'FY5253Quarter', 'FY5253'] and n == 0):\n                            continue\n                    op = getattr(pd.offsets, do)(n,\n                                                 normalize=normalize,\n                                                 **kwargs)\n                    assert_func(klass([x + op for x in s]), s + op)\n                    assert_func(klass([x - op for x in s]), s - op)\n                    assert_func(klass([op + x for x in s]), op + s)\n </s> add  </s> remove             nat_series_dtype_timestamp / 1.0\n </s> add             dt64_series / one </s> remove             nat_series_dtype_timestamp / 1\n </s> add             one / dt64_series </s> remove             datetime_series * 1.0\n        with pytest.raises(TypeError):\n            nat_series_dtype_timestamp * 1.0\n </s> add             one * dt64_series </s> remove     def test_series_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = Series(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([2, 3, 4], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + 1\n            assert_series_equal(res, exp)\n\n            res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n            assert_series_equal(res, exp)\n\n            s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                           pd.Timedelta('3 days')], dtype=dtype)\n            exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                             pd.Timedelta('6 days')])\n            assert_series_equal(pd.Timedelta('3 days') + s, exp)\n            assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n        s = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + s, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(s + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    def test_frame_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = DataFrame(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n            assert_frame_equal(res, exp)\n\n            res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n            assert_frame_equal(res, exp)\n\n </s> add     def test_series_radd_str(self):\n        ser = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + ser, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(ser + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_more(self, dtype):\n        res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([2, 3, 4], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + 1\n        assert_series_equal(res, exp)\n\n        res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n        assert_series_equal(res, exp)\n\n        s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                       pd.Timedelta('3 days')], dtype=dtype)\n        exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                         pd.Timedelta('6 days')])\n        assert_series_equal(pd.Timedelta('3 days') + s, exp)\n        assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_str_invalid(self, dtype, data):\n        ser = Series(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + ser\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_str_invalid(self, dtype, data):\n        df = DataFrame(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + df\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_more(self, dtype):\n        res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n        assert_frame_equal(res, exp)\n\n        res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n        assert_frame_equal(res, exp)\n\n    def test_frame_radd_str(self): </s> remove             datetime_series * 1\n        with pytest.raises(TypeError):\n            nat_series_dtype_timestamp * 1\n </s> add             dt64_series * one", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "pandas/tests/series/test_operators.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         with pytest.raises(TypeError):\n <mask>             self.ts + datetime.now()\n <mask> \n <mask>     def test_series_radd_more(self):\n <mask>         data = [[1, 2, 3],\n <mask>                 [1.1, 2.2, 3.3],\n <mask>                 [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n <mask>                  pd.NaT],\n <mask>                 ['x', 'y', 1]]\n <mask> \n <mask>         for d in data:\n <mask>             for dtype in [None, object]:\n <mask>                 s = Series(d, dtype=dtype)\n <mask>                 with pytest.raises(TypeError):\n <mask>                     'foo_' + s\n <mask> \n <mask>         for dtype in [None, object]:\n <mask>             res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n <mask>             exp = pd.Series([2, 3, 4], dtype=dtype)\n <mask>             assert_series_equal(res, exp)\n <mask>             res = pd.Series([1, 2, 3], dtype=dtype) + 1\n <mask>             assert_series_equal(res, exp)\n <mask> \n <mask>             res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n <mask>             exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n <mask>             assert_series_equal(res, exp)\n <mask>             res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n <mask>             assert_series_equal(res, exp)\n <mask> \n <mask>             s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n <mask>                            pd.Timedelta('3 days')], dtype=dtype)\n <mask>             exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n <mask>                              pd.Timedelta('6 days')])\n <mask>             assert_series_equal(pd.Timedelta('3 days') + s, exp)\n <mask>             assert_series_equal(s + pd.Timedelta('3 days'), exp)\n <mask> \n <mask>         s = pd.Series(['x', np.nan, 'x'])\n <mask>         assert_series_equal('a' + s, pd.Series(['ax', np.nan, 'ax']))\n <mask>         assert_series_equal(s + 'a', pd.Series(['xa', np.nan, 'xa']))\n <mask> \n <mask>     def test_frame_radd_more(self):\n <mask>         data = [[1, 2, 3],\n <mask>                 [1.1, 2.2, 3.3],\n <mask>                 [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n <mask>                  pd.NaT],\n <mask>                 ['x', 'y', 1]]\n <mask> \n <mask>         for d in data:\n <mask>             for dtype in [None, object]:\n <mask>                 s = DataFrame(d, dtype=dtype)\n <mask>                 with pytest.raises(TypeError):\n <mask>                     'foo_' + s\n <mask> \n <mask>         for dtype in [None, object]:\n <mask>             res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n <mask>             exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n <mask>             assert_frame_equal(res, exp)\n <mask>             res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n <mask>             assert_frame_equal(res, exp)\n <mask> \n <mask>             res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n <mask>             exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n <mask>             assert_frame_equal(res, exp)\n <mask>             res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n <mask>             assert_frame_equal(res, exp)\n <mask> \n <mask>         df = pd.DataFrame(['x', np.nan, 'x'])\n <mask>         assert_frame_equal('a' + df, pd.DataFrame(['ax', np.nan, 'ax']))\n <mask>         assert_frame_equal(df + 'a', pd.DataFrame(['xa', np.nan, 'xa']))\n <mask> \n <mask>     def test_operators_frame(self):\n </s> Followup Cleanup DTI test_arithmetic, ASV (#19149) </s> remove \n    # array of offsets - valid for Series only\n    if klass is Series:\n        with tm.assert_produces_warning(PerformanceWarning):\n            s = klass([Timestamp('2000-1-1'), Timestamp('2000-2-1')])\n            result = s + Series([pd.offsets.DateOffset(years=1),\n                                 pd.offsets.MonthEnd()])\n            exp = klass([Timestamp('2001-1-1'), Timestamp('2000-2-29')\n                         ])\n            assert_func(result, exp)\n\n            # same offset\n            result = s + Series([pd.offsets.DateOffset(years=1),\n                                 pd.offsets.DateOffset(years=1)])\n            exp = klass([Timestamp('2001-1-1'), Timestamp('2001-2-1')])\n            assert_func(result, exp)\n\n    s = klass([Timestamp('2000-01-05 00:15:00'),\n               Timestamp('2000-01-31 00:23:00'),\n               Timestamp('2000-01-01'),\n               Timestamp('2000-03-31'),\n               Timestamp('2000-02-29'),\n               Timestamp('2000-12-31'),\n               Timestamp('2000-05-15'),\n               Timestamp('2001-06-15')])\n\n    # DateOffset relativedelta fastpath\n    relative_kwargs = [('years', 2), ('months', 5), ('days', 3),\n                       ('hours', 5), ('minutes', 10), ('seconds', 2),\n                       ('microseconds', 5)]\n    for i, kwd in enumerate(relative_kwargs):\n        op = pd.DateOffset(**dict([kwd]))\n        assert_func(klass([x + op for x in s]), s + op)\n        assert_func(klass([x - op for x in s]), s - op)\n        op = pd.DateOffset(**dict(relative_kwargs[:i + 1]))\n        assert_func(klass([x + op for x in s]), s + op)\n        assert_func(klass([x - op for x in s]), s - op)\n\n    # assert these are equal on a piecewise basis\n    offsets = ['YearBegin', ('YearBegin', {'month': 5}),\n               'YearEnd', ('YearEnd', {'month': 5}),\n               'MonthBegin', 'MonthEnd',\n               'SemiMonthEnd', 'SemiMonthBegin',\n               'Week', ('Week', {'weekday': 3}),\n               'BusinessDay', 'BDay', 'QuarterEnd', 'QuarterBegin',\n               'CustomBusinessDay', 'CDay', 'CBMonthEnd',\n               'CBMonthBegin', 'BMonthBegin', 'BMonthEnd',\n               'BusinessHour', 'BYearBegin', 'BYearEnd',\n               'BQuarterBegin', ('LastWeekOfMonth', {'weekday': 2}),\n               ('FY5253Quarter', {'qtr_with_extra_week': 1,\n                                  'startingMonth': 1,\n                                  'weekday': 2,\n                                  'variation': 'nearest'}),\n               ('FY5253', {'weekday': 0,\n                           'startingMonth': 2,\n                           'variation':\n                           'nearest'}),\n               ('WeekOfMonth', {'weekday': 2,\n                                'week': 2}),\n               'Easter', ('DateOffset', {'day': 4}),\n               ('DateOffset', {'month': 5})]\n\n    with warnings.catch_warnings(record=True):\n        for normalize in (True, False):\n            for do in offsets:\n                if isinstance(do, tuple):\n                    do, kwargs = do\n                else:\n                    do = do\n                    kwargs = {}\n\n                    for n in [0, 5]:\n                        if (do in ['WeekOfMonth', 'LastWeekOfMonth',\n                                   'FY5253Quarter', 'FY5253'] and n == 0):\n                            continue\n                    op = getattr(pd.offsets, do)(n,\n                                                 normalize=normalize,\n                                                 **kwargs)\n                    assert_func(klass([x + op for x in s]), s + op)\n                    assert_func(klass([x - op for x in s]), s - op)\n                    assert_func(klass([op + x for x in s]), op + s)\n </s> add  </s> remove         pytest.param(Timedelta('5m4s'),\n                     marks=pytest.mark.xfail(reason=\"Timedelta.__floordiv__ \"\n                                                    \"bug GH#18846\")),\n </s> add         Timedelta('5m4s'), </s> remove             nat_series_dtype_timestamp / 1.0\n </s> add             dt64_series / one </s> add                 assert_series_equal(result, expected) </s> remove             nat_series_dtype_timestamp / 1\n </s> add             one / dt64_series </s> add     @pytest.mark.parametrize('dt64_series', [\n        Series([Timestamp('19900315'), Timestamp('19900315')]),\n        Series([NaT, Timestamp('19900315')]),\n        Series([NaT, NaT], dtype='datetime64[ns]')])\n    @pytest.mark.parametrize('one', [1, 1.0, np.array(1)])\n    def test_dt64_mul_div_numeric_invalid(self, one, dt64_series):", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "pandas/tests/series/test_operators.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep replace replace replace replace keep keep keep keep", "code_tokens": " <mask>     # ndarray-like stats methods\n <mask> \n <mask>     def count(self, axis=0, level=None, numeric_only=False):\n <mask>         \"\"\"\n <mask>         Return Series with number of non-NA/null observations over requested\n <mask>         axis. Works with non-floating point data as well (detects NaN and None)\n <mask> \n <mask>         Parameters\n <mask>         ----------\n <mask>         axis : {0 or 'index', 1 or 'columns'}, default 0\n <mask>             0 or 'index' for row-wise, 1 or 'columns' for column-wise\n <mask>         level : int or level name, default None\n <mask>             If the axis is a MultiIndex (hierarchical), count along a\n <mask>             particular level, collapsing into a DataFrame\n <mask>         numeric_only : boolean, default False\n <mask>             Include only float, int, boolean data\n <mask> \n <mask>         Returns\n </s> DOC: update the DataFrame.count docstring (#20221)\n\n* DataFrame.count docstring reworked, examples added\r\n\r\n* review corrections\r\n\r\n* review fixes + better description\r\n\r\n* review fixes, full stop and backticks\r\n\r\n* review fix: changed summary, added quoting </s> remove             Include only float, int, boolean data\n </s> add             Include only `float`, `int` or `boolean` data. </s> remove         count : Series (or DataFrame if level specified)\n </s> add         Series or DataFrame\n            For each column/row the number of non-NA/null entries.\n            If `level` is specified returns a `DataFrame`.\n\n        See Also\n        --------\n        Series.count: number of non-NA elements in a Series\n        DataFrame.shape: number of DataFrame rows and columns (including NA\n            elements)\n        DataFrame.isna: boolean same-sized DataFrame showing places of NA\n            elements\n\n        Examples\n        --------\n        Constructing DataFrame from a dictionary:\n\n        >>> df = pd.DataFrame({\"Person\":\n        ...                    [\"John\", \"Myla\", None, \"John\", \"Myla\"],\n        ...                    \"Age\": [24., np.nan, 21., 33, 26],\n        ...                    \"Single\": [False, True, True, True, False]})\n        >>> df\n           Person   Age  Single\n        0    John  24.0   False\n        1    Myla   NaN    True\n        2    None  21.0    True\n        3    John  33.0    True\n        4    Myla  26.0   False\n\n        Notice the uncounted NA values:\n\n        >>> df.count()\n        Person    4\n        Age       4\n        Single    5\n        dtype: int64\n\n        Counts for each **row**:\n\n        >>> df.count(axis='columns')\n        0    3\n        1    2\n        2    2\n        3    3\n        4    3\n        dtype: int64\n\n        Counts for one level of a `MultiIndex`:\n\n        >>> df.set_index([\"Person\", \"Single\"]).count(level=\"Person\")\n                Age\n        Person\n        John      2\n        Myla      1", "html_url": "https://github.com/pandas-dev/pandas/commit/0596cb18fa9705651b0486310792debb2e4df430", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         level : int or level name, default None\n <mask>             If the axis is a MultiIndex (hierarchical), count along a\n <mask>             particular level, collapsing into a DataFrame\n <mask>         numeric_only : boolean, default False\n <mask>             Include only float, int, boolean data\n <mask> \n <mask>         Returns\n <mask>         -------\n <mask>         count : Series (or DataFrame if level specified)\n <mask>         \"\"\"\n <mask>         axis = self._get_axis_number(axis)\n <mask>         if level is not None:\n <mask>             return self._count_level(level, axis=axis,\n </s> DOC: update the DataFrame.count docstring (#20221)\n\n* DataFrame.count docstring reworked, examples added\r\n\r\n* review corrections\r\n\r\n* review fixes + better description\r\n\r\n* review fixes, full stop and backticks\r\n\r\n* review fix: changed summary, added quoting </s> remove             0 or 'index' for row-wise, 1 or 'columns' for column-wise\n        level : int or level name, default None\n            If the axis is a MultiIndex (hierarchical), count along a\n            particular level, collapsing into a DataFrame\n </s> add             If 0 or 'index' counts are generated for each column.\n            If 1 or 'columns' counts are generated for each **row**.\n        level : int or str, optional\n            If the axis is a `MultiIndex` (hierarchical), count along a\n            particular `level`, collapsing into a `DataFrame`.\n            A `str` specifies the level name. </s> remove         Return Series with number of non-NA/null observations over requested\n        axis. Works with non-floating point data as well (detects NaN and None)\n </s> add         Count non-NA cells for each column or row.\n\n        The values `None`, `NaN`, `NaT`, and optionally `numpy.inf` (depending\n        on `pandas.options.mode.use_inf_as_na`) are considered NA.", "html_url": "https://github.com/pandas-dev/pandas/commit/0596cb18fa9705651b0486310792debb2e4df430", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace", "code_tokens": " <mask> # Note: don't use this config for your own repositories. Instead, see\n <mask> # \"Version control integration\" in README.md.\n <mask> exclude: ^(blib2to3/|profiling/|tests/data/)\n <mask> repos:\n <mask> -   repo: local\n <mask>     hooks:\n <mask>     - id: black\n <mask>       name: black\n <mask>       language: system\n <mask>       entry: black\n <mask>       types: [python]\n <mask>     - id: flake8\n <mask>       name: flake8\n <mask>       language: system\n <mask>       entry: flake8\n <mask>       types: [python]\n <mask>     - id: mypy\n <mask>       name: mypy\n <mask>       language: system\n <mask>       entry: mypy\n <mask>       types: [python]\n <mask>       exclude: ^docs/conf.py\n </s> Run pre-commit on Travis CI (#1081) </s> remove cache: pip\n </s> add cache:\n  pip: true\n  directories:\n    - $HOME/.cache/pre-commit </s> remove - pip install coverage coveralls flake8 flake8-bugbear mypy\n </s> add - pip install coverage coveralls pre-commit </s> remove         - TEST_CMD=\"flake8 black.py blackd.py tests/test_black.py\"\n </s> add         - TEST_CMD=\"pre-commit run --all-files\" </s> remove     - name: \"mypy\"\n      python: 3.6\n      env:\n        - TEST_CMD=\"mypy black.py blackd.py tests/test_black.py\"\n    - name: \"black\"\n      python: 3.7\n      env:\n        - TEST_CMD=\"black --check --verbose .\"\n    - name: \"flake8\"\n </s> add     - name: \"lint\" </s> remove dist: xenial\n </s> add ", "html_url": "https://github.com/psf/black/commit/000147c007787fc26e8ccb4fb9843a6f9d80affb", "file_name": ".pre-commit-config.yaml"}
{"docstring_tokens": "replace keep replace keep keep keep keep keep", "code_tokens": " <mask> dist: xenial\n <mask> language: python\n <mask> cache: pip\n <mask> env:\n <mask> - TEST_CMD=\"coverage run tests/test_black.py\"\n <mask> install:\n <mask> - pip install coverage coveralls flake8 flake8-bugbear mypy\n <mask> - pip install -e '.[d]'\n </s> Run pre-commit on Travis CI (#1081) </s> remove - pip install coverage coveralls flake8 flake8-bugbear mypy\n </s> add - pip install coverage coveralls pre-commit </s> remove     - id: black\n      name: black\n      language: system\n      entry: black\n      types: [python]\n    - id: flake8\n      name: flake8\n      language: system\n      entry: flake8\n      types: [python]\n    - id: mypy\n      name: mypy\n      language: system\n      entry: mypy\n      types: [python]\n      exclude: ^docs/conf.py\n </s> add       - id: black\n        name: black\n        language: system\n        entry: black\n        require_serial: true\n        types: [python]\n\n  - repo: https://gitlab.com/pycqa/flake8\n    rev: 3.7.8\n    hooks:\n      - id: flake8\n        additional_dependencies: [flake8-bugbear]\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v0.740\n    hooks:\n      - id: mypy\n        exclude: ^docs/conf.py </s> remove         - TEST_CMD=\"flake8 black.py blackd.py tests/test_black.py\"\n </s> add         - TEST_CMD=\"pre-commit run --all-files\" </s> remove     - name: \"mypy\"\n      python: 3.6\n      env:\n        - TEST_CMD=\"mypy black.py blackd.py tests/test_black.py\"\n    - name: \"black\"\n      python: 3.7\n      env:\n        - TEST_CMD=\"black --check --verbose .\"\n    - name: \"flake8\"\n </s> add     - name: \"lint\" </s> remove -   repo: local\n </s> add   - repo: local", "html_url": "https://github.com/psf/black/commit/000147c007787fc26e8ccb4fb9843a6f9d80affb", "file_name": ".travis.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> cache: pip\n <mask> env:\n <mask> - TEST_CMD=\"coverage run tests/test_black.py\"\n <mask> install:\n <mask> - pip install coverage coveralls flake8 flake8-bugbear mypy\n <mask> - pip install -e '.[d]'\n <mask> script:\n <mask> - $TEST_CMD\n <mask> after_success:\n <mask> - coveralls\n </s> Run pre-commit on Travis CI (#1081) </s> remove cache: pip\n </s> add cache:\n  pip: true\n  directories:\n    - $HOME/.cache/pre-commit </s> remove dist: xenial\n </s> add  </s> remove         - TEST_CMD=\"flake8 black.py blackd.py tests/test_black.py\"\n </s> add         - TEST_CMD=\"pre-commit run --all-files\" </s> remove     - name: \"mypy\"\n      python: 3.6\n      env:\n        - TEST_CMD=\"mypy black.py blackd.py tests/test_black.py\"\n    - name: \"black\"\n      python: 3.7\n      env:\n        - TEST_CMD=\"black --check --verbose .\"\n    - name: \"flake8\"\n </s> add     - name: \"lint\" </s> remove     - id: black\n      name: black\n      language: system\n      entry: black\n      types: [python]\n    - id: flake8\n      name: flake8\n      language: system\n      entry: flake8\n      types: [python]\n    - id: mypy\n      name: mypy\n      language: system\n      entry: mypy\n      types: [python]\n      exclude: ^docs/conf.py\n </s> add       - id: black\n        name: black\n        language: system\n        entry: black\n        require_serial: true\n        types: [python]\n\n  - repo: https://gitlab.com/pycqa/flake8\n    rev: 3.7.8\n    hooks:\n      - id: flake8\n        additional_dependencies: [flake8-bugbear]\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v0.740\n    hooks:\n      - id: mypy\n        exclude: ^docs/conf.py </s> remove -   repo: local\n </s> add   - repo: local", "html_url": "https://github.com/psf/black/commit/000147c007787fc26e8ccb4fb9843a6f9d80affb", "file_name": ".travis.yml"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace replace replace keep keep replace keep keep", "code_tokens": " <mask>   include:\n <mask>     - name: \"mypy\"\n <mask>       python: 3.6\n <mask>       env:\n <mask>         - TEST_CMD=\"mypy black.py blackd.py tests/test_black.py\"\n <mask>     - name: \"black\"\n <mask>       python: 3.7\n <mask>       env:\n <mask>         - TEST_CMD=\"black --check --verbose .\"\n <mask>     - name: \"flake8\"\n <mask>       python: 3.7\n <mask>       env:\n <mask>         - TEST_CMD=\"flake8 black.py blackd.py tests/test_black.py\"\n <mask>     - name: \"3.6\"\n <mask>       python: 3.6\n </s> Run pre-commit on Travis CI (#1081) </s> remove - pip install coverage coveralls flake8 flake8-bugbear mypy\n </s> add - pip install coverage coveralls pre-commit </s> remove     - id: black\n      name: black\n      language: system\n      entry: black\n      types: [python]\n    - id: flake8\n      name: flake8\n      language: system\n      entry: flake8\n      types: [python]\n    - id: mypy\n      name: mypy\n      language: system\n      entry: mypy\n      types: [python]\n      exclude: ^docs/conf.py\n </s> add       - id: black\n        name: black\n        language: system\n        entry: black\n        require_serial: true\n        types: [python]\n\n  - repo: https://gitlab.com/pycqa/flake8\n    rev: 3.7.8\n    hooks:\n      - id: flake8\n        additional_dependencies: [flake8-bugbear]\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v0.740\n    hooks:\n      - id: mypy\n        exclude: ^docs/conf.py </s> remove cache: pip\n </s> add cache:\n  pip: true\n  directories:\n    - $HOME/.cache/pre-commit </s> remove dist: xenial\n </s> add  </s> remove -   repo: local\n </s> add   - repo: local", "html_url": "https://github.com/psf/black/commit/000147c007787fc26e8ccb4fb9843a6f9d80affb", "file_name": ".travis.yml"}
{"docstring_tokens": "replace keep keep keep keep keep", "code_tokens": " <mask> name: Build wheels and publish to PyPI\n <mask> \n <mask> on:\n <mask>   release:\n <mask>     types: [published]\n <mask>   pull_request:\n </s> mypyc build improvements (#3881)\n\nBuild in separate jobs. This makes it clearer if e.g. a single Python\r\nversion is failing. It also potentially gets you more parallelism.\r\n\r\nBuild everything on push to master.\r\n\r\nOnly build Linux 3.8 and 3.11 wheels on PRs. </s> add   push:\n    branches:\n      - main </s> remove build = \"cp3*-*\"\nskip = [\"*-manylinux_i686\", \"*-musllinux_*\", \"*-win32\", \"pp-*\", \"cp312-*\"]\n </s> add build = \"cp3*\"\nskip = [\"*-manylinux_i686\", \"*-musllinux_*\", \"*-win32\", \"pp*\", \"cp312-*\"] </s> remove         include:\n          - os: ubuntu-latest\n            name: linux-x86_64\n          - os: windows-2019\n            name: windows-amd64\n          - os: macos-11\n            name: macos-x86_64\n            macos_arch: \"x86_64\"\n          - os: macos-11\n            name: macos-arm64\n            macos_arch: \"arm64\"\n          - os: macos-11\n            name: macos-universal2\n            macos_arch: \"universal2\"\n </s> add         include: ${{ fromJson(needs.generate_wheels_matrix.outputs.include) }} </s> remove \n      - name: Build wheels via cibuildwheel\n        uses: pypa/cibuildwheel@v2.15.0\n        env:\n          CIBW_ARCHS_MACOS: \"${{ matrix.macos_arch }}\"\n </s> add       - uses: pypa/cibuildwheel@v2.15.0\n        with:\n          only: ${{ matrix.only }} </s> add     if: github.event_name == 'release' </s> remove     name: mypyc wheels (${{ matrix.name }})\n </s> add     name: mypyc wheels ${{ matrix.only }}\n    needs: generate_wheels_matrix", "html_url": "https://github.com/psf/black/commit/004fb79706a02c9a06abd5c416b033340f99e558", "file_name": ".github/workflows/pypi_upload.yml"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     types: [published]\n <mask>   pull_request:\n <mask> \n <mask> permissions:\n <mask>   contents: read\n <mask> \n <mask> jobs:\n </s> mypyc build improvements (#3881)\n\nBuild in separate jobs. This makes it clearer if e.g. a single Python\r\nversion is failing. It also potentially gets you more parallelism.\r\n\r\nBuild everything on push to master.\r\n\r\nOnly build Linux 3.8 and 3.11 wheels on PRs. </s> remove name: Build wheels and publish to PyPI\n </s> add name: Build and publish </s> add     if: github.event_name == 'release' </s> remove build = \"cp3*-*\"\nskip = [\"*-manylinux_i686\", \"*-musllinux_*\", \"*-win32\", \"pp-*\", \"cp312-*\"]\n </s> add build = \"cp3*\"\nskip = [\"*-manylinux_i686\", \"*-musllinux_*\", \"*-win32\", \"pp*\", \"cp312-*\"] </s> remove \n      - name: Build wheels via cibuildwheel\n        uses: pypa/cibuildwheel@v2.15.0\n        env:\n          CIBW_ARCHS_MACOS: \"${{ matrix.macos_arch }}\"\n </s> add       - uses: pypa/cibuildwheel@v2.15.0\n        with:\n          only: ${{ matrix.only }} </s> remove         include:\n          - os: ubuntu-latest\n            name: linux-x86_64\n          - os: windows-2019\n            name: windows-amd64\n          - os: macos-11\n            name: macos-x86_64\n            macos_arch: \"x86_64\"\n          - os: macos-11\n            name: macos-arm64\n            macos_arch: \"arm64\"\n          - os: macos-11\n            name: macos-universal2\n            macos_arch: \"universal2\"\n </s> add         include: ${{ fromJson(needs.generate_wheels_matrix.outputs.include) }} </s> remove     name: mypyc wheels (${{ matrix.name }})\n </s> add     name: mypyc wheels ${{ matrix.only }}\n    needs: generate_wheels_matrix", "html_url": "https://github.com/psf/black/commit/004fb79706a02c9a06abd5c416b033340f99e558", "file_name": ".github/workflows/pypi_upload.yml"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     name: sdist + pure wheel\n <mask>     runs-on: ubuntu-latest\n <mask> \n <mask>     steps:\n <mask>       - uses: actions/checkout@v4\n <mask> \n <mask>       - name: Set up latest Python\n <mask>         uses: actions/setup-python@v4\n </s> mypyc build improvements (#3881)\n\nBuild in separate jobs. This makes it clearer if e.g. a single Python\r\nversion is failing. It also potentially gets you more parallelism.\r\n\r\nBuild everything on push to master.\r\n\r\nOnly build Linux 3.8 and 3.11 wheels on PRs. </s> remove \n      - name: Build wheels via cibuildwheel\n        uses: pypa/cibuildwheel@v2.15.0\n        env:\n          CIBW_ARCHS_MACOS: \"${{ matrix.macos_arch }}\"\n </s> add       - uses: pypa/cibuildwheel@v2.15.0\n        with:\n          only: ${{ matrix.only }} </s> remove         include:\n          - os: ubuntu-latest\n            name: linux-x86_64\n          - os: windows-2019\n            name: windows-amd64\n          - os: macos-11\n            name: macos-x86_64\n            macos_arch: \"x86_64\"\n          - os: macos-11\n            name: macos-arm64\n            macos_arch: \"arm64\"\n          - os: macos-11\n            name: macos-universal2\n            macos_arch: \"universal2\"\n </s> add         include: ${{ fromJson(needs.generate_wheels_matrix.outputs.include) }} </s> add     if: github.event_name == 'release' </s> remove name: Build wheels and publish to PyPI\n </s> add name: Build and publish </s> add   push:\n    branches:\n      - main </s> remove     name: mypyc wheels (${{ matrix.name }})\n </s> add     name: mypyc wheels ${{ matrix.only }}\n    needs: generate_wheels_matrix", "html_url": "https://github.com/psf/black/commit/004fb79706a02c9a06abd5c416b033340f99e558", "file_name": ".github/workflows/pypi_upload.yml"}
{"docstring_tokens": "keep replace keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask>   mypyc:\n <mask>     name: mypyc wheels (${{ matrix.name }})\n <mask>     runs-on: ${{ matrix.os }}\n <mask>     strategy:\n <mask>       fail-fast: false\n <mask>       matrix:\n <mask>         include:\n <mask>           - os: ubuntu-latest\n <mask>             name: linux-x86_64\n <mask>           - os: windows-2019\n <mask>             name: windows-amd64\n <mask>           - os: macos-11\n <mask>             name: macos-x86_64\n <mask>             macos_arch: \"x86_64\"\n <mask>           - os: macos-11\n <mask>             name: macos-arm64\n <mask>             macos_arch: \"arm64\"\n <mask>           - os: macos-11\n <mask>             name: macos-universal2\n <mask>             macos_arch: \"universal2\"\n <mask> \n <mask>     steps:\n <mask>       - uses: actions/checkout@v4\n <mask> \n </s> mypyc build improvements (#3881)\n\nBuild in separate jobs. This makes it clearer if e.g. a single Python\r\nversion is failing. It also potentially gets you more parallelism.\r\n\r\nBuild everything on push to master.\r\n\r\nOnly build Linux 3.8 and 3.11 wheels on PRs. </s> remove \n      - name: Build wheels via cibuildwheel\n        uses: pypa/cibuildwheel@v2.15.0\n        env:\n          CIBW_ARCHS_MACOS: \"${{ matrix.macos_arch }}\"\n </s> add       - uses: pypa/cibuildwheel@v2.15.0\n        with:\n          only: ${{ matrix.only }} </s> add     if: github.event_name == 'release' </s> remove name: Build wheels and publish to PyPI\n </s> add name: Build and publish </s> add     if: github.event_name == 'release' </s> add   push:\n    branches:\n      - main", "html_url": "https://github.com/psf/black/commit/004fb79706a02c9a06abd5c416b033340f99e558", "file_name": ".github/workflows/pypi_upload.yml"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             macos_arch: \"universal2\"\n <mask> \n <mask>     steps:\n <mask>       - uses: actions/checkout@v4\n <mask> \n <mask>       - name: Build wheels via cibuildwheel\n <mask>         uses: pypa/cibuildwheel@v2.15.0\n <mask>         env:\n <mask>           CIBW_ARCHS_MACOS: \"${{ matrix.macos_arch }}\"\n <mask> \n <mask>       - name: Upload wheels as workflow artifacts\n <mask>         uses: actions/upload-artifact@v3\n <mask>         with:\n <mask>           name: ${{ matrix.name }}-mypyc-wheels\n </s> mypyc build improvements (#3881)\n\nBuild in separate jobs. This makes it clearer if e.g. a single Python\r\nversion is failing. It also potentially gets you more parallelism.\r\n\r\nBuild everything on push to master.\r\n\r\nOnly build Linux 3.8 and 3.11 wheels on PRs. </s> remove         include:\n          - os: ubuntu-latest\n            name: linux-x86_64\n          - os: windows-2019\n            name: windows-amd64\n          - os: macos-11\n            name: macos-x86_64\n            macos_arch: \"x86_64\"\n          - os: macos-11\n            name: macos-arm64\n            macos_arch: \"arm64\"\n          - os: macos-11\n            name: macos-universal2\n            macos_arch: \"universal2\"\n </s> add         include: ${{ fromJson(needs.generate_wheels_matrix.outputs.include) }} </s> add     if: github.event_name == 'release' </s> remove     name: mypyc wheels (${{ matrix.name }})\n </s> add     name: mypyc wheels ${{ matrix.only }}\n    needs: generate_wheels_matrix </s> remove name: Build wheels and publish to PyPI\n </s> add name: Build and publish </s> add   push:\n    branches:\n      - main </s> add     if: github.event_name == 'release'", "html_url": "https://github.com/psf/black/commit/004fb79706a02c9a06abd5c416b033340f99e558", "file_name": ".github/workflows/pypi_upload.yml"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     name: Update stable branch\n <mask>     needs: [main, mypyc]\n <mask>     runs-on: ubuntu-latest\n <mask>     permissions:\n <mask>       contents: write\n <mask> \n <mask>     steps:\n </s> mypyc build improvements (#3881)\n\nBuild in separate jobs. This makes it clearer if e.g. a single Python\r\nversion is failing. It also potentially gets you more parallelism.\r\n\r\nBuild everything on push to master.\r\n\r\nOnly build Linux 3.8 and 3.11 wheels on PRs. </s> add   push:\n    branches:\n      - main </s> remove     name: mypyc wheels (${{ matrix.name }})\n </s> add     name: mypyc wheels ${{ matrix.only }}\n    needs: generate_wheels_matrix </s> add     if: github.event_name == 'release' </s> remove         include:\n          - os: ubuntu-latest\n            name: linux-x86_64\n          - os: windows-2019\n            name: windows-amd64\n          - os: macos-11\n            name: macos-x86_64\n            macos_arch: \"x86_64\"\n          - os: macos-11\n            name: macos-arm64\n            macos_arch: \"arm64\"\n          - os: macos-11\n            name: macos-universal2\n            macos_arch: \"universal2\"\n </s> add         include: ${{ fromJson(needs.generate_wheels_matrix.outputs.include) }} </s> remove name: Build wheels and publish to PyPI\n </s> add name: Build and publish </s> remove \n      - name: Build wheels via cibuildwheel\n        uses: pypa/cibuildwheel@v2.15.0\n        env:\n          CIBW_ARCHS_MACOS: \"${{ matrix.macos_arch }}\"\n </s> add       - uses: pypa/cibuildwheel@v2.15.0\n        with:\n          only: ${{ matrix.only }}", "html_url": "https://github.com/psf/black/commit/004fb79706a02c9a06abd5c416b033340f99e558", "file_name": ".github/workflows/pypi_upload.yml"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> # So these are the environments we target:\n <mask> # - Python: CPython 3.8+ only\n <mask> # - Architecture (64-bit only): amd64 / x86_64, universal2, and arm64\n <mask> # - OS: Linux (no musl), Windows, and macOS\n <mask> build = \"cp3*-*\"\n <mask> skip = [\"*-manylinux_i686\", \"*-musllinux_*\", \"*-win32\", \"pp-*\", \"cp312-*\"]\n <mask> # This is the bare minimum needed to run the test suite. Pulling in the full\n <mask> # test_requirements.txt would download a bunch of other packages not necessary\n <mask> # here and would slow down the testing step a fair bit.\n <mask> test-requires = [\"pytest>=6.1.1\"]\n <mask> test-command = 'pytest {project} -k \"not incompatible_with_mypyc\"'\n </s> mypyc build improvements (#3881)\n\nBuild in separate jobs. This makes it clearer if e.g. a single Python\r\nversion is failing. It also potentially gets you more parallelism.\r\n\r\nBuild everything on push to master.\r\n\r\nOnly build Linux 3.8 and 3.11 wheels on PRs. </s> remove name: Build wheels and publish to PyPI\n </s> add name: Build and publish </s> remove         include:\n          - os: ubuntu-latest\n            name: linux-x86_64\n          - os: windows-2019\n            name: windows-amd64\n          - os: macos-11\n            name: macos-x86_64\n            macos_arch: \"x86_64\"\n          - os: macos-11\n            name: macos-arm64\n            macos_arch: \"arm64\"\n          - os: macos-11\n            name: macos-universal2\n            macos_arch: \"universal2\"\n </s> add         include: ${{ fromJson(needs.generate_wheels_matrix.outputs.include) }} </s> remove \n      - name: Build wheels via cibuildwheel\n        uses: pypa/cibuildwheel@v2.15.0\n        env:\n          CIBW_ARCHS_MACOS: \"${{ matrix.macos_arch }}\"\n </s> add       - uses: pypa/cibuildwheel@v2.15.0\n        with:\n          only: ${{ matrix.only }} </s> add     if: github.event_name == 'release' </s> add   push:\n    branches:\n      - main </s> add     if: github.event_name == 'release'", "html_url": "https://github.com/psf/black/commit/004fb79706a02c9a06abd5c416b033340f99e558", "file_name": "pyproject.toml"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> from asyncio.base_events import BaseEventLoop\n <mask> from concurrent.futures import Executor, ProcessPoolExecutor\n <mask> from enum import Enum, Flag\n <mask> from functools import partial, wraps\n <mask> import keyword\n <mask> import logging\n <mask> from multiprocessing import Manager\n <mask> import os\n <mask> from pathlib import Path\n <mask> import re\n </s> Preserve line endings when formatting a file in place (#288) </s> remove from io import StringIO\n </s> add from io import BytesIO, TextIOWrapper </s> add     def test_preserves_line_endings(self) -> None:\n        with TemporaryDirectory() as workspace:\n            test_file = Path(workspace) / \"test.py\"\n            for nl in [\"\\n\", \"\\r\\n\"]:\n                contents = nl.join([\"def f(  ):\", \"    pass\"])\n                test_file.write_bytes(contents.encode())\n                ff(test_file, write_back=black.WriteBack.YES)\n                updated_contents: bytes = test_file.read_bytes()\n                self.assertIn(nl.encode(), updated_contents)  # type: ignore\n                if nl == \"\\n\":\n                    self.assertNotIn(b\"\\r\\n\", updated_contents)  # type: ignore\n </s> remove             sys.stdout = StringIO()\n </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> add .. autofunction:: black.prepare_input\n", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     `line_length` and `fast` options are passed to :func:`format_file_contents`.\n <mask>     \"\"\"\n <mask>     if src.suffix == \".pyi\":\n <mask>         mode |= FileMode.PYI\n <mask>     with tokenize.open(src) as src_buffer:\n <mask>         src_contents = src_buffer.read()\n <mask>     try:\n <mask>         dst_contents = format_file_contents(\n <mask>             src_contents, line_length=line_length, fast=fast, mode=mode\n <mask>         )\n <mask>     except NothingChanged:\n </s> Preserve line endings when formatting a file in place (#288) </s> remove     src = sys.stdin.read()\n </s> add     newline, encoding, src = prepare_input(sys.stdin.buffer.read()) </s> remove         with open(src, \"w\", encoding=src_buffer.encoding) as f:\n </s> add         with open(src, \"w\", encoding=encoding, newline=newline) as f: </s> add def prepare_input(src: bytes) -> Tuple[str, str, str]:\n    \"\"\"Analyze `src` and return a tuple of (newline, encoding, decoded_contents)\n\n    Where `newline` is either CRLF or LF, and `decoded_contents` is decoded with\n    universal newlines (i.e. only LF).\n    \"\"\"\n    srcbuf = io.BytesIO(src)\n    encoding, lines = tokenize.detect_encoding(srcbuf.readline)\n    newline = \"\\r\\n\" if b\"\\r\\n\" == lines[0][-2:] else \"\\n\"\n    srcbuf.seek(0)\n    return newline, encoding, io.TextIOWrapper(srcbuf, encoding).read()\n\n </s> remove             sys.stdout.write(diff(src, dst, src_name, dst_name))\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff(src, dst, src_name, dst_name))\n            f.detach() </s> add     def test_preserves_line_endings(self) -> None:\n        with TemporaryDirectory() as workspace:\n            test_file = Path(workspace) / \"test.py\"\n            for nl in [\"\\n\", \"\\r\\n\"]:\n                contents = nl.join([\"def f(  ):\", \"    pass\"])\n                test_file.write_bytes(contents.encode())\n                ff(test_file, write_back=black.WriteBack.YES)\n                updated_contents: bytes = test_file.read_bytes()\n                self.assertIn(nl.encode(), updated_contents)  # type: ignore\n                if nl == \"\\n\":\n                    self.assertNotIn(b\"\\r\\n\", updated_contents)  # type: ignore\n </s> remove             sys.stdout.write(dst)\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(dst)\n            f.detach()", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     except NothingChanged:\n <mask>         return False\n <mask> \n <mask>     if write_back == write_back.YES:\n <mask>         with open(src, \"w\", encoding=src_buffer.encoding) as f:\n <mask>             f.write(dst_contents)\n <mask>     elif write_back == write_back.DIFF:\n <mask>         src_name = f\"{src}  (original)\"\n <mask>         dst_name = f\"{src}  (formatted)\"\n <mask>         diff_contents = diff(src_contents, dst_contents, src_name, dst_name)\n </s> Preserve line endings when formatting a file in place (#288) </s> remove             sys.stdout.write(dst)\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(dst)\n            f.detach() </s> remove             sys.stdout.write(diff(src, dst, src_name, dst_name))\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff(src, dst, src_name, dst_name))\n            f.detach() </s> remove             sys.stdout.write(diff_contents)\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff_contents)\n            f.detach() </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()\n </s> add     with open(src, \"rb\") as buf:\n        newline, encoding, src_contents = prepare_input(buf.read()) </s> add     def test_preserves_line_endings(self) -> None:\n        with TemporaryDirectory() as workspace:\n            test_file = Path(workspace) / \"test.py\"\n            for nl in [\"\\n\", \"\\r\\n\"]:\n                contents = nl.join([\"def f(  ):\", \"    pass\"])\n                test_file.write_bytes(contents.encode())\n                ff(test_file, write_back=black.WriteBack.YES)\n                updated_contents: bytes = test_file.read_bytes()\n                self.assertIn(nl.encode(), updated_contents)  # type: ignore\n                if nl == \"\\n\":\n                    self.assertNotIn(b\"\\r\\n\", updated_contents)  # type: ignore\n </s> add def prepare_input(src: bytes) -> Tuple[str, str, str]:\n    \"\"\"Analyze `src` and return a tuple of (newline, encoding, decoded_contents)\n\n    Where `newline` is either CRLF or LF, and `decoded_contents` is decoded with\n    universal newlines (i.e. only LF).\n    \"\"\"\n    srcbuf = io.BytesIO(src)\n    encoding, lines = tokenize.detect_encoding(srcbuf.readline)\n    newline = \"\\r\\n\" if b\"\\r\\n\" == lines[0][-2:] else \"\\n\"\n    srcbuf.seek(0)\n    return newline, encoding, io.TextIOWrapper(srcbuf, encoding).read()\n\n", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         diff_contents = diff(src_contents, dst_contents, src_name, dst_name)\n <mask>         if lock:\n <mask>             lock.acquire()\n <mask>         try:\n <mask>             sys.stdout.write(diff_contents)\n <mask>         finally:\n <mask>             if lock:\n <mask>                 lock.release()\n <mask>     return True\n <mask> \n </s> Preserve line endings when formatting a file in place (#288) </s> remove         with open(src, \"w\", encoding=src_buffer.encoding) as f:\n </s> add         with open(src, \"w\", encoding=encoding, newline=newline) as f: </s> remove             sys.stdout.write(dst)\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(dst)\n            f.detach() </s> remove     src = sys.stdin.read()\n </s> add     newline, encoding, src = prepare_input(sys.stdin.buffer.read()) </s> remove             sys.stdout = StringIO()\n </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> remove             sys.stdout.write(diff(src, dst, src_name, dst_name))\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff(src, dst, src_name, dst_name))\n            f.detach() </s> remove         nl = \"\\r\\n\" if \"\\r\\n\" in src_txt[:1024] else \"\\n\"\n        src_txt += nl\n </s> add         src_txt += \"\\n\"", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     If `write_back` is True, write reformatted code back to stdout.\n <mask>     `line_length`, `fast`, `is_pyi`, and `force_py36` arguments are passed to\n <mask>     :func:`format_file_contents`.\n <mask>     \"\"\"\n <mask>     src = sys.stdin.read()\n <mask>     dst = src\n <mask>     try:\n <mask>         dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)\n <mask>         return True\n <mask> \n </s> Preserve line endings when formatting a file in place (#288) </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()\n </s> add     with open(src, \"rb\") as buf:\n        newline, encoding, src_contents = prepare_input(buf.read()) </s> add def prepare_input(src: bytes) -> Tuple[str, str, str]:\n    \"\"\"Analyze `src` and return a tuple of (newline, encoding, decoded_contents)\n\n    Where `newline` is either CRLF or LF, and `decoded_contents` is decoded with\n    universal newlines (i.e. only LF).\n    \"\"\"\n    srcbuf = io.BytesIO(src)\n    encoding, lines = tokenize.detect_encoding(srcbuf.readline)\n    newline = \"\\r\\n\" if b\"\\r\\n\" == lines[0][-2:] else \"\\n\"\n    srcbuf.seek(0)\n    return newline, encoding, io.TextIOWrapper(srcbuf, encoding).read()\n\n </s> remove             sys.stdout.write(diff_contents)\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff_contents)\n            f.detach() </s> remove             sys.stdout = StringIO()\n </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep replace keep keep", "code_tokens": " <mask>         return False\n <mask> \n <mask>     finally:\n <mask>         if write_back == WriteBack.YES:\n <mask>             sys.stdout.write(dst)\n <mask>         elif write_back == WriteBack.DIFF:\n <mask>             src_name = \"<stdin>  (original)\"\n <mask>             dst_name = \"<stdin>  (formatted)\"\n <mask>             sys.stdout.write(diff(src, dst, src_name, dst_name))\n <mask> \n <mask> \n </s> Preserve line endings when formatting a file in place (#288) </s> remove         with open(src, \"w\", encoding=src_buffer.encoding) as f:\n </s> add         with open(src, \"w\", encoding=encoding, newline=newline) as f: </s> remove             sys.stdout.write(diff_contents)\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff_contents)\n            f.detach() </s> remove             sys.stdout = StringIO()\n </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> add def prepare_input(src: bytes) -> Tuple[str, str, str]:\n    \"\"\"Analyze `src` and return a tuple of (newline, encoding, decoded_contents)\n\n    Where `newline` is either CRLF or LF, and `decoded_contents` is decoded with\n    universal newlines (i.e. only LF).\n    \"\"\"\n    srcbuf = io.BytesIO(src)\n    encoding, lines = tokenize.detect_encoding(srcbuf.readline)\n    newline = \"\\r\\n\" if b\"\\r\\n\" == lines[0][-2:] else \"\\n\"\n    srcbuf.seek(0)\n    return newline, encoding, io.TextIOWrapper(srcbuf, encoding).read()\n\n </s> add     def test_preserves_line_endings(self) -> None:\n        with TemporaryDirectory() as workspace:\n            test_file = Path(workspace) / \"test.py\"\n            for nl in [\"\\n\", \"\\r\\n\"]:\n                contents = nl.join([\"def f(  ):\", \"    pass\"])\n                test_file.write_bytes(contents.encode())\n                ff(test_file, write_back=black.WriteBack.YES)\n                updated_contents: bytes = test_file.read_bytes()\n                self.assertIn(nl.encode(), updated_contents)  # type: ignore\n                if nl == \"\\n\":\n                    self.assertNotIn(b\"\\r\\n\", updated_contents)  # type: ignore\n", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> GRAMMARS = [\n <mask>     pygram.python_grammar_no_print_statement_no_exec_statement,\n <mask>     pygram.python_grammar_no_print_statement,\n <mask>     pygram.python_grammar,\n </s> Preserve line endings when formatting a file in place (#288) </s> remove             sys.stdout = StringIO()\n </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove     src = sys.stdin.read()\n </s> add     newline, encoding, src = prepare_input(sys.stdin.buffer.read()) </s> remove             sys.stdout.write(dst)\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(dst)\n            f.detach() </s> remove         nl = \"\\r\\n\" if \"\\r\\n\" in src_txt[:1024] else \"\\n\"\n        src_txt += nl\n </s> add         src_txt += \"\\n\"", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> def lib2to3_parse(src_txt: str) -> Node:\n <mask>     \"\"\"Given a string with source, return the lib2to3 Node.\"\"\"\n <mask>     grammar = pygram.python_grammar_no_print_statement\n <mask>     if src_txt[-1] != \"\\n\":\n <mask>         nl = \"\\r\\n\" if \"\\r\\n\" in src_txt[:1024] else \"\\n\"\n <mask>         src_txt += nl\n <mask>     for grammar in GRAMMARS:\n <mask>         drv = driver.Driver(grammar, pytree.convert)\n <mask>         try:\n <mask>             result = drv.parse_string(src_txt, True)\n <mask>             break\n </s> Preserve line endings when formatting a file in place (#288) </s> add     def test_preserves_line_endings(self) -> None:\n        with TemporaryDirectory() as workspace:\n            test_file = Path(workspace) / \"test.py\"\n            for nl in [\"\\n\", \"\\r\\n\"]:\n                contents = nl.join([\"def f(  ):\", \"    pass\"])\n                test_file.write_bytes(contents.encode())\n                ff(test_file, write_back=black.WriteBack.YES)\n                updated_contents: bytes = test_file.read_bytes()\n                self.assertIn(nl.encode(), updated_contents)  # type: ignore\n                if nl == \"\\n\":\n                    self.assertNotIn(b\"\\r\\n\", updated_contents)  # type: ignore\n </s> add def prepare_input(src: bytes) -> Tuple[str, str, str]:\n    \"\"\"Analyze `src` and return a tuple of (newline, encoding, decoded_contents)\n\n    Where `newline` is either CRLF or LF, and `decoded_contents` is decoded with\n    universal newlines (i.e. only LF).\n    \"\"\"\n    srcbuf = io.BytesIO(src)\n    encoding, lines = tokenize.detect_encoding(srcbuf.readline)\n    newline = \"\\r\\n\" if b\"\\r\\n\" == lines[0][-2:] else \"\\n\"\n    srcbuf.seek(0)\n    return newline, encoding, io.TextIOWrapper(srcbuf, encoding).read()\n\n </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove         with open(src, \"w\", encoding=src_buffer.encoding) as f:\n </s> add         with open(src, \"w\", encoding=encoding, newline=newline) as f: </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()\n </s> add     with open(src, \"rb\") as buf:\n        newline, encoding, src_contents = prepare_input(buf.read())", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> .. autofunction:: black.lib2to3_unparse\n <mask> \n <mask> Split functions\n <mask> ---------------\n <mask> \n <mask> .. autofunction:: black.delimiter_split\n <mask> \n <mask> .. autofunction:: black.left_hand_split\n </s> Preserve line endings when formatting a file in place (#288) </s> add     def test_preserves_line_endings(self) -> None:\n        with TemporaryDirectory() as workspace:\n            test_file = Path(workspace) / \"test.py\"\n            for nl in [\"\\n\", \"\\r\\n\"]:\n                contents = nl.join([\"def f(  ):\", \"    pass\"])\n                test_file.write_bytes(contents.encode())\n                ff(test_file, write_back=black.WriteBack.YES)\n                updated_contents: bytes = test_file.read_bytes()\n                self.assertIn(nl.encode(), updated_contents)  # type: ignore\n                if nl == \"\\n\":\n                    self.assertNotIn(b\"\\r\\n\", updated_contents)  # type: ignore\n </s> remove             sys.stdout = StringIO()\n </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove from io import StringIO\n </s> add from io import BytesIO, TextIOWrapper </s> remove         nl = \"\\r\\n\" if \"\\r\\n\" in src_txt[:1024] else \"\\n\"\n        src_txt += nl\n </s> add         src_txt += \"\\n\"", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "docs/reference/reference_functions.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import asyncio\n <mask> from concurrent.futures import ThreadPoolExecutor\n <mask> from contextlib import contextmanager\n <mask> from functools import partial\n <mask> from io import StringIO\n <mask> import os\n <mask> from pathlib import Path\n <mask> import sys\n <mask> from tempfile import TemporaryDirectory\n <mask> from typing import Any, List, Tuple, Iterator\n </s> Preserve line endings when formatting a file in place (#288) </s> add import io </s> add     def test_preserves_line_endings(self) -> None:\n        with TemporaryDirectory() as workspace:\n            test_file = Path(workspace) / \"test.py\"\n            for nl in [\"\\n\", \"\\r\\n\"]:\n                contents = nl.join([\"def f(  ):\", \"    pass\"])\n                test_file.write_bytes(contents.encode())\n                ff(test_file, write_back=black.WriteBack.YES)\n                updated_contents: bytes = test_file.read_bytes()\n                self.assertIn(nl.encode(), updated_contents)  # type: ignore\n                if nl == \"\\n\":\n                    self.assertNotIn(b\"\\r\\n\", updated_contents)  # type: ignore\n </s> remove             sys.stdout = StringIO()\n </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> add .. autofunction:: black.prepare_input\n", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     def test_piping(self) -> None:\n <mask>         source, expected = read_data(\"../black\")\n <mask>         hold_stdin, hold_stdout = sys.stdin, sys.stdout\n <mask>         try:\n <mask>             sys.stdin, sys.stdout = StringIO(source), StringIO()\n <mask>             sys.stdin.name = \"<stdin>\"\n <mask>             black.format_stdin_to_stdout(\n <mask>                 line_length=ll, fast=True, write_back=black.WriteBack.YES\n <mask>             )\n <mask>             sys.stdout.seek(0)\n <mask>             actual = sys.stdout.read()\n </s> Preserve line endings when formatting a file in place (#288) </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove             sys.stdout = StringIO()\n </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> remove         nl = \"\\r\\n\" if \"\\r\\n\" in src_txt[:1024] else \"\\n\"\n        src_txt += nl\n </s> add         src_txt += \"\\n\" </s> add     def test_preserves_line_endings(self) -> None:\n        with TemporaryDirectory() as workspace:\n            test_file = Path(workspace) / \"test.py\"\n            for nl in [\"\\n\", \"\\r\\n\"]:\n                contents = nl.join([\"def f(  ):\", \"    pass\"])\n                test_file.write_bytes(contents.encode())\n                ff(test_file, write_back=black.WriteBack.YES)\n                updated_contents: bytes = test_file.read_bytes()\n                self.assertIn(nl.encode(), updated_contents)  # type: ignore\n                if nl == \"\\n\":\n                    self.assertNotIn(b\"\\r\\n\", updated_contents)  # type: ignore\n </s> remove             sys.stdout.write(diff(src, dst, src_name, dst_name))\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff(src, dst, src_name, dst_name))\n            f.detach() </s> add def prepare_input(src: bytes) -> Tuple[str, str, str]:\n    \"\"\"Analyze `src` and return a tuple of (newline, encoding, decoded_contents)\n\n    Where `newline` is either CRLF or LF, and `decoded_contents` is decoded with\n    universal newlines (i.e. only LF).\n    \"\"\"\n    srcbuf = io.BytesIO(src)\n    encoding, lines = tokenize.detect_encoding(srcbuf.readline)\n    newline = \"\\r\\n\" if b\"\\r\\n\" == lines[0][-2:] else \"\\n\"\n    srcbuf.seek(0)\n    return newline, encoding, io.TextIOWrapper(srcbuf, encoding).read()\n\n", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         source, _ = read_data(\"expression.py\")\n <mask>         expected, _ = read_data(\"expression.diff\")\n <mask>         hold_stdin, hold_stdout = sys.stdin, sys.stdout\n <mask>         try:\n <mask>             sys.stdin, sys.stdout = StringIO(source), StringIO()\n <mask>             sys.stdin.name = \"<stdin>\"\n <mask>             black.format_stdin_to_stdout(\n <mask>                 line_length=ll, fast=True, write_back=black.WriteBack.DIFF\n <mask>             )\n <mask>             sys.stdout.seek(0)\n <mask>             actual = sys.stdout.read()\n </s> Preserve line endings when formatting a file in place (#288) </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove             sys.stdout = StringIO()\n </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> remove         nl = \"\\r\\n\" if \"\\r\\n\" in src_txt[:1024] else \"\\n\"\n        src_txt += nl\n </s> add         src_txt += \"\\n\" </s> remove             sys.stdout.write(dst)\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(dst)\n            f.detach() </s> remove             sys.stdout.write(diff(src, dst, src_name, dst_name))\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff(src, dst, src_name, dst_name))\n            f.detach() </s> remove     src = sys.stdin.read()\n </s> add     newline, encoding, src = prepare_input(sys.stdin.buffer.read())", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         expected, _ = read_data(\"expression.diff\")\n <mask>         tmp_file = Path(black.dump_to_file(source))\n <mask>         hold_stdout = sys.stdout\n <mask>         try:\n <mask>             sys.stdout = StringIO()\n <mask>             self.assertTrue(ff(tmp_file, write_back=black.WriteBack.DIFF))\n <mask>             sys.stdout.seek(0)\n <mask>             actual = sys.stdout.read()\n <mask>             actual = actual.replace(str(tmp_file), \"<stdin>\")\n <mask>         finally:\n </s> Preserve line endings when formatting a file in place (#288) </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\"\n </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove             sys.stdout.write(dst)\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(dst)\n            f.detach() </s> remove             sys.stdout.write(diff_contents)\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff_contents)\n            f.detach() </s> remove     src = sys.stdin.read()\n </s> add     newline, encoding, src = prepare_input(sys.stdin.buffer.read()) </s> remove         nl = \"\\r\\n\" if \"\\r\\n\" in src_txt[:1024] else \"\\n\"\n        src_txt += nl\n </s> add         src_txt += \"\\n\"", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep", "code_tokens": " <mask>             self.assertEqual(result.exit_code, 2)\n <mask> \n <mask> \n <mask> if __name__ == \"__main__\":\n <mask>     unittest.main()\n </s> Preserve line endings when formatting a file in place (#288) </s> remove             sys.stdout.write(dst)\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(dst)\n            f.detach() </s> remove         with open(src, \"w\", encoding=src_buffer.encoding) as f:\n </s> add         with open(src, \"w\", encoding=encoding, newline=newline) as f: </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()\n </s> add     with open(src, \"rb\") as buf:\n        newline, encoding, src_contents = prepare_input(buf.read()) </s> remove             sys.stdout.write(diff(src, dst, src_name, dst_name))\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff(src, dst, src_name, dst_name))\n            f.detach() </s> add def prepare_input(src: bytes) -> Tuple[str, str, str]:\n    \"\"\"Analyze `src` and return a tuple of (newline, encoding, decoded_contents)\n\n    Where `newline` is either CRLF or LF, and `decoded_contents` is decoded with\n    universal newlines (i.e. only LF).\n    \"\"\"\n    srcbuf = io.BytesIO(src)\n    encoding, lines = tokenize.detect_encoding(srcbuf.readline)\n    newline = \"\\r\\n\" if b\"\\r\\n\" == lines[0][-2:] else \"\\n\"\n    srcbuf.seek(0)\n    return newline, encoding, io.TextIOWrapper(srcbuf, encoding).read()\n\n </s> remove             sys.stdout.write(diff_contents)\n </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff_contents)\n            f.detach()", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     def visit_STRING(self, leaf: Leaf) -> Iterator[Line]:\n <mask>         if is_docstring(leaf) and \"\\\\\\n\" not in leaf.value:\n <mask>             # We're ignoring docstrings with backslash newline escapes because changing\n <mask>             # indentation of those changes the AST representation of the code.\n <mask>             prefix = get_string_prefix(leaf.value)\n <mask>             docstring = leaf.value[len(prefix) :]  # Remove the prefix\n <mask>             quote_char = docstring[0]\n <mask>             # A natural way to remove the outer quotes is to do:\n <mask>             #   docstring = docstring.strip(quote_char)\n <mask>             # but that breaks on \"\"\"\"\"x\"\"\" (which is '\"\"x').\n <mask>             # So we actually need to remove the first character and the next two\n </s> Regression fix: leave R prefixes capitalization alone (#2285)\n\n`black.strings.get_string_prefix` used to lowercase the extracted\r\nprefix before returning it. This is wrong because 1) it ignores the\r\nfact we should leave R prefixes alone because of MagicPython, and 2)\r\nthere is dedicated prefix casing handling code that fixes issue 1.\r\n`.lower` is too naive.\r\n\r\nThis was originally fixed in 20.8b0, but was reintroduced since 21.4b0.\r\n\r\nI also added proper prefix normalization for docstrings by using the\r\n`black.strings.normalize_string_prefix` helper.\r\n\r\nSome more test strings were added to make sure strings with capitalized\r\nprefixes aren't treated differently (actually happened with my original\r\npatch, Jelle had to point it out to me). </s> remove         prefix = get_string_prefix(LL[string_idx].value)\n </s> add         prefix = get_string_prefix(LL[string_idx].value).lower() </s> remove             next_prefix = get_string_prefix(SS)\n </s> add             next_prefix = get_string_prefix(SS).lower() </s> remove             prefix = get_string_prefix(LL[next_str_idx].value)\n </s> add             prefix = get_string_prefix(LL[next_str_idx].value).lower() </s> remove         is_fstring = \"f\" in get_string_prefix(string)\n </s> add         is_fstring = \"f\" in get_string_prefix(string).lower() </s> remove             prefix = get_string_prefix(leaf.value)\n </s> add             prefix = get_string_prefix(leaf.value).lower() </s> remove         prefix += string[prefix_idx].lower()\n </s> add         prefix += string[prefix_idx]", "html_url": "https://github.com/psf/black/commit/00e7e12a3a412ea386806d5d4eeaed345e912940", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     prefix = \"\"\n <mask>     prefix_idx = 0\n <mask>     while string[prefix_idx] in STRING_PREFIX_CHARS:\n <mask>         prefix += string[prefix_idx].lower()\n <mask>         prefix_idx += 1\n <mask> \n <mask>     return prefix\n <mask> \n <mask> \n </s> Regression fix: leave R prefixes capitalization alone (#2285)\n\n`black.strings.get_string_prefix` used to lowercase the extracted\r\nprefix before returning it. This is wrong because 1) it ignores the\r\nfact we should leave R prefixes alone because of MagicPython, and 2)\r\nthere is dedicated prefix casing handling code that fixes issue 1.\r\n`.lower` is too naive.\r\n\r\nThis was originally fixed in 20.8b0, but was reintroduced since 21.4b0.\r\n\r\nI also added proper prefix normalization for docstrings by using the\r\n`black.strings.normalize_string_prefix` helper.\r\n\r\nSome more test strings were added to make sure strings with capitalized\r\nprefixes aren't treated differently (actually happened with my original\r\npatch, Jelle had to point it out to me). </s> remove             prefix = get_string_prefix(leaf.value)\n </s> add             prefix = get_string_prefix(leaf.value).lower() </s> remove             prefix = get_string_prefix(LL[next_str_idx].value)\n </s> add             prefix = get_string_prefix(LL[next_str_idx].value).lower() </s> remove             next_prefix = get_string_prefix(SS)\n </s> add             next_prefix = get_string_prefix(SS).lower() </s> remove             prefix = get_string_prefix(leaf.value)\n            docstring = leaf.value[len(prefix) :]  # Remove the prefix\n </s> add             docstring = normalize_string_prefix(leaf.value, self.remove_u_prefix)\n            prefix = get_string_prefix(docstring)\n            docstring = docstring[len(prefix) :]  # Remove the prefix </s> remove         prefix = get_string_prefix(LL[string_idx].value)\n </s> add         prefix = get_string_prefix(LL[string_idx].value).lower() </s> remove         is_fstring = \"f\" in get_string_prefix(string)\n </s> add         is_fstring = \"f\" in get_string_prefix(string).lower()", "html_url": "https://github.com/psf/black/commit/00e7e12a3a412ea386806d5d4eeaed345e912940", "file_name": "src/black/strings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             not prefix\n <mask>             and is_valid_index(next_str_idx)\n <mask>             and LL[next_str_idx].type == token.STRING\n <mask>         ):\n <mask>             prefix = get_string_prefix(LL[next_str_idx].value)\n <mask>             next_str_idx += 1\n <mask> \n <mask>         # The next loop merges the string group. The final string will be\n <mask>         # contained in 'S'.\n <mask>         #\n </s> Regression fix: leave R prefixes capitalization alone (#2285)\n\n`black.strings.get_string_prefix` used to lowercase the extracted\r\nprefix before returning it. This is wrong because 1) it ignores the\r\nfact we should leave R prefixes alone because of MagicPython, and 2)\r\nthere is dedicated prefix casing handling code that fixes issue 1.\r\n`.lower` is too naive.\r\n\r\nThis was originally fixed in 20.8b0, but was reintroduced since 21.4b0.\r\n\r\nI also added proper prefix normalization for docstrings by using the\r\n`black.strings.normalize_string_prefix` helper.\r\n\r\nSome more test strings were added to make sure strings with capitalized\r\nprefixes aren't treated differently (actually happened with my original\r\npatch, Jelle had to point it out to me). </s> remove             next_prefix = get_string_prefix(SS)\n </s> add             next_prefix = get_string_prefix(SS).lower() </s> remove             prefix = get_string_prefix(leaf.value)\n            docstring = leaf.value[len(prefix) :]  # Remove the prefix\n </s> add             docstring = normalize_string_prefix(leaf.value, self.remove_u_prefix)\n            prefix = get_string_prefix(docstring)\n            docstring = docstring[len(prefix) :]  # Remove the prefix </s> remove         prefix = get_string_prefix(LL[string_idx].value)\n </s> add         prefix = get_string_prefix(LL[string_idx].value).lower() </s> remove         prefix += string[prefix_idx].lower()\n </s> add         prefix += string[prefix_idx] </s> remove             prefix = get_string_prefix(leaf.value)\n </s> add             prefix = get_string_prefix(leaf.value).lower() </s> remove         is_fstring = \"f\" in get_string_prefix(string)\n </s> add         is_fstring = \"f\" in get_string_prefix(string).lower()", "html_url": "https://github.com/psf/black/commit/00e7e12a3a412ea386806d5d4eeaed345e912940", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         while is_valid_index(next_str_idx) and LL[next_str_idx].type == token.STRING:\n <mask>             num_of_strings += 1\n <mask> \n <mask>             SS = LL[next_str_idx].value\n <mask>             next_prefix = get_string_prefix(SS)\n <mask> \n <mask>             # If this is an f-string group but this substring is not prefixed\n <mask>             # with 'f'...\n <mask>             if \"f\" in prefix and \"f\" not in next_prefix:\n <mask>                 # Then we must escape any braces contained in this substring.\n </s> Regression fix: leave R prefixes capitalization alone (#2285)\n\n`black.strings.get_string_prefix` used to lowercase the extracted\r\nprefix before returning it. This is wrong because 1) it ignores the\r\nfact we should leave R prefixes alone because of MagicPython, and 2)\r\nthere is dedicated prefix casing handling code that fixes issue 1.\r\n`.lower` is too naive.\r\n\r\nThis was originally fixed in 20.8b0, but was reintroduced since 21.4b0.\r\n\r\nI also added proper prefix normalization for docstrings by using the\r\n`black.strings.normalize_string_prefix` helper.\r\n\r\nSome more test strings were added to make sure strings with capitalized\r\nprefixes aren't treated differently (actually happened with my original\r\npatch, Jelle had to point it out to me). </s> remove             prefix = get_string_prefix(LL[next_str_idx].value)\n </s> add             prefix = get_string_prefix(LL[next_str_idx].value).lower() </s> remove             prefix = get_string_prefix(leaf.value)\n            docstring = leaf.value[len(prefix) :]  # Remove the prefix\n </s> add             docstring = normalize_string_prefix(leaf.value, self.remove_u_prefix)\n            prefix = get_string_prefix(docstring)\n            docstring = docstring[len(prefix) :]  # Remove the prefix </s> remove         is_fstring = \"f\" in get_string_prefix(string)\n </s> add         is_fstring = \"f\" in get_string_prefix(string).lower() </s> remove         prefix = get_string_prefix(LL[string_idx].value)\n </s> add         prefix = get_string_prefix(LL[string_idx].value).lower() </s> remove         prefix += string[prefix_idx].lower()\n </s> add         prefix += string[prefix_idx] </s> remove             prefix = get_string_prefix(leaf.value)\n </s> add             prefix = get_string_prefix(leaf.value).lower()", "html_url": "https://github.com/psf/black/commit/00e7e12a3a412ea386806d5d4eeaed345e912940", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             if has_triple_quotes(leaf.value):\n <mask>                 return TErr(\"StringMerger does NOT merge multiline strings.\")\n <mask> \n <mask>             num_of_strings += 1\n <mask>             prefix = get_string_prefix(leaf.value)\n <mask>             if \"r\" in prefix:\n <mask>                 return TErr(\"StringMerger does NOT merge raw strings.\")\n <mask> \n <mask>             set_of_prefixes.add(prefix)\n <mask> \n </s> Regression fix: leave R prefixes capitalization alone (#2285)\n\n`black.strings.get_string_prefix` used to lowercase the extracted\r\nprefix before returning it. This is wrong because 1) it ignores the\r\nfact we should leave R prefixes alone because of MagicPython, and 2)\r\nthere is dedicated prefix casing handling code that fixes issue 1.\r\n`.lower` is too naive.\r\n\r\nThis was originally fixed in 20.8b0, but was reintroduced since 21.4b0.\r\n\r\nI also added proper prefix normalization for docstrings by using the\r\n`black.strings.normalize_string_prefix` helper.\r\n\r\nSome more test strings were added to make sure strings with capitalized\r\nprefixes aren't treated differently (actually happened with my original\r\npatch, Jelle had to point it out to me). </s> remove         prefix += string[prefix_idx].lower()\n </s> add         prefix += string[prefix_idx] </s> remove             next_prefix = get_string_prefix(SS)\n </s> add             next_prefix = get_string_prefix(SS).lower() </s> remove             prefix = get_string_prefix(leaf.value)\n            docstring = leaf.value[len(prefix) :]  # Remove the prefix\n </s> add             docstring = normalize_string_prefix(leaf.value, self.remove_u_prefix)\n            prefix = get_string_prefix(docstring)\n            docstring = docstring[len(prefix) :]  # Remove the prefix </s> remove             prefix = get_string_prefix(LL[next_str_idx].value)\n </s> add             prefix = get_string_prefix(LL[next_str_idx].value).lower() </s> remove         prefix = get_string_prefix(LL[string_idx].value)\n </s> add         prefix = get_string_prefix(LL[string_idx].value).lower() </s> remove         is_fstring = \"f\" in get_string_prefix(string)\n </s> add         is_fstring = \"f\" in get_string_prefix(string).lower()", "html_url": "https://github.com/psf/black/commit/00e7e12a3a412ea386806d5d4eeaed345e912940", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         is_valid_index = is_valid_index_factory(LL)\n <mask>         insert_str_child = insert_str_child_factory(LL[string_idx])\n <mask> \n <mask>         prefix = get_string_prefix(LL[string_idx].value)\n <mask> \n <mask>         # We MAY choose to drop the 'f' prefix from substrings that don't\n <mask>         # contain any f-expressions, but ONLY if the original f-string\n <mask>         # contains at least one f-expression. Otherwise, we will alter the AST\n <mask>         # of the program.\n </s> Regression fix: leave R prefixes capitalization alone (#2285)\n\n`black.strings.get_string_prefix` used to lowercase the extracted\r\nprefix before returning it. This is wrong because 1) it ignores the\r\nfact we should leave R prefixes alone because of MagicPython, and 2)\r\nthere is dedicated prefix casing handling code that fixes issue 1.\r\n`.lower` is too naive.\r\n\r\nThis was originally fixed in 20.8b0, but was reintroduced since 21.4b0.\r\n\r\nI also added proper prefix normalization for docstrings by using the\r\n`black.strings.normalize_string_prefix` helper.\r\n\r\nSome more test strings were added to make sure strings with capitalized\r\nprefixes aren't treated differently (actually happened with my original\r\npatch, Jelle had to point it out to me). </s> remove             prefix = get_string_prefix(leaf.value)\n            docstring = leaf.value[len(prefix) :]  # Remove the prefix\n </s> add             docstring = normalize_string_prefix(leaf.value, self.remove_u_prefix)\n            prefix = get_string_prefix(docstring)\n            docstring = docstring[len(prefix) :]  # Remove the prefix </s> remove             prefix = get_string_prefix(LL[next_str_idx].value)\n </s> add             prefix = get_string_prefix(LL[next_str_idx].value).lower() </s> remove             next_prefix = get_string_prefix(SS)\n </s> add             next_prefix = get_string_prefix(SS).lower() </s> remove         is_fstring = \"f\" in get_string_prefix(string)\n </s> add         is_fstring = \"f\" in get_string_prefix(string).lower() </s> remove             prefix = get_string_prefix(leaf.value)\n </s> add             prefix = get_string_prefix(leaf.value).lower() </s> remove         prefix += string[prefix_idx].lower()\n </s> add         prefix += string[prefix_idx]", "html_url": "https://github.com/psf/black/commit/00e7e12a3a412ea386806d5d4eeaed345e912940", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     _fexpr_slices.append(match.span())\n <mask> \n <mask>             yield from _fexpr_slices\n <mask> \n <mask>         is_fstring = \"f\" in get_string_prefix(string)\n <mask> \n <mask>         def breaks_fstring_expression(i: Index) -> bool:\n <mask>             \"\"\"\n <mask>             Returns:\n <mask>                 True iff returning @i would result in the splitting of an\n </s> Regression fix: leave R prefixes capitalization alone (#2285)\n\n`black.strings.get_string_prefix` used to lowercase the extracted\r\nprefix before returning it. This is wrong because 1) it ignores the\r\nfact we should leave R prefixes alone because of MagicPython, and 2)\r\nthere is dedicated prefix casing handling code that fixes issue 1.\r\n`.lower` is too naive.\r\n\r\nThis was originally fixed in 20.8b0, but was reintroduced since 21.4b0.\r\n\r\nI also added proper prefix normalization for docstrings by using the\r\n`black.strings.normalize_string_prefix` helper.\r\n\r\nSome more test strings were added to make sure strings with capitalized\r\nprefixes aren't treated differently (actually happened with my original\r\npatch, Jelle had to point it out to me). </s> remove             next_prefix = get_string_prefix(SS)\n </s> add             next_prefix = get_string_prefix(SS).lower() </s> remove             prefix = get_string_prefix(leaf.value)\n            docstring = leaf.value[len(prefix) :]  # Remove the prefix\n </s> add             docstring = normalize_string_prefix(leaf.value, self.remove_u_prefix)\n            prefix = get_string_prefix(docstring)\n            docstring = docstring[len(prefix) :]  # Remove the prefix </s> remove         prefix = get_string_prefix(LL[string_idx].value)\n </s> add         prefix = get_string_prefix(LL[string_idx].value).lower() </s> remove             prefix = get_string_prefix(LL[next_str_idx].value)\n </s> add             prefix = get_string_prefix(LL[next_str_idx].value).lower() </s> remove         prefix += string[prefix_idx].lower()\n </s> add         prefix += string[prefix_idx] </s> remove             prefix = get_string_prefix(leaf.value)\n </s> add             prefix = get_string_prefix(leaf.value).lower()", "html_url": "https://github.com/psf/black/commit/00e7e12a3a412ea386806d5d4eeaed345e912940", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             sys.stdout.buffer, encoding=encoding, newline=newline, write_through=True\n <mask>         )\n <mask>         if write_back == WriteBack.YES:\n <mask>             # Make sure there's a newline after the content\n <mask>             dst += \"\" if dst[-1] == \"\\n\" else \"\\n\"\n <mask>             f.write(dst)\n <mask>         elif write_back in (WriteBack.DIFF, WriteBack.COLOR_DIFF):\n <mask>             now = datetime.utcnow()\n <mask>             src_name = f\"STDIN\\t{then} +0000\"\n <mask>             dst_name = f\"STDOUT\\t{now} +0000\"\n </s> Accept empty stdin (close #2337) (#2346)\n\nCommit history before merge:\r\n\r\n* Accept empty stdin (close #2337)\r\n* Update tests/test_black.py\r\n* Add changelog\r\n* Assert Black reformats an empty string to an empty string (#2337) (#2346)\r\n* fix </s> add     def test_reformat_one_with_stdin_empty(self) -> None:\n        output = io.StringIO()\n        with patch(\"io.TextIOWrapper\", lambda *args, **kwargs: output):\n            try:\n                black.format_stdin_to_stdout(\n                    fast=True,\n                    content=\"\",\n                    write_back=black.WriteBack.YES,\n                    mode=DEFAULT_MODE,\n                )\n            except io.UnsupportedOperation:\n                pass  # StringIO does not support detach\n            assert output.getvalue() == \"\"\n </s> add import io", "html_url": "https://github.com/psf/black/commit/017aafea992ca1c6d7af45d3013af7ddb7fda12a", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> from contextlib import contextmanager\n <mask> from dataclasses import replace\n <mask> import inspect\n <mask> from io import BytesIO\n <mask> import os\n <mask> from pathlib import Path\n <mask> from platform import system\n <mask> import regex as re\n </s> Accept empty stdin (close #2337) (#2346)\n\nCommit history before merge:\r\n\r\n* Accept empty stdin (close #2337)\r\n* Update tests/test_black.py\r\n* Add changelog\r\n* Assert Black reformats an empty string to an empty string (#2337) (#2346)\r\n* fix </s> add     def test_reformat_one_with_stdin_empty(self) -> None:\n        output = io.StringIO()\n        with patch(\"io.TextIOWrapper\", lambda *args, **kwargs: output):\n            try:\n                black.format_stdin_to_stdout(\n                    fast=True,\n                    content=\"\",\n                    write_back=black.WriteBack.YES,\n                    mode=DEFAULT_MODE,\n                )\n            except io.UnsupportedOperation:\n                pass  # StringIO does not support detach\n            assert output.getvalue() == \"\"\n </s> remove             dst += \"\" if dst[-1] == \"\\n\" else \"\\n\"\n </s> add             if dst and dst[-1] != \"\\n\":\n                dst += \"\\n\"", "html_url": "https://github.com/psf/black/commit/017aafea992ca1c6d7af45d3013af7ddb7fda12a", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>             # __BLACK_STDIN_FILENAME__ should have been stripped\n <mask>             report.done.assert_called_with(expected, black.Changed.YES)\n <mask> \n <mask>     def test_gitignore_exclude(self) -> None:\n <mask>         path = THIS_DIR / \"data\" / \"include_exclude_tests\"\n <mask>         include = re.compile(r\"\\.pyi?$\")\n <mask>         exclude = re.compile(r\"\")\n <mask>         report = black.Report()\n <mask>         gitignore = PathSpec.from_lines(\n </s> Accept empty stdin (close #2337) (#2346)\n\nCommit history before merge:\r\n\r\n* Accept empty stdin (close #2337)\r\n* Update tests/test_black.py\r\n* Add changelog\r\n* Assert Black reformats an empty string to an empty string (#2337) (#2346)\r\n* fix </s> remove             dst += \"\" if dst[-1] == \"\\n\" else \"\\n\"\n </s> add             if dst and dst[-1] != \"\\n\":\n                dst += \"\\n\" </s> add import io", "html_url": "https://github.com/psf/black/commit/017aafea992ca1c6d7af45d3013af7ddb7fda12a", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     else:\n <mask>         ast3 = ast\n <mask> \n <mask> \n <mask> PY310_HINT: Final = \"Consider using --target-version py310 to parse Python 3.10 code.\"\n <mask> PY2_HINT: Final = \"Python 2 support was removed in version 22.0.\"\n <mask> \n <mask> \n <mask> class InvalidInput(ValueError):\n <mask>     \"\"\"Raised when input source code fails all parse attempts.\"\"\"\n </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> add             # Python 3.10+\n            pygram.python_grammar_soft_keywords, </s> remove     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords)\n </s> add  </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None\n </s> add         # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)] </s> add     python_grammar.version = (2, 0)\n </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\")\n </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            ) </s> add     errors = {}", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>             pygram.python_grammar_no_print_statement_no_exec_statement_async_keywords,\n <mask>             # Python 3.0-3.6\n <mask>             pygram.python_grammar_no_print_statement_no_exec_statement,\n <mask>         ]\n <mask> \n <mask>     grammars = []\n <mask>     # If we have to parse both, try to parse async as a keyword first\n <mask>     if not supports_feature(\n <mask>         target_versions, Feature.ASYNC_IDENTIFIERS\n </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords)\n </s> add  </s> remove PY310_HINT: Final = \"Consider using --target-version py310 to parse Python 3.10 code.\"\n </s> add  </s> add     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords)\n </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\")\n </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            ) </s> add         self.version: Tuple[int, int] = (0, 0) </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None\n </s> add         # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)]", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             pygram.python_grammar_no_print_statement_no_exec_statement,\n <mask>         ]\n <mask> \n <mask>     grammars = []\n <mask>     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n <mask>         # Python 3.10+\n <mask>         grammars.append(pygram.python_grammar_soft_keywords)\n <mask>     # If we have to parse both, try to parse async as a keyword first\n <mask>     if not supports_feature(\n <mask>         target_versions, Feature.ASYNC_IDENTIFIERS\n <mask>     ) and not supports_feature(target_versions, Feature.PATTERN_MATCHING):\n <mask>         # Python 3.7-3.9\n </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> add             # Python 3.10+\n            pygram.python_grammar_soft_keywords, </s> add     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords)\n </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\")\n </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            ) </s> remove PY310_HINT: Final = \"Consider using --target-version py310 to parse Python 3.10 code.\"\n </s> add  </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None\n </s> add         # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)] </s> add         self.version: Tuple[int, int] = (0, 0)", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>         )\n <mask>     if not supports_feature(target_versions, Feature.ASYNC_KEYWORDS):\n <mask>         # Python 3.0-3.6\n <mask>         grammars.append(pygram.python_grammar_no_print_statement_no_exec_statement)\n <mask>     # At least one of the above branches must have been taken, because every Python\n <mask>     # version has exactly one of the two 'ASYNC_*' flags\n <mask>     return grammars\n <mask> \n <mask> \n </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords)\n </s> add  </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None\n </s> add         # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)] </s> add             # Python 3.10+\n            pygram.python_grammar_soft_keywords, </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\")\n </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            ) </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.version = (3, 7) </s> add     python_grammar.version = (2, 0)\n", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     grammars = get_grammars(set(target_versions))\n <mask>     for grammar in grammars:\n <mask>         drv = driver.Driver(grammar)\n <mask>         try:\n <mask>             result = drv.parse_string(src_txt, True)\n <mask>             break\n <mask> \n </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {faulty_line}\")\n </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {faulty_line}\"\n            ) </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None\n </s> add         # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)] </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\")\n </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            ) </s> remove PY310_HINT: Final = \"Consider using --target-version py310 to parse Python 3.10 code.\"\n </s> add  </s> add         new.version = self.version </s> add     python_grammar_soft_keywords.version = (3, 10)", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace", "code_tokens": " <mask>             except IndexError:\n <mask>                 faulty_line = \"<line number missing in source>\"\n <mask>             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {faulty_line}\")\n <mask> \n <mask>         except TokenError as te:\n <mask>             # In edge cases these are raised; and typically don't have a \"faulty_line\".\n <mask>             lineno, column = te.args[1]\n <mask>             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\")\n </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None\n </s> add         # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)] </s> remove     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords)\n </s> add  </s> add         self.version: Tuple[int, int] = (0, 0) </s> remove def test_patma_hint() -> None:\n    source, expected = read_data(\"pattern_matching_simple\")\n    mode = black.Mode(target_versions={black.TargetVersion.PY39})\n    with pytest.raises(black.parsing.InvalidInput) as exc_info:\n        assert_format(source, expected, mode, minimum_version=(3, 10))\n\n    exc_info.match(black.parsing.PY310_HINT)\n\n\n </s> add  </s> add     errors = {}", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             lineno, column = te.args[1]\n <mask>             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\")\n <mask> \n <mask>     else:\n <mask>         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n <mask>             src_txt, pygram.python_grammar_soft_keywords\n <mask>         ):\n <mask>             original_msg = exc.args[0]\n <mask>             msg = f\"{original_msg}\\n{PY310_HINT}\"\n <mask>             raise InvalidInput(msg) from None\n <mask> \n <mask>         if matches_grammar(src_txt, pygram.python_grammar) or matches_grammar(\n <mask>             src_txt, pygram.python_grammar_no_print_statement\n <mask>         ):\n <mask>             original_msg = exc.args[0]\n </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\")\n </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            ) </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {faulty_line}\")\n </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {faulty_line}\"\n            ) </s> add     python_grammar.version = (2, 0)\n </s> add     errors = {} </s> remove     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords)\n </s> add  </s> remove PY310_HINT: Final = \"Consider using --target-version py310 to parse Python 3.10 code.\"\n </s> add ", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         self.tokens: Dict[int, int] = {}\n <mask>         self.symbol2label: Dict[str, int] = {}\n <mask>         self.start = 256\n <mask>         # Python 3.7+ parses async as a keyword, not an identifier\n <mask>         self.async_keywords = False\n <mask> \n <mask>     def dump(self, filename: Path) -> None:\n </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> add         new.version = self.version </s> add def test_python_310_without_target_version() -> None:\n    source, expected = read_data(\"pattern_matching_simple\")\n    mode = black.Mode()\n    assert_format(source, expected, mode, minimum_version=(3, 10))\n\n </s> add     errors = {} </s> remove def test_patma_hint() -> None:\n    source, expected = read_data(\"pattern_matching_simple\")\n    mode = black.Mode(target_versions={black.TargetVersion.PY39})\n    with pytest.raises(black.parsing.InvalidInput) as exc_info:\n        assert_format(source, expected, mode, minimum_version=(3, 10))\n\n    exc_info.match(black.parsing.PY310_HINT)\n\n\n </s> add  </s> add     python_grammar_no_print_statement_no_exec_statement.version = (3, 0) </s> add             # Python 3.10+\n            pygram.python_grammar_soft_keywords,", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/blib2to3/pgen2/grammar.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         new.labels = self.labels[:]\n <mask>         new.states = self.states[:]\n <mask>         new.start = self.start\n <mask>         new.async_keywords = self.async_keywords\n <mask>         return new\n <mask> \n <mask>     def report(self) -> None:\n </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> add         self.version: Tuple[int, int] = (0, 0) </s> add def test_python_310_without_target_version() -> None:\n    source, expected = read_data(\"pattern_matching_simple\")\n    mode = black.Mode()\n    assert_format(source, expected, mode, minimum_version=(3, 10))\n\n </s> remove def test_patma_hint() -> None:\n    source, expected = read_data(\"pattern_matching_simple\")\n    mode = black.Mode(target_versions={black.TargetVersion.PY39})\n    with pytest.raises(black.parsing.InvalidInput) as exc_info:\n        assert_format(source, expected, mode, minimum_version=(3, 10))\n\n    exc_info.match(black.parsing.PY310_HINT)\n\n\n </s> add  </s> add     python_grammar_soft_keywords.version = (3, 10) </s> add     errors = {} </s> add     python_grammar.version = (2, 0)\n", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/blib2to3/pgen2/grammar.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     # Python 2\n <mask>     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE, cache_dir)\n <mask>     soft_keywords = python_grammar.soft_keywords.copy()\n <mask>     python_grammar.soft_keywords.clear()\n <mask> \n <mask>     python_symbols = _python_symbols(python_grammar)\n <mask> \n <mask>     # Python 2 + from __future__ import print_function\n </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove PY310_HINT: Final = \"Consider using --target-version py310 to parse Python 3.10 code.\"\n </s> add  </s> add     python_grammar_soft_keywords.version = (3, 10) </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None\n </s> add         # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)] </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.version = (3, 7) </s> add     python_grammar_no_print_statement_no_exec_statement.version = (3, 0) </s> add         self.version: Tuple[int, int] = (0, 0)", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/blib2to3/pygram.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     del python_grammar_no_print_statement_no_exec_statement.keywords[\"print\"]\n <mask>     del python_grammar_no_print_statement_no_exec_statement.keywords[\"exec\"]\n <mask> \n <mask>     # Python 3.7+\n <mask>     python_grammar_no_print_statement_no_exec_statement_async_keywords = (\n <mask>         python_grammar_no_print_statement_no_exec_statement.copy()\n <mask>     )\n </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.version = (3, 7) </s> add         self.version: Tuple[int, int] = (0, 0) </s> add     python_grammar.version = (2, 0)\n </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {faulty_line}\")\n </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {faulty_line}\"\n            ) </s> remove     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords)\n </s> add  </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\")\n </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            )", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/blib2to3/pygram.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         True\n <mask>     )\n <mask> \n <mask>     # Python 3.10+\n <mask>     python_grammar_soft_keywords = (\n <mask>         python_grammar_no_print_statement_no_exec_statement_async_keywords.copy()\n </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> add     python_grammar_no_print_statement_no_exec_statement.version = (3, 0) </s> add     python_grammar_soft_keywords.version = (3, 10) </s> remove     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords)\n </s> add  </s> add             # Python 3.10+\n            pygram.python_grammar_soft_keywords, </s> add     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords)\n </s> add     python_grammar.version = (2, 0)\n", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/blib2to3/pygram.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         python_grammar_no_print_statement_no_exec_statement_async_keywords.copy()\n <mask>     )\n <mask>     python_grammar_soft_keywords.soft_keywords = soft_keywords\n <mask> \n <mask>     pattern_grammar = driver.load_packaged_grammar(\n <mask>         \"blib2to3\", _PATTERN_GRAMMAR_FILE, cache_dir\n <mask>     )\n <mask>     pattern_symbols = _pattern_symbols(pattern_grammar)\n </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.version = (3, 7) </s> add     python_grammar.version = (2, 0)\n </s> add     python_grammar_no_print_statement_no_exec_statement.version = (3, 0) </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {faulty_line}\")\n </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {faulty_line}\"\n            ) </s> add         new.version = self.version </s> add     errors = {}", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/blib2to3/pygram.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def test_patma_invalid() -> None:\n <mask>     source, expected = read_data(\"pattern_matching_invalid\")\n <mask>     mode = black.Mode(target_versions={black.TargetVersion.PY310})\n <mask>     with pytest.raises(black.parsing.InvalidInput) as exc_info:\n </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove def test_patma_hint() -> None:\n    source, expected = read_data(\"pattern_matching_simple\")\n    mode = black.Mode(target_versions={black.TargetVersion.PY39})\n    with pytest.raises(black.parsing.InvalidInput) as exc_info:\n        assert_format(source, expected, mode, minimum_version=(3, 10))\n\n    exc_info.match(black.parsing.PY310_HINT)\n\n\n </s> add  </s> add         new.version = self.version </s> add         self.version: Tuple[int, int] = (0, 0) </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {faulty_line}\")\n </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {faulty_line}\"\n            ) </s> add     python_grammar_soft_keywords.version = (3, 10) </s> add     errors = {}", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     exc_info.match(\"Cannot parse: 10:11\")\n <mask> \n <mask> \n <mask> def test_patma_hint() -> None:\n <mask>     source, expected = read_data(\"pattern_matching_simple\")\n <mask>     mode = black.Mode(target_versions={black.TargetVersion.PY39})\n <mask>     with pytest.raises(black.parsing.InvalidInput) as exc_info:\n <mask>         assert_format(source, expected, mode, minimum_version=(3, 10))\n <mask> \n <mask>     exc_info.match(black.parsing.PY310_HINT)\n <mask> \n <mask> \n <mask> def test_python_2_hint() -> None:\n <mask>     with pytest.raises(black.parsing.InvalidInput) as exc_info:\n <mask>         assert_format(\"print 'daylily'\", \"print 'daylily'\")\n <mask>     exc_info.match(black.parsing.PY2_HINT)\n <mask> \n </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> add def test_python_310_without_target_version() -> None:\n    source, expected = read_data(\"pattern_matching_simple\")\n    mode = black.Mode()\n    assert_format(source, expected, mode, minimum_version=(3, 10))\n\n </s> add         new.version = self.version </s> add         self.version: Tuple[int, int] = (0, 0) </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {faulty_line}\")\n </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {faulty_line}\"\n            ) </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\")\n </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            ) </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None\n </s> add         # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)]", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import asyncio\n <mask> import pickle\n <mask> from asyncio.base_events import BaseEventLoop\n <mask> from concurrent.futures import Executor, ProcessPoolExecutor\n <mask> from enum import Enum\n <mask> from functools import partial, wraps\n <mask> import keyword\n <mask> import logging\n <mask> from multiprocessing import Manager\n <mask> import os\n </s> Refactor --pyi and --py36 into FileMode </s> remove     src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n </s> add     src: str, dst: str, line_length: int, mode: FileMode = FileMode.AUTO_DETECT </s> add     mode: FileMode, </s> remove     pyi: bool,\n    py36: bool,\n </s> add  </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     is_pyi = force_pyi or src.suffix == \".pyi\"\n\n </s> add     if src.suffix == \".pyi\":\n        mode |= FileMode.PYI </s> remove             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n </s> add             src_contents, line_length=line_length, fast=fast, mode=mode", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     YES = 2\n <mask> \n <mask> \n <mask> @click.command()\n <mask> @click.option(\n <mask>     \"-l\",\n <mask>     \"--line-length\",\n <mask>     type=int,\n </s> Refactor --pyi and --py36 into FileMode </s> remove     elt = EmptyLineTracker(is_pyi=is_pyi)\n    py36 = force_py36 or is_python36(src_node)\n </s> add     is_pyi = bool(mode & FileMode.PYI)\n    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node) </s> remove         cache = read_cache(line_length, pyi, py36)\n </s> add         cache = read_cache(line_length, mode) </s> add     elt = EmptyLineTracker(is_pyi=is_pyi) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         reformat_one(\n <mask>             src=sources[0],\n <mask>             line_length=line_length,\n <mask>             fast=fast,\n <mask>             pyi=pyi,\n <mask>             py36=py36,\n <mask>             write_back=write_back,\n <mask>             report=report,\n <mask>         )\n <mask>     else:\n <mask>         loop = asyncio.get_event_loop()\n </s> Refactor --pyi and --py36 into FileMode </s> add             mode=mode, </s> remove                     pyi=pyi,\n                    py36=py36,\n </s> add  </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back,\n </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> add                     mode=mode, </s> remove         dst = format_file_contents(\n            src,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n        )\n </s> add         dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode) </s> remove             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n </s> add             src_contents, line_length=line_length, fast=fast, mode=mode", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>             fast=fast,\n <mask>             write_back=write_back,\n <mask>             report=report,\n <mask>         )\n <mask>     else:\n <mask>         loop = asyncio.get_event_loop()\n <mask>         executor = ProcessPoolExecutor(max_workers=os.cpu_count())\n <mask>         try:\n </s> Refactor --pyi and --py36 into FileMode </s> remove             pyi=pyi,\n            py36=py36,\n </s> add  </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back,\n </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> add                     mode=mode, </s> remove                     pyi=pyi,\n                    py36=py36,\n </s> add  </s> remove         dst = format_file_contents(\n            src,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n        )\n </s> add         dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode) </s> remove             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n </s> add             src_contents, line_length=line_length, fast=fast, mode=mode", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 schedule_formatting(\n <mask>                     sources=sources,\n <mask>                     line_length=line_length,\n <mask>                     fast=fast,\n <mask>                     pyi=pyi,\n <mask>                     py36=py36,\n <mask>                     write_back=write_back,\n <mask>                     report=report,\n <mask>                     loop=loop,\n <mask>                     executor=executor,\n <mask>                 )\n </s> Refactor --pyi and --py36 into FileMode </s> remove             pyi=pyi,\n            py36=py36,\n </s> add  </s> add                     mode=mode, </s> add             mode=mode, </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back,\n </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> add                 mode=mode, </s> remove         dst = format_file_contents(\n            src,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n        )\n </s> add         dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>                     fast=fast,\n <mask>                     write_back=write_back,\n <mask>                     report=report,\n <mask>                     loop=loop,\n <mask>                     executor=executor,\n <mask>                 )\n </s> Refactor --pyi and --py36 into FileMode </s> remove                     pyi=pyi,\n                    py36=py36,\n </s> add  </s> remove             pyi=pyi,\n            py36=py36,\n </s> add  </s> add             mode=mode, </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back,\n </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> add                 mode=mode, </s> remove                 force_pyi=pyi,\n                force_py36=py36,\n </s> add ", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> def reformat_one(\n <mask>     src: Path,\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     pyi: bool,\n <mask>     py36: bool,\n <mask>     write_back: WriteBack,\n <mask>     report: \"Report\",\n <mask> ) -> None:\n <mask>     \"\"\"Reformat a single file under `src` without spawning child processes.\n <mask> \n </s> Refactor --pyi and --py36 into FileMode </s> add     mode: FileMode, </s> remove     pyi: bool,\n    py36: bool,\n </s> add  </s> add     mode: FileMode, </s> remove     force_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add ", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     src: Path,\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     write_back: WriteBack,\n <mask>     report: \"Report\",\n <mask> ) -> None:\n <mask>     \"\"\"Reformat a single file under `src` without spawning child processes.\n <mask> \n </s> Refactor --pyi and --py36 into FileMode </s> remove     pyi: bool,\n    py36: bool,\n </s> add  </s> add     mode: FileMode, </s> remove     pyi: bool,\n    py36: bool,\n </s> add  </s> remove     force_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     mode: FileMode = FileMode.AUTO_DETECT,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     try:\n <mask>         changed = Changed.NO\n <mask>         if not src.is_file() and str(src) == \"-\":\n <mask>             if format_stdin_to_stdout(\n <mask>                 line_length=line_length,\n <mask>                 fast=fast,\n <mask>                 is_pyi=pyi,\n <mask>                 force_py36=py36,\n <mask>                 write_back=write_back,\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>         else:\n <mask>             cache: Cache = {}\n <mask>             if write_back != WriteBack.DIFF:\n </s> Refactor --pyi and --py36 into FileMode </s> remove                 cache = read_cache(line_length, pyi, py36)\n </s> add                 cache = read_cache(line_length, mode) </s> remove                 force_pyi=pyi,\n                force_py36=py36,\n </s> add  </s> add                 mode=mode, </s> remove                 write_cache(cache, [src], line_length, pyi, py36)\n </s> add                 write_cache(cache, [src], line_length, mode) </s> remove         cache = read_cache(line_length, pyi, py36)\n </s> add         cache = read_cache(line_length, mode) </s> remove             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n </s> add             src_contents, line_length=line_length, fast=fast, mode=mode", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 changed = Changed.YES\n <mask>         else:\n <mask>             cache: Cache = {}\n <mask>             if write_back != WriteBack.DIFF:\n <mask>                 cache = read_cache(line_length, pyi, py36)\n <mask>                 src = src.resolve()\n <mask>                 if src in cache and cache[src] == get_cache_info(src):\n <mask>                     changed = Changed.CACHED\n <mask>             if changed is not Changed.CACHED and format_file_in_place(\n <mask>                 src,\n </s> Refactor --pyi and --py36 into FileMode </s> remove                 force_pyi=pyi,\n                force_py36=py36,\n </s> add  </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back,\n </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> remove         cache = read_cache(line_length, pyi, py36)\n </s> add         cache = read_cache(line_length, mode) </s> remove                 write_cache(cache, [src], line_length, pyi, py36)\n </s> add                 write_cache(cache, [src], line_length, mode) </s> add                 mode=mode, </s> remove     cache_file = get_cache_file(line_length, pyi, py36)\n </s> add     cache_file = get_cache_file(line_length, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             if changed is not Changed.CACHED and format_file_in_place(\n <mask>                 src,\n <mask>                 line_length=line_length,\n <mask>                 fast=fast,\n <mask>                 force_pyi=pyi,\n <mask>                 force_py36=py36,\n <mask>                 write_back=write_back,\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>             if write_back == WriteBack.YES and changed is not Changed.NO:\n <mask>                 write_cache(cache, [src], line_length, pyi, py36)\n </s> Refactor --pyi and --py36 into FileMode </s> remove                 write_cache(cache, [src], line_length, pyi, py36)\n </s> add                 write_cache(cache, [src], line_length, mode) </s> add                 mode=mode, </s> remove                 cache = read_cache(line_length, pyi, py36)\n </s> add                 cache = read_cache(line_length, mode) </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back,\n </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> remove         write_cache(cache, formatted, line_length, pyi, py36)\n </s> add         write_cache(cache, formatted, line_length, mode) </s> remove     cache_file = get_cache_file(line_length, pyi, py36)\n </s> add     cache_file = get_cache_file(line_length, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>                 line_length=line_length,\n <mask>                 fast=fast,\n <mask>                 write_back=write_back,\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>             if write_back == WriteBack.YES and changed is not Changed.NO:\n <mask>                 write_cache(cache, [src], line_length, mode)\n <mask>         report.done(src, changed)\n <mask>     except Exception as exc:\n </s> Refactor --pyi and --py36 into FileMode </s> remove                 write_cache(cache, [src], line_length, pyi, py36)\n </s> add                 write_cache(cache, [src], line_length, mode) </s> remove                 force_pyi=pyi,\n                force_py36=py36,\n </s> add  </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back,\n </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> remove         write_cache(cache, formatted, line_length, pyi, py36)\n </s> add         write_cache(cache, formatted, line_length, mode) </s> remove                 cache = read_cache(line_length, pyi, py36)\n </s> add                 cache = read_cache(line_length, mode) </s> remove             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n </s> add             src_contents, line_length=line_length, fast=fast, mode=mode", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 write_back=write_back,\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>             if write_back == WriteBack.YES and changed is not Changed.NO:\n <mask>                 write_cache(cache, [src], line_length, pyi, py36)\n <mask>         report.done(src, changed)\n <mask>     except Exception as exc:\n <mask>         report.failed(src, str(exc))\n <mask> \n <mask> \n </s> Refactor --pyi and --py36 into FileMode </s> add                 mode=mode, </s> remove                 force_pyi=pyi,\n                force_py36=py36,\n </s> add  </s> remove         write_cache(cache, formatted, line_length, pyi, py36)\n </s> add         write_cache(cache, formatted, line_length, mode) </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back,\n </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> remove                 cache = read_cache(line_length, pyi, py36)\n </s> add                 cache = read_cache(line_length, mode) </s> remove         cache = read_cache(line_length, pyi, py36)\n </s> add         cache = read_cache(line_length, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> async def schedule_formatting(\n <mask>     sources: List[Path],\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     pyi: bool,\n <mask>     py36: bool,\n <mask>     write_back: WriteBack,\n <mask>     report: \"Report\",\n <mask>     loop: BaseEventLoop,\n <mask>     executor: Executor,\n <mask> ) -> None:\n </s> Refactor --pyi and --py36 into FileMode </s> add     mode: FileMode, </s> remove     pyi: bool,\n    py36: bool,\n </s> add  </s> add     mode: FileMode, </s> remove     cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n </s> add     cache: Cache, sources: List[Path], line_length: int, mode: FileMode </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> remove     force_pyi: bool = False,\n    force_py36: bool = False,\n </s> add ", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     write_back: WriteBack,\n <mask>     report: \"Report\",\n <mask>     loop: BaseEventLoop,\n <mask>     executor: Executor,\n <mask> ) -> None:\n </s> Refactor --pyi and --py36 into FileMode </s> remove     pyi: bool,\n    py36: bool,\n </s> add  </s> remove     pyi: bool,\n    py36: bool,\n </s> add  </s> add     mode: FileMode, </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> remove     force_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> add     mode: FileMode = FileMode.AUTO_DETECT,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     :func:`format_file_in_place`.\n <mask>     \"\"\"\n <mask>     cache: Cache = {}\n <mask>     if write_back != WriteBack.DIFF:\n <mask>         cache = read_cache(line_length, pyi, py36)\n <mask>         sources, cached = filter_cached(cache, sources)\n <mask>         for src in cached:\n <mask>             report.done(src, Changed.CACHED)\n <mask>     cancelled = []\n <mask>     formatted = []\n </s> Refactor --pyi and --py36 into FileMode </s> remove                 cache = read_cache(line_length, pyi, py36)\n </s> add                 cache = read_cache(line_length, mode) </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back,\n </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> remove     cache_file = get_cache_file(line_length, pyi, py36)\n </s> add     cache_file = get_cache_file(line_length, mode) </s> remove     cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n </s> add     cache: Cache, sources: List[Path], line_length: int, mode: FileMode </s> remove     cache_file = get_cache_file(line_length, pyi, py36)\n </s> add     cache_file = get_cache_file(line_length, mode) </s> remove                 write_cache(cache, [src], line_length, pyi, py36)\n </s> add                 write_cache(cache, [src], line_length, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 format_file_in_place,\n <mask>                 src,\n <mask>                 line_length,\n <mask>                 fast,\n <mask>                 pyi,\n <mask>                 py36,\n <mask>                 write_back,\n <mask>                 lock,\n <mask>             ): src\n <mask>             for src in sorted(sources)\n <mask>         }\n </s> Refactor --pyi and --py36 into FileMode </s> add                 mode, </s> remove                 force_pyi=pyi,\n                force_py36=py36,\n </s> add  </s> remove                 cache = read_cache(line_length, pyi, py36)\n </s> add                 cache = read_cache(line_length, mode) </s> remove         cache = read_cache(line_length, pyi, py36)\n </s> add         cache = read_cache(line_length, mode) </s> remove                 write_cache(cache, [src], line_length, pyi, py36)\n </s> add                 write_cache(cache, [src], line_length, mode) </s> remove     cache_file = get_cache_file(line_length, pyi, py36)\n </s> add     cache_file = get_cache_file(line_length, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>                 fast,\n <mask>                 write_back,\n <mask>                 lock,\n <mask>             ): src\n <mask>             for src in sorted(sources)\n <mask>         }\n <mask>         pending: Iterable[asyncio.Task] = tasks.keys()\n </s> Refactor --pyi and --py36 into FileMode </s> remove                 pyi,\n                py36,\n </s> add  </s> remove         cache = read_cache(line_length, pyi, py36)\n </s> add         cache = read_cache(line_length, mode) </s> remove     cache_file = get_cache_file(line_length, pyi, py36)\n </s> add     cache_file = get_cache_file(line_length, mode) </s> add     elt = EmptyLineTracker(is_pyi=is_pyi) </s> remove                 cache = read_cache(line_length, pyi, py36)\n </s> add                 cache = read_cache(line_length, mode) </s> remove         dst = format_file_contents(\n            src,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n        )\n </s> add         dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     report.done(src, Changed.YES if task.result() else Changed.NO)\n <mask>     if cancelled:\n <mask>         await asyncio.gather(*cancelled, loop=loop, return_exceptions=True)\n <mask>     if write_back == WriteBack.YES and formatted:\n <mask>         write_cache(cache, formatted, line_length, pyi, py36)\n <mask> \n <mask> \n <mask> def format_file_in_place(\n <mask>     src: Path,\n <mask>     line_length: int,\n </s> Refactor --pyi and --py36 into FileMode </s> remove                 write_cache(cache, [src], line_length, pyi, py36)\n </s> add                 write_cache(cache, [src], line_length, mode) </s> remove                 force_pyi=pyi,\n                force_py36=py36,\n </s> add  </s> add                 mode=mode, </s> remove                 cache = read_cache(line_length, pyi, py36)\n </s> add                 cache = read_cache(line_length, mode) </s> remove def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache:\n </s> add def read_cache(line_length: int, mode: FileMode) -> Cache: </s> remove     force_pyi: bool = False,\n    force_py36: bool = False,\n </s> add ", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> def format_file_in_place(\n <mask>     src: Path,\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     force_pyi: bool = False,\n <mask>     force_py36: bool = False,\n <mask>     write_back: WriteBack = WriteBack.NO,\n <mask>     lock: Any = None,  # multiprocessing.Manager().Lock() is some crazy proxy\n <mask> ) -> bool:\n <mask>     \"\"\"Format file under `src` path. Return True if changed.\n <mask> \n </s> Refactor --pyi and --py36 into FileMode </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     pyi: bool,\n    py36: bool,\n </s> add  </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> add     mode: FileMode,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     write_back: WriteBack = WriteBack.NO,\n <mask>     lock: Any = None,  # multiprocessing.Manager().Lock() is some crazy proxy\n <mask> ) -> bool:\n <mask>     \"\"\"Format file under `src` path. Return True if changed.\n <mask> \n <mask>     If `write_back` is True, write reformatted code back to stdout.\n <mask>     `line_length` and `fast` options are passed to :func:`format_file_contents`.\n </s> Refactor --pyi and --py36 into FileMode </s> remove     force_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> remove     is_pyi = force_pyi or src.suffix == \".pyi\"\n\n </s> add     if src.suffix == \".pyi\":\n        mode |= FileMode.PYI </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     pyi: bool,\n    py36: bool,\n </s> add ", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep replace replace keep keep keep keep replace replace replace replace replace keep keep keep", "code_tokens": " <mask>     If `write_back` is True, write reformatted code back to stdout.\n <mask>     `line_length` and `fast` options are passed to :func:`format_file_contents`.\n <mask>     \"\"\"\n <mask>     is_pyi = force_pyi or src.suffix == \".pyi\"\n <mask> \n <mask>     with tokenize.open(src) as src_buffer:\n <mask>         src_contents = src_buffer.read()\n <mask>     try:\n <mask>         dst_contents = format_file_contents(\n <mask>             src_contents,\n <mask>             line_length=line_length,\n <mask>             fast=fast,\n <mask>             is_pyi=is_pyi,\n <mask>             force_py36=force_py36,\n <mask>         )\n <mask>     except NothingChanged:\n <mask>         return False\n </s> Refactor --pyi and --py36 into FileMode </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove         dst = format_file_contents(\n            src,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n        )\n </s> add         dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode) </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> remove     dst_contents = format_str(\n        src_contents, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    )\n </s> add     dst_contents = format_str(src_contents, line_length=line_length, mode=mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def format_stdin_to_stdout(\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     is_pyi: bool = False,\n <mask>     force_py36: bool = False,\n <mask>     write_back: WriteBack = WriteBack.NO,\n <mask> ) -> bool:\n <mask>     \"\"\"Format file on stdin. Return True if changed.\n <mask> \n <mask>     If `write_back` is True, write reformatted code back to stdout.\n </s> Refactor --pyi and --py36 into FileMode </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     force_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     is_pyi = force_pyi or src.suffix == \".pyi\"\n\n </s> add     if src.suffix == \".pyi\":\n        mode |= FileMode.PYI </s> remove     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> def format_stdin_to_stdout(\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     write_back: WriteBack = WriteBack.NO,\n <mask> ) -> bool:\n <mask>     \"\"\"Format file on stdin. Return True if changed.\n <mask> \n <mask>     If `write_back` is True, write reformatted code back to stdout.\n <mask>     `line_length`, `fast`, `is_pyi`, and `force_py36` arguments are passed to\n </s> Refactor --pyi and --py36 into FileMode </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     is_pyi = force_pyi or src.suffix == \".pyi\"\n\n </s> add     if src.suffix == \".pyi\":\n        mode |= FileMode.PYI </s> remove     force_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     pyi: bool,\n    py36: bool,\n </s> add ", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     src = sys.stdin.read()\n <mask>     dst = src\n <mask>     try:\n <mask>         dst = format_file_contents(\n <mask>             src,\n <mask>             line_length=line_length,\n <mask>             fast=fast,\n <mask>             is_pyi=is_pyi,\n <mask>             force_py36=force_py36,\n <mask>         )\n <mask>         return True\n <mask> \n <mask>     except NothingChanged:\n <mask>         return False\n <mask> \n </s> Refactor --pyi and --py36 into FileMode </s> remove             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n </s> add             src_contents, line_length=line_length, fast=fast, mode=mode </s> remove     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    )\n </s> add     newdst = format_str(dst, line_length=line_length, mode=mode) </s> remove         assert_stable(\n            src_contents,\n            dst_contents,\n            line_length=line_length,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n        )\n </s> add         assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode) </s> remove def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n </s> add def get_cache_file(line_length: int, mode: FileMode) -> Path:\n    pyi = bool(mode & FileMode.PYI)\n    py36 = bool(mode & FileMode.PYTHON36) </s> remove     dst_contents = format_str(\n        src_contents, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    )\n </s> add     dst_contents = format_str(src_contents, line_length=line_length, mode=mode) </s> remove     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     src_contents: str,\n <mask>     *,\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     is_pyi: bool = False,\n <mask>     force_py36: bool = False,\n <mask> ) -> FileContent:\n <mask>     \"\"\"Reformat contents a file and return new contents.\n <mask> \n <mask>     If `fast` is False, additionally confirm that the reformatted code is\n <mask>     valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.\n </s> Refactor --pyi and --py36 into FileMode </s> remove     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> remove     force_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> remove     src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n </s> add     src: str, dst: str, line_length: int, mode: FileMode = FileMode.AUTO_DETECT </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> add     mode: FileMode = FileMode.AUTO_DETECT,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     if src_contents.strip() == \"\":\n <mask>         raise NothingChanged\n <mask> \n <mask>     dst_contents = format_str(\n <mask>         src_contents, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n <mask>     )\n <mask>     if src_contents == dst_contents:\n <mask>         raise NothingChanged\n <mask> \n <mask>     if not fast:\n <mask>         assert_equivalent(src_contents, dst_contents)\n </s> Refactor --pyi and --py36 into FileMode </s> remove         assert_stable(\n            src_contents,\n            dst_contents,\n            line_length=line_length,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n        )\n </s> add         assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode) </s> remove             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n </s> add             src_contents, line_length=line_length, fast=fast, mode=mode </s> remove     is_pyi = force_pyi or src.suffix == \".pyi\"\n\n </s> add     if src.suffix == \".pyi\":\n        mode |= FileMode.PYI </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back,\n </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> remove     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    )\n </s> add     newdst = format_str(dst, line_length=line_length, mode=mode) </s> remove                 force_pyi=pyi,\n                force_py36=py36,\n </s> add ", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace replace keep keep keep keep replace replace replace replace replace keep", "code_tokens": " <mask>     if not fast:\n <mask>         assert_equivalent(src_contents, dst_contents)\n <mask>         assert_stable(\n <mask>             src_contents,\n <mask>             dst_contents,\n <mask>             line_length=line_length,\n <mask>             is_pyi=is_pyi,\n <mask>             force_py36=force_py36,\n <mask>         )\n <mask>     return dst_contents\n <mask> \n <mask> \n <mask> def format_str(\n <mask>     src_contents: str,\n <mask>     line_length: int,\n <mask>     *,\n <mask>     is_pyi: bool = False,\n <mask>     force_py36: bool = False,\n <mask> ) -> FileContent:\n </s> Refactor --pyi and --py36 into FileMode </s> remove     src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n </s> add     src: str, dst: str, line_length: int, mode: FileMode = FileMode.AUTO_DETECT </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    )\n </s> add     newdst = format_str(dst, line_length=line_length, mode=mode) </s> remove     dst_contents = format_str(\n        src_contents, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    )\n </s> add     dst_contents = format_str(src_contents, line_length=line_length, mode=mode) </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add ", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     src_node = lib2to3_parse(src_contents)\n <mask>     dst_contents = \"\"\n <mask>     future_imports = get_future_imports(src_node)\n <mask>     elt = EmptyLineTracker(is_pyi=is_pyi)\n <mask>     py36 = force_py36 or is_python36(src_node)\n <mask>     lines = LineGenerator(\n <mask>         remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n <mask>     )\n <mask>     empty_line = Line()\n <mask>     after = 0\n </s> Refactor --pyi and --py36 into FileMode </s> add     elt = EmptyLineTracker(is_pyi=is_pyi) </s> remove     is_pyi = force_pyi or src.suffix == \".pyi\"\n\n </s> add     if src.suffix == \".pyi\":\n        mode |= FileMode.PYI </s> add class FileMode(Flag):\n    AUTO_DETECT = 0\n    PYTHON36 = 1\n    PYI = 2\n\n </s> remove         cache = read_cache(line_length, pyi, py36)\n </s> add         cache = read_cache(line_length, mode) </s> remove     dst_contents = format_str(\n        src_contents, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    )\n </s> add     dst_contents = format_str(src_contents, line_length=line_length, mode=mode) </s> remove         dst = format_file_contents(\n            src,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n        )\n </s> add         dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)\n <mask>     lines = LineGenerator(\n <mask>         remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n <mask>     )\n <mask>     empty_line = Line()\n <mask>     after = 0\n <mask>     for current_line in lines.visit(src_node):\n <mask>         for _ in range(after):\n <mask>             dst_contents += str(empty_line)\n <mask>         before, after = elt.maybe_empty_lines(current_line)\n </s> Refactor --pyi and --py36 into FileMode </s> remove     elt = EmptyLineTracker(is_pyi=is_pyi)\n    py36 = force_py36 or is_python36(src_node)\n </s> add     is_pyi = bool(mode & FileMode.PYI)\n    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node) </s> remove def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n </s> add def get_cache_file(line_length: int, mode: FileMode) -> Path:\n    pyi = bool(mode & FileMode.PYI)\n    py36 = bool(mode & FileMode.PYTHON36) </s> add                 mode, </s> remove         cache = read_cache(line_length, pyi, py36)\n </s> add         cache = read_cache(line_length, mode) </s> remove     cache_file = get_cache_file(line_length, pyi, py36)\n </s> add     cache_file = get_cache_file(line_length, mode) </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36_mode)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep replace keep keep replace replace replace keep keep keep keep", "code_tokens": " <mask> \n <mask> def assert_stable(\n <mask>     src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n <mask> ) -> None:\n <mask>     \"\"\"Raise AssertionError if `dst` reformats differently the second time.\"\"\"\n <mask>     newdst = format_str(\n <mask>         dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n <mask>     )\n <mask>     if dst != newdst:\n <mask>         log = dump_to_file(\n <mask>             diff(src, dst, \"source\", \"first pass\"),\n <mask>             diff(dst, newdst, \"first pass\", \"second pass\"),\n </s> Refactor --pyi and --py36 into FileMode </s> remove     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> remove     force_pyi: bool = False,\n    force_py36: bool = False,\n </s> add  </s> remove     cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n </s> add     cache: Cache, sources: List[Path], line_length: int, mode: FileMode", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     return False\n <mask> \n <mask> \n <mask> def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n <mask>     return (\n <mask>         CACHE_DIR\n <mask>         / f\"cache.{line_length}{'.pyi' if pyi else ''}{'.py36' if py36 else ''}.pickle\"\n <mask>     )\n <mask> \n </s> Refactor --pyi and --py36 into FileMode </s> remove def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache:\n </s> add def read_cache(line_length: int, mode: FileMode) -> Cache: </s> remove     cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n </s> add     cache: Cache, sources: List[Path], line_length: int, mode: FileMode </s> remove     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT </s> remove     cache_file = get_cache_file(line_length, pyi, py36)\n </s> add     cache_file = get_cache_file(line_length, mode) </s> remove     src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n </s> add     src: str, dst: str, line_length: int, mode: FileMode = FileMode.AUTO_DETECT </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     mode: FileMode = FileMode.AUTO_DETECT,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask> def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache:\n <mask>     \"\"\"Read the cache if it exists and is well formed.\n <mask> \n <mask>     If it is not well formed, the call to write_cache later should resolve the issue.\n <mask>     \"\"\"\n <mask>     cache_file = get_cache_file(line_length, pyi, py36)\n <mask>     if not cache_file.exists():\n <mask>         return {}\n <mask> \n <mask>     with cache_file.open(\"rb\") as fobj:\n </s> Refactor --pyi and --py36 into FileMode </s> remove     cache_file = get_cache_file(line_length, pyi, py36)\n </s> add     cache_file = get_cache_file(line_length, mode) </s> remove     cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n </s> add     cache: Cache, sources: List[Path], line_length: int, mode: FileMode </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n </s> add def get_cache_file(line_length: int, mode: FileMode) -> Path:\n    pyi = bool(mode & FileMode.PYI)\n    py36 = bool(mode & FileMode.PYTHON36) </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add ", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep replace keep keep", "code_tokens": " <mask>     return todo, done\n <mask> \n <mask> \n <mask> def write_cache(\n <mask>     cache: Cache,\n <mask>     sources: List[Path],\n <mask>     line_length: int,\n <mask>     pyi: bool = False,\n <mask>     py36: bool = False,\n <mask> ) -> None:\n <mask>     \"\"\"Update the cache file.\"\"\"\n <mask>     cache_file = get_cache_file(line_length, pyi, py36)\n <mask>     try:\n <mask>         if not CACHE_DIR.exists():\n </s> Refactor --pyi and --py36 into FileMode </s> remove def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache:\n </s> add def read_cache(line_length: int, mode: FileMode) -> Cache: </s> remove def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n </s> add def get_cache_file(line_length: int, mode: FileMode) -> Path:\n    pyi = bool(mode & FileMode.PYI)\n    py36 = bool(mode & FileMode.PYTHON36) </s> remove     cache_file = get_cache_file(line_length, pyi, py36)\n </s> add     cache_file = get_cache_file(line_length, mode) </s> remove     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,\n </s> add     mode: FileMode = FileMode.AUTO_DETECT,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         black.assert_stable(source, actual, line_length=ll)\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_stub(self) -> None:\n <mask>         source, expected = read_data(\"stub.pyi\")\n <mask>         actual = fs(source, mode=mode)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_stable(source, actual, line_length=ll, mode=mode)\n </s> Refactor --pyi and --py36 into FileMode </s> remove         black.assert_stable(source, actual, line_length=ll, is_pyi=True)\n </s> add         black.assert_stable(source, actual, line_length=ll, mode=mode) </s> remove         actual = fs(source, is_pyi=True)\n </s> add         actual = fs(source, mode=mode) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI </s> remove     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    )\n </s> add     newdst = format_str(dst, line_length=line_length, mode=mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep replace keep replace", "code_tokens": " <mask>         source, expected = read_data(\"stub.pyi\")\n <mask>         actual = fs(source, is_pyi=True)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_stable(source, actual, line_length=ll, is_pyi=True)\n </s> Refactor --pyi and --py36 into FileMode </s> add         mode = black.FileMode.PYI </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI </s> remove             two = black.read_cache(2)\n </s> add             two = black.read_cache(2, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_cache_broken_file(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)\n <mask>             with cache_file.open(\"w\") as fobj:\n <mask>                 fobj.write(\"this is not a pickle\")\n </s> Refactor --pyi and --py36 into FileMode </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace keep", "code_tokens": " <mask> \n <mask>     def test_cache_broken_file(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n <mask>             with cache_file.open(\"w\") as fobj:\n <mask>                 fobj.write(\"this is not a pickle\")\n <mask>             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n <mask>             src = (workspace / \"test.py\").resolve()\n </s> Refactor --pyi and --py36 into FileMode </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> add         mode = black.FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             with src.open(\"w\") as fobj:\n <mask>                 fobj.write(\"print('hello')\")\n <mask>             result = CliRunner().invoke(black.main, [str(src)])\n <mask>             self.assertEqual(result.exit_code, 0)\n <mask>             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertIn(src, cache)\n <mask> \n <mask>     def test_cache_single_file_already_cached(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             src = (workspace / \"test.py\").resolve()\n </s> Refactor --pyi and --py36 into FileMode </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode)\n <mask>             self.assertIn(src, cache)\n <mask> \n <mask>     def test_cache_single_file_already_cached(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             src = (workspace / \"test.py\").resolve()\n <mask>             with src.open(\"w\") as fobj:\n <mask>                 fobj.write(\"print('hello')\")\n <mask>             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n </s> Refactor --pyi and --py36 into FileMode </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         with cache_dir() as workspace:\n <mask>             src = (workspace / \"test.py\").resolve()\n <mask>             with src.open(\"w\") as fobj:\n <mask>                 fobj.write(\"print('hello')\")\n <mask>             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n <mask>             result = CliRunner().invoke(black.main, [str(src)])\n <mask>             self.assertEqual(result.exit_code, 0)\n <mask>             with src.open(\"r\") as fobj:\n <mask>                 self.assertEqual(fobj.read(), \"print('hello')\")\n <mask> \n </s> Refactor --pyi and --py36 into FileMode </s> remove             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> add         mode = black.FileMode.AUTO_DETECT </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>                 self.assertEqual(fobj.read(), \"print('hello')\")\n <mask> \n <mask>     @event_loop(close=False)\n <mask>     def test_cache_multiple_files(self) -> None:\n <mask>         with cache_dir() as workspace, patch(\n <mask>             \"black.ProcessPoolExecutor\", new=ThreadPoolExecutor\n <mask>         ):\n <mask>             one = (workspace / \"one.py\").resolve()\n <mask>             with one.open(\"w\") as fobj:\n </s> Refactor --pyi and --py36 into FileMode </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [path], 1)\n            one = black.read_cache(1)\n </s> add             black.write_cache({}, [path], 1, mode)\n            one = black.read_cache(1, mode) </s> remove             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 fobj.write(\"print('hello')\")\n <mask>             two = (workspace / \"two.py\").resolve()\n <mask>             with two.open(\"w\") as fobj:\n <mask>                 fobj.write(\"print('hello')\")\n <mask>             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH)\n <mask>             result = CliRunner().invoke(black.main, [str(workspace)])\n <mask>             self.assertEqual(result.exit_code, 0)\n <mask>             with one.open(\"r\") as fobj:\n <mask>                 self.assertEqual(fobj.read(), \"print('hello')\")\n <mask>             with two.open(\"r\") as fobj:\n </s> Refactor --pyi and --py36 into FileMode </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             with one.open(\"r\") as fobj:\n <mask>                 self.assertEqual(fobj.read(), \"print('hello')\")\n <mask>             with two.open(\"r\") as fobj:\n <mask>                 self.assertEqual(fobj.read(), 'print(\"hello\")\\n')\n <mask>             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertIn(one, cache)\n <mask>             self.assertIn(two, cache)\n <mask> \n <mask>     def test_no_cache_when_writeback_diff(self) -> None:\n <mask>         with cache_dir() as workspace:\n </s> Refactor --pyi and --py36 into FileMode </s> remove             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_no_cache_when_writeback_diff(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             src = (workspace / \"test.py\").resolve()\n <mask>             with src.open(\"w\") as fobj:\n <mask>                 fobj.write(\"print('hello')\")\n <mask>             result = CliRunner().invoke(black.main, [str(src), \"--diff\"])\n </s> Refactor --pyi and --py36 into FileMode </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             with src.open(\"w\") as fobj:\n <mask>                 fobj.write(\"print('hello')\")\n <mask>             result = CliRunner().invoke(black.main, [str(src), \"--diff\"])\n <mask>             self.assertEqual(result.exit_code, 0)\n <mask>             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertFalse(cache_file.exists())\n <mask> \n <mask>     def test_no_cache_when_stdin(self) -> None:\n <mask>         with cache_dir():\n <mask>             result = CliRunner().invoke(black.main, [\"-\"], input=\"print('hello')\")\n </s> Refactor --pyi and --py36 into FileMode </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)\n <mask>             self.assertFalse(cache_file.exists())\n <mask> \n <mask>     def test_no_cache_when_stdin(self) -> None:\n <mask>         with cache_dir():\n <mask>             result = CliRunner().invoke(black.main, [\"-\"], input=\"print('hello')\")\n <mask>             self.assertEqual(result.exit_code, 0)\n <mask>             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)\n <mask>             self.assertFalse(cache_file.exists())\n </s> Refactor --pyi and --py36 into FileMode </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {})", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def test_no_cache_when_stdin(self) -> None:\n <mask>         with cache_dir():\n <mask>             result = CliRunner().invoke(black.main, [\"-\"], input=\"print('hello')\")\n <mask>             self.assertEqual(result.exit_code, 0)\n <mask>             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertFalse(cache_file.exists())\n <mask> \n <mask>     def test_read_cache_no_cachefile(self) -> None:\n <mask>         with cache_dir():\n <mask>             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n </s> Refactor --pyi and --py36 into FileMode </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_read_cache_no_cachefile(self) -> None:\n <mask>         with cache_dir():\n <mask>             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {})\n <mask> \n <mask>     def test_write_cache_read_cache(self) -> None:\n <mask>         mode = black.FileMode.AUTO_DETECT\n </s> Refactor --pyi and --py36 into FileMode </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> add         mode = black.FileMode.AUTO_DETECT </s> add         mode = black.FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             self.assertFalse(cache_file.exists())\n <mask> \n <mask>     def test_read_cache_no_cachefile(self) -> None:\n <mask>         with cache_dir():\n <mask>             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n <mask> \n <mask>     def test_write_cache_read_cache(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             src = (workspace / \"test.py\").resolve()\n <mask>             src.touch()\n </s> Refactor --pyi and --py36 into FileMode </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         with cache_dir():\n <mask>             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {})\n <mask> \n <mask>     def test_write_cache_read_cache(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             src = (workspace / \"test.py\").resolve()\n <mask>             src.touch()\n <mask>             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n <mask>             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode)\n <mask>             self.assertIn(src, cache)\n </s> Refactor --pyi and --py36 into FileMode </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     def test_write_cache_read_cache(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             src = (workspace / \"test.py\").resolve()\n <mask>             src.touch()\n <mask>             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n <mask>             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertIn(src, cache)\n <mask>             self.assertEqual(cache[src], black.get_cache_info(src))\n <mask> \n <mask>     def test_filter_cached(self) -> None:\n <mask>         with TemporaryDirectory() as workspace:\n </s> Refactor --pyi and --py36 into FileMode </s> add         mode = black.FileMode.AUTO_DETECT </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>             self.assertEqual(todo, [uncached, cached_but_changed])\n <mask>             self.assertEqual(done, [cached])\n <mask> \n <mask>     def test_write_cache_creates_directory_if_needed(self) -> None:\n <mask>         with cache_dir(exists=False) as workspace:\n <mask>             self.assertFalse(workspace.exists())\n <mask>             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH, mode)\n <mask>             self.assertTrue(workspace.exists())\n <mask> \n <mask>     @event_loop(close=False)\n </s> Refactor --pyi and --py36 into FileMode </s> remove             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [path], 1)\n            one = black.read_cache(1)\n </s> add             black.write_cache({}, [path], 1, mode)\n            one = black.read_cache(1, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             with clean.open(\"w\") as fobj:\n <mask>                 fobj.write('print(\"hello\")\\n')\n <mask>             result = CliRunner().invoke(black.main, [str(workspace)])\n <mask>             self.assertEqual(result.exit_code, 123)\n <mask>             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertNotIn(failing, cache)\n <mask>             self.assertIn(clean, cache)\n <mask> \n <mask>     def test_write_cache_write_fail(self) -> None:\n <mask>         with cache_dir(), patch.object(Path, \"open\") as mock:\n </s> Refactor --pyi and --py36 into FileMode </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_write_cache_write_fail(self) -> None:\n <mask>         with cache_dir(), patch.object(Path, \"open\") as mock:\n <mask>             mock.side_effect = OSError\n <mask>             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH, mode)\n <mask> \n <mask>     @event_loop(close=False)\n <mask>     def test_check_diff_use_together(self) -> None:\n </s> Refactor --pyi and --py36 into FileMode </s> remove             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [path], 1)\n            one = black.read_cache(1)\n </s> add             black.write_cache({}, [path], 1, mode)\n            one = black.read_cache(1, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_write_cache_write_fail(self) -> None:\n <mask>         with cache_dir(), patch.object(Path, \"open\") as mock:\n <mask>             mock.side_effect = OSError\n <mask>             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH)\n <mask> \n <mask>     @event_loop(close=False)\n <mask>     def test_check_diff_use_together(self) -> None:\n <mask>         with cache_dir():\n <mask>             # Files which will be reformatted.\n </s> Refactor --pyi and --py36 into FileMode </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_read_cache_line_lengths(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             path = (workspace / \"file.py\").resolve()\n <mask>             path.touch()\n <mask>             black.write_cache({}, [path], 1, mode)\n <mask>             one = black.read_cache(1, mode)\n <mask>             self.assertIn(path, one)\n </s> Refactor --pyi and --py36 into FileMode </s> remove             black.write_cache({}, [path], 1)\n            one = black.read_cache(1)\n </s> add             black.write_cache({}, [path], 1, mode)\n            one = black.read_cache(1, mode) </s> remove             two = black.read_cache(2)\n </s> add             two = black.read_cache(2, mode) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace keep keep", "code_tokens": " <mask>         with cache_dir() as workspace:\n <mask>             path = (workspace / \"file.py\").resolve()\n <mask>             path.touch()\n <mask>             black.write_cache({}, [path], 1)\n <mask>             one = black.read_cache(1)\n <mask>             self.assertIn(path, one)\n <mask>             two = black.read_cache(2)\n <mask>             self.assertNotIn(path, two)\n <mask> \n </s> Refactor --pyi and --py36 into FileMode </s> add         mode = black.FileMode.AUTO_DETECT </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI </s> remove             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_single_file_force_pyi(self) -> None:\n <mask>         contents, expected = read_data(\"force_pyi\")\n <mask>         with cache_dir() as workspace:\n <mask>             path = (workspace / \"file.py\").resolve()\n <mask>             with open(path, \"w\") as fh:\n <mask>                 fh.write(contents)\n <mask>             result = CliRunner().invoke(black.main, [str(path), \"--pyi\"])\n </s> Refactor --pyi and --py36 into FileMode </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI </s> remove             two = black.read_cache(2)\n </s> add             two = black.read_cache(2, mode) </s> remove             black.write_cache({}, [path], 1)\n            one = black.read_cache(1)\n </s> add             black.write_cache({}, [path], 1, mode)\n            one = black.read_cache(1, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> add         mode = black.FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace keep keep keep", "code_tokens": " <mask>             self.assertEqual(result.exit_code, 0)\n <mask>             with open(path, \"r\") as fh:\n <mask>                 actual = fh.read()\n <mask>             # verify cache with --pyi is separate\n <mask>             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True)\n <mask>             self.assertIn(path, pyi_cache)\n <mask>             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertNotIn(path, normal_cache)\n <mask>         self.assertEqual(actual, expected)\n <mask> \n </s> Refactor --pyi and --py36 into FileMode </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi_mode)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             py36_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True)\n </s> add             py36_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36_mode) </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36_mode)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>     @event_loop(close=False)\n <mask>     def test_multi_file_force_pyi(self) -> None:\n <mask>         contents, expected = read_data(\"force_pyi\")\n <mask>         with cache_dir() as workspace:\n <mask>             paths = [\n <mask>                 (workspace / \"file1.py\").resolve(),\n </s> Refactor --pyi and --py36 into FileMode </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI </s> remove             two = black.read_cache(2)\n </s> add             two = black.read_cache(2, mode) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 with open(path, \"r\") as fh:\n <mask>                     actual = fh.read()\n <mask>                 self.assertEqual(actual, expected)\n <mask>             # verify cache with --pyi is separate\n <mask>             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True)\n <mask>             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             for path in paths:\n <mask>                 self.assertIn(path, pyi_cache)\n <mask>                 self.assertNotIn(path, normal_cache)\n <mask> \n <mask>     def test_pipe_force_pyi(self) -> None:\n </s> Refactor --pyi and --py36 into FileMode </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36_mode)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True)\n </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi_mode) </s> remove             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             py36_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True)\n </s> add             py36_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36_mode) </s> remove             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         actual = result.output\n <mask>         self.assertFormatEqual(actual, expected)\n <mask> \n <mask>     def test_single_file_force_py36(self) -> None:\n <mask>         source, expected = read_data(\"force_py36\")\n <mask>         with cache_dir() as workspace:\n <mask>             path = (workspace / \"file.py\").resolve()\n <mask>             with open(path, \"w\") as fh:\n </s> Refactor --pyi and --py36 into FileMode </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         mode = black.FileMode.AUTO_DETECT </s> remove         black.assert_stable(source, actual, line_length=ll, is_pyi=True)\n </s> add         black.assert_stable(source, actual, line_length=ll, mode=mode) </s> remove             black.write_cache({}, [path], 1)\n            one = black.read_cache(1)\n </s> add             black.write_cache({}, [path], 1, mode)\n            one = black.read_cache(1, mode) </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36_mode)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace keep replace keep", "code_tokens": " <mask>                 actual = fh.read()\n <mask>             # verify cache with --py36 is separate\n <mask>             py36_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True)\n <mask>             self.assertIn(path, py36_cache)\n <mask>             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertNotIn(path, normal_cache)\n </s> Refactor --pyi and --py36 into FileMode </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36_mode)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True)\n </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi_mode) </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi_mode)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     @event_loop(close=False)\n <mask>     def test_multi_file_force_py36(self) -> None:\n <mask>         source, expected = read_data(\"force_py36\")\n <mask>         with cache_dir() as workspace:\n <mask>             paths = [\n <mask>                 (workspace / \"file1.py\").resolve(),\n </s> Refactor --pyi and --py36 into FileMode </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> remove         black.assert_stable(source, actual, line_length=ll, is_pyi=True)\n </s> add         black.assert_stable(source, actual, line_length=ll, mode=mode) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI </s> add         mode = black.FileMode.AUTO_DETECT </s> remove         actual = fs(source, is_pyi=True)\n </s> add         actual = fs(source, mode=mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 with open(path, \"r\") as fh:\n <mask>                     actual = fh.read()\n <mask>                 self.assertEqual(actual, expected)\n <mask>             # verify cache with --py36 is separate\n <mask>             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True)\n <mask>             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             for path in paths:\n <mask>                 self.assertIn(path, pyi_cache)\n <mask>                 self.assertNotIn(path, normal_cache)\n <mask> \n <mask>     def test_pipe_force_py36(self) -> None:\n </s> Refactor --pyi and --py36 into FileMode </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi_mode)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True)\n </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi_mode) </s> remove             py36_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True)\n </s> add             py36_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36_mode) </s> remove             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n </s> add             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> from blib2to3.pgen2.grammar import Grammar\n <mask> from blib2to3.pgen2.parse import ParseError\n <mask> \n <mask> \n <mask> DEFAULT_LINE_LENGTH = 88\n <mask> DEFAULT_EXCLUDES = (\n <mask>     r\"/(\\.eggs|\\.git|\\.hg|\\.mypy_cache|\\.nox|\\.tox|\\.venv|_build|buck-out|build|dist)/\"\n <mask> )\n </s> use versioneer to manage __version__ (#981) </s> remove __version__ = \"19.3b0\"\n </s> add  </s> add import versioneer </s> remove CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__))\n </s> add CACHE_DIR = Path(user_cache_dir(\"black\", version=__git_version__)) </s> remove def get_version() -> str:\n    black_py = CURRENT_DIR / \"black.py\"\n    _version_re = re.compile(r\"__version__\\s+=\\s+(?P<version>.*)\")\n    with open(black_py, \"r\", encoding=\"utf8\") as f:\n        match = _version_re.search(f.read())\n        version = match.group(\"version\") if match is not None else '\"unknown\"'\n    return str(ast.literal_eval(version))\n\n\n </s> add ", "html_url": "https://github.com/psf/black/commit/025d2ca4ba4f8e6e1f5915751eba972975dd9ff9", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from blib2to3.pgen2.grammar import Grammar\n <mask> from blib2to3.pgen2.parse import ParseError\n <mask> \n <mask> \n <mask> __version__ = \"19.3b0\"\n <mask> DEFAULT_LINE_LENGTH = 88\n <mask> DEFAULT_EXCLUDES = (\n <mask>     r\"/(\\.eggs|\\.git|\\.hg|\\.mypy_cache|\\.nox|\\.tox|\\.venv|_build|buck-out|build|dist)/\"\n <mask> )\n <mask> DEFAULT_INCLUDES = r\"\\.pyi?$\"\n </s> use versioneer to manage __version__ (#981) </s> add from _version import get_versions\n\nv = get_versions()\n__version__ = v.get(\"closest-tag\", v[\"version\"])\n__git_version__ = v.get(\"full-revisionid\") </s> remove CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__))\n </s> add CACHE_DIR = Path(user_cache_dir(\"black\", version=__git_version__)) </s> add import versioneer </s> remove def get_version() -> str:\n    black_py = CURRENT_DIR / \"black.py\"\n    _version_re = re.compile(r\"__version__\\s+=\\s+(?P<version>.*)\")\n    with open(black_py, \"r\", encoding=\"utf8\") as f:\n        match = _version_re.search(f.read())\n        version = match.group(\"version\") if match is not None else '\"unknown\"'\n    return str(ast.literal_eval(version))\n\n\n </s> add ", "html_url": "https://github.com/psf/black/commit/025d2ca4ba4f8e6e1f5915751eba972975dd9ff9", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> DEFAULT_EXCLUDES = (\n <mask>     r\"/(\\.eggs|\\.git|\\.hg|\\.mypy_cache|\\.nox|\\.tox|\\.venv|_build|buck-out|build|dist)/\"\n <mask> )\n <mask> DEFAULT_INCLUDES = r\"\\.pyi?$\"\n <mask> CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__))\n <mask> \n <mask> \n <mask> # types\n <mask> FileContent = str\n <mask> Encoding = str\n </s> use versioneer to manage __version__ (#981) </s> remove __version__ = \"19.3b0\"\n </s> add  </s> add from _version import get_versions\n\nv = get_versions()\n__version__ = v.get(\"closest-tag\", v[\"version\"])\n__git_version__ = v.get(\"full-revisionid\") </s> remove def get_version() -> str:\n    black_py = CURRENT_DIR / \"black.py\"\n    _version_re = re.compile(r\"__version__\\s+=\\s+(?P<version>.*)\")\n    with open(black_py, \"r\", encoding=\"utf8\") as f:\n        match = _version_re.search(f.read())\n        version = match.group(\"version\") if match is not None else '\"unknown\"'\n    return str(ast.literal_eval(version))\n\n\n </s> add  </s> add import versioneer", "html_url": "https://github.com/psf/black/commit/025d2ca4ba4f8e6e1f5915751eba972975dd9ff9", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> from setuptools import setup\n <mask> import sys\n <mask> \n <mask> assert sys.version_info >= (3, 6, 0), \"black requires Python 3.6+\"\n <mask> from pathlib import Path  # noqa E402\n <mask> \n <mask> CURRENT_DIR = Path(__file__).parent\n <mask> \n </s> use versioneer to manage __version__ (#981) </s> add from _version import get_versions\n\nv = get_versions()\n__version__ = v.get(\"closest-tag\", v[\"version\"])\n__git_version__ = v.get(\"full-revisionid\") </s> remove __version__ = \"19.3b0\"\n </s> add  </s> remove CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__))\n </s> add CACHE_DIR = Path(user_cache_dir(\"black\", version=__git_version__)) </s> remove def get_version() -> str:\n    black_py = CURRENT_DIR / \"black.py\"\n    _version_re = re.compile(r\"__version__\\s+=\\s+(?P<version>.*)\")\n    with open(black_py, \"r\", encoding=\"utf8\") as f:\n        match = _version_re.search(f.read())\n        version = match.group(\"version\") if match is not None else '\"unknown\"'\n    return str(ast.literal_eval(version))\n\n\n </s> add ", "html_url": "https://github.com/psf/black/commit/025d2ca4ba4f8e6e1f5915751eba972975dd9ff9", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     with open(readme_md, encoding=\"utf8\") as ld_file:\n <mask>         return ld_file.read()\n <mask> \n <mask> \n <mask> def get_version() -> str:\n <mask>     black_py = CURRENT_DIR / \"black.py\"\n <mask>     _version_re = re.compile(r\"__version__\\s+=\\s+(?P<version>.*)\")\n <mask>     with open(black_py, \"r\", encoding=\"utf8\") as f:\n <mask>         match = _version_re.search(f.read())\n <mask>         version = match.group(\"version\") if match is not None else '\"unknown\"'\n <mask>     return str(ast.literal_eval(version))\n <mask> \n <mask> \n <mask> setup(\n <mask>     name=\"black\",\n <mask>     version=get_version(),\n <mask>     description=\"The uncompromising code formatter.\",\n <mask>     long_description=get_long_description(),\n </s> use versioneer to manage __version__ (#981) </s> remove CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__))\n </s> add CACHE_DIR = Path(user_cache_dir(\"black\", version=__git_version__)) </s> add from _version import get_versions\n\nv = get_versions()\n__version__ = v.get(\"closest-tag\", v[\"version\"])\n__git_version__ = v.get(\"full-revisionid\") </s> remove __version__ = \"19.3b0\"\n </s> add  </s> add import versioneer", "html_url": "https://github.com/psf/black/commit/025d2ca4ba4f8e6e1f5915751eba972975dd9ff9", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             input=BytesIO(source.encode(\"utf8\")),\n <mask>         )\n <mask>         self.assertEqual(result.exit_code, 0)\n <mask>         self.assertFormatEqual(expected, result.output)\n <mask>         black.assert_equivalent(source, result.output)\n <mask>         black.assert_stable(source, result.output, DEFAULT_MODE)\n <mask> \n <mask>     def test_piping_diff(self) -> None:\n <mask>         diff_header = re.compile(\n <mask>             r\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n <mask>             r\"\\+\\d\\d\\d\\d\"\n </s> Speed up tests even more (#2205)\n\nThere's three optimizations in this commit:\r\n\r\n1. Don't check if Black's output is stable or equivalant if no changes\r\n   were made in the first place. It's not like passing the same code\r\n   (for both source and actual) through black.assert_equivalent or\r\n   black.assert_stable is useful. It's not a big deal for the smaller\r\n   tests, but it eats a lot of time in tests/test_format.py since\r\n   its test cases are big. This is also closer to how Black works IRL.\r\n\r\n2. Use a smaller file for `test_root_logger_not_used_directly` since\r\n   the logging it's checking happens during blib2to3's startup so the\r\n   file doesn't really matter.\r\n\r\n3. If we're checking a file is formatting (i.e. test_source_is_formatted)\r\n   don't run Black over it again with `black.format_file_in_place`.\r\n   `tests/test_format.py::TestSimpleFormat.check_file` is good enough. </s> remove         black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, mode)\n </s> add         if source != actual:\n            black.assert_equivalent(source, actual)\n            black.assert_stable(source, actual, mode) </s> remove         self.assertFalse(ff(path))\n </s> add  </s> remove             ff(THIS_FILE)\n </s> add             ff(THIS_DIR / \"util.py\") </s> remove     ff,\n </s> add ", "html_url": "https://github.com/psf/black/commit/036bea4aa0e2b9b3fe50d0d49addc811cce61fa4", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             error=fail,\n <mask>             critical=fail,\n <mask>             log=fail,\n <mask>         ):\n <mask>             ff(THIS_FILE)\n <mask> \n <mask>     def test_invalid_config_return_code(self) -> None:\n <mask>         tmp_file = Path(black.dump_to_file())\n <mask>         try:\n <mask>             tmp_config = Path(black.dump_to_file())\n </s> Speed up tests even more (#2205)\n\nThere's three optimizations in this commit:\r\n\r\n1. Don't check if Black's output is stable or equivalant if no changes\r\n   were made in the first place. It's not like passing the same code\r\n   (for both source and actual) through black.assert_equivalent or\r\n   black.assert_stable is useful. It's not a big deal for the smaller\r\n   tests, but it eats a lot of time in tests/test_format.py since\r\n   its test cases are big. This is also closer to how Black works IRL.\r\n\r\n2. Use a smaller file for `test_root_logger_not_used_directly` since\r\n   the logging it's checking happens during blib2to3's startup so the\r\n   file doesn't really matter.\r\n\r\n3. If we're checking a file is formatting (i.e. test_source_is_formatted)\r\n   don't run Black over it again with `black.format_file_in_place`.\r\n   `tests/test_format.py::TestSimpleFormat.check_file` is good enough. </s> remove         self.assertFalse(ff(path))\n </s> add  </s> remove         black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, mode)\n </s> add         if source != actual:\n            black.assert_equivalent(source, actual)\n            black.assert_stable(source, actual, mode) </s> remove         black.assert_equivalent(source, result.output)\n        black.assert_stable(source, result.output, DEFAULT_MODE)\n </s> add         if source != result.output:\n            black.assert_equivalent(source, result.output)\n            black.assert_stable(source, result.output, DEFAULT_MODE) </s> remove     ff,\n </s> add ", "html_url": "https://github.com/psf/black/commit/036bea4aa0e2b9b3fe50d0d49addc811cce61fa4", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from tests.util import (\n <mask>     BlackBaseTestCase,\n <mask>     fs,\n <mask>     ff,\n <mask>     DEFAULT_MODE,\n <mask>     dump_to_stderr,\n <mask>     read_data,\n <mask>     THIS_DIR,\n <mask> )\n </s> Speed up tests even more (#2205)\n\nThere's three optimizations in this commit:\r\n\r\n1. Don't check if Black's output is stable or equivalant if no changes\r\n   were made in the first place. It's not like passing the same code\r\n   (for both source and actual) through black.assert_equivalent or\r\n   black.assert_stable is useful. It's not a big deal for the smaller\r\n   tests, but it eats a lot of time in tests/test_format.py since\r\n   its test cases are big. This is also closer to how Black works IRL.\r\n\r\n2. Use a smaller file for `test_root_logger_not_used_directly` since\r\n   the logging it's checking happens during blib2to3's startup so the\r\n   file doesn't really matter.\r\n\r\n3. If we're checking a file is formatting (i.e. test_source_is_formatted)\r\n   don't run Black over it again with `black.format_file_in_place`.\r\n   `tests/test_format.py::TestSimpleFormat.check_file` is good enough. </s> remove         black.assert_equivalent(source, result.output)\n        black.assert_stable(source, result.output, DEFAULT_MODE)\n </s> add         if source != result.output:\n            black.assert_equivalent(source, result.output)\n            black.assert_stable(source, result.output, DEFAULT_MODE) </s> remove         self.assertFalse(ff(path))\n </s> add  </s> remove         black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, mode)\n </s> add         if source != actual:\n            black.assert_equivalent(source, actual)\n            black.assert_stable(source, actual, mode) </s> remove             ff(THIS_FILE)\n </s> add             ff(THIS_DIR / \"util.py\")", "html_url": "https://github.com/psf/black/commit/036bea4aa0e2b9b3fe50d0d49addc811cce61fa4", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_source_is_formatted(self, filename: str) -> None:\n <mask>         path = THIS_DIR.parent / filename\n <mask>         self.check_file(str(path), DEFAULT_MODE, data=False)\n <mask>         self.assertFalse(ff(path))\n <mask> \n <mask>     def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n <mask>         source, expected = read_data(filename, data=data)\n <mask>         actual = fs(source, mode=mode)\n <mask>         self.assertFormatEqual(expected, actual)\n </s> Speed up tests even more (#2205)\n\nThere's three optimizations in this commit:\r\n\r\n1. Don't check if Black's output is stable or equivalant if no changes\r\n   were made in the first place. It's not like passing the same code\r\n   (for both source and actual) through black.assert_equivalent or\r\n   black.assert_stable is useful. It's not a big deal for the smaller\r\n   tests, but it eats a lot of time in tests/test_format.py since\r\n   its test cases are big. This is also closer to how Black works IRL.\r\n\r\n2. Use a smaller file for `test_root_logger_not_used_directly` since\r\n   the logging it's checking happens during blib2to3's startup so the\r\n   file doesn't really matter.\r\n\r\n3. If we're checking a file is formatting (i.e. test_source_is_formatted)\r\n   don't run Black over it again with `black.format_file_in_place`.\r\n   `tests/test_format.py::TestSimpleFormat.check_file` is good enough. </s> remove         black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, mode)\n </s> add         if source != actual:\n            black.assert_equivalent(source, actual)\n            black.assert_stable(source, actual, mode) </s> remove             ff(THIS_FILE)\n </s> add             ff(THIS_DIR / \"util.py\") </s> remove         black.assert_equivalent(source, result.output)\n        black.assert_stable(source, result.output, DEFAULT_MODE)\n </s> add         if source != result.output:\n            black.assert_equivalent(source, result.output)\n            black.assert_stable(source, result.output, DEFAULT_MODE) </s> remove     ff,\n </s> add ", "html_url": "https://github.com/psf/black/commit/036bea4aa0e2b9b3fe50d0d49addc811cce61fa4", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace replace", "code_tokens": " <mask>     def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n <mask>         source, expected = read_data(filename, data=data)\n <mask>         actual = fs(source, mode=mode)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, mode)\n </s> Speed up tests even more (#2205)\n\nThere's three optimizations in this commit:\r\n\r\n1. Don't check if Black's output is stable or equivalant if no changes\r\n   were made in the first place. It's not like passing the same code\r\n   (for both source and actual) through black.assert_equivalent or\r\n   black.assert_stable is useful. It's not a big deal for the smaller\r\n   tests, but it eats a lot of time in tests/test_format.py since\r\n   its test cases are big. This is also closer to how Black works IRL.\r\n\r\n2. Use a smaller file for `test_root_logger_not_used_directly` since\r\n   the logging it's checking happens during blib2to3's startup so the\r\n   file doesn't really matter.\r\n\r\n3. If we're checking a file is formatting (i.e. test_source_is_formatted)\r\n   don't run Black over it again with `black.format_file_in_place`.\r\n   `tests/test_format.py::TestSimpleFormat.check_file` is good enough. </s> remove         self.assertFalse(ff(path))\n </s> add  </s> remove         black.assert_equivalent(source, result.output)\n        black.assert_stable(source, result.output, DEFAULT_MODE)\n </s> add         if source != result.output:\n            black.assert_equivalent(source, result.output)\n            black.assert_stable(source, result.output, DEFAULT_MODE) </s> remove             ff(THIS_FILE)\n </s> add             ff(THIS_DIR / \"util.py\") </s> remove     ff,\n </s> add ", "html_url": "https://github.com/psf/black/commit/036bea4aa0e2b9b3fe50d0d49addc811cce61fa4", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep replace keep keep replace keep", "code_tokens": " <mask> \n <mask>     steps:\n <mask>       - uses: actions/checkout@v1\n <mask> \n <mask>       - name: Set up Python ${{ matrix.python-version }}\n <mask>         uses: actions/setup-python@v1\n <mask>         with:\n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove         uses: actions/setup-python@v1\n </s> add         uses: actions/setup-python@v2 </s> remove       - uses: actions/checkout@v1\n </s> add       - uses: actions/checkout@v2 </s> remove     rev: v0.761\n </s> add     rev: v0.770 </s> remove     rev: 3.7.9\n </s> add     rev: 3.8.1 </s> remove         click.secho(f\"\\nFailed Projects:\\n\", bold=True)\n </s> add         click.secho(\"\\nFailed Projects:\\n\", bold=True)", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": ".github/workflows/lint.yml"}
{"docstring_tokens": "keep replace keep keep replace keep keep keep keep", "code_tokens": " <mask>     steps:\n <mask>       - uses: actions/checkout@v1\n <mask> \n <mask>       - name: Set up Python ${{ matrix.python-version }}\n <mask>         uses: actions/setup-python@v1\n <mask>         with:\n <mask>           python-version: ${{ matrix.python-version }}\n <mask> \n <mask>       - name: Install dependencies\n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": ".github/workflows/test.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         require_serial: true\n <mask>         types: [python]\n <mask> \n <mask>   - repo: https://gitlab.com/pycqa/flake8\n <mask>     rev: 3.7.9\n <mask>     hooks:\n <mask>       - id: flake8\n <mask>         additional_dependencies: [flake8-bugbear]\n <mask> \n <mask>   - repo: https://github.com/pre-commit/mirrors-mypy\n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove     rev: v0.761\n </s> add     rev: v0.770 </s> remove       - uses: actions/checkout@v1\n </s> add       - uses: actions/checkout@v2 </s> remove         uses: actions/setup-python@v1\n </s> add         uses: actions/setup-python@v2 </s> remove         uses: actions/setup-python@v1\n </s> add         uses: actions/setup-python@v2 </s> remove       - uses: actions/checkout@v1\n </s> add       - uses: actions/checkout@v2 </s> remove         click.secho(f\"\\nFailed Projects:\\n\", bold=True)\n </s> add         click.secho(\"\\nFailed Projects:\\n\", bold=True)", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": ".pre-commit-config.yaml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       - id: flake8\n <mask>         additional_dependencies: [flake8-bugbear]\n <mask> \n <mask>   - repo: https://github.com/pre-commit/mirrors-mypy\n <mask>     rev: v0.761\n <mask>     hooks:\n <mask>       - id: mypy\n <mask>         exclude: ^docs/conf.py\n <mask> \n <mask>   - repo: https://github.com/prettier/prettier\n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove     rev: 3.7.9\n </s> add     rev: 3.8.1 </s> remove       - uses: actions/checkout@v1\n </s> add       - uses: actions/checkout@v2 </s> remove         uses: actions/setup-python@v1\n </s> add         uses: actions/setup-python@v2 </s> remove         uses: actions/setup-python@v1\n </s> add         uses: actions/setup-python@v2 </s> remove       - uses: actions/checkout@v1\n </s> add       - uses: actions/checkout@v2 </s> remove         click.secho(f\"\\nFailed Projects:\\n\", bold=True)\n </s> add         click.secho(\"\\nFailed Projects:\\n\", bold=True)", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": ".pre-commit-config.yaml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     target_version = config.get(\"target_version\")\n <mask>     if target_version is not None and not isinstance(target_version, list):\n <mask>         raise click.BadOptionUsage(\n <mask>             \"target-version\", f\"Config key target-version must be a list\"\n <mask>         )\n <mask> \n <mask>     default_map: Dict[str, Any] = {}\n <mask>     if ctx.default_map:\n <mask>         default_map.update(ctx.default_map)\n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove                 and not any(l.type == token.COMMA for l in leaves)\n </s> add                 and not any(leaf.type == token.COMMA for leaf in leaves) </s> remove         LOG.error(f\"No git binary found\")\n </s> add         LOG.error(\"No git binary found\") </s> remove             for l in transform(line, features):\n                if str(l).strip(\"\\n\") == line_str:\n </s> add             for transformed_line in transform(line, features):\n                if str(transformed_line).strip(\"\\n\") == line_str: </s> remove         LOG.error(f\"Can not find 'black' executable in PATH. No point in running\")\n </s> add         LOG.error(\"Can not find 'black' executable in PATH. No point in running\") </s> remove             rf\"(In|Out)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \\+\\d\\d\\d\\d\"\n </s> add             r\"(In|Out)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \\+\\d\\d\\d\\d\" </s> remove         first_line = next((l.lineno for l in self.leaves if l.lineno != 0), 0)\n        last_line = next((l.lineno for l in reversed(self.leaves) if l.lineno != 0), 0)\n </s> add         first_line = next((leaf.lineno for leaf in self.leaves if leaf.lineno != 0), 0)\n        last_line = next(\n            (leaf.lineno for leaf in reversed(self.leaves) if leaf.lineno != 0), 0\n        )", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         # only report an unsplittable 'type: ignore' if this line was\n <mask>         # one line in the original code.\n <mask> \n <mask>         # Grab the first and last line numbers, skipping generated leaves\n <mask>         first_line = next((l.lineno for l in self.leaves if l.lineno != 0), 0)\n <mask>         last_line = next((l.lineno for l in reversed(self.leaves) if l.lineno != 0), 0)\n <mask> \n <mask>         if first_line == last_line:\n <mask>             # We look at the last two leaves since a comma or an\n <mask>             # invisible paren could have been added at the end of the\n <mask>             # line.\n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove             for l in transform(line, features):\n                if str(l).strip(\"\\n\") == line_str:\n </s> add             for transformed_line in transform(line, features):\n                if str(transformed_line).strip(\"\\n\") == line_str: </s> remove                 and not any(l.type == token.COMMA for l in leaves)\n </s> add                 and not any(leaf.type == token.COMMA for leaf in leaves) </s> remove         for l in split_func(line, features):\n            normalize_prefix(l.leaves[0], inside_brackets=True)\n            yield l\n </s> add         for line in split_func(line, features):\n            normalize_prefix(line.leaves[0], inside_brackets=True)\n            yield line </s> remove             \"target-version\", f\"Config key target-version must be a list\"\n </s> add             \"target-version\", \"Config key target-version must be a list\" </s> remove         click.secho(f\"\\nFailed Projects:\\n\", bold=True)\n </s> add         click.secho(\"\\nFailed Projects:\\n\", bold=True) </s> remove         LOG.error(f\"Can not find 'black' executable in PATH. No point in running\")\n </s> add         LOG.error(\"Can not find 'black' executable in PATH. No point in running\")", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         # mission and return the original line in the end, or attempt a different\n <mask>         # split altogether.\n <mask>         result: List[Line] = []\n <mask>         try:\n <mask>             for l in transform(line, features):\n <mask>                 if str(l).strip(\"\\n\") == line_str:\n <mask>                     raise CannotTransform(\n <mask>                         \"Line transformer returned an unchanged result\"\n <mask>                     )\n <mask> \n <mask>                 result.extend(\n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove         first_line = next((l.lineno for l in self.leaves if l.lineno != 0), 0)\n        last_line = next((l.lineno for l in reversed(self.leaves) if l.lineno != 0), 0)\n </s> add         first_line = next((leaf.lineno for leaf in self.leaves if leaf.lineno != 0), 0)\n        last_line = next(\n            (leaf.lineno for leaf in reversed(self.leaves) if leaf.lineno != 0), 0\n        ) </s> remove                 and not any(l.type == token.COMMA for l in leaves)\n </s> add                 and not any(leaf.type == token.COMMA for leaf in leaves) </s> remove         for l in split_func(line, features):\n            normalize_prefix(l.leaves[0], inside_brackets=True)\n            yield l\n </s> add         for line in split_func(line, features):\n            normalize_prefix(line.leaves[0], inside_brackets=True)\n            yield line </s> remove             \"target-version\", f\"Config key target-version must be a list\"\n </s> add             \"target-version\", \"Config key target-version must be a list\" </s> remove         LOG.error(f\"Can not find 'black' executable in PATH. No point in running\")\n </s> add         LOG.error(\"Can not find 'black' executable in PATH. No point in running\") </s> remove         LOG.error(f\"No git binary found\")\n </s> add         LOG.error(\"No git binary found\")", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     )\n <mask> \n <mask>                 result.extend(\n <mask>                     transform_line(\n <mask>                         l,\n <mask>                         line_length=line_length,\n <mask>                         normalize_strings=normalize_strings,\n <mask>                         features=features,\n <mask>                     )\n <mask>                 )\n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove             for l in transform(line, features):\n                if str(l).strip(\"\\n\") == line_str:\n </s> add             for transformed_line in transform(line, features):\n                if str(transformed_line).strip(\"\\n\") == line_str: </s> remove         click.secho(f\"\\nFailed Projects:\\n\", bold=True)\n </s> add         click.secho(\"\\nFailed Projects:\\n\", bold=True) </s> remove             rf\"(In|Out)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \\+\\d\\d\\d\\d\"\n </s> add             r\"(In|Out)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \\+\\d\\d\\d\\d\" </s> remove         LOG.error(f\"No git binary found\")\n </s> add         LOG.error(\"No git binary found\") </s> remove             rf\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n            rf\"\\+\\d\\d\\d\\d\"\n </s> add             r\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n            r\"\\+\\d\\d\\d\\d\" </s> remove             \"target-version\", f\"Config key target-version must be a list\"\n </s> add             \"target-version\", \"Config key target-version must be a list\"", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             # be careful not to add one after any comments or within type annotations.\n <mask>             no_commas = (\n <mask>                 original.is_def\n <mask>                 and opening_bracket.value == \"(\"\n <mask>                 and not any(l.type == token.COMMA for l in leaves)\n <mask>             )\n <mask> \n <mask>             if original.is_import or no_commas:\n <mask>                 for i in range(len(leaves) - 1, -1, -1):\n <mask>                     if leaves[i].type == STANDALONE_COMMENT:\n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove             for l in transform(line, features):\n                if str(l).strip(\"\\n\") == line_str:\n </s> add             for transformed_line in transform(line, features):\n                if str(transformed_line).strip(\"\\n\") == line_str: </s> remove         first_line = next((l.lineno for l in self.leaves if l.lineno != 0), 0)\n        last_line = next((l.lineno for l in reversed(self.leaves) if l.lineno != 0), 0)\n </s> add         first_line = next((leaf.lineno for leaf in self.leaves if leaf.lineno != 0), 0)\n        last_line = next(\n            (leaf.lineno for leaf in reversed(self.leaves) if leaf.lineno != 0), 0\n        ) </s> remove             \"target-version\", f\"Config key target-version must be a list\"\n </s> add             \"target-version\", \"Config key target-version must be a list\" </s> remove         click.secho(f\"\\nFailed Projects:\\n\", bold=True)\n </s> add         click.secho(\"\\nFailed Projects:\\n\", bold=True) </s> remove         LOG.error(f\"No git binary found\")\n </s> add         LOG.error(\"No git binary found\") </s> remove         for l in split_func(line, features):\n            normalize_prefix(l.leaves[0], inside_brackets=True)\n            yield l\n </s> add         for line in split_func(line, features):\n            normalize_prefix(line.leaves[0], inside_brackets=True)\n            yield line", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask> \n <mask>     @wraps(split_func)\n <mask>     def split_wrapper(line: Line, features: Collection[Feature] = ()) -> Iterator[Line]:\n <mask>         for l in split_func(line, features):\n <mask>             normalize_prefix(l.leaves[0], inside_brackets=True)\n <mask>             yield l\n <mask> \n <mask>     return split_wrapper\n <mask> \n <mask> \n <mask> @dont_increase_indentation\n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove             for l in transform(line, features):\n                if str(l).strip(\"\\n\") == line_str:\n </s> add             for transformed_line in transform(line, features):\n                if str(transformed_line).strip(\"\\n\") == line_str: </s> remove         first_line = next((l.lineno for l in self.leaves if l.lineno != 0), 0)\n        last_line = next((l.lineno for l in reversed(self.leaves) if l.lineno != 0), 0)\n </s> add         first_line = next((leaf.lineno for leaf in self.leaves if leaf.lineno != 0), 0)\n        last_line = next(\n            (leaf.lineno for leaf in reversed(self.leaves) if leaf.lineno != 0), 0\n        ) </s> remove                 and not any(l.type == token.COMMA for l in leaves)\n </s> add                 and not any(leaf.type == token.COMMA for leaf in leaves) </s> remove             rf\"(In|Out)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \\+\\d\\d\\d\\d\"\n </s> add             r\"(In|Out)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \\+\\d\\d\\d\\d\" </s> remove             rf\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n            rf\"\\+\\d\\d\\d\\d\"\n </s> add             r\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n            r\"\\+\\d\\d\\d\\d\" </s> remove         LOG.error(f\"No git binary found\")\n </s> add         LOG.error(\"No git binary found\")", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         LOG.debug(f\"Creating {work_path}\")\n <mask>         work_path.mkdir()\n <mask> \n <mask>     if not which(\"black\"):\n <mask>         LOG.error(f\"Can not find 'black' executable in PATH. No point in running\")\n <mask>         return -1\n <mask> \n <mask>     try:\n <mask>         ret_val = await lib.process_queue(\n <mask>             config, work_path, workers, keep, long_checkouts, rebase\n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove             for l in transform(line, features):\n                if str(l).strip(\"\\n\") == line_str:\n </s> add             for transformed_line in transform(line, features):\n                if str(transformed_line).strip(\"\\n\") == line_str: </s> remove                 and not any(l.type == token.COMMA for l in leaves)\n </s> add                 and not any(leaf.type == token.COMMA for leaf in leaves) </s> remove         LOG.error(f\"No git binary found\")\n </s> add         LOG.error(\"No git binary found\") </s> remove             \"target-version\", f\"Config key target-version must be a list\"\n </s> add             \"target-version\", \"Config key target-version must be a list\" </s> remove         for l in split_func(line, features):\n            normalize_prefix(l.leaves[0], inside_brackets=True)\n            yield l\n </s> add         for line in split_func(line, features):\n            normalize_prefix(line.leaves[0], inside_brackets=True)\n            yield line </s> remove         first_line = next((l.lineno for l in self.leaves if l.lineno != 0), 0)\n        last_line = next((l.lineno for l in reversed(self.leaves) if l.lineno != 0), 0)\n </s> add         first_line = next((leaf.lineno for leaf in self.leaves if leaf.lineno != 0), 0)\n        last_line = next(\n            (leaf.lineno for leaf in reversed(self.leaves) if leaf.lineno != 0), 0\n        )", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black_primer/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         f\" - {results.stats['skipped_long_checkout']} skipped due to long checkout\"\n <mask>     )\n <mask> \n <mask>     if results.failed_projects:\n <mask>         click.secho(f\"\\nFailed Projects:\\n\", bold=True)\n <mask> \n <mask>     for project_name, project_cpe in results.failed_projects.items():\n <mask>         print(f\"## {project_name}:\")\n <mask>         print(f\" - Returned {project_cpe.returncode}\")\n <mask>         if project_cpe.stderr:\n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove                 and not any(l.type == token.COMMA for l in leaves)\n </s> add                 and not any(leaf.type == token.COMMA for leaf in leaves) </s> remove             for l in transform(line, features):\n                if str(l).strip(\"\\n\") == line_str:\n </s> add             for transformed_line in transform(line, features):\n                if str(transformed_line).strip(\"\\n\") == line_str: </s> remove         first_line = next((l.lineno for l in self.leaves if l.lineno != 0), 0)\n        last_line = next((l.lineno for l in reversed(self.leaves) if l.lineno != 0), 0)\n </s> add         first_line = next((leaf.lineno for leaf in self.leaves if leaf.lineno != 0), 0)\n        last_line = next(\n            (leaf.lineno for leaf in reversed(self.leaves) if leaf.lineno != 0), 0\n        ) </s> remove         for l in split_func(line, features):\n            normalize_prefix(l.leaves[0], inside_brackets=True)\n            yield l\n </s> add         for line in split_func(line, features):\n            normalize_prefix(line.leaves[0], inside_brackets=True)\n            yield line </s> remove         LOG.error(f\"Can not find 'black' executable in PATH. No point in running\")\n </s> add         LOG.error(\"Can not find 'black' executable in PATH. No point in running\") </s> remove             \"target-version\", f\"Config key target-version must be a list\"\n </s> add             \"target-version\", \"Config key target-version must be a list\"", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black_primer/lib.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ) -> Optional[Path]:\n <mask>     \"\"\"git Clone project or rebase\"\"\"\n <mask>     git_bin = str(which(\"git\"))\n <mask>     if not git_bin:\n <mask>         LOG.error(f\"No git binary found\")\n <mask>         return None\n <mask> \n <mask>     repo_url_parts = urlparse(project_config[\"git_clone_url\"])\n <mask>     path_parts = repo_url_parts.path[1:].split(\"/\", maxsplit=1)\n <mask> \n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove             \"target-version\", f\"Config key target-version must be a list\"\n </s> add             \"target-version\", \"Config key target-version must be a list\" </s> remove             rf\"(In|Out)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \\+\\d\\d\\d\\d\"\n </s> add             r\"(In|Out)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \\+\\d\\d\\d\\d\" </s> remove             rf\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n            rf\"\\+\\d\\d\\d\\d\"\n </s> add             r\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n            r\"\\+\\d\\d\\d\\d\" </s> remove                 and not any(l.type == token.COMMA for l in leaves)\n </s> add                 and not any(leaf.type == token.COMMA for leaf in leaves) </s> remove         LOG.error(f\"Can not find 'black' executable in PATH. No point in running\")\n </s> add         LOG.error(\"Can not find 'black' executable in PATH. No point in running\") </s> remove             for l in transform(line, features):\n                if str(l).strip(\"\\n\") == line_str:\n </s> add             for transformed_line in transform(line, features):\n                if str(transformed_line).strip(\"\\n\") == line_str:", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black_primer/lib.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         black.assert_stable(source, result.output, black.FileMode())\n <mask> \n <mask>     def test_piping_diff(self) -> None:\n <mask>         diff_header = re.compile(\n <mask>             rf\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n <mask>             rf\"\\+\\d\\d\\d\\d\"\n <mask>         )\n <mask>         source, _ = read_data(\"expression.py\")\n <mask>         expected, _ = read_data(\"expression.diff\")\n <mask>         config = THIS_DIR / \"data\" / \"empty_pyproject.toml\"\n <mask>         args = [\n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove             rf\"(In|Out)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \\+\\d\\d\\d\\d\"\n </s> add             r\"(In|Out)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \\+\\d\\d\\d\\d\" </s> remove         LOG.error(f\"No git binary found\")\n </s> add         LOG.error(\"No git binary found\") </s> remove         for l in split_func(line, features):\n            normalize_prefix(l.leaves[0], inside_brackets=True)\n            yield l\n </s> add         for line in split_func(line, features):\n            normalize_prefix(line.leaves[0], inside_brackets=True)\n            yield line </s> remove             \"target-version\", f\"Config key target-version must be a list\"\n </s> add             \"target-version\", \"Config key target-version must be a list\" </s> remove         first_line = next((l.lineno for l in self.leaves if l.lineno != 0), 0)\n        last_line = next((l.lineno for l in reversed(self.leaves) if l.lineno != 0), 0)\n </s> add         first_line = next((leaf.lineno for leaf in self.leaves if leaf.lineno != 0), 0)\n        last_line = next(\n            (leaf.lineno for leaf in reversed(self.leaves) if leaf.lineno != 0), 0\n        ) </s> remove             for l in transform(line, features):\n                if str(l).strip(\"\\n\") == line_str:\n </s> add             for transformed_line in transform(line, features):\n                if str(transformed_line).strip(\"\\n\") == line_str:", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @unittest_run_loop\n <mask>     async def test_blackd_diff(self) -> None:\n <mask>         diff_header = re.compile(\n <mask>             rf\"(In|Out)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \\+\\d\\d\\d\\d\"\n <mask>         )\n <mask> \n <mask>         source, _ = read_data(\"blackd_diff.py\")\n <mask>         expected, _ = read_data(\"blackd_diff.diff\")\n <mask> \n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove             rf\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n            rf\"\\+\\d\\d\\d\\d\"\n </s> add             r\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n            r\"\\+\\d\\d\\d\\d\" </s> remove         LOG.error(f\"No git binary found\")\n </s> add         LOG.error(\"No git binary found\") </s> remove         for l in split_func(line, features):\n            normalize_prefix(l.leaves[0], inside_brackets=True)\n            yield l\n </s> add         for line in split_func(line, features):\n            normalize_prefix(line.leaves[0], inside_brackets=True)\n            yield line </s> remove             \"target-version\", f\"Config key target-version must be a list\"\n </s> add             \"target-version\", \"Config key target-version must be a list\" </s> remove                 and not any(l.type == token.COMMA for l in leaves)\n </s> add                 and not any(leaf.type == token.COMMA for leaf in leaves) </s> remove         LOG.error(f\"Can not find 'black' executable in PATH. No point in running\")\n </s> add         LOG.error(\"Can not find 'black' executable in PATH. No point in running\")", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> on:\n <mask>   push:\n <mask>     branches:\n <mask>       - \"master\"\n <mask> \n <mask> jobs:\n <mask>   docker:\n <mask>     runs-on: ubuntu-latest\n <mask>     steps:\n <mask>       - name: Checkout\n </s> Add automatic version tagging to Docker CI Pushes (#2132)\n\n* Add automatic version tagging to Docker Uploads\r\n- If the git comment has a tag, set that on the docker images pushed\r\n- If we don't have a tag, we just set `latest_non_release`\r\n\r\n* Add trigger on release creation too\r\n\r\n* Make prettier happy omn docker.yml </s> remove           tags: pyfound/black:latest\n </s> add           tags: pyfound/black:latest,pyfound/black:${{ env.GIT_TAG }} </s> add       - name: Check + set version tag\n        run:\n          echo \"GIT_TAG=$(git describe --candidates=0 --tags 2> /dev/null || echo\n          latest_non_release)\" >> $GITHUB_ENV\n", "html_url": "https://github.com/psf/black/commit/04fd4432f6c6007e419d7174930569a75ea60fed", "file_name": ".github/workflows/docker.yml"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         with:\n <mask>           username: ${{ secrets.DOCKERHUB_USERNAME }}\n <mask>           password: ${{ secrets.DOCKERHUB_TOKEN }}\n <mask> \n <mask>       - name: Build and push\n <mask>         uses: docker/build-push-action@v2\n <mask>         with:\n <mask>           context: .\n </s> Add automatic version tagging to Docker CI Pushes (#2132)\n\n* Add automatic version tagging to Docker Uploads\r\n- If the git comment has a tag, set that on the docker images pushed\r\n- If we don't have a tag, we just set `latest_non_release`\r\n\r\n* Add trigger on release creation too\r\n\r\n* Make prettier happy omn docker.yml </s> remove           tags: pyfound/black:latest\n </s> add           tags: pyfound/black:latest,pyfound/black:${{ env.GIT_TAG }} </s> add   release:\n    types: created", "html_url": "https://github.com/psf/black/commit/04fd4432f6c6007e419d7174930569a75ea60fed", "file_name": ".github/workflows/docker.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep", "code_tokens": " <mask>         with:\n <mask>           context: .\n <mask>           platforms: linux/amd64,linux/arm64\n <mask>           push: true\n <mask>           tags: pyfound/black:latest\n <mask> \n <mask>       - name: Image digest\n <mask>         run: echo ${{ steps.docker_build.outputs.digest }}\n </s> Add automatic version tagging to Docker CI Pushes (#2132)\n\n* Add automatic version tagging to Docker Uploads\r\n- If the git comment has a tag, set that on the docker images pushed\r\n- If we don't have a tag, we just set `latest_non_release`\r\n\r\n* Add trigger on release creation too\r\n\r\n* Make prettier happy omn docker.yml </s> add       - name: Check + set version tag\n        run:\n          echo \"GIT_TAG=$(git describe --candidates=0 --tags 2> /dev/null || echo\n          latest_non_release)\" >> $GITHUB_ENV\n </s> add   release:\n    types: created", "html_url": "https://github.com/psf/black/commit/04fd4432f6c6007e419d7174930569a75ea60fed", "file_name": ".github/workflows/docker.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             before = 0\n <mask>         depth = current_line.depth\n <mask>         while self.previous_defs and self.previous_defs[-1] >= depth:\n <mask>             if self.is_pyi:\n <mask>                 before = 0 if depth else 1\n <mask>             else:\n <mask>                 if depth:\n <mask>                     before = 1\n <mask>                 elif (\n <mask>                     not depth\n </s> Stubs: preserve blank line between attributes and methods (#2736) </s> remove                 # Blank line between a block of functions (maybe with preceding\n                # decorators) and a block of non-functions\n                newlines = 1\n </s> add                 if not current_line.depth:\n                    # Blank line between a block of functions (maybe with preceding\n                    # decorators) and a block of non-functions\n                    newlines = 1\n                else:\n                    # In classes empty lines between attributes and methods should\n                    # be preserved. The +1 offset is to negate the -1 done later as\n                    # this function is indented.\n                    newlines = min(2, before + 1) </s> add     attr: int\n    attr2: str\n </s> remove class B: ...\n </s> add class B:\n    this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add class D: ... </s> add     attr: int\n    attr2: str\n </s> remove     ...\n </s> add     this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "src/black/lines.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                     newlines = 1\n <mask>             elif (\n <mask>                 current_line.is_def or current_line.is_decorator\n <mask>             ) and not self.previous_line.is_def:\n <mask>                 # Blank line between a block of functions (maybe with preceding\n <mask>                 # decorators) and a block of non-functions\n <mask>                 newlines = 1\n <mask>             else:\n <mask>                 newlines = 0\n <mask>         else:\n <mask>             newlines = 2\n <mask>         if current_line.depth and newlines:\n </s> Stubs: preserve blank line between attributes and methods (#2736) </s> remove                 before = 0 if depth else 1\n </s> add                 assert self.previous_line is not None\n                if depth and not current_line.is_def and self.previous_line.is_def:\n                    # Empty lines between attributes and methods should be preserved.\n                    before = min(1, before)\n                elif depth:\n                    before = 0\n                else:\n                    before = 1 </s> add     attr: int\n    attr2: str\n </s> remove class B: ...\n </s> add class B:\n    this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add class D: ... </s> add     attr: int\n    attr2: str\n </s> remove     ...\n </s> add     this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "src/black/lines.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> def f(): ...\n <mask> \n <mask> class C:\n <mask>     ...\n <mask> \n <mask> class B:\n </s> Stubs: preserve blank line between attributes and methods (#2736) </s> add class D: ... </s> remove class B: ...\n </s> add class B:\n    this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> remove     ...\n </s> add     this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add     attr: int\n    attr2: str\n </s> add     attr: int\n    attr2: str\n </s> remove                 # Blank line between a block of functions (maybe with preceding\n                # decorators) and a block of non-functions\n                newlines = 1\n </s> add                 if not current_line.depth:\n                    # Blank line between a block of functions (maybe with preceding\n                    # decorators) and a block of non-functions\n                    newlines = 1\n                else:\n                    # In classes empty lines between attributes and methods should\n                    # be preserved. The +1 offset is to negate the -1 done later as\n                    # this function is indented.\n                    newlines = min(2, before + 1)", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "tests/data/stub.pyi"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> class C:\n <mask>     ...\n <mask> \n <mask> class B:\n <mask>     ...\n <mask> \n <mask> class A:\n <mask>     def f(self) -> int:\n <mask>         ...\n <mask> \n </s> Stubs: preserve blank line between attributes and methods (#2736) </s> remove class B: ...\n </s> add class B:\n    this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add class D: ... </s> add class D: \n    ...\n\n </s> add     attr: int\n    attr2: str\n </s> add     attr: int\n    attr2: str\n </s> remove                 # Blank line between a block of functions (maybe with preceding\n                # decorators) and a block of non-functions\n                newlines = 1\n </s> add                 if not current_line.depth:\n                    # Blank line between a block of functions (maybe with preceding\n                    # decorators) and a block of non-functions\n                    newlines = 1\n                else:\n                    # In classes empty lines between attributes and methods should\n                    # be preserved. The +1 offset is to negate the -1 done later as\n                    # this function is indented.\n                    newlines = min(2, before + 1)", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "tests/data/stub.pyi"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     but_this_newline_should_also_be_kept: int\n <mask> \n <mask> class A:\n <mask>     def f(self) -> int:\n <mask>         ...\n <mask> \n <mask>     def g(self) -> str: ...\n <mask> \n </s> Stubs: preserve blank line between attributes and methods (#2736) </s> remove class B: ...\n </s> add class B:\n    this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add     attr: int\n    attr2: str\n </s> remove     ...\n </s> add     this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add class D: ... </s> add class D: \n    ...\n\n </s> remove                 # Blank line between a block of functions (maybe with preceding\n                # decorators) and a block of non-functions\n                newlines = 1\n </s> add                 if not current_line.depth:\n                    # Blank line between a block of functions (maybe with preceding\n                    # decorators) and a block of non-functions\n                    newlines = 1\n                else:\n                    # In classes empty lines between attributes and methods should\n                    # be preserved. The +1 offset is to negate the -1 done later as\n                    # this function is indented.\n                    newlines = min(2, before + 1)", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "tests/data/stub.pyi"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> def f(): ...\n <mask> \n <mask> class C: ...\n <mask> \n <mask> class B:\n <mask>     this_lack_of_newline_should_be_kept: int\n <mask>     def b(self) -> None: ...\n </s> Stubs: preserve blank line between attributes and methods (#2736) </s> remove class B: ...\n </s> add class B:\n    this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> remove     ...\n </s> add     this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add     attr: int\n    attr2: str\n </s> add class D: \n    ...\n\n </s> add     attr: int\n    attr2: str\n </s> remove                 # Blank line between a block of functions (maybe with preceding\n                # decorators) and a block of non-functions\n                newlines = 1\n </s> add                 if not current_line.depth:\n                    # Blank line between a block of functions (maybe with preceding\n                    # decorators) and a block of non-functions\n                    newlines = 1\n                else:\n                    # In classes empty lines between attributes and methods should\n                    # be preserved. The +1 offset is to negate the -1 done later as\n                    # this function is indented.\n                    newlines = min(2, before + 1)", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "tests/data/stub.pyi"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def f(): ...\n <mask> \n <mask> class C: ...\n <mask> class B: ...\n <mask> \n <mask> class A:\n <mask>     def f(self) -> int: ...\n <mask>     def g(self) -> str: ...\n <mask> \n </s> Stubs: preserve blank line between attributes and methods (#2736) </s> add     attr: int\n    attr2: str\n </s> add class D: ... </s> add     attr: int\n    attr2: str\n </s> remove     ...\n </s> add     this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add class D: \n    ...\n\n </s> remove                 # Blank line between a block of functions (maybe with preceding\n                # decorators) and a block of non-functions\n                newlines = 1\n </s> add                 if not current_line.depth:\n                    # Blank line between a block of functions (maybe with preceding\n                    # decorators) and a block of non-functions\n                    newlines = 1\n                else:\n                    # In classes empty lines between attributes and methods should\n                    # be preserved. The +1 offset is to negate the -1 done later as\n                    # this function is indented.\n                    newlines = min(2, before + 1)", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "tests/data/stub.pyi"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     but_this_newline_should_also_be_kept: int\n <mask> \n <mask> class A:\n <mask>     def f(self) -> int: ...\n <mask>     def g(self) -> str: ...\n <mask> \n <mask> def g(): ...\n <mask> def h(): ...\n </s> Stubs: preserve blank line between attributes and methods (#2736) </s> remove class B: ...\n </s> add class B:\n    this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add     attr: int\n    attr2: str\n </s> remove     ...\n </s> add     this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add class D: ... </s> add class D: \n    ...\n\n </s> remove                 # Blank line between a block of functions (maybe with preceding\n                # decorators) and a block of non-functions\n                newlines = 1\n </s> add                 if not current_line.depth:\n                    # Blank line between a block of functions (maybe with preceding\n                    # decorators) and a block of non-functions\n                    newlines = 1\n                else:\n                    # In classes empty lines between attributes and methods should\n                    # be preserved. The +1 offset is to negate the -1 done later as\n                    # this function is indented.\n                    newlines = min(2, before + 1)", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "tests/data/stub.pyi"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> @click.command(context_settings=dict(help_option_names=[\"-h\", \"--help\"]))\n <mask> @click.option(\n <mask>     \"-l\",\n <mask>     \"--line-length\",\n <mask>     type=int,\n </s> Add `black -c \"code\"` (#761) </s> add     if code is not None:\n        print(format_str(code, mode=mode))\n        ctx.exit(0) </s> add     code: Optional[str],", "html_url": "https://github.com/psf/black/commit/06004cd319a6623a1fc29b582eb81e315179629f", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> def main(\n <mask>     ctx: click.Context,\n <mask>     line_length: int,\n <mask>     target_version: List[TargetVersion],\n <mask>     check: bool,\n <mask>     diff: bool,\n <mask>     fast: bool,\n <mask>     pyi: bool,\n </s> Add `black -c \"code\"` (#761) </s> add     if code is not None:\n        print(format_str(code, mode=mode))\n        ctx.exit(0) </s> add @click.option(\"-c\", \"--code\", type=str, help=\"Format the code passed in as a string.\")", "html_url": "https://github.com/psf/black/commit/06004cd319a6623a1fc29b582eb81e315179629f", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     )\n <mask>     if config and verbose:\n <mask>         out(f\"Using configuration from {config}.\", bold=False, fg=\"blue\")\n <mask>     try:\n <mask>         include_regex = re_compile_maybe_verbose(include)\n <mask>     except re.error:\n <mask>         err(f\"Invalid regular expression for include given: {include!r}\")\n <mask>         ctx.exit(2)\n </s> Add `black -c \"code\"` (#761) </s> add     code: Optional[str], </s> add @click.option(\"-c\", \"--code\", type=str, help=\"Format the code passed in as a string.\")", "html_url": "https://github.com/psf/black/commit/06004cd319a6623a1fc29b582eb81e315179629f", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     # this is mitigated by a try/catch in https://github.com/psf/black/pull/2974/\n <mask>     # this ignore can be removed when support for aiohttp 3.7 is dropped.\n <mask>     '''ignore:Decorator `@unittest_run_loop` is no longer needed in aiohttp 3\\.8\\+:DeprecationWarning''',\n <mask>     # this is mitigated by https://github.com/python/cpython/issues/79071 in python 3.8+\n <mask>     # this ignore can be removed when support for 3.7 is dropped.\n <mask>     '''ignore:Bare functions are deprecated, use async ones:DeprecationWarning''',\n <mask> ]\n </s> Mitigate deprecation of aiohttp's `@middleware` decorator (#3259)\n\nThis is deprecated since aiohttp 4.0. If it doesn't exist just define a\r\nno-op decorator that does nothing (after the other aiohttp imports\r\nthough!). By doing this, it's safe to ignore the DeprecationWarning\r\nwithout needing to require the latest aiohttp once they remove\r\n`@middleware`. </s> add if TYPE_CHECKING:\n    F = TypeVar(\"F\", bound=Callable[..., Any])\n    middleware: Callable[[F], F]\nelse:\n    try:\n        from aiohttp.web_middlewares import middleware\n    except ImportError:\n        # @middleware is deprecated and its behaviour is the default since aiohttp 4.0\n        # so if it doesn't exist anymore, define a no-op for forward compatibility.\n        middleware = lambda x: x  # noqa: E731\n </s> remove     @middleware  # type: ignore[misc]\n </s> add     @middleware </s> remove     return impl  # type: ignore[no-any-return]\n </s> add     return impl </s> remove from aiohttp.web_middlewares import middleware\n </s> add  </s> remove from typing import Awaitable, Callable, Iterable\n </s> add from typing import TYPE_CHECKING, Any, Awaitable, Callable, Iterable, TypeVar", "html_url": "https://github.com/psf/black/commit/062e644aae4299a320aeac59085df4c020ba6c81", "file_name": "pyproject.toml"}
{"docstring_tokens": "replace keep replace keep keep keep keep keep", "code_tokens": " <mask> from typing import Awaitable, Callable, Iterable\n <mask> \n <mask> from aiohttp.web_middlewares import middleware\n <mask> from aiohttp.web_request import Request\n <mask> from aiohttp.web_response import StreamResponse\n <mask> \n <mask> Handler = Callable[[Request], Awaitable[StreamResponse]]\n <mask> Middleware = Callable[[Request, Handler], Awaitable[StreamResponse]]\n </s> Mitigate deprecation of aiohttp's `@middleware` decorator (#3259)\n\nThis is deprecated since aiohttp 4.0. If it doesn't exist just define a\r\nno-op decorator that does nothing (after the other aiohttp imports\r\nthough!). By doing this, it's safe to ignore the DeprecationWarning\r\nwithout needing to require the latest aiohttp once they remove\r\n`@middleware`. </s> add if TYPE_CHECKING:\n    F = TypeVar(\"F\", bound=Callable[..., Any])\n    middleware: Callable[[F], F]\nelse:\n    try:\n        from aiohttp.web_middlewares import middleware\n    except ImportError:\n        # @middleware is deprecated and its behaviour is the default since aiohttp 4.0\n        # so if it doesn't exist anymore, define a no-op for forward compatibility.\n        middleware = lambda x: x  # noqa: E731\n </s> remove     return impl  # type: ignore[no-any-return]\n </s> add     return impl </s> remove     @middleware  # type: ignore[misc]\n </s> add     @middleware </s> add     # this is mitigated by a try/catch in https://github.com/psf/black/pull/3198/\n    # this ignore can be removed when support for aiohttp 3.x is dropped.\n    '''ignore:Middleware decorator is deprecated since 4\\.0 and its behaviour is default, you can simply remove this decorator:DeprecationWarning''',", "html_url": "https://github.com/psf/black/commit/062e644aae4299a320aeac59085df4c020ba6c81", "file_name": "src/blackd/middlewares.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from aiohttp.web_request import Request\n <mask> from aiohttp.web_response import StreamResponse\n <mask> \n <mask> Handler = Callable[[Request], Awaitable[StreamResponse]]\n <mask> Middleware = Callable[[Request, Handler], Awaitable[StreamResponse]]\n <mask> \n <mask> \n <mask> def cors(allow_headers: Iterable[str]) -> Middleware:\n </s> Mitigate deprecation of aiohttp's `@middleware` decorator (#3259)\n\nThis is deprecated since aiohttp 4.0. If it doesn't exist just define a\r\nno-op decorator that does nothing (after the other aiohttp imports\r\nthough!). By doing this, it's safe to ignore the DeprecationWarning\r\nwithout needing to require the latest aiohttp once they remove\r\n`@middleware`. </s> remove     @middleware  # type: ignore[misc]\n </s> add     @middleware </s> remove from aiohttp.web_middlewares import middleware\n </s> add  </s> remove     return impl  # type: ignore[no-any-return]\n </s> add     return impl </s> remove from typing import Awaitable, Callable, Iterable\n </s> add from typing import TYPE_CHECKING, Any, Awaitable, Callable, Iterable, TypeVar </s> add     # this is mitigated by a try/catch in https://github.com/psf/black/pull/3198/\n    # this ignore can be removed when support for aiohttp 3.x is dropped.\n    '''ignore:Middleware decorator is deprecated since 4\\.0 and its behaviour is default, you can simply remove this decorator:DeprecationWarning''',", "html_url": "https://github.com/psf/black/commit/062e644aae4299a320aeac59085df4c020ba6c81", "file_name": "src/blackd/middlewares.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Middleware = Callable[[Request, Handler], Awaitable[StreamResponse]]\n <mask> \n <mask> \n <mask> def cors(allow_headers: Iterable[str]) -> Middleware:\n <mask>     @middleware  # type: ignore[misc]\n <mask>     async def impl(request: Request, handler: Handler) -> StreamResponse:\n <mask>         is_options = request.method == \"OPTIONS\"\n <mask>         is_preflight = is_options and \"Access-Control-Request-Method\" in request.headers\n <mask>         if is_preflight:\n <mask>             resp = StreamResponse()\n </s> Mitigate deprecation of aiohttp's `@middleware` decorator (#3259)\n\nThis is deprecated since aiohttp 4.0. If it doesn't exist just define a\r\nno-op decorator that does nothing (after the other aiohttp imports\r\nthough!). By doing this, it's safe to ignore the DeprecationWarning\r\nwithout needing to require the latest aiohttp once they remove\r\n`@middleware`. </s> add if TYPE_CHECKING:\n    F = TypeVar(\"F\", bound=Callable[..., Any])\n    middleware: Callable[[F], F]\nelse:\n    try:\n        from aiohttp.web_middlewares import middleware\n    except ImportError:\n        # @middleware is deprecated and its behaviour is the default since aiohttp 4.0\n        # so if it doesn't exist anymore, define a no-op for forward compatibility.\n        middleware = lambda x: x  # noqa: E731\n </s> remove     return impl  # type: ignore[no-any-return]\n </s> add     return impl </s> add     # this is mitigated by a try/catch in https://github.com/psf/black/pull/3198/\n    # this ignore can be removed when support for aiohttp 3.x is dropped.\n    '''ignore:Middleware decorator is deprecated since 4\\.0 and its behaviour is default, you can simply remove this decorator:DeprecationWarning''', </s> remove from aiohttp.web_middlewares import middleware\n </s> add  </s> remove from typing import Awaitable, Callable, Iterable\n </s> add from typing import TYPE_CHECKING, Any, Awaitable, Callable, Iterable, TypeVar", "html_url": "https://github.com/psf/black/commit/062e644aae4299a320aeac59085df4c020ba6c81", "file_name": "src/blackd/middlewares.py"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask>             )\n <mask> \n <mask>         return resp\n <mask> \n <mask>     return impl  # type: ignore[no-any-return]\n </s> Mitigate deprecation of aiohttp's `@middleware` decorator (#3259)\n\nThis is deprecated since aiohttp 4.0. If it doesn't exist just define a\r\nno-op decorator that does nothing (after the other aiohttp imports\r\nthough!). By doing this, it's safe to ignore the DeprecationWarning\r\nwithout needing to require the latest aiohttp once they remove\r\n`@middleware`. </s> remove     @middleware  # type: ignore[misc]\n </s> add     @middleware </s> add     # this is mitigated by a try/catch in https://github.com/psf/black/pull/3198/\n    # this ignore can be removed when support for aiohttp 3.x is dropped.\n    '''ignore:Middleware decorator is deprecated since 4\\.0 and its behaviour is default, you can simply remove this decorator:DeprecationWarning''', </s> add if TYPE_CHECKING:\n    F = TypeVar(\"F\", bound=Callable[..., Any])\n    middleware: Callable[[F], F]\nelse:\n    try:\n        from aiohttp.web_middlewares import middleware\n    except ImportError:\n        # @middleware is deprecated and its behaviour is the default since aiohttp 4.0\n        # so if it doesn't exist anymore, define a no-op for forward compatibility.\n        middleware = lambda x: x  # noqa: E731\n </s> remove from aiohttp.web_middlewares import middleware\n </s> add  </s> remove from typing import Awaitable, Callable, Iterable\n </s> add from typing import TYPE_CHECKING, Any, Awaitable, Callable, Iterable, TypeVar", "html_url": "https://github.com/psf/black/commit/062e644aae4299a320aeac59085df4c020ba6c81", "file_name": "src/blackd/middlewares.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from pathlib import Path\n <mask> import tokenize\n <mask> import sys\n <mask> from typing import (\n <mask>     Dict, Generic, Iterable, Iterator, List, Optional, Set, Tuple, TypeVar, Union\n <mask> )\n <mask> \n <mask> from attr import dataclass, Factory\n <mask> import click\n <mask> \n </s> Implement `# fmt: off` and `# fmt: on`\n\nFixes #5 </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node)\n </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> add     def visit_unformatted(self, node: LN) -> Iterator[Line]:\n        if isinstance(node, Node):\n            for child in node.children:\n                yield from self.visit(child)\n\n        else:\n            try:\n                self.current_line.append(node)\n            except FormatOn as f_on:\n                f_on.trim_prefix(node)\n                yield from self.line()\n                yield from self.visit(node)\n </s> add         # DEDENT has no value. Additionally, in blib2to3 it never holds comments. </s> add     def visit(self, node: LN) -> Iterator[Line]:\n        \"\"\"High-level entry point to the visitor.\"\"\"\n        if isinstance(self.current_line, UnformattedLines):\n            # File contained `# fmt: off`\n            yield from self.visit_unformatted(node)\n\n        else:\n            yield from super().visit(node)\n </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_fmtonoff(self) -> None:\n        source, expected = read_data('fmtonoff')\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, line_length=ll)\n </s> add # fmt: on", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         (two on module-level), as well as providing an extra empty line after flow\n <mask>         control keywords to make them more prominent.\n <mask>         \"\"\"\n <mask>         before, after = self._maybe_empty_lines(current_line)\n <mask>         before -= self.previous_after\n <mask>         self.previous_after = after\n <mask>         self.previous_line = current_line\n </s> Implement `# fmt: off` and `# fmt: on`\n\nFixes #5 </s> remove     def line(self, indent: int = 0) -> Iterator[Line]:\n </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]: </s> add     def visit_unformatted(self, node: LN) -> Iterator[Line]:\n        if isinstance(node, Node):\n            for child in node.children:\n                yield from self.visit(child)\n\n        else:\n            try:\n                self.current_line.append(node)\n            except FormatOn as f_on:\n                f_on.trim_prefix(node)\n                yield from self.line()\n                yield from self.visit(node)\n </s> add     consumed = 0 </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node)\n </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> add     if isinstance(line, UnformattedLines):\n        yield line\n        return\n </s> add         consumed += len(line) + 1  # adding the length of the split '\\n'", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     in ways that will no longer stringify to valid Python code on the tree.\n <mask>     \"\"\"\n <mask>     current_line: Line = Factory(Line)\n <mask> \n <mask>     def line(self, indent: int = 0) -> Iterator[Line]:\n <mask>         \"\"\"Generate a line.\n <mask> \n <mask>         If the line is empty, only emit if it makes sense.\n <mask>         If the line is too long, split it first and then generate.\n <mask> \n </s> Implement `# fmt: off` and `# fmt: on`\n\nFixes #5 </s> add     if isinstance(line, UnformattedLines):\n        yield line\n        return\n </s> add     consumed = 0 </s> add         consumed += len(line) + 1  # adding the length of the split '\\n' </s> remove             self.current_line.depth += indent\n </s> add             if self.current_line.__class__ == type:\n                self.current_line.depth += indent\n            else:\n                self.current_line = type(depth=self.current_line.depth + indent) </s> add         # DEDENT has no value. Additionally, in blib2to3 it never holds comments. </s> remove         self.current_line = Line(depth=complete_line.depth + indent)\n </s> add         self.current_line = type(depth=complete_line.depth + indent)", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         if not self.current_line:\n <mask>             self.current_line.depth += indent\n <mask>             return  # Line is empty, don't emit. Creating a new one unnecessary.\n <mask> \n <mask>         complete_line = self.current_line\n <mask>         self.current_line = Line(depth=complete_line.depth + indent)\n <mask>         yield complete_line\n <mask> \n <mask>     def visit_default(self, node: LN) -> Iterator[Line]:\n <mask>         if isinstance(node, Leaf):\n </s> Implement `# fmt: off` and `# fmt: on`\n\nFixes #5 </s> add     def visit(self, node: LN) -> Iterator[Line]:\n        \"\"\"High-level entry point to the visitor.\"\"\"\n        if isinstance(self.current_line, UnformattedLines):\n            # File contained `# fmt: off`\n            yield from self.visit_unformatted(node)\n\n        else:\n            yield from super().visit(node)\n </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node)\n </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> remove     def line(self, indent: int = 0) -> Iterator[Line]:\n </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]: </s> add     def visit_unformatted(self, node: LN) -> Iterator[Line]:\n        if isinstance(node, Node):\n            for child in node.children:\n                yield from self.visit(child)\n\n        else:\n            try:\n                self.current_line.append(node)\n            except FormatOn as f_on:\n                f_on.trim_prefix(node)\n                yield from self.line()\n                yield from self.visit(node)\n </s> add     consumed = 0", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         complete_line = self.current_line\n <mask>         self.current_line = type(depth=complete_line.depth + indent)\n <mask>         yield complete_line\n <mask> \n <mask>     def visit_default(self, node: LN) -> Iterator[Line]:\n <mask>         if isinstance(node, Leaf):\n <mask>             any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()\n <mask>             try:\n <mask>                 for comment in generate_comments(node):\n <mask>                     if any_open_brackets:\n </s> Implement `# fmt: off` and `# fmt: on`\n\nFixes #5 </s> remove         self.current_line = Line(depth=complete_line.depth + indent)\n </s> add         self.current_line = type(depth=complete_line.depth + indent) </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node)\n </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> remove             self.current_line.depth += indent\n </s> add             if self.current_line.__class__ == type:\n                self.current_line.depth += indent\n            else:\n                self.current_line = type(depth=self.current_line.depth + indent) </s> add     def visit_unformatted(self, node: LN) -> Iterator[Line]:\n        if isinstance(node, Node):\n            for child in node.children:\n                yield from self.visit(child)\n\n        else:\n            try:\n                self.current_line.append(node)\n            except FormatOn as f_on:\n                f_on.trim_prefix(node)\n                yield from self.line()\n                yield from self.visit(node)\n </s> remove         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines)\n </s> add         comment = make_comment(line)\n        yield Leaf(comment_type, comment, prefix='\\n' * nlines)\n\n        if comment in {'# fmt: on', '# yapf: enable'}:\n            raise FormatOn(consumed)\n\n        if comment in {'# fmt: off', '# yapf: disable'}:\n            raise FormatOff(consumed) </s> add     consumed = 0", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def visit_default(self, node: LN) -> Iterator[Line]:\n <mask>         if isinstance(node, Leaf):\n <mask>             any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()\n <mask>             for comment in generate_comments(node):\n <mask>                 if any_open_brackets:\n <mask>                     # any comment within brackets is subject to splitting\n <mask>                     self.current_line.append(comment)\n <mask>                 elif comment.type == token.COMMENT:\n <mask>                     # regular trailing comment\n <mask>                     self.current_line.append(comment)\n <mask>                     yield from self.line()\n <mask> \n <mask>                 else:\n <mask>                     # regular standalone comment\n <mask>                     yield from self.line()\n <mask> \n <mask>                     self.current_line.append(comment)\n <mask>                     yield from self.line()\n <mask> \n <mask>             normalize_prefix(node, inside_brackets=any_open_brackets)\n <mask>             if node.type not in WHITESPACE:\n <mask>                 self.current_line.append(node)\n <mask>         yield from super().visit_default(node)\n <mask> \n <mask>     def visit_INDENT(self, node: Node) -> Iterator[Line]:\n <mask>         yield from self.line(+1)\n <mask>         yield from self.visit_default(node)\n </s> Implement `# fmt: off` and `# fmt: on`\n\nFixes #5 </s> add     def visit(self, node: LN) -> Iterator[Line]:\n        \"\"\"High-level entry point to the visitor.\"\"\"\n        if isinstance(self.current_line, UnformattedLines):\n            # File contained `# fmt: off`\n            yield from self.visit_unformatted(node)\n\n        else:\n            yield from super().visit(node)\n </s> add     def visit_unformatted(self, node: LN) -> Iterator[Line]:\n        if isinstance(node, Node):\n            for child in node.children:\n                yield from self.visit(child)\n\n        else:\n            try:\n                self.current_line.append(node)\n            except FormatOn as f_on:\n                f_on.trim_prefix(node)\n                yield from self.line()\n                yield from self.visit(node)\n </s> add         # DEDENT has no value. Additionally, in blib2to3 it never holds comments. </s> remove         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines)\n </s> add         comment = make_comment(line)\n        yield Leaf(comment_type, comment, prefix='\\n' * nlines)\n\n        if comment in {'# fmt: on', '# yapf: enable'}:\n            raise FormatOn(consumed)\n\n        if comment in {'# fmt: off', '# yapf: disable'}:\n            raise FormatOff(consumed) </s> remove         self.current_line = Line(depth=complete_line.depth + indent)\n </s> add         self.current_line = type(depth=complete_line.depth + indent) </s> remove             self.current_line.depth += indent\n </s> add             if self.current_line.__class__ == type:\n                self.current_line.depth += indent\n            else:\n                self.current_line = type(depth=self.current_line.depth + indent)", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         yield from self.line(+1)\n <mask>         yield from self.visit_default(node)\n <mask> \n <mask>     def visit_DEDENT(self, node: Node) -> Iterator[Line]:\n <mask>         yield from self.line(-1)\n <mask> \n <mask>     def visit_stmt(self, node: Node, keywords: Set[str]) -> Iterator[Line]:\n <mask>         \"\"\"Visit a statement.\n </s> Implement `# fmt: off` and `# fmt: on`\n\nFixes #5 </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node)\n </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> add     def visit_unformatted(self, node: LN) -> Iterator[Line]:\n        if isinstance(node, Node):\n            for child in node.children:\n                yield from self.visit(child)\n\n        else:\n            try:\n                self.current_line.append(node)\n            except FormatOn as f_on:\n                f_on.trim_prefix(node)\n                yield from self.line()\n                yield from self.visit(node)\n </s> add     def visit(self, node: LN) -> Iterator[Line]:\n        \"\"\"High-level entry point to the visitor.\"\"\"\n        if isinstance(self.current_line, UnformattedLines):\n            # File contained `# fmt: off`\n            yield from self.visit_unformatted(node)\n\n        else:\n            yield from super().visit(node)\n </s> remove         self.current_line = Line(depth=complete_line.depth + indent)\n </s> add         self.current_line = type(depth=complete_line.depth + indent) </s> remove     def line(self, indent: int = 0) -> Iterator[Line]:\n </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]: </s> remove         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines)\n </s> add         comment = make_comment(line)\n        yield Leaf(comment_type, comment, prefix='\\n' * nlines)\n\n        if comment in {'# fmt: on', '# yapf: enable'}:\n            raise FormatOn(consumed)\n\n        if comment in {'# fmt: off', '# yapf: disable'}:\n            raise FormatOff(consumed)", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>     def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:\n <mask>         yield from self.visit_default(leaf)\n <mask>         yield from self.line()\n <mask> \n <mask>     def __attrs_post_init__(self) -> None:\n <mask>         \"\"\"You are in a twisty little maze of passages.\"\"\"\n <mask>         v = self.visit_stmt\n <mask>         self.visit_if_stmt = partial(v, keywords={'if', 'else', 'elif'})\n <mask>         self.visit_while_stmt = partial(v, keywords={'while', 'else'})\n </s> Implement `# fmt: off` and `# fmt: on`\n\nFixes #5 </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node)\n </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> add     def visit(self, node: LN) -> Iterator[Line]:\n        \"\"\"High-level entry point to the visitor.\"\"\"\n        if isinstance(self.current_line, UnformattedLines):\n            # File contained `# fmt: off`\n            yield from self.visit_unformatted(node)\n\n        else:\n            yield from super().visit(node)\n </s> add         # DEDENT has no value. Additionally, in blib2to3 it never holds comments. </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_fmtonoff(self) -> None:\n        source, expected = read_data('fmtonoff')\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, line_length=ll)\n </s> remove         self.current_line = Line(depth=complete_line.depth + indent)\n </s> add         self.current_line = type(depth=complete_line.depth + indent) </s> remove     def line(self, indent: int = 0) -> Iterator[Line]:\n </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]:", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         return\n <mask> \n <mask>     nlines = 0\n <mask>     for index, line in enumerate(p.split('\\n')):\n <mask>         consumed += len(line) + 1  # adding the length of the split '\\n'\n <mask>         line = line.lstrip()\n <mask>         if not line:\n </s> Implement `# fmt: off` and `# fmt: on`\n\nFixes #5 </s> add         consumed += len(line) + 1  # adding the length of the split '\\n' </s> remove     def line(self, indent: int = 0) -> Iterator[Line]:\n </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]: </s> add     if isinstance(line, UnformattedLines):\n        yield line\n        return\n </s> add     def visit(self, node: LN) -> Iterator[Line]:\n        \"\"\"High-level entry point to the visitor.\"\"\"\n        if isinstance(self.current_line, UnformattedLines):\n            # File contained `# fmt: off`\n            yield from self.visit_unformatted(node)\n\n        else:\n            yield from super().visit(node)\n </s> remove             self.current_line.depth += indent\n </s> add             if self.current_line.__class__ == type:\n                self.current_line.depth += indent\n            else:\n                self.current_line = type(depth=self.current_line.depth + indent) </s> remove         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines)\n </s> add         comment = make_comment(line)\n        yield Leaf(comment_type, comment, prefix='\\n' * nlines)\n\n        if comment in {'# fmt: on', '# yapf: enable'}:\n            raise FormatOn(consumed)\n\n        if comment in {'# fmt: off', '# yapf: disable'}:\n            raise FormatOff(consumed)", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     nlines = 0\n <mask>     for index, line in enumerate(p.split('\\n')):\n <mask>         line = line.lstrip()\n <mask>         if not line:\n <mask>             nlines += 1\n <mask>         if not line.startswith('#'):\n <mask>             continue\n </s> Implement `# fmt: off` and `# fmt: on`\n\nFixes #5 </s> add     consumed = 0 </s> remove         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines)\n </s> add         comment = make_comment(line)\n        yield Leaf(comment_type, comment, prefix='\\n' * nlines)\n\n        if comment in {'# fmt: on', '# yapf: enable'}:\n            raise FormatOn(consumed)\n\n        if comment in {'# fmt: off', '# yapf: disable'}:\n            raise FormatOff(consumed) </s> add     if isinstance(line, UnformattedLines):\n        yield line\n        return\n </s> remove             self.current_line.depth += indent\n </s> add             if self.current_line.__class__ == type:\n                self.current_line.depth += indent\n            else:\n                self.current_line = type(depth=self.current_line.depth + indent) </s> add         if isinstance(current_line, UnformattedLines):\n            return 0, 0\n </s> remove     def line(self, indent: int = 0) -> Iterator[Line]:\n </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]:", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if index == 0 and leaf.type != token.ENDMARKER:\n <mask>             comment_type = token.COMMENT  # simple trailing comment\n <mask>         else:\n <mask>             comment_type = STANDALONE_COMMENT\n <mask>         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines)\n <mask> \n <mask>         nlines = 0\n <mask> \n <mask> \n <mask> def make_comment(content: str) -> str:\n </s> Implement `# fmt: off` and `# fmt: on`\n\nFixes #5 </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node)\n </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> add     consumed = 0 </s> add         consumed += len(line) + 1  # adding the length of the split '\\n' </s> add     def visit(self, node: LN) -> Iterator[Line]:\n        \"\"\"High-level entry point to the visitor.\"\"\"\n        if isinstance(self.current_line, UnformattedLines):\n            # File contained `# fmt: off`\n            yield from self.visit_unformatted(node)\n\n        else:\n            yield from super().visit(node)\n </s> remove             self.current_line.depth += indent\n </s> add             if self.current_line.__class__ == type:\n                self.current_line.depth += indent\n            else:\n                self.current_line = type(depth=self.current_line.depth + indent) </s> add     def visit_unformatted(self, node: LN) -> Iterator[Line]:\n        if isinstance(node, Node):\n            for child in node.children:\n                yield from self.visit(child)\n\n        else:\n            try:\n                self.current_line.append(node)\n            except FormatOn as f_on:\n                f_on.trim_prefix(node)\n                yield from self.line()\n                yield from self.visit(node)\n", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     If `py36` is True, splitting may generate syntax that is only compatible\n <mask>     with Python 3.6 and later.\n <mask>     \"\"\"\n <mask>     line_str = str(line).strip('\\n')\n <mask>     if len(line_str) <= line_length and '\\n' not in line_str:\n <mask>         yield line\n <mask>         return\n <mask> \n </s> Implement `# fmt: off` and `# fmt: on`\n\nFixes #5 </s> remove     def line(self, indent: int = 0) -> Iterator[Line]:\n </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]: </s> remove             self.current_line.depth += indent\n </s> add             if self.current_line.__class__ == type:\n                self.current_line.depth += indent\n            else:\n                self.current_line = type(depth=self.current_line.depth + indent) </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node)\n </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> add     consumed = 0 </s> add         consumed += len(line) + 1  # adding the length of the split '\\n' </s> remove         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines)\n </s> add         comment = make_comment(line)\n        yield Leaf(comment_type, comment, prefix='\\n' * nlines)\n\n        if comment in {'# fmt: on', '# yapf: enable'}:\n            raise FormatOn(consumed)\n\n        if comment in {'# fmt: off', '# yapf: disable'}:\n            raise FormatOff(consumed)", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "add keep keep keep keep keep keep", "code_tokens": " <mask> #!/usr/bin/env python3\n <mask> # Some license here.\n <mask> #\n <mask> # Has many lines. Many, many lines.\n <mask> # Many, many, many lines.\n <mask> \"\"\"Module docstring.\n <mask> \n </s> Implement `# fmt: off` and `# fmt: on`\n\nFixes #5 </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node)\n </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> add     consumed = 0 </s> add         consumed += len(line) + 1  # adding the length of the split '\\n' </s> add         # DEDENT has no value. Additionally, in blib2to3 it never holds comments. </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_fmtonoff(self) -> None:\n        source, expected = read_data('fmtonoff')\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, line_length=ll)\n </s> remove         self.current_line = Line(depth=complete_line.depth + indent)\n </s> add         self.current_line = type(depth=complete_line.depth + indent)", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "tests/comments.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         # black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, line_length=ll)\n <mask> \n <mask>     def test_report(self) -> None:\n <mask>         report = black.Report()\n <mask>         out_lines = []\n <mask>         err_lines = []\n </s> Implement `# fmt: off` and `# fmt: on`\n\nFixes #5 </s> add     def visit_unformatted(self, node: LN) -> Iterator[Line]:\n        if isinstance(node, Node):\n            for child in node.children:\n                yield from self.visit(child)\n\n        else:\n            try:\n                self.current_line.append(node)\n            except FormatOn as f_on:\n                f_on.trim_prefix(node)\n                yield from self.line()\n                yield from self.visit(node)\n </s> remove         self.current_line = Line(depth=complete_line.depth + indent)\n </s> add         self.current_line = type(depth=complete_line.depth + indent) </s> add     def visit(self, node: LN) -> Iterator[Line]:\n        \"\"\"High-level entry point to the visitor.\"\"\"\n        if isinstance(self.current_line, UnformattedLines):\n            # File contained `# fmt: off`\n            yield from self.visit_unformatted(node)\n\n        else:\n            yield from super().visit(node)\n </s> remove         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines)\n </s> add         comment = make_comment(line)\n        yield Leaf(comment_type, comment, prefix='\\n' * nlines)\n\n        if comment in {'# fmt: on', '# yapf: enable'}:\n            raise FormatOn(consumed)\n\n        if comment in {'# fmt: off', '# yapf: disable'}:\n            raise FormatOff(consumed) </s> remove     def line(self, indent: int = 0) -> Iterator[Line]:\n </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]: </s> add     consumed = 0", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> [flake8]\n <mask> extend-ignore = E203, E266, E501\n <mask> # line length is intentionally set to 80 here because black uses Bugbear\n <mask> # See https://github.com/psf/black/blob/master/docs/the_black_code_style.md#line-length for more details\n <mask> max-line-length = 80\n <mask> max-complexity = 18\n <mask> select = B,C,E,F,W,T4,B9\n <mask> # We need to configure the mypy.ini because the flake8-mypy's default\n <mask> # options don't properly override it, so if we don't specify it we get\n </s> Replace references to master branch (#2210)\n\nCommit history before merge:\r\n\r\n* Replace references to master branch\r\n* Update .flake8 to reference docs on RTD\r\n\r\n  We're moving away from GitHub as a documentation host to only RTD because\r\n  it's makes our lives easier creating good docs. I know this link is dead right now,\r\n  but it won't be once we release a new version with the documentation reorganization\r\n  changes (which should be soon!).\r\n\r\n  Co-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove     parser.add_argument(\"versions\", nargs=\"*\", default=(\"master\",), help=\"\")\n </s> add     parser.add_argument(\"versions\", nargs=\"*\", default=(\"main\",), help=\"\") </s> remove             version = \"master\"\n </s> add             version = \"main\" </s> remove     git_switch_branch(\"master\", repo=options.black_repo)\n </s> add     git_switch_branch(\"main\", repo=options.black_repo) </s> remove         git_switch_branch(\"master\", repo=repo)\n </s> add         git_switch_branch(\"main\", repo=repo)", "html_url": "https://github.com/psf/black/commit/06ccb88bf2bd35a4dc5d591bb296b5b299d07323", "file_name": ".flake8"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def get_package_source(package: str, version: Optional[str]) -> str:\n <mask>     if package == \"cpython\":\n <mask>         if version is None:\n <mask>             version = \"master\"\n <mask>         return f\"https://github.com/python/cpython/archive/{version}.zip\"\n <mask>     elif package == \"pypy\":\n <mask>         if version is None:\n <mask>             version = \"branch/default\"\n <mask>         return (\n </s> Replace references to master branch (#2210)\n\nCommit history before merge:\r\n\r\n* Replace references to master branch\r\n* Update .flake8 to reference docs on RTD\r\n\r\n  We're moving away from GitHub as a documentation host to only RTD because\r\n  it's makes our lives easier creating good docs. I know this link is dead right now,\r\n  but it won't be once we release a new version with the documentation reorganization\r\n  changes (which should be soon!).\r\n\r\n  Co-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove     git_switch_branch(\"master\", repo=options.black_repo)\n </s> add     git_switch_branch(\"main\", repo=options.black_repo) </s> remove # See https://github.com/psf/black/blob/master/docs/the_black_code_style.md#line-length for more details\n </s> add # See https://black.readthedocs.io/en/stable/the_black_code_style/current_style.html#line-length for more details </s> remove         git_switch_branch(\"master\", repo=repo)\n </s> add         git_switch_branch(\"main\", repo=repo) </s> remove     parser.add_argument(\"versions\", nargs=\"*\", default=(\"master\",), help=\"\")\n </s> add     parser.add_argument(\"versions\", nargs=\"*\", default=(\"main\",), help=\"\")", "html_url": "https://github.com/psf/black/commit/06ccb88bf2bd35a4dc5d591bb296b5b299d07323", "file_name": "gallery/gallery.py"}
{"docstring_tokens": "keep keep replace keep replace keep", "code_tokens": " <mask>                 input_directory=options.input,\n <mask>             )\n <mask>         git_switch_branch(\"master\", repo=repo)\n <mask> \n <mask>     git_switch_branch(\"master\", repo=options.black_repo)\n <mask> \n </s> Replace references to master branch (#2210)\n\nCommit history before merge:\r\n\r\n* Replace references to master branch\r\n* Update .flake8 to reference docs on RTD\r\n\r\n  We're moving away from GitHub as a documentation host to only RTD because\r\n  it's makes our lives easier creating good docs. I know this link is dead right now,\r\n  but it won't be once we release a new version with the documentation reorganization\r\n  changes (which should be soon!).\r\n\r\n  Co-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove     parser.add_argument(\"versions\", nargs=\"*\", default=(\"master\",), help=\"\")\n </s> add     parser.add_argument(\"versions\", nargs=\"*\", default=(\"main\",), help=\"\") </s> remove             version = \"master\"\n </s> add             version = \"main\" </s> remove # See https://github.com/psf/black/blob/master/docs/the_black_code_style.md#line-length for more details\n </s> add # See https://black.readthedocs.io/en/stable/the_black_code_style/current_style.html#line-length for more details", "html_url": "https://github.com/psf/black/commit/06ccb88bf2bd35a4dc5d591bb296b5b299d07323", "file_name": "gallery/gallery.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         default=Path(\"/output\"),\n <mask>         type=Path,\n <mask>         help=\"Output directory to download and put result artifacts.\",\n <mask>     )\n <mask>     parser.add_argument(\"versions\", nargs=\"*\", default=(\"master\",), help=\"\")\n <mask> \n <mask>     options = parser.parse_args()\n <mask>     repos = init_repos(options)\n <mask>     format_repos(repos, options)\n <mask> \n </s> Replace references to master branch (#2210)\n\nCommit history before merge:\r\n\r\n* Replace references to master branch\r\n* Update .flake8 to reference docs on RTD\r\n\r\n  We're moving away from GitHub as a documentation host to only RTD because\r\n  it's makes our lives easier creating good docs. I know this link is dead right now,\r\n  but it won't be once we release a new version with the documentation reorganization\r\n  changes (which should be soon!).\r\n\r\n  Co-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove # See https://github.com/psf/black/blob/master/docs/the_black_code_style.md#line-length for more details\n </s> add # See https://black.readthedocs.io/en/stable/the_black_code_style/current_style.html#line-length for more details </s> remove     git_switch_branch(\"master\", repo=options.black_repo)\n </s> add     git_switch_branch(\"main\", repo=options.black_repo) </s> remove             version = \"master\"\n </s> add             version = \"main\" </s> remove         git_switch_branch(\"master\", repo=repo)\n </s> add         git_switch_branch(\"main\", repo=repo)", "html_url": "https://github.com/psf/black/commit/06ccb88bf2bd35a4dc5d591bb296b5b299d07323", "file_name": "gallery/gallery.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> }\n <mask> \n <mask> \n <mask> @dataclass\n <mask> class FileMode:\n <mask>     target_versions: Set[TargetVersion] = field(default_factory=set)\n <mask>     line_length: int = DEFAULT_LINE_LENGTH\n <mask>     string_normalization: bool = True\n <mask>     is_pyi: bool = False\n <mask> \n </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     mode: FileMode,\n </s> add     mode: Mode, </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode\n </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove     mode = FileMode(\n </s> add     mode = Mode( </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None:\n </s> add def write_cache(cache: Cache, sources: Iterable[Path], mode: Mode) -> None: </s> remove     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: FileMode,\n    report: \"Report\",\n </s> add     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None:\n </s> add def assert_stable(src: str, dst: str, mode: Mode) -> None:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def supports_feature(target_versions: Set[TargetVersion], feature: Feature) -> bool:\n <mask>     return all(feature in VERSION_TO_FEATURES[version] for version in target_versions)\n <mask> \n <mask> \n </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None:\n </s> add def write_cache(cache: Cache, sources: Iterable[Path], mode: Mode) -> None: </s> remove     mode: FileMode,\n </s> add     mode: Mode, </s> remove     mode: FileMode,\n </s> add     mode: Mode, </s> remove def get_cache_file(mode: FileMode) -> Path:\n </s> add def get_cache_file(mode: Mode) -> Path: </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode\n </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove def read_cache(mode: FileMode) -> Cache:\n </s> add def read_cache(mode: Mode) -> Cache:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         versions = PY36_VERSIONS\n <mask>     else:\n <mask>         # We'll autodetect later.\n <mask>         versions = set()\n <mask>     mode = FileMode(\n <mask>         target_versions=versions,\n <mask>         line_length=line_length,\n <mask>         is_pyi=pyi,\n <mask>         string_normalization=not skip_string_normalization,\n <mask>     )\n </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     mode: FileMode,\n </s> add     mode: Mode, </s> add # Legacy name, left for integrations.\nFileMode = Mode\n\n </s> remove class FileMode:\n </s> add class Mode: </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None:\n </s> add def write_cache(cache: Cache, sources: Iterable[Path], mode: Mode) -> None: </s> remove     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: FileMode,\n    report: \"Report\",\n </s> add     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None:\n </s> add def assert_stable(src: str, dst: str, mode: Mode) -> None:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             ctx.exit(0)\n <mask> \n <mask> \n <mask> def reformat_one(\n <mask>     src: Path, fast: bool, write_back: WriteBack, mode: FileMode, report: \"Report\"\n <mask> ) -> None:\n <mask>     \"\"\"Reformat a single file under `src` without spawning child processes.\n <mask> \n <mask>     `fast`, `write_back`, and `mode` options are passed to\n <mask>     :func:`format_file_in_place` or :func:`format_stdin_to_stdout`.\n </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     mode: FileMode,\n </s> add     mode: Mode, </s> remove     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: FileMode,\n    report: \"Report\",\n </s> add     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove def format_file_contents(\n    src_contents: str, *, fast: bool, mode: FileMode\n) -> FileContent:\n </s> add def format_file_contents(src_contents: str, *, fast: bool, mode: Mode) -> FileContent: </s> remove     mode: FileMode,\n </s> add     mode: Mode, </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode\n </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove def format_str(src_contents: str, *, mode: FileMode) -> FileContent:\n </s> add def format_str(src_contents: str, *, mode: Mode) -> FileContent:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         report.failed(src, str(exc))\n <mask> \n <mask> \n <mask> def reformat_many(\n <mask>     sources: Set[Path],\n <mask>     fast: bool,\n <mask>     write_back: WriteBack,\n <mask>     mode: FileMode,\n <mask>     report: \"Report\",\n <mask> ) -> None:\n <mask>     \"\"\"Reformat multiple files using a ProcessPoolExecutor.\"\"\"\n <mask>     loop = asyncio.get_event_loop()\n <mask>     worker_count = os.cpu_count()\n <mask>     if sys.platform == \"win32\":\n </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     mode: FileMode,\n </s> add     mode: Mode, </s> remove     src: Path, fast: bool, write_back: WriteBack, mode: FileMode, report: \"Report\"\n </s> add     src: Path, fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove     mode: FileMode,\n </s> add     mode: Mode, </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None:\n </s> add def write_cache(cache: Cache, sources: Iterable[Path], mode: Mode) -> None: </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode\n </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None:\n </s> add def assert_stable(src: str, dst: str, mode: Mode) -> None:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> async def schedule_formatting(\n <mask>     sources: Set[Path],\n <mask>     fast: bool,\n <mask>     write_back: WriteBack,\n <mask>     mode: FileMode,\n <mask>     report: \"Report\",\n <mask>     loop: asyncio.AbstractEventLoop,\n <mask>     executor: Executor,\n <mask> ) -> None:\n <mask>     \"\"\"Run formatting of `sources` in parallel using the provided `executor`.\n </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: FileMode,\n    report: \"Report\",\n </s> add     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove     src: Path, fast: bool, write_back: WriteBack, mode: FileMode, report: \"Report\"\n </s> add     src: Path, fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None:\n </s> add def write_cache(cache: Cache, sources: Iterable[Path], mode: Mode) -> None: </s> remove     mode: FileMode,\n </s> add     mode: Mode, </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode\n </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove def format_file_contents(\n    src_contents: str, *, fast: bool, mode: FileMode\n) -> FileContent:\n </s> add def format_file_contents(src_contents: str, *, fast: bool, mode: Mode) -> FileContent:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def format_file_in_place(\n <mask>     src: Path,\n <mask>     fast: bool,\n <mask>     mode: FileMode,\n <mask>     write_back: WriteBack = WriteBack.NO,\n <mask>     lock: Any = None,  # multiprocessing.Manager().Lock() is some crazy proxy\n <mask> ) -> bool:\n <mask>     \"\"\"Format file under `src` path. Return True if changed.\n <mask> \n </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode\n </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove     src: Path, fast: bool, write_back: WriteBack, mode: FileMode, report: \"Report\"\n </s> add     src: Path, fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: FileMode,\n    report: \"Report\",\n </s> add     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> add # Legacy name, left for integrations.\nFileMode = Mode\n\n </s> remove def format_file_contents(\n    src_contents: str, *, fast: bool, mode: FileMode\n) -> FileContent:\n </s> add def format_file_contents(src_contents: str, *, fast: bool, mode: Mode) -> FileContent: </s> remove     mode: FileMode,\n </s> add     mode: Mode,", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return True\n <mask> \n <mask> \n <mask> def format_stdin_to_stdout(\n <mask>     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode\n <mask> ) -> bool:\n <mask>     \"\"\"Format file on stdin. Return True if changed.\n <mask> \n <mask>     If `write_back` is YES, write reformatted code back to stdout. If it is DIFF,\n <mask>     write a diff to stdout. The `mode` argument is passed to\n </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     mode: FileMode,\n </s> add     mode: Mode, </s> remove def format_file_contents(\n    src_contents: str, *, fast: bool, mode: FileMode\n) -> FileContent:\n </s> add def format_file_contents(src_contents: str, *, fast: bool, mode: Mode) -> FileContent: </s> remove def read_cache(mode: FileMode) -> Cache:\n </s> add def read_cache(mode: Mode) -> Cache: </s> remove     src: Path, fast: bool, write_back: WriteBack, mode: FileMode, report: \"Report\"\n </s> add     src: Path, fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove def get_cache_file(mode: FileMode) -> Path:\n </s> add def get_cache_file(mode: Mode) -> Path: </s> remove     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: FileMode,\n    report: \"Report\",\n </s> add     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\"", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             f.write(diff(src, dst, src_name, dst_name))\n <mask>         f.detach()\n <mask> \n <mask> \n <mask> def format_file_contents(\n <mask>     src_contents: str, *, fast: bool, mode: FileMode\n <mask> ) -> FileContent:\n <mask>     \"\"\"Reformat contents a file and return new contents.\n <mask> \n <mask>     If `fast` is False, additionally confirm that the reformatted code is\n <mask>     valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.\n <mask>     `mode` is passed to :func:`format_str`.\n </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode\n </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove def format_str(src_contents: str, *, mode: FileMode) -> FileContent:\n </s> add def format_str(src_contents: str, *, mode: Mode) -> FileContent: </s> remove     src: Path, fast: bool, write_back: WriteBack, mode: FileMode, report: \"Report\"\n </s> add     src: Path, fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove def read_cache(mode: FileMode) -> Cache:\n </s> add def read_cache(mode: Mode) -> Cache: </s> remove def get_cache_file(mode: FileMode) -> Path:\n </s> add def get_cache_file(mode: Mode) -> Path: </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None:\n </s> add def assert_stable(src: str, dst: str, mode: Mode) -> None:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         assert_stable(src_contents, dst_contents, mode=mode)\n <mask>     return dst_contents\n <mask> \n <mask> \n <mask> def format_str(src_contents: str, *, mode: FileMode) -> FileContent:\n <mask>     \"\"\"Reformat a string and return new contents.\n <mask> \n <mask>     `mode` determines formatting options, such as how many characters per line are\n <mask>     allowed.  Example:\n <mask> \n </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     >>> print(black.format_str(\"def f(arg:str='')->None:...\", mode=FileMode()))\n </s> add     >>> print(black.format_str(\"def f(arg:str='')->None:...\", mode=Mode())) </s> remove def format_file_contents(\n    src_contents: str, *, fast: bool, mode: FileMode\n) -> FileContent:\n </s> add def format_file_contents(src_contents: str, *, fast: bool, mode: Mode) -> FileContent: </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None:\n </s> add def assert_stable(src: str, dst: str, mode: Mode) -> None: </s> remove     src: Path, fast: bool, write_back: WriteBack, mode: FileMode, report: \"Report\"\n </s> add     src: Path, fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode\n </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove def get_cache_file(mode: FileMode) -> Path:\n </s> add def get_cache_file(mode: Mode) -> Path:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     `mode` determines formatting options, such as how many characters per line are\n <mask>     allowed.  Example:\n <mask> \n <mask>     >>> import black\n <mask>     >>> print(black.format_str(\"def f(arg:str='')->None:...\", mode=FileMode()))\n <mask>     def f(arg: str = \"\") -> None:\n <mask>         ...\n <mask> \n <mask>     A more complex example:\n <mask>     >>> print(\n </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove def format_str(src_contents: str, *, mode: FileMode) -> FileContent:\n </s> add def format_str(src_contents: str, *, mode: Mode) -> FileContent: </s> remove     ...     mode=black.FileMode(\n </s> add     ...     mode=black.Mode( </s> remove     src: Path, fast: bool, write_back: WriteBack, mode: FileMode, report: \"Report\"\n </s> add     src: Path, fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove     mode: FileMode,\n </s> add     mode: Mode, </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None:\n </s> add def write_cache(cache: Cache, sources: Iterable[Path], mode: Mode) -> None: </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None:\n </s> add def assert_stable(src: str, dst: str, mode: Mode) -> None:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     A more complex example:\n <mask>     >>> print(\n <mask>     ...   black.format_str(\n <mask>     ...     \"def f(arg:str='')->None: hey\",\n <mask>     ...     mode=black.FileMode(\n <mask>     ...       target_versions={black.TargetVersion.PY36},\n <mask>     ...       line_length=10,\n <mask>     ...       string_normalization=False,\n <mask>     ...       is_pyi=False,\n <mask>     ...     ),\n </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     >>> print(black.format_str(\"def f(arg:str='')->None:...\", mode=FileMode()))\n </s> add     >>> print(black.format_str(\"def f(arg:str='')->None:...\", mode=Mode())) </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None:\n </s> add def write_cache(cache: Cache, sources: Iterable[Path], mode: Mode) -> None: </s> remove def read_cache(mode: FileMode) -> Cache:\n </s> add def read_cache(mode: Mode) -> Cache: </s> remove def get_cache_file(mode: FileMode) -> Path:\n </s> add def get_cache_file(mode: Mode) -> Path: </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None:\n </s> add def assert_stable(src: str, dst: str, mode: Mode) -> None: </s> remove def format_str(src_contents: str, *, mode: FileMode) -> FileContent:\n </s> add def format_str(src_contents: str, *, mode: Mode) -> FileContent:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             f\"This diff might be helpful: {log}\"\n <mask>         ) from None\n <mask> \n <mask> \n <mask> def assert_stable(src: str, dst: str, mode: FileMode) -> None:\n <mask>     \"\"\"Raise AssertionError if `dst` reformats differently the second time.\"\"\"\n <mask>     newdst = format_str(dst, mode=mode)\n <mask>     if dst != newdst:\n <mask>         log = dump_to_file(\n <mask>             diff(src, dst, \"source\", \"first pass\"),\n </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove def format_str(src_contents: str, *, mode: FileMode) -> FileContent:\n </s> add def format_str(src_contents: str, *, mode: Mode) -> FileContent: </s> remove def format_file_contents(\n    src_contents: str, *, fast: bool, mode: FileMode\n) -> FileContent:\n </s> add def format_file_contents(src_contents: str, *, fast: bool, mode: Mode) -> FileContent: </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None:\n </s> add def write_cache(cache: Cache, sources: Iterable[Path], mode: Mode) -> None: </s> remove def read_cache(mode: FileMode) -> Cache:\n </s> add def read_cache(mode: Mode) -> Cache: </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode\n </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove def get_cache_file(mode: FileMode) -> Path:\n </s> add def get_cache_file(mode: Mode) -> Path:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep replace keep keep keep replace keep keep", "code_tokens": " <mask> \n <mask> def get_cache_file(mode: FileMode) -> Path:\n <mask>     return CACHE_DIR / f\"cache.{mode.get_cache_key()}.pickle\"\n <mask> \n <mask> \n <mask> def read_cache(mode: FileMode) -> Cache:\n <mask>     \"\"\"Read the cache if it exists and is well formed.\n <mask> \n </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None:\n </s> add def write_cache(cache: Cache, sources: Iterable[Path], mode: Mode) -> None: </s> remove def format_str(src_contents: str, *, mode: FileMode) -> FileContent:\n </s> add def format_str(src_contents: str, *, mode: Mode) -> FileContent: </s> remove def format_file_contents(\n    src_contents: str, *, fast: bool, mode: FileMode\n) -> FileContent:\n </s> add def format_file_contents(src_contents: str, *, fast: bool, mode: Mode) -> FileContent: </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None:\n </s> add def assert_stable(src: str, dst: str, mode: Mode) -> None: </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode\n </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             done.add(src)\n <mask>     return todo, done\n <mask> \n <mask> \n <mask> def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None:\n <mask>     \"\"\"Update the cache file.\"\"\"\n <mask>     cache_file = get_cache_file(mode)\n <mask>     try:\n <mask>         CACHE_DIR.mkdir(parents=True, exist_ok=True)\n <mask>         new_cache = {**cache, **{src.resolve(): get_cache_info(src) for src in sources}}\n </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove def read_cache(mode: FileMode) -> Cache:\n </s> add def read_cache(mode: Mode) -> Cache: </s> add # Legacy name, left for integrations.\nFileMode = Mode\n\n </s> remove     mode: FileMode,\n </s> add     mode: Mode, </s> remove     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: FileMode,\n    report: \"Report\",\n </s> add     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove def get_cache_file(mode: FileMode) -> Path:\n </s> add def get_cache_file(mode: Mode) -> Path: </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None:\n </s> add def assert_stable(src: str, dst: str, mode: Mode) -> None:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             if value_head in {'f\"', 'F\"', \"f'\", \"F'\", \"rf\", \"fr\", \"RF\", \"FR\"}:\n <mask>                 features.add(Feature.F_STRINGS)\n <mask> \n <mask>         elif n.type == token.NUMBER:\n <mask>             if \"_\" in n.value:  # type: ignore\n <mask>                 features.add(Feature.NUMERIC_UNDERSCORES)\n <mask> \n <mask>         elif n.type == token.SLASH:\n <mask>             if n.parent and n.parent.type in {\n <mask>                 syms.typedargslist,\n </s> Improve Python 2 only syntax detection (GH-2592)\n\n* Improve Python 2 only syntax detection\r\n\r\nFirst of all this fixes a mistake I made in Python 2 deprecation PR\r\nusing token.* to check for print/exec statements. Turns out that\r\nfor nodes with a type value higher than 256 its numeric type isn't\r\nguaranteed to be constant. Using syms.* instead fixes this.\r\n\r\nAlso add support for the following cases:\r\n\r\n    print \"hello, world!\"\r\n\r\n    exec \"print('hello, world!')\"\r\n\r\n    def set_position((x, y), value):\r\n        pass\r\n\r\n    try:\r\n        pass\r\n    except Exception, err:\r\n        pass\r\n\r\n    raise RuntimeError, \"I feel like crashing today :p\"\r\n\r\n    `wow_these_really_did_exist`\r\n\r\n    10L\r\n\r\n* Add octal support, more test cases, and fixup long ints\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com>\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com> </s> add             elif n.value.endswith((\"L\", \"l\")):\n                # Python 2: 10L\n                features.add(Feature.LONG_INT_LITERAL)\n            elif len(n.value) >= 2 and n.value[0] == \"0\" and n.value[1].isdigit():\n                # Python 2: 0123; 00123; ...\n                if not all(char == \"0\" for char in n.value):\n                    # although we don't want to match 0000 or similar\n                    features.add(Feature.OCTAL_INT_LITERAL) </s> remove         elif n.type == token.PRINT_STMT:\n </s> add         # Python 2 only features (for its deprecation) except for integers, see above\n        elif n.type == syms.print_stmt: </s> remove         elif n.type == token.EXEC_STMT:\n </s> add         elif n.type == syms.exec_stmt: </s> add @pytest.mark.python2\ndef test_python_2_deprecation_autodetection_extended() -> None:\n    # this test has a similar construction to test_get_features_used_decorator\n    python2, non_python2 = read_data(\"python2_detection\")\n    for python2_case in python2.split(\"###\"):\n        node = black.lib2to3_parse(python2_case)\n        assert black.detect_target_versions(node) == {TargetVersion.PY27}, python2_case\n    for non_python2_case in non_python2.split(\"###\"):\n        node = black.lib2to3_parse(non_python2_case)\n        assert black.detect_target_versions(node) != {\n            TargetVersion.PY27\n        }, non_python2_case\n\n </s> remove # temporary for Python 2 deprecation\nPRINT_STMT: Final = 316\nEXEC_STMT: Final = 288\n </s> add  </s> add     AUTOMATIC_PARAMETER_UNPACKING = 202\n    COMMA_STYLE_EXCEPT = 203\n    COMMA_STYLE_RAISE = 204\n    LONG_INT_LITERAL = 205\n    OCTAL_INT_LITERAL = 206\n    BACKQUOTE_REPR = 207", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         elif n.type == token.NUMBER:\n <mask>             assert isinstance(n, Leaf)\n <mask>             if \"_\" in n.value:\n <mask>                 features.add(Feature.NUMERIC_UNDERSCORES)\n <mask> \n <mask>         elif n.type == token.SLASH:\n <mask>             if n.parent and n.parent.type in {\n <mask>                 syms.typedargslist,\n </s> Improve Python 2 only syntax detection (GH-2592)\n\n* Improve Python 2 only syntax detection\r\n\r\nFirst of all this fixes a mistake I made in Python 2 deprecation PR\r\nusing token.* to check for print/exec statements. Turns out that\r\nfor nodes with a type value higher than 256 its numeric type isn't\r\nguaranteed to be constant. Using syms.* instead fixes this.\r\n\r\nAlso add support for the following cases:\r\n\r\n    print \"hello, world!\"\r\n\r\n    exec \"print('hello, world!')\"\r\n\r\n    def set_position((x, y), value):\r\n        pass\r\n\r\n    try:\r\n        pass\r\n    except Exception, err:\r\n        pass\r\n\r\n    raise RuntimeError, \"I feel like crashing today :p\"\r\n\r\n    `wow_these_really_did_exist`\r\n\r\n    10L\r\n\r\n* Add octal support, more test cases, and fixup long ints\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com>\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com> </s> remove             if \"_\" in n.value:  # type: ignore\n </s> add             assert isinstance(n, Leaf)\n            if \"_\" in n.value: </s> remove         elif n.type == token.PRINT_STMT:\n </s> add         # Python 2 only features (for its deprecation) except for integers, see above\n        elif n.type == syms.print_stmt: </s> remove         elif n.type == token.EXEC_STMT:\n </s> add         elif n.type == syms.exec_stmt: </s> add @pytest.mark.python2\ndef test_python_2_deprecation_autodetection_extended() -> None:\n    # this test has a similar construction to test_get_features_used_decorator\n    python2, non_python2 = read_data(\"python2_detection\")\n    for python2_case in python2.split(\"###\"):\n        node = black.lib2to3_parse(python2_case)\n        assert black.detect_target_versions(node) == {TargetVersion.PY27}, python2_case\n    for non_python2_case in non_python2.split(\"###\"):\n        node = black.lib2to3_parse(non_python2_case)\n        assert black.detect_target_versions(node) != {\n            TargetVersion.PY27\n        }, non_python2_case\n\n </s> remove # temporary for Python 2 deprecation\nPRINT_STMT: Final = 316\nEXEC_STMT: Final = 288\n </s> add  </s> add     AUTOMATIC_PARAMETER_UNPACKING = 202\n    COMMA_STYLE_EXCEPT = 203\n    COMMA_STYLE_RAISE = 204\n    LONG_INT_LITERAL = 205\n    OCTAL_INT_LITERAL = 206\n    BACKQUOTE_REPR = 207", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace keep", "code_tokens": " <mask>                     for argch in ch.children:\n <mask>                         if argch.type in STARS:\n <mask>                             features.add(feature)\n <mask> \n <mask>         elif n.type == token.PRINT_STMT:\n <mask>             features.add(Feature.PRINT_STMT)\n <mask>         elif n.type == token.EXEC_STMT:\n <mask>             features.add(Feature.EXEC_STMT)\n </s> Improve Python 2 only syntax detection (GH-2592)\n\n* Improve Python 2 only syntax detection\r\n\r\nFirst of all this fixes a mistake I made in Python 2 deprecation PR\r\nusing token.* to check for print/exec statements. Turns out that\r\nfor nodes with a type value higher than 256 its numeric type isn't\r\nguaranteed to be constant. Using syms.* instead fixes this.\r\n\r\nAlso add support for the following cases:\r\n\r\n    print \"hello, world!\"\r\n\r\n    exec \"print('hello, world!')\"\r\n\r\n    def set_position((x, y), value):\r\n        pass\r\n\r\n    try:\r\n        pass\r\n    except Exception, err:\r\n        pass\r\n\r\n    raise RuntimeError, \"I feel like crashing today :p\"\r\n\r\n    `wow_these_really_did_exist`\r\n\r\n    10L\r\n\r\n* Add octal support, more test cases, and fixup long ints\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com>\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com> </s> add             elif n.value.endswith((\"L\", \"l\")):\n                # Python 2: 10L\n                features.add(Feature.LONG_INT_LITERAL)\n            elif len(n.value) >= 2 and n.value[0] == \"0\" and n.value[1].isdigit():\n                # Python 2: 0123; 00123; ...\n                if not all(char == \"0\" for char in n.value):\n                    # although we don't want to match 0000 or similar\n                    features.add(Feature.OCTAL_INT_LITERAL) </s> remove             if \"_\" in n.value:  # type: ignore\n </s> add             assert isinstance(n, Leaf)\n            if \"_\" in n.value: </s> add @pytest.mark.python2\ndef test_python_2_deprecation_autodetection_extended() -> None:\n    # this test has a similar construction to test_get_features_used_decorator\n    python2, non_python2 = read_data(\"python2_detection\")\n    for python2_case in python2.split(\"###\"):\n        node = black.lib2to3_parse(python2_case)\n        assert black.detect_target_versions(node) == {TargetVersion.PY27}, python2_case\n    for non_python2_case in non_python2.split(\"###\"):\n        node = black.lib2to3_parse(non_python2_case)\n        assert black.detect_target_versions(node) != {\n            TargetVersion.PY27\n        }, non_python2_case\n\n </s> remove # temporary for Python 2 deprecation\nPRINT_STMT: Final = 316\nEXEC_STMT: Final = 288\n </s> add  </s> add     AUTOMATIC_PARAMETER_UNPACKING = 202\n    COMMA_STYLE_EXCEPT = 203\n    COMMA_STYLE_RAISE = 204\n    LONG_INT_LITERAL = 205\n    OCTAL_INT_LITERAL = 206\n    BACKQUOTE_REPR = 207", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     # temporary for Python 2 deprecation\n <mask>     PRINT_STMT = 200\n <mask>     EXEC_STMT = 201\n <mask> \n <mask> \n <mask> VERSION_TO_FEATURES: Dict[TargetVersion, Set[Feature]] = {\n <mask>     TargetVersion.PY27: {\n </s> Improve Python 2 only syntax detection (GH-2592)\n\n* Improve Python 2 only syntax detection\r\n\r\nFirst of all this fixes a mistake I made in Python 2 deprecation PR\r\nusing token.* to check for print/exec statements. Turns out that\r\nfor nodes with a type value higher than 256 its numeric type isn't\r\nguaranteed to be constant. Using syms.* instead fixes this.\r\n\r\nAlso add support for the following cases:\r\n\r\n    print \"hello, world!\"\r\n\r\n    exec \"print('hello, world!')\"\r\n\r\n    def set_position((x, y), value):\r\n        pass\r\n\r\n    try:\r\n        pass\r\n    except Exception, err:\r\n        pass\r\n\r\n    raise RuntimeError, \"I feel like crashing today :p\"\r\n\r\n    `wow_these_really_did_exist`\r\n\r\n    10L\r\n\r\n* Add octal support, more test cases, and fixup long ints\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com>\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com> </s> remove # temporary for Python 2 deprecation\nPRINT_STMT: Final = 316\nEXEC_STMT: Final = 288\n </s> add  </s> add @pytest.mark.python2\ndef test_python_2_deprecation_autodetection_extended() -> None:\n    # this test has a similar construction to test_get_features_used_decorator\n    python2, non_python2 = read_data(\"python2_detection\")\n    for python2_case in python2.split(\"###\"):\n        node = black.lib2to3_parse(python2_case)\n        assert black.detect_target_versions(node) == {TargetVersion.PY27}, python2_case\n    for non_python2_case in non_python2.split(\"###\"):\n        node = black.lib2to3_parse(non_python2_case)\n        assert black.detect_target_versions(node) != {\n            TargetVersion.PY27\n        }, non_python2_case\n\n </s> add             elif n.value.endswith((\"L\", \"l\")):\n                # Python 2: 10L\n                features.add(Feature.LONG_INT_LITERAL)\n            elif len(n.value) >= 2 and n.value[0] == \"0\" and n.value[1].isdigit():\n                # Python 2: 0123; 00123; ...\n                if not all(char == \"0\" for char in n.value):\n                    # although we don't want to match 0000 or similar\n                    features.add(Feature.OCTAL_INT_LITERAL) </s> remove         elif n.type == token.PRINT_STMT:\n </s> add         # Python 2 only features (for its deprecation) except for integers, see above\n        elif n.type == syms.print_stmt: </s> remove             if \"_\" in n.value:  # type: ignore\n </s> add             assert isinstance(n, Leaf)\n            if \"_\" in n.value: </s> add         Feature.AUTOMATIC_PARAMETER_UNPACKING,\n        Feature.COMMA_STYLE_EXCEPT,\n        Feature.COMMA_STYLE_RAISE,\n        Feature.LONG_INT_LITERAL,\n        Feature.OCTAL_INT_LITERAL,\n        Feature.BACKQUOTE_REPR,", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "src/black/mode.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         Feature.PRINT_STMT,\n <mask>         Feature.EXEC_STMT,\n <mask>     },\n <mask>     TargetVersion.PY33: {Feature.UNICODE_LITERALS, Feature.ASYNC_IDENTIFIERS},\n <mask>     TargetVersion.PY34: {Feature.UNICODE_LITERALS, Feature.ASYNC_IDENTIFIERS},\n <mask>     TargetVersion.PY35: {\n <mask>         Feature.UNICODE_LITERALS,\n </s> Improve Python 2 only syntax detection (GH-2592)\n\n* Improve Python 2 only syntax detection\r\n\r\nFirst of all this fixes a mistake I made in Python 2 deprecation PR\r\nusing token.* to check for print/exec statements. Turns out that\r\nfor nodes with a type value higher than 256 its numeric type isn't\r\nguaranteed to be constant. Using syms.* instead fixes this.\r\n\r\nAlso add support for the following cases:\r\n\r\n    print \"hello, world!\"\r\n\r\n    exec \"print('hello, world!')\"\r\n\r\n    def set_position((x, y), value):\r\n        pass\r\n\r\n    try:\r\n        pass\r\n    except Exception, err:\r\n        pass\r\n\r\n    raise RuntimeError, \"I feel like crashing today :p\"\r\n\r\n    `wow_these_really_did_exist`\r\n\r\n    10L\r\n\r\n* Add octal support, more test cases, and fixup long ints\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com>\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com> </s> add @pytest.mark.python2\ndef test_python_2_deprecation_autodetection_extended() -> None:\n    # this test has a similar construction to test_get_features_used_decorator\n    python2, non_python2 = read_data(\"python2_detection\")\n    for python2_case in python2.split(\"###\"):\n        node = black.lib2to3_parse(python2_case)\n        assert black.detect_target_versions(node) == {TargetVersion.PY27}, python2_case\n    for non_python2_case in non_python2.split(\"###\"):\n        node = black.lib2to3_parse(non_python2_case)\n        assert black.detect_target_versions(node) != {\n            TargetVersion.PY27\n        }, non_python2_case\n\n </s> add     AUTOMATIC_PARAMETER_UNPACKING = 202\n    COMMA_STYLE_EXCEPT = 203\n    COMMA_STYLE_RAISE = 204\n    LONG_INT_LITERAL = 205\n    OCTAL_INT_LITERAL = 206\n    BACKQUOTE_REPR = 207 </s> remove             if \"_\" in n.value:  # type: ignore\n </s> add             assert isinstance(n, Leaf)\n            if \"_\" in n.value: </s> add             elif n.value.endswith((\"L\", \"l\")):\n                # Python 2: 10L\n                features.add(Feature.LONG_INT_LITERAL)\n            elif len(n.value) >= 2 and n.value[0] == \"0\" and n.value[1].isdigit():\n                # Python 2: 0123; 00123; ...\n                if not all(char == \"0\" for char in n.value):\n                    # although we don't want to match 0000 or similar\n                    features.add(Feature.OCTAL_INT_LITERAL) </s> add @pytest.mark.python2 </s> remove # temporary for Python 2 deprecation\nPRINT_STMT: Final = 316\nEXEC_STMT: Final = 288\n </s> add ", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "src/black/mode.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> ERRORTOKEN: Final = 58\n <mask> COLONEQUAL: Final = 59\n <mask> N_TOKENS: Final = 60\n <mask> NT_OFFSET: Final = 256\n <mask> # temporary for Python 2 deprecation\n <mask> PRINT_STMT: Final = 316\n <mask> EXEC_STMT: Final = 288\n <mask> # --end constants--\n <mask> \n <mask> tok_name: Final[Dict[int, str]] = {}\n <mask> for _name, _value in list(globals().items()):\n <mask>     if type(_value) is type(0):\n </s> Improve Python 2 only syntax detection (GH-2592)\n\n* Improve Python 2 only syntax detection\r\n\r\nFirst of all this fixes a mistake I made in Python 2 deprecation PR\r\nusing token.* to check for print/exec statements. Turns out that\r\nfor nodes with a type value higher than 256 its numeric type isn't\r\nguaranteed to be constant. Using syms.* instead fixes this.\r\n\r\nAlso add support for the following cases:\r\n\r\n    print \"hello, world!\"\r\n\r\n    exec \"print('hello, world!')\"\r\n\r\n    def set_position((x, y), value):\r\n        pass\r\n\r\n    try:\r\n        pass\r\n    except Exception, err:\r\n        pass\r\n\r\n    raise RuntimeError, \"I feel like crashing today :p\"\r\n\r\n    `wow_these_really_did_exist`\r\n\r\n    10L\r\n\r\n* Add octal support, more test cases, and fixup long ints\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com>\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com> </s> add     AUTOMATIC_PARAMETER_UNPACKING = 202\n    COMMA_STYLE_EXCEPT = 203\n    COMMA_STYLE_RAISE = 204\n    LONG_INT_LITERAL = 205\n    OCTAL_INT_LITERAL = 206\n    BACKQUOTE_REPR = 207 </s> add @pytest.mark.python2\ndef test_python_2_deprecation_autodetection_extended() -> None:\n    # this test has a similar construction to test_get_features_used_decorator\n    python2, non_python2 = read_data(\"python2_detection\")\n    for python2_case in python2.split(\"###\"):\n        node = black.lib2to3_parse(python2_case)\n        assert black.detect_target_versions(node) == {TargetVersion.PY27}, python2_case\n    for non_python2_case in non_python2.split(\"###\"):\n        node = black.lib2to3_parse(non_python2_case)\n        assert black.detect_target_versions(node) != {\n            TargetVersion.PY27\n        }, non_python2_case\n\n </s> remove         elif n.type == token.PRINT_STMT:\n </s> add         # Python 2 only features (for its deprecation) except for integers, see above\n        elif n.type == syms.print_stmt: </s> add             elif n.value.endswith((\"L\", \"l\")):\n                # Python 2: 10L\n                features.add(Feature.LONG_INT_LITERAL)\n            elif len(n.value) >= 2 and n.value[0] == \"0\" and n.value[1].isdigit():\n                # Python 2: 0123; 00123; ...\n                if not all(char == \"0\" for char in n.value):\n                    # although we don't want to match 0000 or similar\n                    features.add(Feature.OCTAL_INT_LITERAL) </s> add @pytest.mark.python2 </s> remove             if \"_\" in n.value:  # type: ignore\n </s> add             assert isinstance(n, Leaf)\n            if \"_\" in n.value:", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "src/blib2to3/pgen2/token.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> @pytest.mark.parametrize(\"explicit\", [True, False], ids=[\"explicit\", \"autodetection\"])\n <mask> def test_python_2_deprecation_with_target_version(explicit: bool) -> None:\n <mask>     args = [\n <mask>         \"--config\",\n <mask>         str(THIS_DIR / \"empty.toml\"),\n </s> Improve Python 2 only syntax detection (GH-2592)\n\n* Improve Python 2 only syntax detection\r\n\r\nFirst of all this fixes a mistake I made in Python 2 deprecation PR\r\nusing token.* to check for print/exec statements. Turns out that\r\nfor nodes with a type value higher than 256 its numeric type isn't\r\nguaranteed to be constant. Using syms.* instead fixes this.\r\n\r\nAlso add support for the following cases:\r\n\r\n    print \"hello, world!\"\r\n\r\n    exec \"print('hello, world!')\"\r\n\r\n    def set_position((x, y), value):\r\n        pass\r\n\r\n    try:\r\n        pass\r\n    except Exception, err:\r\n        pass\r\n\r\n    raise RuntimeError, \"I feel like crashing today :p\"\r\n\r\n    `wow_these_really_did_exist`\r\n\r\n    10L\r\n\r\n* Add octal support, more test cases, and fixup long ints\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com>\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com> </s> add @pytest.mark.python2\ndef test_python_2_deprecation_autodetection_extended() -> None:\n    # this test has a similar construction to test_get_features_used_decorator\n    python2, non_python2 = read_data(\"python2_detection\")\n    for python2_case in python2.split(\"###\"):\n        node = black.lib2to3_parse(python2_case)\n        assert black.detect_target_versions(node) == {TargetVersion.PY27}, python2_case\n    for non_python2_case in non_python2.split(\"###\"):\n        node = black.lib2to3_parse(non_python2_case)\n        assert black.detect_target_versions(node) != {\n            TargetVersion.PY27\n        }, non_python2_case\n\n </s> add     AUTOMATIC_PARAMETER_UNPACKING = 202\n    COMMA_STYLE_EXCEPT = 203\n    COMMA_STYLE_RAISE = 204\n    LONG_INT_LITERAL = 205\n    OCTAL_INT_LITERAL = 206\n    BACKQUOTE_REPR = 207 </s> remove # temporary for Python 2 deprecation\nPRINT_STMT: Final = 316\nEXEC_STMT: Final = 288\n </s> add  </s> add         Feature.AUTOMATIC_PARAMETER_UNPACKING,\n        Feature.COMMA_STYLE_EXCEPT,\n        Feature.COMMA_STYLE_RAISE,\n        Feature.LONG_INT_LITERAL,\n        Feature.OCTAL_INT_LITERAL,\n        Feature.BACKQUOTE_REPR, </s> remove         elif n.type == token.EXEC_STMT:\n </s> add         elif n.type == syms.exec_stmt: </s> remove         elif n.type == token.PRINT_STMT:\n </s> add         # Python 2 only features (for its deprecation) except for integers, see above\n        elif n.type == syms.print_stmt:", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>         result = BlackRunner().invoke(black.main, args)\n <mask>     assert \"DEPRECATION: Python 2 support will be removed\" in result.stderr\n <mask> \n <mask> \n <mask> with open(black.__file__, \"r\", encoding=\"utf-8\") as _bf:\n <mask>     black_source_lines = _bf.readlines()\n <mask> \n <mask> \n <mask> def tracefunc(\n </s> Improve Python 2 only syntax detection (GH-2592)\n\n* Improve Python 2 only syntax detection\r\n\r\nFirst of all this fixes a mistake I made in Python 2 deprecation PR\r\nusing token.* to check for print/exec statements. Turns out that\r\nfor nodes with a type value higher than 256 its numeric type isn't\r\nguaranteed to be constant. Using syms.* instead fixes this.\r\n\r\nAlso add support for the following cases:\r\n\r\n    print \"hello, world!\"\r\n\r\n    exec \"print('hello, world!')\"\r\n\r\n    def set_position((x, y), value):\r\n        pass\r\n\r\n    try:\r\n        pass\r\n    except Exception, err:\r\n        pass\r\n\r\n    raise RuntimeError, \"I feel like crashing today :p\"\r\n\r\n    `wow_these_really_did_exist`\r\n\r\n    10L\r\n\r\n* Add octal support, more test cases, and fixup long ints\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com>\r\n\r\nCo-authored-by: Jelle Zijlstra <jelle.zijlstra@gmail.com> </s> add @pytest.mark.python2 </s> remove # temporary for Python 2 deprecation\nPRINT_STMT: Final = 316\nEXEC_STMT: Final = 288\n </s> add  </s> add             elif n.value.endswith((\"L\", \"l\")):\n                # Python 2: 10L\n                features.add(Feature.LONG_INT_LITERAL)\n            elif len(n.value) >= 2 and n.value[0] == \"0\" and n.value[1].isdigit():\n                # Python 2: 0123; 00123; ...\n                if not all(char == \"0\" for char in n.value):\n                    # although we don't want to match 0000 or similar\n                    features.add(Feature.OCTAL_INT_LITERAL) </s> add     AUTOMATIC_PARAMETER_UNPACKING = 202\n    COMMA_STYLE_EXCEPT = 203\n    COMMA_STYLE_RAISE = 204\n    LONG_INT_LITERAL = 205\n    OCTAL_INT_LITERAL = 206\n    BACKQUOTE_REPR = 207 </s> remove         elif n.type == token.PRINT_STMT:\n </s> add         # Python 2 only features (for its deprecation) except for integers, see above\n        elif n.type == syms.print_stmt: </s> remove             if \"_\" in n.value:  # type: ignore\n </s> add             assert isinstance(n, Leaf)\n            if \"_\" in n.value:", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     ),\n <mask> )\n <mask> @click.version_option(version=__version__)\n <mask> @click.argument(\n <mask>     \"src\",\n <mask>     nargs=-1,\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove                     sources, line_length, fast, write_back, report, loop, executor\n </s> add                     sources=sources,\n                    line_length=line_length,\n                    fast=fast,\n                    pyi=pyi,\n                    py36=py36,\n                    write_back=write_back,\n                    report=report,\n                    loop=loop,\n                    executor=executor, </s> remove             src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n </s> add             src_contents,\n            dst_contents,\n            line_length=line_length,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi)\n </s> add     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> add     pyi: bool,\n    py36: bool, </s> remove def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:\n </s> add def assert_stable(\n    src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n) -> None: </s> add     pyi: bool,\n    py36: bool,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     diff: bool,\n <mask>     fast: bool,\n <mask>     quiet: bool,\n <mask>     src: List[str],\n <mask> ) -> None:\n <mask>     \"\"\"The uncompromising code formatter.\"\"\"\n <mask>     sources: List[Path] = []\n <mask>     for s in src:\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> add     pyi: bool,\n    py36: bool, </s> remove     src: Path, line_length: int, fast: bool, write_back: WriteBack, report: \"Report\"\n </s> add     src: Path,\n    line_length: int,\n    fast: bool,\n    pyi: bool,\n    py36: bool,\n    write_back: WriteBack,\n    report: \"Report\", </s> add     force_pyi: bool = False,\n    force_py36: bool = False, </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO\n </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove         cache = read_cache(line_length)\n </s> add         cache = read_cache(line_length, pyi, py36) </s> remove     cache_file = get_cache_file(line_length)\n </s> add     cache_file = get_cache_file(line_length, pyi, py36)", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         ctx.exit(0)\n <mask>         return\n <mask> \n <mask>     elif len(sources) == 1:\n <mask>         reformat_one(sources[0], line_length, fast, write_back, report)\n <mask>     else:\n <mask>         loop = asyncio.get_event_loop()\n <mask>         executor = ProcessPoolExecutor(max_workers=os.cpu_count())\n <mask>         try:\n <mask>             loop.run_until_complete(\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove                     sources, line_length, fast, write_back, report, loop, executor\n </s> add                     sources=sources,\n                    line_length=line_length,\n                    fast=fast,\n                    pyi=pyi,\n                    py36=py36,\n                    write_back=write_back,\n                    report=report,\n                    loop=loop,\n                    executor=executor, </s> remove                 executor, format_file_in_place, src, line_length, fast, write_back, lock\n </s> add                 executor,\n                format_file_in_place,\n                src,\n                line_length,\n                fast,\n                pyi,\n                py36,\n                write_back,\n                lock, </s> remove                 line_length=line_length, fast=fast, write_back=write_back\n </s> add                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove                 cache = read_cache(line_length)\n </s> add                 cache = read_cache(line_length, pyi, py36) </s> remove             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi\n </s> add             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove     is_pyi = src.suffix == \".pyi\"\n </s> add     is_pyi = force_pyi or src.suffix == \".pyi\"", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         executor = ProcessPoolExecutor(max_workers=os.cpu_count())\n <mask>         try:\n <mask>             loop.run_until_complete(\n <mask>                 schedule_formatting(\n <mask>                     sources, line_length, fast, write_back, report, loop, executor\n <mask>                 )\n <mask>             )\n <mask>         finally:\n <mask>             shutdown(loop)\n <mask>         if not quiet:\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove         reformat_one(sources[0], line_length, fast, write_back, report)\n </s> add         reformat_one(\n            src=sources[0],\n            line_length=line_length,\n            fast=fast,\n            pyi=pyi,\n            py36=py36,\n            write_back=write_back,\n            report=report,\n        ) </s> remove                 executor, format_file_in_place, src, line_length, fast, write_back, lock\n </s> add                 executor,\n                format_file_in_place,\n                src,\n                line_length,\n                fast,\n                pyi,\n                py36,\n                write_back,\n                lock, </s> add     pyi: bool,\n    py36: bool, </s> remove         cache = read_cache(line_length)\n </s> add         cache = read_cache(line_length, pyi, py36) </s> remove             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi\n </s> add             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None:\n </s> add def write_cache(\n    cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n) -> None:", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> def reformat_one(\n <mask>     src: Path, line_length: int, fast: bool, write_back: WriteBack, report: \"Report\"\n <mask> ) -> None:\n <mask>     \"\"\"Reformat a single file under `src` without spawning child processes.\n <mask> \n <mask>     If `quiet` is True, non-error messages are not output. `line_length`,\n <mask>     `write_back`, and `fast` options are passed to :func:`format_file_in_place`.\n <mask>     \"\"\"\n <mask>     try:\n <mask>         changed = Changed.NO\n <mask>         if not src.is_file() and str(src) == \"-\":\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove     `line_length`, `write_back`, and `fast` options are passed to\n </s> add     `line_length`, `write_back`, `fast`, and `pyi` options are passed to </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO\n </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> add     force_pyi: bool = False,\n    force_py36: bool = False, </s> remove                 line_length=line_length, fast=fast, write_back=write_back\n </s> add                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove     is_pyi = src.suffix == \".pyi\"\n </s> add     is_pyi = force_pyi or src.suffix == \".pyi\"", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     try:\n <mask>         changed = Changed.NO\n <mask>         if not src.is_file() and str(src) == \"-\":\n <mask>             if format_stdin_to_stdout(\n <mask>                 line_length=line_length, fast=fast, write_back=write_back\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>         else:\n <mask>             cache: Cache = {}\n <mask>             if write_back != WriteBack.DIFF:\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove                 cache = read_cache(line_length)\n </s> add                 cache = read_cache(line_length, pyi, py36) </s> remove                 src, line_length=line_length, fast=fast, write_back=write_back\n </s> add                 src,\n                line_length=line_length,\n                fast=fast,\n                force_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove                 write_cache(cache, [src], line_length)\n </s> add                 write_cache(cache, [src], line_length, pyi, py36) </s> remove     `write_back`, and `fast` options are passed to :func:`format_file_in_place`.\n </s> add     `write_back`, `fast` and `pyi` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`. </s> remove         cache = read_cache(line_length)\n </s> add         cache = read_cache(line_length, pyi, py36) </s> remove     `line_length`, `write_back`, and `fast` options are passed to\n </s> add     `line_length`, `write_back`, `fast`, and `pyi` options are passed to", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         else:\n <mask>             cache: Cache = {}\n <mask>             if write_back != WriteBack.DIFF:\n <mask>                 cache = read_cache(line_length)\n <mask>                 src = src.resolve()\n <mask>                 if src in cache and cache[src] == get_cache_info(src):\n <mask>                     changed = Changed.CACHED\n <mask>             if changed is not Changed.CACHED and format_file_in_place(\n <mask>                 src, line_length=line_length, fast=fast, write_back=write_back\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>             if write_back == WriteBack.YES and changed is not Changed.NO:\n <mask>                 write_cache(cache, [src], line_length)\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove                 write_cache(cache, [src], line_length)\n </s> add                 write_cache(cache, [src], line_length, pyi, py36) </s> remove                 line_length=line_length, fast=fast, write_back=write_back\n </s> add                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove         cache = read_cache(line_length)\n </s> add         cache = read_cache(line_length, pyi, py36) </s> remove     `line_length`, `write_back`, and `fast` options are passed to\n </s> add     `line_length`, `write_back`, `fast`, and `pyi` options are passed to </s> remove         write_cache(cache, formatted, line_length)\n </s> add         write_cache(cache, formatted, line_length, pyi, py36)", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 src, line_length=line_length, fast=fast, write_back=write_back\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>             if write_back == WriteBack.YES and changed is not Changed.NO:\n <mask>                 write_cache(cache, [src], line_length)\n <mask>         report.done(src, changed)\n <mask>     except Exception as exc:\n <mask>         report.failed(src, str(exc))\n <mask> \n <mask> \n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove                 src, line_length=line_length, fast=fast, write_back=write_back\n </s> add                 src,\n                line_length=line_length,\n                fast=fast,\n                force_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove                 line_length=line_length, fast=fast, write_back=write_back\n </s> add                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove                 cache = read_cache(line_length)\n </s> add                 cache = read_cache(line_length, pyi, py36) </s> remove         write_cache(cache, formatted, line_length)\n </s> add         write_cache(cache, formatted, line_length, pyi, py36) </s> remove             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi\n </s> add             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove     `write_back`, and `fast` options are passed to :func:`format_file_in_place`.\n </s> add     `write_back`, `fast` and `pyi` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`.", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     sources: List[Path],\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     write_back: WriteBack,\n <mask>     report: \"Report\",\n <mask>     loop: BaseEventLoop,\n <mask>     executor: Executor,\n <mask> ) -> None:\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove     src: Path, line_length: int, fast: bool, write_back: WriteBack, report: \"Report\"\n </s> add     src: Path,\n    line_length: int,\n    fast: bool,\n    pyi: bool,\n    py36: bool,\n    write_back: WriteBack,\n    report: \"Report\", </s> remove def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None:\n </s> add def write_cache(\n    cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n) -> None: </s> add     pyi: bool,\n    py36: bool, </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO\n </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> add     force_pyi: bool = False,\n    force_py36: bool = False, </s> remove     cache_file = get_cache_file(line_length)\n </s> add     cache_file = get_cache_file(line_length, pyi, py36)", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>     (Use ProcessPoolExecutors for actual parallelism.)\n <mask> \n <mask>     `line_length`, `write_back`, and `fast` options are passed to\n <mask>     :func:`format_file_in_place`.\n <mask>     \"\"\"\n <mask>     cache: Cache = {}\n <mask>     if write_back != WriteBack.DIFF:\n <mask>         cache = read_cache(line_length)\n <mask>         sources, cached = filter_cached(cache, sources)\n <mask>         for src in cached:\n <mask>             report.done(src, Changed.CACHED)\n <mask>     cancelled = []\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove                 cache = read_cache(line_length)\n </s> add                 cache = read_cache(line_length, pyi, py36) </s> remove     `write_back`, and `fast` options are passed to :func:`format_file_in_place`.\n </s> add     `write_back`, `fast` and `pyi` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`. </s> remove                 line_length=line_length, fast=fast, write_back=write_back\n </s> add                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove     is_pyi = src.suffix == \".pyi\"\n </s> add     is_pyi = force_pyi or src.suffix == \".pyi\" </s> remove     src: Path, line_length: int, fast: bool, write_back: WriteBack, report: \"Report\"\n </s> add     src: Path,\n    line_length: int,\n    fast: bool,\n    pyi: bool,\n    py36: bool,\n    write_back: WriteBack,\n    report: \"Report\",", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             manager = Manager()\n <mask>             lock = manager.Lock()\n <mask>         tasks = {\n <mask>             loop.run_in_executor(\n <mask>                 executor, format_file_in_place, src, line_length, fast, write_back, lock\n <mask>             ): src\n <mask>             for src in sorted(sources)\n <mask>         }\n <mask>         pending: Iterable[asyncio.Task] = tasks.keys()\n <mask>         try:\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove                 src, line_length=line_length, fast=fast, write_back=write_back\n </s> add                 src,\n                line_length=line_length,\n                fast=fast,\n                force_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove                 cache = read_cache(line_length)\n </s> add                 cache = read_cache(line_length, pyi, py36) </s> remove         reformat_one(sources[0], line_length, fast, write_back, report)\n </s> add         reformat_one(\n            src=sources[0],\n            line_length=line_length,\n            fast=fast,\n            pyi=pyi,\n            py36=py36,\n            write_back=write_back,\n            report=report,\n        ) </s> remove         cache = read_cache(line_length)\n </s> add         cache = read_cache(line_length, pyi, py36) </s> remove     cache_file = get_cache_file(line_length)\n </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove                     sources, line_length, fast, write_back, report, loop, executor\n </s> add                     sources=sources,\n                    line_length=line_length,\n                    fast=fast,\n                    pyi=pyi,\n                    py36=py36,\n                    write_back=write_back,\n                    report=report,\n                    loop=loop,\n                    executor=executor,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     report.done(src, Changed.YES if task.result() else Changed.NO)\n <mask>     if cancelled:\n <mask>         await asyncio.gather(*cancelled, loop=loop, return_exceptions=True)\n <mask>     if write_back == WriteBack.YES and formatted:\n <mask>         write_cache(cache, formatted, line_length)\n <mask> \n <mask> \n <mask> def format_file_in_place(\n <mask>     src: Path,\n <mask>     line_length: int,\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove                 src, line_length=line_length, fast=fast, write_back=write_back\n </s> add                 src,\n                line_length=line_length,\n                fast=fast,\n                force_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove                 write_cache(cache, [src], line_length)\n </s> add                 write_cache(cache, [src], line_length, pyi, py36) </s> remove                 cache = read_cache(line_length)\n </s> add                 cache = read_cache(line_length, pyi, py36) </s> remove def get_cache_file(line_length: int) -> Path:\n    return CACHE_DIR / f\"cache.{line_length}.pickle\"\n </s> add def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n    return (\n        CACHE_DIR\n        / f\"cache.{line_length}{'.pyi' if pyi else ''}{'.py36' if py36 else ''}.pickle\"\n    ) </s> remove                 line_length=line_length, fast=fast, write_back=write_back\n </s> add                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> add     force_pyi: bool = False,\n    force_py36: bool = False,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     src: Path,\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     write_back: WriteBack = WriteBack.NO,\n <mask>     lock: Any = None,  # multiprocessing.Manager().Lock() is some crazy proxy\n <mask> ) -> bool:\n <mask>     \"\"\"Format file under `src` path. Return True if changed.\n <mask> \n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO\n </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove     src: Path, line_length: int, fast: bool, write_back: WriteBack, report: \"Report\"\n </s> add     src: Path,\n    line_length: int,\n    fast: bool,\n    pyi: bool,\n    py36: bool,\n    write_back: WriteBack,\n    report: \"Report\", </s> add     pyi: bool,\n    py36: bool, </s> add     pyi: bool,\n    py36: bool, </s> remove     `write_back`, and `fast` options are passed to :func:`format_file_in_place`.\n </s> add     `write_back`, `fast` and `pyi` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`. </s> remove             self.assertEqual(result.exit_code, 1)\n </s> add             self.assertEqual(result.exit_code, 1, result.output)", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     If `write_back` is True, write reformatted code back to stdout.\n <mask>     `line_length` and `fast` options are passed to :func:`format_file_contents`.\n <mask>     \"\"\"\n <mask>     is_pyi = src.suffix == \".pyi\"\n <mask> \n <mask>     with tokenize.open(src) as src_buffer:\n <mask>         src_contents = src_buffer.read()\n <mask>     try:\n <mask>         dst_contents = format_file_contents(\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO\n </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi\n </s> add             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove     `write_back`, and `fast` options are passed to :func:`format_file_in_place`.\n </s> add     `write_back`, `fast` and `pyi` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`. </s> remove     `line_length`, `write_back`, and `fast` options are passed to\n </s> add     `line_length`, `write_back`, `fast`, and `pyi` options are passed to </s> remove     cache_file = get_cache_file(line_length)\n </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove     src: Path, line_length: int, fast: bool, write_back: WriteBack, report: \"Report\"\n </s> add     src: Path,\n    line_length: int,\n    fast: bool,\n    pyi: bool,\n    py36: bool,\n    write_back: WriteBack,\n    report: \"Report\",", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     with tokenize.open(src) as src_buffer:\n <mask>         src_contents = src_buffer.read()\n <mask>     try:\n <mask>         dst_contents = format_file_contents(\n <mask>             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi\n <mask>         )\n <mask>     except NothingChanged:\n <mask>         return False\n <mask> \n <mask>     if write_back == write_back.YES:\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove     is_pyi = src.suffix == \".pyi\"\n </s> add     is_pyi = force_pyi or src.suffix == \".pyi\" </s> remove             src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n </s> add             src_contents,\n            dst_contents,\n            line_length=line_length,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove                 write_cache(cache, [src], line_length)\n </s> add                 write_cache(cache, [src], line_length, pyi, py36) </s> remove                 line_length=line_length, fast=fast, write_back=write_back\n </s> add                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove         reformat_one(sources[0], line_length, fast, write_back, report)\n </s> add         reformat_one(\n            src=sources[0],\n            line_length=line_length,\n            fast=fast,\n            pyi=pyi,\n            py36=py36,\n            write_back=write_back,\n            report=report,\n        ) </s> remove                 src, line_length=line_length, fast=fast, write_back=write_back\n </s> add                 src,\n                line_length=line_length,\n                fast=fast,\n                force_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return True\n <mask> \n <mask> \n <mask> def format_stdin_to_stdout(\n <mask>     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO\n <mask> ) -> bool:\n <mask>     \"\"\"Format file on stdin. Return True if changed.\n <mask> \n <mask>     If `write_back` is True, write reformatted code back to stdout.\n <mask>     `line_length` and `fast` arguments are passed to :func:`format_file_contents`.\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove     is_pyi = src.suffix == \".pyi\"\n </s> add     is_pyi = force_pyi or src.suffix == \".pyi\" </s> add     force_pyi: bool = False,\n    force_py36: bool = False, </s> remove     src: Path, line_length: int, fast: bool, write_back: WriteBack, report: \"Report\"\n </s> add     src: Path,\n    line_length: int,\n    fast: bool,\n    pyi: bool,\n    py36: bool,\n    write_back: WriteBack,\n    report: \"Report\", </s> remove     `write_back`, and `fast` options are passed to :func:`format_file_in_place`.\n </s> add     `write_back`, `fast` and `pyi` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`. </s> remove     `line_length`, `write_back`, and `fast` options are passed to\n </s> add     `line_length`, `write_back`, `fast`, and `pyi` options are passed to </s> add     pyi: bool,\n    py36: bool,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     if not fast:\n <mask>         assert_equivalent(src_contents, dst_contents)\n <mask>         assert_stable(\n <mask>             src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n <mask>         )\n <mask>     return dst_contents\n <mask> \n <mask> \n <mask> def format_str(\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi\n </s> add             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove     src_contents: str, line_length: int, *, is_pyi: bool = False\n </s> add     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False, </s> remove     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi)\n </s> add     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> remove     py36 = is_python36(src_node)\n </s> add     py36 = force_py36 or is_python36(src_node) </s> remove def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:\n </s> add def assert_stable(\n    src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n) -> None: </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO\n </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return dst_contents\n <mask> \n <mask> \n <mask> def format_str(\n <mask>     src_contents: str, line_length: int, *, is_pyi: bool = False\n <mask> ) -> FileContent:\n <mask>     \"\"\"Reformat a string and return new contents.\n <mask> \n <mask>     `line_length` determines how many characters per line are allowed.\n <mask>     \"\"\"\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:\n </s> add def assert_stable(\n    src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n) -> None: </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO\n </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi)\n </s> add     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> remove def get_cache_file(line_length: int) -> Path:\n    return CACHE_DIR / f\"cache.{line_length}.pickle\"\n </s> add def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n    return (\n        CACHE_DIR\n        / f\"cache.{line_length}{'.pyi' if pyi else ''}{'.py36' if py36 else ''}.pickle\"\n    ) </s> remove             src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n </s> add             src_contents,\n            dst_contents,\n            line_length=line_length,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove     `write_back`, and `fast` options are passed to :func:`format_file_in_place`.\n </s> add     `write_back`, `fast` and `pyi` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`.", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     src_node = lib2to3_parse(src_contents)\n <mask>     dst_contents = \"\"\n <mask>     future_imports = get_future_imports(src_node)\n <mask>     elt = EmptyLineTracker(is_pyi=is_pyi)\n <mask>     py36 = is_python36(src_node)\n <mask>     lines = LineGenerator(\n <mask>         remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n <mask>     )\n <mask>     empty_line = Line()\n <mask>     after = 0\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi\n </s> add             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove     is_pyi = src.suffix == \".pyi\"\n </s> add     is_pyi = force_pyi or src.suffix == \".pyi\" </s> remove         cache = read_cache(line_length)\n </s> add         cache = read_cache(line_length, pyi, py36) </s> remove                 cache = read_cache(line_length)\n </s> add                 cache = read_cache(line_length, pyi, py36) </s> remove                 executor, format_file_in_place, src, line_length, fast, write_back, lock\n </s> add                 executor,\n                format_file_in_place,\n                src,\n                line_length,\n                fast,\n                pyi,\n                py36,\n                write_back,\n                lock, </s> remove     src_contents: str, line_length: int, *, is_pyi: bool = False\n </s> add     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             f\"This diff might be helpful: {log}\"\n <mask>         ) from None\n <mask> \n <mask> \n <mask> def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:\n <mask>     \"\"\"Raise AssertionError if `dst` reformats differently the second time.\"\"\"\n <mask>     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi)\n <mask>     if dst != newdst:\n <mask>         log = dump_to_file(\n <mask>             diff(src, dst, \"source\", \"first pass\"),\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi)\n </s> add     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> remove     src_contents: str, line_length: int, *, is_pyi: bool = False\n </s> add     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False, </s> remove def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None:\n </s> add def write_cache(\n    cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n) -> None: </s> remove def get_cache_file(line_length: int) -> Path:\n    return CACHE_DIR / f\"cache.{line_length}.pickle\"\n </s> add def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n    return (\n        CACHE_DIR\n        / f\"cache.{line_length}{'.pyi' if pyi else ''}{'.py36' if py36 else ''}.pickle\"\n    ) </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO\n </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove def read_cache(line_length: int) -> Cache:\n </s> add def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache:", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:\n <mask>     \"\"\"Raise AssertionError if `dst` reformats differently the second time.\"\"\"\n <mask>     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi)\n <mask>     if dst != newdst:\n <mask>         log = dump_to_file(\n <mask>             diff(src, dst, \"source\", \"first pass\"),\n <mask>             diff(dst, newdst, \"first pass\", \"second pass\"),\n <mask>         )\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:\n </s> add def assert_stable(\n    src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n) -> None: </s> remove     src_contents: str, line_length: int, *, is_pyi: bool = False\n </s> add     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False, </s> remove def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None:\n </s> add def write_cache(\n    cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n) -> None: </s> remove def get_cache_file(line_length: int) -> Path:\n    return CACHE_DIR / f\"cache.{line_length}.pickle\"\n </s> add def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n    return (\n        CACHE_DIR\n        / f\"cache.{line_length}{'.pyi' if pyi else ''}{'.py36' if py36 else ''}.pickle\"\n    ) </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO\n </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove def read_cache(line_length: int) -> Cache:\n </s> add def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache:", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep replace replace keep keep replace keep keep keep", "code_tokens": " <mask>     return False\n <mask> \n <mask> \n <mask> def get_cache_file(line_length: int) -> Path:\n <mask>     return CACHE_DIR / f\"cache.{line_length}.pickle\"\n <mask> \n <mask> \n <mask> def read_cache(line_length: int) -> Cache:\n <mask>     \"\"\"Read the cache if it exists and is well formed.\n <mask> \n <mask>     If it is not well formed, the call to write_cache later should resolve the issue.\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove     cache_file = get_cache_file(line_length)\n </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None:\n </s> add def write_cache(\n    cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n) -> None: </s> remove     cache_file = get_cache_file(line_length)\n </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO\n </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove     `line_length`, `write_back`, and `fast` options are passed to\n </s> add     `line_length`, `write_back`, `fast`, and `pyi` options are passed to", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"Read the cache if it exists and is well formed.\n <mask> \n <mask>     If it is not well formed, the call to write_cache later should resolve the issue.\n <mask>     \"\"\"\n <mask>     cache_file = get_cache_file(line_length)\n <mask>     if not cache_file.exists():\n <mask>         return {}\n <mask> \n <mask>     with cache_file.open(\"rb\") as fobj:\n <mask>         try:\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove def read_cache(line_length: int) -> Cache:\n </s> add def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache: </s> remove def get_cache_file(line_length: int) -> Path:\n    return CACHE_DIR / f\"cache.{line_length}.pickle\"\n </s> add def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n    return (\n        CACHE_DIR\n        / f\"cache.{line_length}{'.pyi' if pyi else ''}{'.py36' if py36 else ''}.pickle\"\n    ) </s> remove     cache_file = get_cache_file(line_length)\n </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None:\n </s> add def write_cache(\n    cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n) -> None: </s> remove     `line_length`, `write_back`, and `fast` options are passed to\n </s> add     `line_length`, `write_back`, `fast`, and `pyi` options are passed to </s> remove     is_pyi = src.suffix == \".pyi\"\n </s> add     is_pyi = force_pyi or src.suffix == \".pyi\"", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             done.append(src)\n <mask>     return todo, done\n <mask> \n <mask> \n <mask> def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None:\n <mask>     \"\"\"Update the cache file.\"\"\"\n <mask>     cache_file = get_cache_file(line_length)\n <mask>     try:\n <mask>         if not CACHE_DIR.exists():\n <mask>             CACHE_DIR.mkdir(parents=True)\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove     cache_file = get_cache_file(line_length)\n </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove def read_cache(line_length: int) -> Cache:\n </s> add def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache: </s> remove     cache_file = get_cache_file(line_length)\n </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove def get_cache_file(line_length: int) -> Path:\n    return CACHE_DIR / f\"cache.{line_length}.pickle\"\n </s> add def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n    return (\n        CACHE_DIR\n        / f\"cache.{line_length}{'.pyi' if pyi else ''}{'.py36' if py36 else ''}.pickle\"\n    ) </s> add     pyi: bool,\n    py36: bool, </s> remove def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:\n </s> add def assert_stable(\n    src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n) -> None:", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None:\n <mask>     \"\"\"Update the cache file.\"\"\"\n <mask>     cache_file = get_cache_file(line_length)\n <mask>     try:\n <mask>         if not CACHE_DIR.exists():\n <mask>             CACHE_DIR.mkdir(parents=True)\n <mask>         new_cache = {**cache, **{src.resolve(): get_cache_info(src) for src in sources}}\n <mask>         with cache_file.open(\"wb\") as fobj:\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None:\n </s> add def write_cache(\n    cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n) -> None: </s> remove     cache_file = get_cache_file(line_length)\n </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove def read_cache(line_length: int) -> Cache:\n </s> add def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache: </s> remove         cache = read_cache(line_length)\n </s> add         cache = read_cache(line_length, pyi, py36) </s> remove                 cache = read_cache(line_length)\n </s> add                 cache = read_cache(line_length, pyi, py36) </s> remove                 executor, format_file_in_place, src, line_length, fast, write_back, lock\n </s> add                 executor,\n                format_file_in_place,\n                src,\n                line_length,\n                fast,\n                pyi,\n                py36,\n                write_back,\n                lock,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH)\n <mask> \n <mask>     def test_check_diff_use_together(self) -> None:\n <mask>         with cache_dir():\n <mask>             # Files which will be reformatted.\n <mask>             src1 = (THIS_DIR / \"string_quotes.py\").resolve()\n <mask>             result = CliRunner().invoke(black.main, [str(src1), \"--diff\", \"--check\"])\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove             self.assertEqual(result.exit_code, 1)\n </s> add             self.assertEqual(result.exit_code, 1, result.output) </s> remove def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:\n </s> add def assert_stable(\n    src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n) -> None: </s> remove def get_cache_file(line_length: int) -> Path:\n    return CACHE_DIR / f\"cache.{line_length}.pickle\"\n </s> add def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n    return (\n        CACHE_DIR\n        / f\"cache.{line_length}{'.pyi' if pyi else ''}{'.py36' if py36 else ''}.pickle\"\n    ) </s> remove     cache_file = get_cache_file(line_length)\n </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> add     force_pyi: bool = False,\n    force_py36: bool = False, </s> remove def read_cache(line_length: int) -> Cache:\n </s> add def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache:", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             # Multi file command.\n <mask>             result = CliRunner().invoke(\n <mask>                 black.main, [str(src1), str(src2), \"--diff\", \"--check\"]\n <mask>             )\n <mask>             self.assertEqual(result.exit_code, 1)\n <mask> \n <mask>     def test_no_files(self) -> None:\n <mask>         with cache_dir():\n <mask>             # Without an argument, black exits with error code 0.\n <mask>             result = CliRunner().invoke(black.main, [])\n </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> add     @event_loop(close=False) </s> add     force_pyi: bool = False,\n    force_py36: bool = False, </s> remove     is_pyi = src.suffix == \".pyi\"\n </s> add     is_pyi = force_pyi or src.suffix == \".pyi\" </s> remove     cache_file = get_cache_file(line_length)\n </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi\n </s> add             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO\n </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ) -> None:\n <mask>     \"\"\"Run Black and record failures\"\"\"\n <mask>     cmd = [str(which(BLACK_BINARY))]\n <mask>     if \"cli_arguments\" in project_config and project_config[\"cli_arguments\"]:\n <mask>         cmd.extend(*project_config[\"cli_arguments\"])\n <mask>     cmd.append(\"--check\")\n <mask>     if no_diff:\n <mask>         cmd.append(\".\")\n <mask>     else:\n <mask>         cmd.extend([\"--diff\", \".\"])\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/lib.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> {\n <mask>   \"configuration_format_version\": 20200509,\n <mask>   \"projects\": {\n <mask>     \"aioexabgp\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/cooperlees/aioexabgp.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"attrs\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/python-attrs/attrs.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"bandersnatch\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/pypa/bandersnatch.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"channels\": {\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"channels\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/django/channels.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     },\n <mask>     \"django\": {\n <mask>       \"disabled_reason\": \"black --check --diff returned 123 on tests_syntax_error.py\",\n <mask>       \"disabled\": true,\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/django/django.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"flake8-bugbear\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/PyCQA/flake8-bugbear.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"hypothesis\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/HypothesisWorks/hypothesis.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"pandas\": {\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     },\n <mask>     \"pandas\": {\n <mask>       \"disabled_reason\": \"black-primer runs failing on Pandas - #2193\",\n <mask>       \"disabled\": true,\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/pandas-dev/pandas.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"no_cli_args_reason\": \"breaks black with new string parsing - #2188\", </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"pillow\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/python-pillow/Pillow.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"poetry\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/python-poetry/poetry.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"pyanalyze\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/quora/pyanalyze.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"pyramid\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/Pylons/pyramid.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"ptr\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/facebookincubator/ptr.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"pytest\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/pytest-dev/pytest.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"sqlalchemy\": {\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> add       \"no_cli_args_reason\": \"breaks black with new string parsing - #2188\", </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"sqlalchemy\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/sqlalchemy/sqlalchemy.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"tox\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/tox-dev/tox.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"typeshed\": {\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"typeshed\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/python/typeshed.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"virtualenv\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/pypa/virtualenv.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"warehouse\": {\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"warehouse\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/pypa/warehouse.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     }\n </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"Holds leaves and comments. Can be printed with `str(line)`.\"\"\"\n <mask> \n <mask>     depth: int = 0\n <mask>     leaves: List[Leaf] = Factory(list)\n <mask>     # The LeafID keys of comments must remain ordered by the corresponding leaf's index\n <mask>     # in leaves\n <mask>     comments: Dict[LeafID, List[Leaf]] = Factory(dict)\n <mask>     bracket_tracker: BracketTracker = Factory(BracketTracker)\n <mask>     inside_brackets: bool = False\n <mask>     should_explode: bool = False\n <mask> \n <mask>     def append(self, leaf: Leaf, preformatted: bool = False) -> None:\n </s> Simplify the #606 patch\n\nThanks for the original patch to solve #509, @hauntsaninja. </s> remove         else:\n            leaf_id = id(self.leaves[-1])\n            if leaf_id not in self.comments:\n                self.comments[leaf_id] = [comment]\n            else:\n                self.comments[leaf_id].append(comment)\n            return True\n </s> add         self.comments.setdefault(id(self.leaves[-1]), []).append(comment)\n        return True </s> remove         # Remember, the LeafID keys of self.comments are ordered by the\n        # corresponding leaf's index in self.leaves\n        # If id(self.leaves[-2]) is in self.comments, the order doesn't change.\n        # Otherwise, we insert it into self.comments, and it becomes the last entry.\n        # However, since we delete id(self.leaves[-1]) from self.comments, the invariant\n        # is maintained\n        self.comments.setdefault(id(self.leaves[-2]), []).extend(\n            self.comments.get(id(self.leaves[-1]), [])\n </s> add         trailing_comma = self.leaves.pop()\n        trailing_comma_comments = self.comments.pop(id(trailing_comma), [])\n        self.comments.setdefault(id(self.leaves[-1]), []).extend(\n            trailing_comma_comments </s> remove         self.comments.pop(id(self.leaves[-1]), None)\n        self.leaves.pop()\n </s> add ", "html_url": "https://github.com/psf/black/commit/087fedb17eeb6e9b1189792ca046ffa6d98579fe", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             comment.type = STANDALONE_COMMENT\n <mask>             comment.prefix = \"\"\n <mask>             return False\n <mask> \n <mask>         else:\n <mask>             leaf_id = id(self.leaves[-1])\n <mask>             if leaf_id not in self.comments:\n <mask>                 self.comments[leaf_id] = [comment]\n <mask>             else:\n <mask>                 self.comments[leaf_id].append(comment)\n <mask>             return True\n <mask> \n <mask>     def comments_after(self, leaf: Leaf) -> List[Leaf]:\n <mask>         \"\"\"Generate comments that should appear directly after `leaf`.\"\"\"\n <mask>         return self.comments.get(id(leaf), [])\n <mask> \n </s> Simplify the #606 patch\n\nThanks for the original patch to solve #509, @hauntsaninja. </s> remove     # The LeafID keys of comments must remain ordered by the corresponding leaf's index\n    # in leaves\n    comments: Dict[LeafID, List[Leaf]] = Factory(dict)\n </s> add     comments: Dict[LeafID, List[Leaf]] = Factory(dict)  # keys ordered like `leaves` </s> remove         # Remember, the LeafID keys of self.comments are ordered by the\n        # corresponding leaf's index in self.leaves\n        # If id(self.leaves[-2]) is in self.comments, the order doesn't change.\n        # Otherwise, we insert it into self.comments, and it becomes the last entry.\n        # However, since we delete id(self.leaves[-1]) from self.comments, the invariant\n        # is maintained\n        self.comments.setdefault(id(self.leaves[-2]), []).extend(\n            self.comments.get(id(self.leaves[-1]), [])\n </s> add         trailing_comma = self.leaves.pop()\n        trailing_comma_comments = self.comments.pop(id(trailing_comma), [])\n        self.comments.setdefault(id(self.leaves[-1]), []).extend(\n            trailing_comma_comments </s> remove         self.comments.pop(id(self.leaves[-1]), None)\n        self.leaves.pop()\n </s> add ", "html_url": "https://github.com/psf/black/commit/087fedb17eeb6e9b1189792ca046ffa6d98579fe", "file_name": "black.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace replace replace keep replace replace", "code_tokens": " <mask>     def remove_trailing_comma(self) -> None:\n <mask>         \"\"\"Remove the trailing comma and moves the comments attached to it.\"\"\"\n <mask>         # Remember, the LeafID keys of self.comments are ordered by the\n <mask>         # corresponding leaf's index in self.leaves\n <mask>         # If id(self.leaves[-2]) is in self.comments, the order doesn't change.\n <mask>         # Otherwise, we insert it into self.comments, and it becomes the last entry.\n <mask>         # However, since we delete id(self.leaves[-1]) from self.comments, the invariant\n <mask>         # is maintained\n <mask>         self.comments.setdefault(id(self.leaves[-2]), []).extend(\n <mask>             self.comments.get(id(self.leaves[-1]), [])\n <mask>         )\n <mask>         self.comments.pop(id(self.leaves[-1]), None)\n <mask>         self.leaves.pop()\n </s> Simplify the #606 patch\n\nThanks for the original patch to solve #509, @hauntsaninja. </s> remove     # The LeafID keys of comments must remain ordered by the corresponding leaf's index\n    # in leaves\n    comments: Dict[LeafID, List[Leaf]] = Factory(dict)\n </s> add     comments: Dict[LeafID, List[Leaf]] = Factory(dict)  # keys ordered like `leaves` </s> remove         else:\n            leaf_id = id(self.leaves[-1])\n            if leaf_id not in self.comments:\n                self.comments[leaf_id] = [comment]\n            else:\n                self.comments[leaf_id].append(comment)\n            return True\n </s> add         self.comments.setdefault(id(self.leaves[-1]), []).append(comment)\n        return True", "html_url": "https://github.com/psf/black/commit/087fedb17eeb6e9b1189792ca046ffa6d98579fe", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return 0\n <mask> \n <mask> \n <mask> def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:\n <mask>     \"\"\"Return the priority of the `leaf` delimiter, given a line before after it.\n <mask> \n <mask>     The delimiter priorities returned here are from those delimiters that would\n <mask>     cause a line break before themselves.\n <mask> \n <mask>     Higher numbers are higher priority.\n </s> Make sure `async for` is not broken up to separate lines (#503)\n\nFixes #372. </s> remove     if leaf.type != token.NAME:\n </s> add     if leaf.type not in {token.NAME, token.ASYNC}: </s> remove         return COMPREHENSION_PRIORITY\n </s> add         if (\n            not isinstance(leaf.prev_sibling, Leaf)\n            or leaf.prev_sibling.value != \"async\"\n        ):\n            return COMPREHENSION_PRIORITY </s> add def g():\n    return (something_long * something_long async for something_long in async_generator(with_an_argument))\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> add def g():\n    return (\n        something_long * something_long\n        async for something_long in async_generator(with_an_argument)\n    )\n\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> add         or leaf.type == token.ASYNC", "html_url": "https://github.com/psf/black/commit/08f1cdd00b4876b2a0545d46981924d5873a3289", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         and previous.type == token.STRING\n <mask>     ):\n <mask>         return STRING_PRIORITY\n <mask> \n <mask>     if leaf.type != token.NAME:\n <mask>         return 0\n <mask> \n <mask>     if (\n <mask>         leaf.value == \"for\"\n <mask>         and leaf.parent\n </s> Make sure `async for` is not broken up to separate lines (#503)\n\nFixes #372. </s> remove         return COMPREHENSION_PRIORITY\n </s> add         if (\n            not isinstance(leaf.prev_sibling, Leaf)\n            or leaf.prev_sibling.value != \"async\"\n        ):\n            return COMPREHENSION_PRIORITY </s> add         or leaf.type == token.ASYNC </s> add def g():\n    return (\n        something_long * something_long\n        async for something_long in async_generator(with_an_argument)\n    )\n\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> add def g():\n    return (something_long * something_long async for something_long in async_generator(with_an_argument))\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> remove     \"\"\"Return the priority of the `leaf` delimiter, given a line before after it.\n </s> add     \"\"\"Return the priority of the `leaf` delimiter, given a line break before it.", "html_url": "https://github.com/psf/black/commit/08f1cdd00b4876b2a0545d46981924d5873a3289", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         leaf.value == \"for\"\n <mask>         and leaf.parent\n <mask>         and leaf.parent.type in {syms.comp_for, syms.old_comp_for}\n <mask>     ):\n <mask>         if (\n <mask>             not isinstance(leaf.prev_sibling, Leaf)\n <mask>             or leaf.prev_sibling.value != \"async\"\n <mask>         ):\n </s> Make sure `async for` is not broken up to separate lines (#503)\n\nFixes #372. </s> remove         return COMPREHENSION_PRIORITY\n </s> add         if (\n            not isinstance(leaf.prev_sibling, Leaf)\n            or leaf.prev_sibling.value != \"async\"\n        ):\n            return COMPREHENSION_PRIORITY </s> remove     if leaf.type != token.NAME:\n </s> add     if leaf.type not in {token.NAME, token.ASYNC}: </s> add def g():\n    return (\n        something_long * something_long\n        async for something_long in async_generator(with_an_argument)\n    )\n\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> add def g():\n    return (something_long * something_long async for something_long in async_generator(with_an_argument))\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> remove     \"\"\"Return the priority of the `leaf` delimiter, given a line before after it.\n </s> add     \"\"\"Return the priority of the `leaf` delimiter, given a line break before it.", "html_url": "https://github.com/psf/black/commit/08f1cdd00b4876b2a0545d46981924d5873a3289", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         leaf.value == \"for\"\n <mask>         and leaf.parent\n <mask>         and leaf.parent.type in {syms.comp_for, syms.old_comp_for}\n <mask>     ):\n <mask>         return COMPREHENSION_PRIORITY\n <mask> \n <mask>     if (\n <mask>         leaf.value == \"if\"\n <mask>         and leaf.parent\n <mask>         and leaf.parent.type in {syms.comp_if, syms.old_comp_if}\n </s> Make sure `async for` is not broken up to separate lines (#503)\n\nFixes #372. </s> add         or leaf.type == token.ASYNC </s> remove     if leaf.type != token.NAME:\n </s> add     if leaf.type not in {token.NAME, token.ASYNC}: </s> add def g():\n    return (\n        something_long * something_long\n        async for something_long in async_generator(with_an_argument)\n    )\n\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> add def g():\n    return (something_long * something_long async for something_long in async_generator(with_an_argument))\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> remove     \"\"\"Return the priority of the `leaf` delimiter, given a line before after it.\n </s> add     \"\"\"Return the priority of the `leaf` delimiter, given a line break before it.", "html_url": "https://github.com/psf/black/commit/08f1cdd00b4876b2a0545d46981924d5873a3289", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     return (i*2 async for i in arange(42))\n <mask> \n <mask> # output\n <mask> \n <mask> \n <mask> #!/usr/bin/env python3.7\n <mask> \n <mask> \n </s> Make sure `async for` is not broken up to separate lines (#503)\n\nFixes #372. </s> add def g():\n    return (\n        something_long * something_long\n        async for something_long in async_generator(with_an_argument)\n    )\n\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> remove         return COMPREHENSION_PRIORITY\n </s> add         if (\n            not isinstance(leaf.prev_sibling, Leaf)\n            or leaf.prev_sibling.value != \"async\"\n        ):\n            return COMPREHENSION_PRIORITY </s> remove     if leaf.type != token.NAME:\n </s> add     if leaf.type not in {token.NAME, token.ASYNC}: </s> add         or leaf.type == token.ASYNC </s> remove     \"\"\"Return the priority of the `leaf` delimiter, given a line before after it.\n </s> add     \"\"\"Return the priority of the `leaf` delimiter, given a line break before it.", "html_url": "https://github.com/psf/black/commit/08f1cdd00b4876b2a0545d46981924d5873a3289", "file_name": "tests/data/python37.py"}
{"docstring_tokens": "keep keep keep add", "code_tokens": " <mask> \n <mask> \n <mask> def f():\n <mask>     return (i * 2 async for i in arange(42))\n </s> Make sure `async for` is not broken up to separate lines (#503)\n\nFixes #372. </s> add def g():\n    return (something_long * something_long async for something_long in async_generator(with_an_argument))\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> remove         return COMPREHENSION_PRIORITY\n </s> add         if (\n            not isinstance(leaf.prev_sibling, Leaf)\n            or leaf.prev_sibling.value != \"async\"\n        ):\n            return COMPREHENSION_PRIORITY </s> remove     if leaf.type != token.NAME:\n </s> add     if leaf.type not in {token.NAME, token.ASYNC}: </s> add         or leaf.type == token.ASYNC </s> remove     \"\"\"Return the priority of the `leaf` delimiter, given a line before after it.\n </s> add     \"\"\"Return the priority of the `leaf` delimiter, given a line break before it.", "html_url": "https://github.com/psf/black/commit/08f1cdd00b4876b2a0545d46981924d5873a3289", "file_name": "tests/data/python37.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import re\n <mask> from typing import FrozenSet, List, Set, TYPE_CHECKING\n <mask> \n <mask> import pytest\n <mask> from _pytest.store import StoreKey\n <mask> \n <mask> log = logging.getLogger(__name__)\n <mask> \n <mask> \n <mask> if TYPE_CHECKING:\n </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> add import pathlib </s> remove from py.path import local\n </s> add  </s> remove from _pytest.tmpdir import tmpdir\n </s> add  </s> remove ALL_POSSIBLE_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]()\nENABLED_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]()\n </s> add ALL_POSSIBLE_OPTIONAL_MARKERS = StashKey[FrozenSet[str]]()\nENABLED_OPTIONAL_MARKERS = StashKey[FrozenSet[str]]() </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\"", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/optional.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     from _pytest.mark.structures import MarkDecorator\n <mask>     from _pytest.nodes import Node\n <mask> \n <mask> \n <mask> ALL_POSSIBLE_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]()\n <mask> ENABLED_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]()\n <mask> \n <mask> \n <mask> def pytest_addoption(parser: \"Parser\") -> None:\n <mask>     group = parser.getgroup(\"collect\")\n <mask>     group.addoption(\n </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove from _pytest.tmpdir import tmpdir\n </s> add  </s> add import pathlib </s> remove from py.path import local\n </s> add  </s> remove from _pytest.store import StoreKey\n </s> add try:\n    from pytest import StashKey\nexcept ImportError:\n    # pytest < 7\n    from _pytest.store import StoreKey as StashKey </s> remove def test_ipynb_flag(tmpdir: local) -> None:\n </s> add def test_ipynb_flag(tmp_path: pathlib.Path) -> None: </s> remove def test_ipynb_diff_with_no_change_dir(tmpdir: tmpdir) -> None:\n </s> add def test_ipynb_diff_with_no_change_dir(tmp_path: pathlib.Path) -> None:", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/optional.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> )\n <mask> import pytest\n <mask> from black import Mode\n <mask> from _pytest.monkeypatch import MonkeyPatch\n <mask> from py.path import local\n <mask> from tests.util import DATA_DIR\n <mask> \n <mask> pytestmark = pytest.mark.jupyter\n <mask> pytest.importorskip(\"IPython\", reason=\"IPython is an optional dependency\")\n <mask> pytest.importorskip(\"tokenize_rt\", reason=\"tokenize-rt is an optional dependency\")\n </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> add import pathlib </s> remove from _pytest.tmpdir import tmpdir\n </s> add  </s> remove from _pytest.store import StoreKey\n </s> add try:\n    from pytest import StashKey\nexcept ImportError:\n    # pytest < 7\n    from _pytest.store import StoreKey as StashKey </s> remove ALL_POSSIBLE_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]()\nENABLED_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]()\n </s> add ALL_POSSIBLE_OPTIONAL_MARKERS = StashKey[FrozenSet[str]]()\nENABLED_OPTIONAL_MARKERS = StashKey[FrozenSet[str]]() </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")])\n </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")]) </s> remove     monkeypatch: MonkeyPatch, tmpdir: local\n </s> add     monkeypatch: MonkeyPatch, tmp_path: pathlib.Path", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep replace keep", "code_tokens": " <mask>     assert expected in result.output\n <mask> \n <mask> \n <mask> def test_cache_isnt_written_if_no_jupyter_deps_single(\n <mask>     monkeypatch: MonkeyPatch, tmpdir: local\n <mask> ) -> None:\n <mask>     # Check that the cache isn't written to if Jupyter dependencies aren't installed.\n <mask>     jupyter_dependencies_are_installed.cache_clear()\n <mask>     nb = DATA_DIR / \"notebook_trailing_newline.ipynb\"\n <mask>     tmp_nb = tmpdir / \"notebook.ipynb\"\n <mask>     with open(nb) as src, open(tmp_nb, \"w\") as dst:\n </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     monkeypatch: MonkeyPatch, tmpdir: local\n </s> add     monkeypatch: MonkeyPatch, tmp_path: pathlib.Path </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")])\n </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")]) </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove def test_ipynb_diff_with_no_change_dir(tmpdir: tmpdir) -> None:\n </s> add def test_ipynb_diff_with_no_change_dir(tmp_path: pathlib.Path) -> None:", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         dst.write(src.read())\n <mask>     monkeypatch.setattr(\n <mask>         \"black.jupyter_dependencies_are_installed\", lambda verbose, quiet: False\n <mask>     )\n <mask>     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")])\n <mask>     assert \"No Python files are present to be formatted. Nothing to do\" in result.output\n <mask>     jupyter_dependencies_are_installed.cache_clear()\n <mask>     monkeypatch.setattr(\n <mask>         \"black.jupyter_dependencies_are_installed\", lambda verbose, quiet: True\n <mask>     )\n </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     result = runner.invoke(main, [str(tmpdir)])\n </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")])\n </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")]) </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     result = runner.invoke(main, [str(tmpdir)])\n </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     result = runner.invoke(main, [str(tmpdir)])\n </s> add     result = runner.invoke(main, [str(tmp_path)])", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace keep", "code_tokens": " <mask>     )\n <mask>     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")])\n <mask>     assert \"reformatted\" in result.output\n <mask> \n <mask> \n <mask> def test_cache_isnt_written_if_no_jupyter_deps_dir(\n <mask>     monkeypatch: MonkeyPatch, tmpdir: local\n <mask> ) -> None:\n </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     monkeypatch: MonkeyPatch, tmpdir: local\n </s> add     monkeypatch: MonkeyPatch, tmp_path: pathlib.Path </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")])\n </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")]) </s> remove     result = runner.invoke(main, [str(tmpdir)])\n </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove def test_ipynb_flag(tmpdir: local) -> None:\n </s> add def test_ipynb_flag(tmp_path: pathlib.Path) -> None: </s> remove def test_ipynb_diff_with_no_change_dir(tmpdir: tmpdir) -> None:\n </s> add def test_ipynb_diff_with_no_change_dir(tmp_path: pathlib.Path) -> None:", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ) -> None:\n <mask>     # Check that the cache isn't written to if Jupyter dependencies aren't installed.\n <mask>     jupyter_dependencies_are_installed.cache_clear()\n <mask>     nb = DATA_DIR / \"notebook_trailing_newline.ipynb\"\n <mask>     tmp_nb = tmpdir / \"notebook.ipynb\"\n <mask>     with open(nb) as src, open(tmp_nb, \"w\") as dst:\n <mask>         dst.write(src.read())\n <mask>     monkeypatch.setattr(\n <mask>         \"black.files.jupyter_dependencies_are_installed\", lambda verbose, quiet: False\n <mask>     )\n </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     monkeypatch: MonkeyPatch, tmpdir: local\n </s> add     monkeypatch: MonkeyPatch, tmp_path: pathlib.Path </s> remove     monkeypatch: MonkeyPatch, tmpdir: local\n </s> add     monkeypatch: MonkeyPatch, tmp_path: pathlib.Path </s> remove     result = runner.invoke(main, [str(tmpdir)])\n </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove     result = runner.invoke(main, [str(tmpdir)])\n </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")])\n </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")])", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         dst.write(src.read())\n <mask>     monkeypatch.setattr(\n <mask>         \"black.files.jupyter_dependencies_are_installed\", lambda verbose, quiet: False\n <mask>     )\n <mask>     result = runner.invoke(main, [str(tmpdir)])\n <mask>     assert \"No Python files are present to be formatted. Nothing to do\" in result.output\n <mask>     jupyter_dependencies_are_installed.cache_clear()\n <mask>     monkeypatch.setattr(\n <mask>         \"black.files.jupyter_dependencies_are_installed\", lambda verbose, quiet: True\n <mask>     )\n </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")])\n </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")]) </s> remove     result = runner.invoke(main, [str(tmpdir)])\n </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")])\n </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")]) </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     result = runner.invoke(main, [str(tmpdir)])\n </s> add     result = runner.invoke(main, [str(tmp_path)])", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep replace", "code_tokens": " <mask>     jupyter_dependencies_are_installed.cache_clear()\n <mask>     monkeypatch.setattr(\n <mask>         \"black.files.jupyter_dependencies_are_installed\", lambda verbose, quiet: True\n <mask>     )\n <mask>     result = runner.invoke(main, [str(tmpdir)])\n <mask>     assert \"reformatted\" in result.output\n <mask> \n <mask> \n <mask> def test_ipynb_flag(tmpdir: local) -> None:\n </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     result = runner.invoke(main, [str(tmpdir)])\n </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")])\n </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")]) </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")])\n </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")]) </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.a_file_extension_which_is_definitely_not_ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.a_file_extension_which_is_definitely_not_ipynb\"", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def test_ipynb_flag(tmpdir: local) -> None:\n <mask>     nb = DATA_DIR / \"notebook_trailing_newline.ipynb\"\n <mask>     tmp_nb = tmpdir / \"notebook.a_file_extension_which_is_definitely_not_ipynb\"\n <mask>     with open(nb) as src, open(tmp_nb, \"w\") as dst:\n <mask>         dst.write(src.read())\n <mask>     result = runner.invoke(\n <mask>         main,\n <mask>         [\n </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove def test_ipynb_flag(tmpdir: local) -> None:\n </s> add def test_ipynb_flag(tmp_path: pathlib.Path) -> None: </s> remove     result = runner.invoke(main, [str(tmpdir)])\n </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove def test_ipynb_diff_with_no_change_dir(tmpdir: tmpdir) -> None:\n </s> add def test_ipynb_diff_with_no_change_dir(tmp_path: pathlib.Path) -> None:", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> import pytest\n <mask> import os\n <mask> \n <mask> from tests.util import THIS_DIR\n <mask> from black import main, jupyter_dependencies_are_installed\n <mask> from click.testing import CliRunner\n <mask> \n <mask> pytestmark = pytest.mark.no_jupyter\n </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove from _pytest.tmpdir import tmpdir\n </s> add  </s> remove from py.path import local\n </s> add  </s> remove from _pytest.store import StoreKey\n </s> add try:\n    from pytest import StashKey\nexcept ImportError:\n    # pytest < 7\n    from _pytest.store import StoreKey as StashKey </s> remove ALL_POSSIBLE_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]()\nENABLED_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]()\n </s> add ALL_POSSIBLE_OPTIONAL_MARKERS = StashKey[FrozenSet[str]]()\nENABLED_OPTIONAL_MARKERS = StashKey[FrozenSet[str]]() </s> remove     tmp_nb = tmpdir / \"notebook.a_file_extension_which_is_definitely_not_ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.a_file_extension_which_is_definitely_not_ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\"", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_no_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from tests.util import THIS_DIR\n <mask> from black import main, jupyter_dependencies_are_installed\n <mask> from click.testing import CliRunner\n <mask> from _pytest.tmpdir import tmpdir\n <mask> \n <mask> pytestmark = pytest.mark.no_jupyter\n <mask> \n <mask> runner = CliRunner()\n <mask> \n </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> add import pathlib </s> remove from py.path import local\n </s> add  </s> remove from _pytest.store import StoreKey\n </s> add try:\n    from pytest import StashKey\nexcept ImportError:\n    # pytest < 7\n    from _pytest.store import StoreKey as StashKey </s> remove ALL_POSSIBLE_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]()\nENABLED_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]()\n </s> add ALL_POSSIBLE_OPTIONAL_MARKERS = StashKey[FrozenSet[str]]()\nENABLED_OPTIONAL_MARKERS = StashKey[FrozenSet[str]]() </s> remove def test_ipynb_diff_with_no_change_dir(tmpdir: tmpdir) -> None:\n </s> add def test_ipynb_diff_with_no_change_dir(tmp_path: pathlib.Path) -> None: </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\"", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_no_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask>     )\n <mask>     assert expected_output in result.output\n <mask> \n <mask> \n <mask> def test_ipynb_diff_with_no_change_dir(tmpdir: tmpdir) -> None:\n <mask>     jupyter_dependencies_are_installed.cache_clear()\n <mask>     runner = CliRunner()\n <mask>     nb = os.path.join(\"tests\", \"data\", \"notebook_trailing_newline.ipynb\")\n <mask>     tmp_nb = tmpdir / \"notebook.ipynb\"\n <mask>     with open(nb) as src, open(tmp_nb, \"w\") as dst:\n <mask>         dst.write(src.read())\n <mask>     result = runner.invoke(main, [str(tmpdir)])\n <mask>     expected_output = (\n </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     result = runner.invoke(main, [str(tmpdir)])\n </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove def test_ipynb_flag(tmpdir: local) -> None:\n </s> add def test_ipynb_flag(tmp_path: pathlib.Path) -> None: </s> remove     tmp_nb = tmpdir / \"notebook.a_file_extension_which_is_definitely_not_ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.a_file_extension_which_is_definitely_not_ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\"", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_no_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     nb = os.path.join(\"tests\", \"data\", \"notebook_trailing_newline.ipynb\")\n <mask>     tmp_nb = tmpdir / \"notebook.ipynb\"\n <mask>     with open(nb) as src, open(tmp_nb, \"w\") as dst:\n <mask>         dst.write(src.read())\n <mask>     result = runner.invoke(main, [str(tmpdir)])\n <mask>     expected_output = (\n <mask>         \"Skipping .ipynb files as Jupyter dependencies are not installed.\\n\"\n <mask>         \"You can fix this by running ``pip install black[jupyter]``\\n\"\n <mask>     )\n <mask>     assert expected_output in result.output\n </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove def test_ipynb_diff_with_no_change_dir(tmpdir: tmpdir) -> None:\n </s> add def test_ipynb_diff_with_no_change_dir(tmp_path: pathlib.Path) -> None: </s> remove def test_ipynb_flag(tmpdir: local) -> None:\n </s> add def test_ipynb_flag(tmp_path: pathlib.Path) -> None: </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.a_file_extension_which_is_definitely_not_ipynb\"\n </s> add     tmp_nb = tmp_path / \"notebook.a_file_extension_which_is_definitely_not_ipynb\"", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_no_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep", "code_tokens": " <mask> \n <mask> [flake8]\n <mask> ignore = E203, E266, E501, W503\n <mask> max-line-length = 80\n <mask> max-complexity = 15\n <mask> select = B,C,E,F,W,T4,B9\n </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> remove __version__ = \"18.4a5\"\n </s> add __version__ = \"18.4a6\" </s> remove     \"\"\"Split line into many lines, starting with the last matching bracket pair.\"\"\"\n </s> add     \"\"\"Split line into many lines, starting with the last matching bracket pair.\n\n    If the split was by optional parentheses, attempt splitting without them, too.\n    \"\"\" </s> remove     Prefer RHS otherwise.\n </s> add     Prefer RHS otherwise.  This is why this function is not symmetrical with\n    :func:`right_hand_split` which also handles optional parentheses. </s> add         except CannotSplit:\n            pass </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit}\n </s> add         omit = {id(closing_bracket), *omit}\n        try: </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": ".flake8"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from blib2to3 import pygram, pytree\n <mask> from blib2to3.pgen2 import driver, token\n <mask> from blib2to3.pgen2.parse import ParseError\n <mask> \n <mask> __version__ = \"18.4a5\"\n <mask> DEFAULT_LINE_LENGTH = 88\n <mask> \n <mask> # types\n <mask> syms = pygram.python_symbols\n <mask> FileContent = str\n </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> add from name_of_a_company.extremely_long_project_name.component.ttypes import CuteLittleServiceHandlerFactoryyy </s> add from name_of_a_company.extremely_long_project_name.component.ttypes import (\n    CuteLittleServiceHandlerFactoryyy\n) </s> add         except CannotSplit:\n            pass </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import </s> remove max-complexity = 15\n </s> add max-complexity = 18 </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit}\n </s> add         omit = {id(closing_bracket), *omit}\n        try:", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:\n <mask>     \"\"\"Split line into many lines, starting with the first matching bracket pair.\n <mask> \n <mask>     Note: this usually looks weird, only use this for function definitions.\n <mask>     Prefer RHS otherwise.\n <mask>     \"\"\"\n <mask>     head = Line(depth=line.depth)\n <mask>     body = Line(depth=line.depth + 1, inside_brackets=True)\n <mask>     tail = Line(depth=line.depth)\n <mask>     tail_leaves: List[Leaf] = []\n </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> remove     \"\"\"Split line into many lines, starting with the last matching bracket pair.\"\"\"\n </s> add     \"\"\"Split line into many lines, starting with the last matching bracket pair.\n\n    If the split was by optional parentheses, attempt splitting without them, too.\n    \"\"\" </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import </s> add         except CannotSplit:\n            pass </s> remove max-complexity = 15\n </s> add max-complexity = 18 </s> remove __version__ = \"18.4a5\"\n </s> add __version__ = \"18.4a6\" </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit}\n </s> add         omit = {id(closing_bracket), *omit}\n        try:", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def right_hand_split(\n <mask>     line: Line, py36: bool = False, omit: Collection[LeafID] = ()\n <mask> ) -> Iterator[Line]:\n <mask>     \"\"\"Split line into many lines, starting with the last matching bracket pair.\"\"\"\n <mask>     head = Line(depth=line.depth)\n <mask>     body = Line(depth=line.depth + 1, inside_brackets=True)\n <mask>     tail = Line(depth=line.depth)\n <mask>     tail_leaves: List[Leaf] = []\n <mask>     body_leaves: List[Leaf] = []\n </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> remove     Prefer RHS otherwise.\n </s> add     Prefer RHS otherwise.  This is why this function is not symmetrical with\n    :func:`right_hand_split` which also handles optional parentheses. </s> remove max-complexity = 15\n </s> add max-complexity = 18 </s> remove __version__ = \"18.4a5\"\n </s> add __version__ = \"18.4a6\" </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit}\n </s> add         omit = {id(closing_bracket), *omit}\n        try: </s> add         except CannotSplit:\n            pass </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     bracket_split_succeeded_or_raise(head, body, tail)\n <mask>     assert opening_bracket and closing_bracket\n <mask>     if (\n <mask>         opening_bracket.type == token.LPAR\n <mask>         and not opening_bracket.value\n <mask>         # the closing bracket is an optional paren\n <mask>         and closing_bracket.type == token.RPAR\n <mask>         and not closing_bracket.value\n <mask>         # there are no delimiters or standalone comments in the body\n </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> add         # the closing bracket is an optional paren </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit}\n </s> add         omit = {id(closing_bracket), *omit}\n        try: </s> remove     Prefer RHS otherwise.\n </s> add     Prefer RHS otherwise.  This is why this function is not symmetrical with\n    :func:`right_hand_split` which also handles optional parentheses. </s> remove     \"\"\"Split line into many lines, starting with the last matching bracket pair.\"\"\"\n </s> add     \"\"\"Split line into many lines, starting with the last matching bracket pair.\n\n    If the split was by optional parentheses, attempt splitting without them, too.\n    \"\"\" </s> add         except CannotSplit:\n            pass", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         opening_bracket.type == token.LPAR\n <mask>         and not opening_bracket.value\n <mask>         and closing_bracket.type == token.RPAR\n <mask>         and not closing_bracket.value\n <mask>         # there are no delimiters or standalone comments in the body\n <mask>         and not body.bracket_tracker.delimiters\n <mask>         and not line.contains_standalone_comments(0)\n </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> add         # the opening bracket is an optional paren </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit}\n </s> add         omit = {id(closing_bracket), *omit}\n        try: </s> remove     Prefer RHS otherwise.\n </s> add     Prefer RHS otherwise.  This is why this function is not symmetrical with\n    :func:`right_hand_split` which also handles optional parentheses. </s> remove     \"\"\"Split line into many lines, starting with the last matching bracket pair.\"\"\"\n </s> add     \"\"\"Split line into many lines, starting with the last matching bracket pair.\n\n    If the split was by optional parentheses, attempt splitting without them, too.\n    \"\"\" </s> add         except CannotSplit:\n            pass", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         and not opening_bracket.value\n <mask>         # the closing bracket is an optional paren\n <mask>         and closing_bracket.type == token.RPAR\n <mask>         and not closing_bracket.value\n <mask>     ):\n <mask>         omit = {id(closing_bracket), *omit}\n <mask>         try:\n <mask>             yield from right_hand_split(line, py36=py36, omit=omit)\n </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit}\n </s> add         omit = {id(closing_bracket), *omit}\n        try: </s> add         # the opening bracket is an optional paren </s> add         # the closing bracket is an optional paren </s> add         except CannotSplit:\n            pass </s> remove     Prefer RHS otherwise.\n </s> add     Prefer RHS otherwise.  This is why this function is not symmetrical with\n    :func:`right_hand_split` which also handles optional parentheses. </s> remove __version__ = \"18.4a5\"\n </s> add __version__ = \"18.4a6\"", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         and not opening_bracket.value\n <mask>         and closing_bracket.type == token.RPAR\n <mask>         and not closing_bracket.value\n <mask>     ):\n <mask>         # These parens were optional. If there aren't any delimiters or standalone\n <mask>         # comments in the body, they were unnecessary and another split without\n <mask>         # them should be attempted.\n <mask>         if not (\n <mask>             body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n <mask>         ):\n <mask>             omit = {id(closing_bracket), *omit}\n <mask>             yield from right_hand_split(line, py36=py36, omit=omit)\n <mask>             return\n <mask> \n <mask>     ensure_visible(opening_bracket)\n <mask>     ensure_visible(closing_bracket)\n </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import </s> add         except CannotSplit:\n            pass </s> add         # the closing bracket is an optional paren </s> add         # the opening bracket is an optional paren </s> remove     \"\"\"Split line into many lines, starting with the last matching bracket pair.\"\"\"\n </s> add     \"\"\"Split line into many lines, starting with the last matching bracket pair.\n\n    If the split was by optional parentheses, attempt splitting without them, too.\n    \"\"\" </s> remove __version__ = \"18.4a5\"\n </s> add __version__ = \"18.4a6\"", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         omit = {id(closing_bracket), *omit}\n <mask>         try:\n <mask>             yield from right_hand_split(line, py36=py36, omit=omit)\n <mask>             return\n <mask> \n <mask>     ensure_visible(opening_bracket)\n <mask>     ensure_visible(closing_bracket)\n <mask>     for result in (head, body, tail):\n </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit}\n </s> add         omit = {id(closing_bracket), *omit}\n        try: </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import </s> remove     Prefer RHS otherwise.\n </s> add     Prefer RHS otherwise.  This is why this function is not symmetrical with\n    :func:`right_hand_split` which also handles optional parentheses. </s> remove __version__ = \"18.4a5\"\n </s> add __version__ = \"18.4a6\" </s> add         # the opening bracket is an optional paren </s> remove max-complexity = 15\n </s> add max-complexity = 18", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> from some_library import (\n <mask>     Just, Enough, Libraries, To, Fit, In, This, Nice, Split, Which, We, No, Longer, Use\n <mask> )\n <mask> \n <mask> from .a.b.c.subprocess import *\n <mask> from . import (tasks)\n <mask> from . import (A, B, C)\n <mask> from . import SomeVeryLongNameAndAllOfItsAdditionalLetters1, \\\n </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> add from name_of_a_company.extremely_long_project_name.component.ttypes import (\n    CuteLittleServiceHandlerFactoryyy\n) </s> remove __version__ = \"18.4a5\"\n </s> add __version__ = \"18.4a6\" </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import </s> add         except CannotSplit:\n            pass </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit}\n </s> add         omit = {id(closing_bracket), *omit}\n        try: </s> remove     \"\"\"Split line into many lines, starting with the last matching bracket pair.\"\"\"\n </s> add     \"\"\"Split line into many lines, starting with the last matching bracket pair.\n\n    If the split was by optional parentheses, attempt splitting without them, too.\n    \"\"\"", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "tests/import_spacing.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     Longer,\n <mask>     Use,\n <mask> )\n <mask> \n <mask> from .a.b.c.subprocess import *\n <mask> from . import tasks\n <mask> from . import A, B, C\n </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> add from name_of_a_company.extremely_long_project_name.component.ttypes import CuteLittleServiceHandlerFactoryyy </s> remove __version__ = \"18.4a5\"\n </s> add __version__ = \"18.4a6\" </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import </s> add         except CannotSplit:\n            pass </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit}\n </s> add         omit = {id(closing_bracket), *omit}\n        try: </s> remove     \"\"\"Split line into many lines, starting with the last matching bracket pair.\"\"\"\n </s> add     \"\"\"Split line into many lines, starting with the last matching bracket pair.\n\n    If the split was by optional parentheses, attempt splitting without them, too.\n    \"\"\"", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "tests/import_spacing.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import asyncio\n <mask> import logging\n <mask> import sys\n <mask> from concurrent.futures import Executor, ProcessPoolExecutor\n <mask> from datetime import datetime\n <mask> from functools import partial\n <mask> from multiprocessing import freeze_support\n <mask> from typing import Set, Tuple\n </s> Change sys.exit to raise ImportError (#2440)\n\nThe fix for #1688 in #1761 breaks help(\"modules\") introspection and also leads\r\nto unhappy results when inadvertently importing blackd from Python. Basically\r\nthe sys.exit(-1) causes the whole Python REPL to exit -- not great to suffice.\r\n\r\nCommit history before merge:\r\n\r\n* Change sys.exit to Raise.\r\n* Add #2440 to changelog.\r\n* Fix lint error from prettier\r\n* Remove exception chain for more helpful user message.\r\n\r\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove     print(\n </s> add     raise ImportError( </s> remove         + \"to obtain aiohttp_cors: `pip install black[d]`\",\n        file=sys.stderr,\n    )\n    sys.exit(-1)\n </s> add         + \"to obtain aiohttp_cors: `pip install black[d]`\"\n    ) from None", "html_url": "https://github.com/psf/black/commit/0969ca4a46c4a2081be38f7e96a81a74b308c75f", "file_name": "src/blackd/__init__.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace replace replace replace keep keep", "code_tokens": " <mask>     from aiohttp import web\n <mask>     import aiohttp_cors\n <mask> except ImportError as ie:\n <mask>     print(\n <mask>         f\"aiohttp dependency is not installed: {ie}. \"\n <mask>         + \"Please re-install black with the '[d]' extra install \"\n <mask>         + \"to obtain aiohttp_cors: `pip install black[d]`\",\n <mask>         file=sys.stderr,\n <mask>     )\n <mask>     sys.exit(-1)\n <mask> \n <mask> import black\n </s> Change sys.exit to raise ImportError (#2440)\n\nThe fix for #1688 in #1761 breaks help(\"modules\") introspection and also leads\r\nto unhappy results when inadvertently importing blackd from Python. Basically\r\nthe sys.exit(-1) causes the whole Python REPL to exit -- not great to suffice.\r\n\r\nCommit history before merge:\r\n\r\n* Change sys.exit to Raise.\r\n* Add #2440 to changelog.\r\n* Fix lint error from prettier\r\n* Remove exception chain for more helpful user message.\r\n\r\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove import sys\n </s> add ", "html_url": "https://github.com/psf/black/commit/0969ca4a46c4a2081be38f7e96a81a74b308c75f", "file_name": "src/blackd/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> if _initialize_black_env():\n <mask>   import black\n <mask>   import time\n <mask> \n <mask> def Black():\n <mask>   start = time.time()\n <mask>   configs = get_configs()\n <mask>   mode = black.FileMode(\n <mask>     line_length=configs[\"line_length\"],\n <mask>     string_normalization=not configs[\"skip_string_normalization\"],\n </s> Allow to pass the FileMode options in the vim plugin (#1319) </s> add   black_kwargs = {}\n  if \"target_version\" in kwargs:\n    target_version = kwargs[\"target_version\"]\n\n    if not isinstance(target_version, (list, set)):\n      target_version = [target_version]\n    target_version = set(filter(lambda x: x, map(lambda tv: get_target_version(tv), target_version)))\n    black_kwargs[\"target_versions\"] = target_version\n </s> remove function black#Black()\n  :py3 Black()\n </s> add function black#Black(...)\n    let kwargs = {}\n    for arg in a:000\n        let arg_list = split(arg, '=')\n        let kwargs[arg_list[0]] = arg_list[1]\n    endfor\npython3 << EOF\nimport vim\nkwargs = vim.eval(\"kwargs\")\nEOF\n  :py3 Black(**kwargs) </s> add     **black_kwargs, </s> add if !exists(\"g:black_target_version\")\n  let g:black_target_version = \"\"\nendif </s> remove command! Black :call black#Black()\n </s> add command! -nargs=* -complete=customlist,BlackComplete Black :call black#Black(<f-args>) </s> add function BlackComplete(ArgLead, CmdLine, CursorPos)\n  return [\n\\    'target_version=py27',\n\\    'target_version=py36',\n\\    'target_version=py37',\n\\    'target_version=py38',\n\\    'target_version=py39',\n\\  ]\nendfunction", "html_url": "https://github.com/psf/black/commit/09915f4bd2d13652c089b9a96408b39116d82eb0", "file_name": "autoload/black.vim"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>   start = time.time()\n <mask>   configs = get_configs()\n <mask>   mode = black.FileMode(\n <mask>     line_length=configs[\"line_length\"],\n <mask>     string_normalization=not configs[\"skip_string_normalization\"],\n <mask>     is_pyi=vim.current.buffer.name.endswith('.pyi'),\n <mask>     **black_kwargs,\n </s> Allow to pass the FileMode options in the vim plugin (#1319) </s> remove def Black():\n </s> add def get_target_version(tv):\n  if isinstance(tv, black.TargetVersion):\n    return tv\n  ret = None\n  try:\n    ret = black.TargetVersion[tv.upper()]\n  except KeyError:\n    print(f\"WARNING: Target version {tv!r} not recognized by Black, using default target\")\n  return ret\n\ndef Black(**kwargs):\n  \"\"\"\n  kwargs allows you to override ``target_versions`` argument of\n  ``black.FileMode``.\n\n  ``target_version`` needs to be cleaned because ``black.FileMode``\n  expects the ``target_versions`` argument to be a set of TargetVersion enums.\n\n  Allow kwargs[\"target_version\"] to be a string to allow\n  to type it more quickly.\n\n  Using also target_version instead of target_versions to remain\n  consistent to Black's documentation of the structure of pyproject.toml.\n  \"\"\" </s> add     **black_kwargs, </s> remove function black#Black()\n  :py3 Black()\n </s> add function black#Black(...)\n    let kwargs = {}\n    for arg in a:000\n        let arg_list = split(arg, '=')\n        let kwargs[arg_list[0]] = arg_list[1]\n    endfor\npython3 << EOF\nimport vim\nkwargs = vim.eval(\"kwargs\")\nEOF\n  :py3 Black(**kwargs) </s> add if !exists(\"g:black_target_version\")\n  let g:black_target_version = \"\"\nendif </s> remove command! Black :call black#Black()\n </s> add command! -nargs=* -complete=customlist,BlackComplete Black :call black#Black(<f-args>) </s> add function BlackComplete(ArgLead, CmdLine, CursorPos)\n  return [\n\\    'target_version=py27',\n\\    'target_version=py36',\n\\    'target_version=py37',\n\\    'target_version=py38',\n\\    'target_version=py39',\n\\  ]\nendfunction", "html_url": "https://github.com/psf/black/commit/09915f4bd2d13652c089b9a96408b39116d82eb0", "file_name": "autoload/black.vim"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     string_normalization=not configs[\"skip_string_normalization\"],\n <mask>     is_pyi=vim.current.buffer.name.endswith('.pyi'),\n <mask>   )\n <mask>   quiet = configs[\"quiet\"]\n <mask> \n <mask>   buffer_str = '\\n'.join(vim.current.buffer) + '\\n'\n <mask>   try:\n <mask>     new_buffer_str = black.format_file_contents(\n </s> Allow to pass the FileMode options in the vim plugin (#1319) </s> add   black_kwargs = {}\n  if \"target_version\" in kwargs:\n    target_version = kwargs[\"target_version\"]\n\n    if not isinstance(target_version, (list, set)):\n      target_version = [target_version]\n    target_version = set(filter(lambda x: x, map(lambda tv: get_target_version(tv), target_version)))\n    black_kwargs[\"target_versions\"] = target_version\n </s> remove def Black():\n </s> add def get_target_version(tv):\n  if isinstance(tv, black.TargetVersion):\n    return tv\n  ret = None\n  try:\n    ret = black.TargetVersion[tv.upper()]\n  except KeyError:\n    print(f\"WARNING: Target version {tv!r} not recognized by Black, using default target\")\n  return ret\n\ndef Black(**kwargs):\n  \"\"\"\n  kwargs allows you to override ``target_versions`` argument of\n  ``black.FileMode``.\n\n  ``target_version`` needs to be cleaned because ``black.FileMode``\n  expects the ``target_versions`` argument to be a set of TargetVersion enums.\n\n  Allow kwargs[\"target_version\"] to be a string to allow\n  to type it more quickly.\n\n  Using also target_version instead of target_versions to remain\n  consistent to Black's documentation of the structure of pyproject.toml.\n  \"\"\" </s> remove function black#Black()\n  :py3 Black()\n </s> add function black#Black(...)\n    let kwargs = {}\n    for arg in a:000\n        let arg_list = split(arg, '=')\n        let kwargs[arg_list[0]] = arg_list[1]\n    endfor\npython3 << EOF\nimport vim\nkwargs = vim.eval(\"kwargs\")\nEOF\n  :py3 Black(**kwargs) </s> add if !exists(\"g:black_target_version\")\n  let g:black_target_version = \"\"\nendif </s> remove command! Black :call black#Black()\n </s> add command! -nargs=* -complete=customlist,BlackComplete Black :call black#Black(<f-args>) </s> add function BlackComplete(ArgLead, CmdLine, CursorPos)\n  return [\n\\    'target_version=py27',\n\\    'target_version=py36',\n\\    'target_version=py37',\n\\    'target_version=py38',\n\\    'target_version=py39',\n\\  ]\nendfunction", "html_url": "https://github.com/psf/black/commit/09915f4bd2d13652c089b9a96408b39116d82eb0", "file_name": "autoload/black.vim"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>   print(f'Black, version {black.__version__} on Python {sys.version}.')\n <mask> \n <mask> EndPython3\n <mask> \n <mask> function black#Black()\n <mask>   :py3 Black()\n <mask> endfunction\n <mask> \n <mask> function black#BlackUpgrade()\n <mask>   :py3 BlackUpgrade()\n <mask> endfunction\n </s> Allow to pass the FileMode options in the vim plugin (#1319) </s> add function BlackComplete(ArgLead, CmdLine, CursorPos)\n  return [\n\\    'target_version=py27',\n\\    'target_version=py36',\n\\    'target_version=py37',\n\\    'target_version=py38',\n\\    'target_version=py39',\n\\  ]\nendfunction </s> remove command! Black :call black#Black()\n </s> add command! -nargs=* -complete=customlist,BlackComplete Black :call black#Black(<f-args>) </s> add if !exists(\"g:black_target_version\")\n  let g:black_target_version = \"\"\nendif </s> remove def Black():\n </s> add def get_target_version(tv):\n  if isinstance(tv, black.TargetVersion):\n    return tv\n  ret = None\n  try:\n    ret = black.TargetVersion[tv.upper()]\n  except KeyError:\n    print(f\"WARNING: Target version {tv!r} not recognized by Black, using default target\")\n  return ret\n\ndef Black(**kwargs):\n  \"\"\"\n  kwargs allows you to override ``target_versions`` argument of\n  ``black.FileMode``.\n\n  ``target_version`` needs to be cleaned because ``black.FileMode``\n  expects the ``target_versions`` argument to be a set of TargetVersion enums.\n\n  Allow kwargs[\"target_version\"] to be a string to allow\n  to type it more quickly.\n\n  Using also target_version instead of target_versions to remain\n  consistent to Black's documentation of the structure of pyproject.toml.\n  \"\"\" </s> add     **black_kwargs, </s> add   black_kwargs = {}\n  if \"target_version\" in kwargs:\n    target_version = kwargs[\"target_version\"]\n\n    if not isinstance(target_version, (list, set)):\n      target_version = [target_version]\n    target_version = set(filter(lambda x: x, map(lambda tv: get_target_version(tv), target_version)))\n    black_kwargs[\"target_versions\"] = target_version\n", "html_url": "https://github.com/psf/black/commit/09915f4bd2d13652c089b9a96408b39116d82eb0", "file_name": "autoload/black.vim"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> endif\n <mask> if !exists(\"g:black_quiet\")\n <mask>   let g:black_quiet = 0\n <mask> endif\n <mask> \n <mask> function BlackComplete(ArgLead, CmdLine, CursorPos)\n <mask>   return [\n <mask> \\    'target_version=py27',\n <mask> \\    'target_version=py36',\n <mask> \\    'target_version=py37',\n </s> Allow to pass the FileMode options in the vim plugin (#1319) </s> add function BlackComplete(ArgLead, CmdLine, CursorPos)\n  return [\n\\    'target_version=py27',\n\\    'target_version=py36',\n\\    'target_version=py37',\n\\    'target_version=py38',\n\\    'target_version=py39',\n\\  ]\nendfunction </s> remove command! Black :call black#Black()\n </s> add command! -nargs=* -complete=customlist,BlackComplete Black :call black#Black(<f-args>) </s> remove function black#Black()\n  :py3 Black()\n </s> add function black#Black(...)\n    let kwargs = {}\n    for arg in a:000\n        let arg_list = split(arg, '=')\n        let kwargs[arg_list[0]] = arg_list[1]\n    endfor\npython3 << EOF\nimport vim\nkwargs = vim.eval(\"kwargs\")\nEOF\n  :py3 Black(**kwargs) </s> add   black_kwargs = {}\n  if \"target_version\" in kwargs:\n    target_version = kwargs[\"target_version\"]\n\n    if not isinstance(target_version, (list, set)):\n      target_version = [target_version]\n    target_version = set(filter(lambda x: x, map(lambda tv: get_target_version(tv), target_version)))\n    black_kwargs[\"target_versions\"] = target_version\n </s> remove def Black():\n </s> add def get_target_version(tv):\n  if isinstance(tv, black.TargetVersion):\n    return tv\n  ret = None\n  try:\n    ret = black.TargetVersion[tv.upper()]\n  except KeyError:\n    print(f\"WARNING: Target version {tv!r} not recognized by Black, using default target\")\n  return ret\n\ndef Black(**kwargs):\n  \"\"\"\n  kwargs allows you to override ``target_versions`` argument of\n  ``black.FileMode``.\n\n  ``target_version`` needs to be cleaned because ``black.FileMode``\n  expects the ``target_versions`` argument to be a set of TargetVersion enums.\n\n  Allow kwargs[\"target_version\"] to be a string to allow\n  to type it more quickly.\n\n  Using also target_version instead of target_versions to remain\n  consistent to Black's documentation of the structure of pyproject.toml.\n  \"\"\" </s> add     **black_kwargs,", "html_url": "https://github.com/psf/black/commit/09915f4bd2d13652c089b9a96408b39116d82eb0", "file_name": "plugin/black.vim"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>   let g:black_target_version = \"\"\n <mask> endif\n <mask> \n <mask> \n <mask> command! -nargs=* -complete=customlist,BlackComplete Black :call black#Black(<f-args>)\n <mask> command! BlackUpgrade :call black#BlackUpgrade()\n <mask> command! BlackVersion :call black#BlackVersion()\n </s> Allow to pass the FileMode options in the vim plugin (#1319) </s> remove command! Black :call black#Black()\n </s> add command! -nargs=* -complete=customlist,BlackComplete Black :call black#Black(<f-args>) </s> add if !exists(\"g:black_target_version\")\n  let g:black_target_version = \"\"\nendif </s> remove function black#Black()\n  :py3 Black()\n </s> add function black#Black(...)\n    let kwargs = {}\n    for arg in a:000\n        let arg_list = split(arg, '=')\n        let kwargs[arg_list[0]] = arg_list[1]\n    endfor\npython3 << EOF\nimport vim\nkwargs = vim.eval(\"kwargs\")\nEOF\n  :py3 Black(**kwargs) </s> add   black_kwargs = {}\n  if \"target_version\" in kwargs:\n    target_version = kwargs[\"target_version\"]\n\n    if not isinstance(target_version, (list, set)):\n      target_version = [target_version]\n    target_version = set(filter(lambda x: x, map(lambda tv: get_target_version(tv), target_version)))\n    black_kwargs[\"target_versions\"] = target_version\n </s> add     **black_kwargs, </s> remove def Black():\n </s> add def get_target_version(tv):\n  if isinstance(tv, black.TargetVersion):\n    return tv\n  ret = None\n  try:\n    ret = black.TargetVersion[tv.upper()]\n  except KeyError:\n    print(f\"WARNING: Target version {tv!r} not recognized by Black, using default target\")\n  return ret\n\ndef Black(**kwargs):\n  \"\"\"\n  kwargs allows you to override ``target_versions`` argument of\n  ``black.FileMode``.\n\n  ``target_version`` needs to be cleaned because ``black.FileMode``\n  expects the ``target_versions`` argument to be a set of TargetVersion enums.\n\n  Allow kwargs[\"target_version\"] to be a string to allow\n  to type it more quickly.\n\n  Using also target_version instead of target_versions to remain\n  consistent to Black's documentation of the structure of pyproject.toml.\n  \"\"\"", "html_url": "https://github.com/psf/black/commit/09915f4bd2d13652c089b9a96408b39116d82eb0", "file_name": "plugin/black.vim"}
{"docstring_tokens": "keep keep keep keep replace keep keep", "code_tokens": " <mask>   let g:black_quiet = 0\n <mask> endif\n <mask> \n <mask> \n <mask> command! Black :call black#Black()\n <mask> command! BlackUpgrade :call black#BlackUpgrade()\n <mask> command! BlackVersion :call black#BlackVersion()\n </s> Allow to pass the FileMode options in the vim plugin (#1319) </s> add function BlackComplete(ArgLead, CmdLine, CursorPos)\n  return [\n\\    'target_version=py27',\n\\    'target_version=py36',\n\\    'target_version=py37',\n\\    'target_version=py38',\n\\    'target_version=py39',\n\\  ]\nendfunction </s> add if !exists(\"g:black_target_version\")\n  let g:black_target_version = \"\"\nendif </s> remove function black#Black()\n  :py3 Black()\n </s> add function black#Black(...)\n    let kwargs = {}\n    for arg in a:000\n        let arg_list = split(arg, '=')\n        let kwargs[arg_list[0]] = arg_list[1]\n    endfor\npython3 << EOF\nimport vim\nkwargs = vim.eval(\"kwargs\")\nEOF\n  :py3 Black(**kwargs) </s> add   black_kwargs = {}\n  if \"target_version\" in kwargs:\n    target_version = kwargs[\"target_version\"]\n\n    if not isinstance(target_version, (list, set)):\n      target_version = [target_version]\n    target_version = set(filter(lambda x: x, map(lambda tv: get_target_version(tv), target_version)))\n    black_kwargs[\"target_versions\"] = target_version\n </s> add     **black_kwargs, </s> remove def Black():\n </s> add def get_target_version(tv):\n  if isinstance(tv, black.TargetVersion):\n    return tv\n  ret = None\n  try:\n    ret = black.TargetVersion[tv.upper()]\n  except KeyError:\n    print(f\"WARNING: Target version {tv!r} not recognized by Black, using default target\")\n  return ret\n\ndef Black(**kwargs):\n  \"\"\"\n  kwargs allows you to override ``target_versions`` argument of\n  ``black.FileMode``.\n\n  ``target_version`` needs to be cleaned because ``black.FileMode``\n  expects the ``target_versions`` argument to be a set of TargetVersion enums.\n\n  Allow kwargs[\"target_version\"] to be a string to allow\n  to type it more quickly.\n\n  Using also target_version instead of target_versions to remain\n  consistent to Black's documentation of the structure of pyproject.toml.\n  \"\"\"", "html_url": "https://github.com/psf/black/commit/09915f4bd2d13652c089b9a96408b39116d82eb0", "file_name": "plugin/black.vim"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>    installation_and_usage\n <mask>    the_black_code_style\n <mask>    editor_integration\n <mask>    version_control_integration \n <mask>    contributing\n <mask>    change_log\n <mask>    reference/reference_summary\n <mask>    authors\n <mask> \n </s> Update documentation\n\n* Add \"Ignore non-modified files\" from the README\n* Add missing functions to the reference </s> add .. autofunction:: black.max_delimiter_priority_in_atom\n </s> add Caching\n-------\n\n.. autofunction:: black.filter_cached\n\n.. autofunction:: black.get_cache_info\n\n.. autofunction:: black.read_cache\n\n.. autofunction:: black.write_cache\n </s> add .. autofunction:: black.reformat_one\n", "html_url": "https://github.com/psf/black/commit/0a340e1f227c3705ed1b0dbbbf634c98e2e82ada", "file_name": "docs/index.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. autofunction:: black.format_str\n <mask> \n <mask> .. autofunction:: black.schedule_formatting\n <mask> \n <mask> File operations\n <mask> ---------------\n <mask> \n </s> Update documentation\n\n* Add \"Ignore non-modified files\" from the README\n* Add missing functions to the reference </s> add .. autofunction:: black.max_delimiter_priority_in_atom\n </s> add Caching\n-------\n\n.. autofunction:: black.filter_cached\n\n.. autofunction:: black.get_cache_info\n\n.. autofunction:: black.read_cache\n\n.. autofunction:: black.write_cache\n </s> remove    version_control_integration \n </s> add    version_control_integration\n   ignoring_non_modified_files", "html_url": "https://github.com/psf/black/commit/0a340e1f227c3705ed1b0dbbbf634c98e2e82ada", "file_name": "docs/reference/reference_functions.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> .. autofunction:: black.split_line\n <mask> \n <mask> .. autofunction:: black.bracket_split_succeeded_or_raise\n <mask> \n <mask> Utilities\n <mask> ---------\n <mask> \n <mask> .. py:function:: black.DebugVisitor.show(code: str) -> None\n <mask> \n </s> Update documentation\n\n* Add \"Ignore non-modified files\" from the README\n* Add missing functions to the reference </s> add .. autofunction:: black.max_delimiter_priority_in_atom\n </s> add .. autofunction:: black.reformat_one\n </s> remove    version_control_integration \n </s> add    version_control_integration\n   ignoring_non_modified_files", "html_url": "https://github.com/psf/black/commit/0a340e1f227c3705ed1b0dbbbf634c98e2e82ada", "file_name": "docs/reference/reference_functions.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. autofunction:: black.make_comment\n <mask> \n <mask> .. autofunction:: black.normalize_prefix\n <mask> \n <mask> .. autofunction:: black.normalize_string_quotes\n <mask> \n <mask> .. autofunction:: black.normalize_invisible_parens\n <mask> \n </s> Update documentation\n\n* Add \"Ignore non-modified files\" from the README\n* Add missing functions to the reference </s> add Caching\n-------\n\n.. autofunction:: black.filter_cached\n\n.. autofunction:: black.get_cache_info\n\n.. autofunction:: black.read_cache\n\n.. autofunction:: black.write_cache\n </s> add .. autofunction:: black.reformat_one\n </s> remove    version_control_integration \n </s> add    version_control_integration\n   ignoring_non_modified_files", "html_url": "https://github.com/psf/black/commit/0a340e1f227c3705ed1b0dbbbf634c98e2e82ada", "file_name": "docs/reference/reference_functions.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     target_versions: Set[TargetVersion] = field(default_factory=set)\n <mask>     line_length: int = DEFAULT_LINE_LENGTH\n <mask>     string_normalization: bool = True\n <mask>     magic_trailing_comma: bool = True\n <mask>     experimental_string_processing: bool = False\n <mask> \n <mask>     def get_cache_key(self) -> str:\n <mask>         if self.target_versions:\n </s> fix magic comma and experimental string cache flags (#2131)\n\n* fix magic comma and experimental string cache flags\r\n\r\n* more changelog\r\n\r\n* Update CHANGES.md\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com>\r\n\r\n* fix tests\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com> </s> remove     is_pyi: bool = False\n </s> add  </s> remove         source, expected = read_data(str(path), data=False)\n        actual = fs(source, mode=DEFAULT_MODE)\n </s> add         self.check_file(str(path), DEFAULT_MODE, data=False)\n        self.assertFalse(ff(path))\n\n    def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n        source, expected = read_data(filename, data=data)\n        actual = fs(source, mode=mode) </s> remove DEFAULT_MODE = black.FileMode(experimental_string_processing=True)\n </s> add DEFAULT_MODE = black.Mode() </s> remove         actual = fs(source)\n </s> add         mode = black.Mode(experimental_string_processing=True)\n        actual = fs(source, mode=mode) </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        mode = replace(DEFAULT_MODE, string_normalization=False)\n </s> add         black.assert_stable(source, actual, mode)\n        mode = replace(mode, string_normalization=False) </s> remove         source, expected = read_data(filename)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, DEFAULT_MODE)\n </s> add         self.check_file(filename, DEFAULT_MODE)\n\n    @parameterized.expand(EXPERIMENTAL_STRING_PROCESSING_CASES)\n    @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_experimental_format(self, filename: str) -> None:\n        self.check_file(filename, black.Mode(experimental_string_processing=True))", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     line_length: int = DEFAULT_LINE_LENGTH\n <mask>     string_normalization: bool = True\n <mask>     magic_trailing_comma: bool = True\n <mask>     experimental_string_processing: bool = False\n <mask>     is_pyi: bool = False\n <mask> \n <mask>     def get_cache_key(self) -> str:\n <mask>         if self.target_versions:\n <mask>             version_str = \",\".join(\n <mask>                 str(version.value)\n </s> fix magic comma and experimental string cache flags (#2131)\n\n* fix magic comma and experimental string cache flags\r\n\r\n* more changelog\r\n\r\n* Update CHANGES.md\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com>\r\n\r\n* fix tests\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com> </s> add     is_pyi: bool = False </s> remove         source, expected = read_data(str(path), data=False)\n        actual = fs(source, mode=DEFAULT_MODE)\n </s> add         self.check_file(str(path), DEFAULT_MODE, data=False)\n        self.assertFalse(ff(path))\n\n    def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n        source, expected = read_data(filename, data=data)\n        actual = fs(source, mode=mode) </s> remove DEFAULT_MODE = black.FileMode(experimental_string_processing=True)\n </s> add DEFAULT_MODE = black.Mode() </s> remove         actual = fs(source)\n </s> add         mode = black.Mode(experimental_string_processing=True)\n        actual = fs(source, mode=mode) </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        mode = replace(DEFAULT_MODE, string_normalization=False)\n </s> add         black.assert_stable(source, actual, mode)\n        mode = replace(mode, string_normalization=False) </s> remove         source, expected = read_data(filename)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, DEFAULT_MODE)\n </s> add         self.check_file(filename, DEFAULT_MODE)\n\n    @parameterized.expand(EXPERIMENTAL_STRING_PROCESSING_CASES)\n    @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_experimental_format(self, filename: str) -> None:\n        self.check_file(filename, black.Mode(experimental_string_processing=True))", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>             str(int(self.string_normalization)),\n <mask>             str(int(self.is_pyi)),\n <mask>         ]\n <mask>         return \".\".join(parts)\n <mask> \n <mask> \n <mask> # Legacy name, left for integrations.\n <mask> FileMode = Mode\n </s> fix magic comma and experimental string cache flags (#2131)\n\n* fix magic comma and experimental string cache flags\r\n\r\n* more changelog\r\n\r\n* Update CHANGES.md\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com>\r\n\r\n* fix tests\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com> </s> add EXPERIMENTAL_STRING_PROCESSING_CASES = [\n    \"cantfit\",\n    \"comments7\",\n    \"long_strings\",\n    \"long_strings__edge_case\",\n    \"long_strings__regression\",\n    \"percent_precedence\",\n]\n </s> remove     is_pyi: bool = False\n </s> add  </s> add     is_pyi: bool = False </s> remove         actual = fs(source)\n </s> add         mode = black.Mode(experimental_string_processing=True)\n        actual = fs(source, mode=mode) </s> remove DEFAULT_MODE = black.FileMode(experimental_string_processing=True)\n </s> add DEFAULT_MODE = black.Mode() </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        mode = replace(DEFAULT_MODE, string_normalization=False)\n </s> add         black.assert_stable(source, actual, mode)\n        mode = replace(mode, string_normalization=False)", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep replace keep keep replace replace keep keep keep keep", "code_tokens": " <mask>     def test_string_quotes(self) -> None:\n <mask>         source, expected = read_data(\"string_quotes\")\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, DEFAULT_MODE)\n <mask>         mode = replace(DEFAULT_MODE, string_normalization=False)\n <mask>         not_normalized = fs(source, mode=mode)\n <mask>         self.assertFormatEqual(source.replace(\"\\\\\\n\", \"\"), not_normalized)\n <mask>         black.assert_equivalent(source, not_normalized)\n <mask>         black.assert_stable(source, not_normalized, mode=mode)\n </s> fix magic comma and experimental string cache flags (#2131)\n\n* fix magic comma and experimental string cache flags\r\n\r\n* more changelog\r\n\r\n* Update CHANGES.md\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com>\r\n\r\n* fix tests\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com> </s> remove         source, expected = read_data(str(path), data=False)\n        actual = fs(source, mode=DEFAULT_MODE)\n </s> add         self.check_file(str(path), DEFAULT_MODE, data=False)\n        self.assertFalse(ff(path))\n\n    def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n        source, expected = read_data(filename, data=data)\n        actual = fs(source, mode=mode) </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        self.assertFalse(ff(path))\n </s> add         black.assert_stable(source, actual, mode) </s> remove         source, expected = read_data(filename)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, DEFAULT_MODE)\n </s> add         self.check_file(filename, DEFAULT_MODE)\n\n    @parameterized.expand(EXPERIMENTAL_STRING_PROCESSING_CASES)\n    @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_experimental_format(self, filename: str) -> None:\n        self.check_file(filename, black.Mode(experimental_string_processing=True)) </s> remove     is_pyi: bool = False\n </s> add  </s> add     is_pyi: bool = False", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> SIMPLE_CASES = [\n <mask>     \"beginning_backslash\",\n <mask>     \"bracketmatch\",\n <mask>     \"cantfit\",\n <mask>     \"class_blank_parentheses\",\n <mask>     \"class_methods_new_line\",\n <mask>     \"collections\",\n <mask>     \"comments\",\n <mask>     \"comments2\",\n </s> fix magic comma and experimental string cache flags (#2131)\n\n* fix magic comma and experimental string cache flags\r\n\r\n* more changelog\r\n\r\n* Update CHANGES.md\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com>\r\n\r\n* fix tests\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com> </s> add EXPERIMENTAL_STRING_PROCESSING_CASES = [\n    \"cantfit\",\n    \"comments7\",\n    \"long_strings\",\n    \"long_strings__edge_case\",\n    \"long_strings__regression\",\n    \"percent_precedence\",\n]\n </s> remove     is_pyi: bool = False\n </s> add  </s> add     is_pyi: bool = False </s> remove         actual = fs(source)\n </s> add         mode = black.Mode(experimental_string_processing=True)\n        actual = fs(source, mode=mode) </s> remove DEFAULT_MODE = black.FileMode(experimental_string_processing=True)\n </s> add DEFAULT_MODE = black.Mode() </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        mode = replace(DEFAULT_MODE, string_normalization=False)\n </s> add         black.assert_stable(source, actual, mode)\n        mode = replace(mode, string_normalization=False)", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"comments3\",\n <mask>     \"comments4\",\n <mask>     \"comments5\",\n <mask>     \"comments6\",\n <mask>     \"comments7\",\n <mask>     \"comments_non_breaking_space\",\n <mask>     \"comment_after_escaped_newline\",\n <mask>     \"composition\",\n <mask>     \"composition_no_trailing_comma\",\n <mask>     \"docstring\",\n </s> fix magic comma and experimental string cache flags (#2131)\n\n* fix magic comma and experimental string cache flags\r\n\r\n* more changelog\r\n\r\n* Update CHANGES.md\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com>\r\n\r\n* fix tests\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com> </s> add EXPERIMENTAL_STRING_PROCESSING_CASES = [\n    \"cantfit\",\n    \"comments7\",\n    \"long_strings\",\n    \"long_strings__edge_case\",\n    \"long_strings__regression\",\n    \"percent_precedence\",\n]\n </s> remove DEFAULT_MODE = black.FileMode(experimental_string_processing=True)\n </s> add DEFAULT_MODE = black.Mode() </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        self.assertFalse(ff(path))\n </s> add         black.assert_stable(source, actual, mode) </s> remove         source, expected = read_data(str(path), data=False)\n        actual = fs(source, mode=DEFAULT_MODE)\n </s> add         self.check_file(str(path), DEFAULT_MODE, data=False)\n        self.assertFalse(ff(path))\n\n    def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n        source, expected = read_data(filename, data=data)\n        actual = fs(source, mode=mode) </s> remove         source, expected = read_data(filename)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, DEFAULT_MODE)\n </s> add         self.check_file(filename, DEFAULT_MODE)\n\n    @parameterized.expand(EXPERIMENTAL_STRING_PROCESSING_CASES)\n    @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_experimental_format(self, filename: str) -> None:\n        self.check_file(filename, black.Mode(experimental_string_processing=True)) </s> remove     \"percent_precedence\",\n </s> add ", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep replace replace replace keep replace keep", "code_tokens": " <mask>     \"import_spacing\",\n <mask>     \"long_strings\",\n <mask>     \"long_strings__edge_case\",\n <mask>     \"long_strings__regression\",\n <mask>     \"numeric_literals_py2\",\n <mask>     \"percent_precedence\",\n <mask>     \"python2\",\n </s> fix magic comma and experimental string cache flags (#2131)\n\n* fix magic comma and experimental string cache flags\r\n\r\n* more changelog\r\n\r\n* Update CHANGES.md\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com>\r\n\r\n* fix tests\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com> </s> add EXPERIMENTAL_STRING_PROCESSING_CASES = [\n    \"cantfit\",\n    \"comments7\",\n    \"long_strings\",\n    \"long_strings__edge_case\",\n    \"long_strings__regression\",\n    \"percent_precedence\",\n]\n </s> remove DEFAULT_MODE = black.FileMode(experimental_string_processing=True)\n </s> add DEFAULT_MODE = black.Mode() </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        self.assertFalse(ff(path))\n </s> add         black.assert_stable(source, actual, mode) </s> remove         source, expected = read_data(str(path), data=False)\n        actual = fs(source, mode=DEFAULT_MODE)\n </s> add         self.check_file(str(path), DEFAULT_MODE, data=False)\n        self.assertFalse(ff(path))\n\n    def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n        source, expected = read_data(filename, data=data)\n        actual = fs(source, mode=mode) </s> remove         source, expected = read_data(filename)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, DEFAULT_MODE)\n </s> add         self.check_file(filename, DEFAULT_MODE)\n\n    @parameterized.expand(EXPERIMENTAL_STRING_PROCESSING_CASES)\n    @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_experimental_format(self, filename: str) -> None:\n        self.check_file(filename, black.Mode(experimental_string_processing=True))", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> ]\n <mask> \n <mask> \n <mask> SOURCES = [\n <mask>     \"tests/test_black.py\",\n <mask>     \"tests/test_format.py\",\n <mask>     \"tests/test_blackd.py\",\n <mask>     \"src/black/__init__.py\",\n </s> fix magic comma and experimental string cache flags (#2131)\n\n* fix magic comma and experimental string cache flags\r\n\r\n* more changelog\r\n\r\n* Update CHANGES.md\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com>\r\n\r\n* fix tests\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com> </s> remove     \"cantfit\",\n </s> add  </s> add             str(int(self.magic_trailing_comma)),\n            str(int(self.experimental_string_processing)), </s> remove     is_pyi: bool = False\n </s> add  </s> add     is_pyi: bool = False </s> remove         actual = fs(source)\n </s> add         mode = black.Mode(experimental_string_processing=True)\n        actual = fs(source, mode=mode) </s> remove DEFAULT_MODE = black.FileMode(experimental_string_processing=True)\n </s> add DEFAULT_MODE = black.Mode()", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> class TestSimpleFormat(BlackBaseTestCase):\n <mask>     @parameterized.expand(SIMPLE_CASES)\n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_simple_format(self, filename: str) -> None:\n <mask>         source, expected = read_data(filename)\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, DEFAULT_MODE)\n <mask> \n <mask>     @parameterized.expand(SOURCES)\n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_source_is_formatted(self, filename: str) -> None:\n <mask>         path = THIS_DIR.parent / filename\n </s> fix magic comma and experimental string cache flags (#2131)\n\n* fix magic comma and experimental string cache flags\r\n\r\n* more changelog\r\n\r\n* Update CHANGES.md\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com>\r\n\r\n* fix tests\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com> </s> remove         source, expected = read_data(str(path), data=False)\n        actual = fs(source, mode=DEFAULT_MODE)\n </s> add         self.check_file(str(path), DEFAULT_MODE, data=False)\n        self.assertFalse(ff(path))\n\n    def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n        source, expected = read_data(filename, data=data)\n        actual = fs(source, mode=mode) </s> remove         actual = fs(source)\n </s> add         mode = black.Mode(experimental_string_processing=True)\n        actual = fs(source, mode=mode) </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        mode = replace(DEFAULT_MODE, string_normalization=False)\n </s> add         black.assert_stable(source, actual, mode)\n        mode = replace(mode, string_normalization=False) </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        self.assertFalse(ff(path))\n </s> add         black.assert_stable(source, actual, mode) </s> remove DEFAULT_MODE = black.FileMode(experimental_string_processing=True)\n </s> add DEFAULT_MODE = black.Mode() </s> remove     is_pyi: bool = False\n </s> add ", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep replace replace", "code_tokens": " <mask>     @parameterized.expand(SOURCES)\n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_source_is_formatted(self, filename: str) -> None:\n <mask>         path = THIS_DIR.parent / filename\n <mask>         source, expected = read_data(str(path), data=False)\n <mask>         actual = fs(source, mode=DEFAULT_MODE)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, DEFAULT_MODE)\n <mask>         self.assertFalse(ff(path))\n </s> fix magic comma and experimental string cache flags (#2131)\n\n* fix magic comma and experimental string cache flags\r\n\r\n* more changelog\r\n\r\n* Update CHANGES.md\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com>\r\n\r\n* fix tests\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com> </s> remove         source, expected = read_data(filename)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, DEFAULT_MODE)\n </s> add         self.check_file(filename, DEFAULT_MODE)\n\n    @parameterized.expand(EXPERIMENTAL_STRING_PROCESSING_CASES)\n    @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_experimental_format(self, filename: str) -> None:\n        self.check_file(filename, black.Mode(experimental_string_processing=True)) </s> remove         actual = fs(source)\n </s> add         mode = black.Mode(experimental_string_processing=True)\n        actual = fs(source, mode=mode) </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        mode = replace(DEFAULT_MODE, string_normalization=False)\n </s> add         black.assert_stable(source, actual, mode)\n        mode = replace(mode, string_normalization=False) </s> remove DEFAULT_MODE = black.FileMode(experimental_string_processing=True)\n </s> add DEFAULT_MODE = black.Mode() </s> remove     is_pyi: bool = False\n </s> add ", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> EMPTY_LINE = \"# EMPTY LINE WITH WHITESPACE\" + \" (this comment will be removed)\"\n <mask> DETERMINISTIC_HEADER = \"[Deterministic header]\"\n <mask> \n <mask> \n <mask> DEFAULT_MODE = black.FileMode(experimental_string_processing=True)\n <mask> ff = partial(black.format_file_in_place, mode=DEFAULT_MODE, fast=True)\n <mask> fs = partial(black.format_str, mode=DEFAULT_MODE)\n <mask> \n <mask> \n <mask> def dump_to_stderr(*output: str) -> str:\n </s> fix magic comma and experimental string cache flags (#2131)\n\n* fix magic comma and experimental string cache flags\r\n\r\n* more changelog\r\n\r\n* Update CHANGES.md\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com>\r\n\r\n* fix tests\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com> </s> remove     is_pyi: bool = False\n </s> add  </s> add     is_pyi: bool = False </s> remove         source, expected = read_data(str(path), data=False)\n        actual = fs(source, mode=DEFAULT_MODE)\n </s> add         self.check_file(str(path), DEFAULT_MODE, data=False)\n        self.assertFalse(ff(path))\n\n    def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n        source, expected = read_data(filename, data=data)\n        actual = fs(source, mode=mode) </s> remove         source, expected = read_data(filename)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, DEFAULT_MODE)\n </s> add         self.check_file(filename, DEFAULT_MODE)\n\n    @parameterized.expand(EXPERIMENTAL_STRING_PROCESSING_CASES)\n    @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_experimental_format(self, filename: str) -> None:\n        self.check_file(filename, black.Mode(experimental_string_processing=True)) </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        self.assertFalse(ff(path))\n </s> add         black.assert_stable(source, actual, mode) </s> remove         actual = fs(source)\n </s> add         mode = black.Mode(experimental_string_processing=True)\n        actual = fs(source, mode=mode)", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/util.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> toml = \">=0.9.4\"\n <mask> black = {editable = true, path = \".\", extras = [\"d\"]}\n <mask> \n <mask> [dev-packages]\n <mask> pre-commit = \"*\"\n <mask> coverage = \"*\"\n <mask> flake8 = \"*\"\n <mask> flake8-bugbear = \"*\"\n </s> Add CORS support to blackd (#627)\n\nSee issue #622. Use aiohttp-cors to allow cross-origin requests to blackd,\r\nand add a dependency on it to the pipfile. </s> remove     app.add_routes([web.post(\"/\", partial(handle, executor=executor))])\n </s> add     cors = aiohttp_cors.setup(app)\n    resource = cors.add(app.router.add_resource(\"/\"))\n    cors.add(\n        resource.add_route(\"POST\", partial(handle, executor=executor)),\n        {\n            \"*\": aiohttp_cors.ResourceOptions(\n                allow_headers=(*BLACK_HEADERS, \"Content-Type\"), expose_headers=\"*\"\n            )\n        },\n    )\n </s> add BLACK_HEADERS = [\n    VERSION_HEADER,\n    LINE_LENGTH_HEADER,\n    PYTHON_VARIANT_HEADER,\n    SKIP_STRING_NORMALIZATION_HEADER,\n    SKIP_NUMERIC_UNDERSCORE_NORMALIZATION_HEADER,\n    FAST_OR_SAFE_HEADER,\n]\n </s> add import aiohttp_cors", "html_url": "https://github.com/psf/black/commit/0b40a7badf82c53c8a23b3a03273619f8440855d", "file_name": "Pipfile"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> from functools import partial\n <mask> import logging\n <mask> \n <mask> from aiohttp import web\n <mask> import black\n <mask> import click\n <mask> \n <mask> # This is used internally by tests to shut down the server prematurely\n </s> Add CORS support to blackd (#627)\n\nSee issue #622. Use aiohttp-cors to allow cross-origin requests to blackd,\r\nand add a dependency on it to the pipfile. </s> remove     app.add_routes([web.post(\"/\", partial(handle, executor=executor))])\n </s> add     cors = aiohttp_cors.setup(app)\n    resource = cors.add(app.router.add_resource(\"/\"))\n    cors.add(\n        resource.add_route(\"POST\", partial(handle, executor=executor)),\n        {\n            \"*\": aiohttp_cors.ResourceOptions(\n                allow_headers=(*BLACK_HEADERS, \"Content-Type\"), expose_headers=\"*\"\n            )\n        },\n    )\n </s> add BLACK_HEADERS = [\n    VERSION_HEADER,\n    LINE_LENGTH_HEADER,\n    PYTHON_VARIANT_HEADER,\n    SKIP_STRING_NORMALIZATION_HEADER,\n    SKIP_NUMERIC_UNDERSCORE_NORMALIZATION_HEADER,\n    FAST_OR_SAFE_HEADER,\n]\n </s> add aiohttp-cors = \"*\"", "html_url": "https://github.com/psf/black/commit/0b40a7badf82c53c8a23b3a03273619f8440855d", "file_name": "blackd.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> FAST_OR_SAFE_HEADER = \"X-Fast-Or-Safe\"\n <mask> \n <mask> \n <mask> @click.command(context_settings={\"help_option_names\": [\"-h\", \"--help\"]})\n <mask> @click.option(\n <mask>     \"--bind-host\", type=str, help=\"Address to bind the server to.\", default=\"localhost\"\n <mask> )\n </s> Add CORS support to blackd (#627)\n\nSee issue #622. Use aiohttp-cors to allow cross-origin requests to blackd,\r\nand add a dependency on it to the pipfile. </s> add aiohttp-cors = \"*\" </s> remove     app.add_routes([web.post(\"/\", partial(handle, executor=executor))])\n </s> add     cors = aiohttp_cors.setup(app)\n    resource = cors.add(app.router.add_resource(\"/\"))\n    cors.add(\n        resource.add_route(\"POST\", partial(handle, executor=executor)),\n        {\n            \"*\": aiohttp_cors.ResourceOptions(\n                allow_headers=(*BLACK_HEADERS, \"Content-Type\"), expose_headers=\"*\"\n            )\n        },\n    )\n </s> add import aiohttp_cors", "html_url": "https://github.com/psf/black/commit/0b40a7badf82c53c8a23b3a03273619f8440855d", "file_name": "blackd.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def make_app() -> web.Application:\n <mask>     app = web.Application()\n <mask>     executor = ProcessPoolExecutor()\n <mask>     app.add_routes([web.post(\"/\", partial(handle, executor=executor))])\n <mask>     return app\n <mask> \n <mask> \n <mask> async def handle(request: web.Request, executor: Executor) -> web.Response:\n <mask>     try:\n </s> Add CORS support to blackd (#627)\n\nSee issue #622. Use aiohttp-cors to allow cross-origin requests to blackd,\r\nand add a dependency on it to the pipfile. </s> add aiohttp-cors = \"*\" </s> add BLACK_HEADERS = [\n    VERSION_HEADER,\n    LINE_LENGTH_HEADER,\n    PYTHON_VARIANT_HEADER,\n    SKIP_STRING_NORMALIZATION_HEADER,\n    SKIP_NUMERIC_UNDERSCORE_NORMALIZATION_HEADER,\n    FAST_OR_SAFE_HEADER,\n]\n </s> add import aiohttp_cors", "html_url": "https://github.com/psf/black/commit/0b40a7badf82c53c8a23b3a03273619f8440855d", "file_name": "blackd.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> if TYPE_CHECKING:\n <mask>     import colorama  # noqa: F401\n <mask> \n <mask> \n <mask> @lru_cache()\n <mask> def find_project_root(\n <mask>     srcs: Sequence[str], stdin_filename: Optional[str] = None\n <mask> ) -> Tuple[Path, str]:\n <mask>     \"\"\"Return a directory containing .git, .hg, or pyproject.toml.\n <mask> \n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def parse(self) -> Tuple[Dict[Text, List[\"DFAState\"]], Text]:\n </s> add     def parse(self) -> Tuple[Dict[str, List[\"DFAState\"]], str]: </s> remove @lru_cache()\n </s> add @lru_cache </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None:\n </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None: </s> remove     def __repr__(self) -> Text:\n </s> add     def __repr__(self) -> str: </s> remove     def expect(self, type: int, value: Optional[Any] = None) -> Text:\n </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str: </s> remove         return \"%s(%s, %r)\" % (\n </s> add         return \"{}({}, {!r})\".format(", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/black/files.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     return SpecifierSet(\",\".join(str(s) for s in specifiers))\n <mask> \n <mask> \n <mask> @lru_cache()\n <mask> def find_user_pyproject_toml() -> Path:\n <mask>     r\"\"\"Return the path to the top-level user configuration for black.\n <mask> \n <mask>     This looks for ~\\.black on Windows and ~/.config/black on Linux and other\n <mask>     Unix systems.\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove import copy\n </s> add  </s> remove class Base(object):\n </s> add class Base: </s> remove def main(*args: Text) -> bool:\n </s> add def main(*args: str) -> bool: </s> remove     def make_label(self, c: PgenGrammar, label: Text) -> int:\n </s> add     def make_label(self, c: PgenGrammar, label: str) -> int:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/black/files.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         user_config_path = Path(config_root).expanduser() / \"black\"\n <mask>     return user_config_path.resolve()\n <mask> \n <mask> \n <mask> @lru_cache()\n <mask> def get_gitignore(root: Path) -> PathSpec:\n <mask>     \"\"\"Return a PathSpec matching gitignore content if present.\"\"\"\n <mask>     gitignore = root / \".gitignore\"\n <mask>     lines: List[str] = []\n <mask>     if gitignore.is_file():\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]:\n </s> add     def _partially_consume_prefix(self, prefix: str, column: int) -> Tuple[str, str]: </s> remove @lru_cache()\n </s> add @lru_cache </s> remove     tokens: List[Text]\n </s> add     tokens: List[str] </s> remove     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None:\n </s> add     def compat(self, token: Tuple[int, str], iterable: Iterable[TokenInfo]) -> None: </s> remove     name: Optional[Text] = None  # Optional name used to store match in results dict\n </s> add     name: Optional[str] = None  # Optional name used to store match in results dict </s> remove     def __repr__(self) -> Text:\n </s> add     def __repr__(self) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/black/files.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     mask: str\n <mask>     src: str\n <mask> \n <mask> \n <mask> @lru_cache()\n <mask> def jupyter_dependencies_are_installed(*, verbose: bool, quiet: bool) -> bool:\n <mask>     try:\n <mask>         # isort: off\n <mask>         # tokenize_rt is less commonly installed than IPython\n <mask>         # and IPython is expensive to import\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     value: Text\n </s> add     value: str </s> remove @lru_cache()\n </s> add @lru_cache </s> remove     def addtoken(self, type: int, value: Text, context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: str, context: Context) -> bool: </s> remove     if type(_value) is type(0):\n </s> add     if type(_value) is int: </s> remove import sys\n </s> add  </s> remove     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: str, context: Context) -> bool:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/black/handle_ipynb_magics.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         try:\n <mask>             f = open(filename)\n <mask>         except OSError as err:\n <mask>             print(\"Can't open %s: %s\" % (filename, err))\n <mask>             return False\n <mask>         self.symbol2number = {}\n <mask>         self.number2symbol = {}\n <mask>         lineno = 0\n <mask>         for line in f:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove             print(\"Can't open %s: %s\" % (filename, err))\n </s> add             print(f\"Can't open {filename}: {err}\") </s> remove                 print(\"%s(%s): can't parse %s\" % (filename, lineno, line.strip()))\n </s> add                 print(f\"{filename}({lineno}): can't parse {line.strip()}\") </s> remove             return bytes()\n </s> add             return b'' </s> remove     def calcfirst(self, name: Text) -> None:\n </s> add     def calcfirst(self, name: str) -> None: </s> remove     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]:\n </s> add     def _partially_consume_prefix(self, prefix: str, column: int) -> Tuple[str, str]: </s> remove     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]:\n </s> add     def make_first(self, c: PgenGrammar, name: str) -> Dict[int, int]:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         for line in f:\n <mask>             lineno += 1\n <mask>             mo = re.match(r\"^#define\\s+(\\w+)\\s+(\\d+)$\", line)\n <mask>             if not mo and line.strip():\n <mask>                 print(\"%s(%s): can't parse %s\" % (filename, lineno, line.strip()))\n <mask>             else:\n <mask>                 symbol, number = mo.groups()\n <mask>                 number = int(number)\n <mask>                 assert symbol not in self.symbol2number\n <mask>                 assert number not in self.number2symbol\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove             print(\"Can't open %s: %s\" % (filename, err))\n </s> add             print(f\"Can't open {filename}: {err}\") </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None:\n </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> remove     name: Optional[Text] = None  # Optional name used to store match in results dict\n </s> add     name: Optional[str] = None  # Optional name used to store match in results dict </s> remove     def __repr__(self) -> Text:\n </s> add     def __repr__(self) -> str: </s> remove     def make_label(self, c: PgenGrammar, label: Text) -> int:\n </s> add     def make_label(self, c: PgenGrammar, label: str) -> int: </s> remove     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]:\n </s> add     def make_first(self, c: PgenGrammar, name: str) -> Dict[int, int]:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         try:\n <mask>             f = open(filename)\n <mask>         except OSError as err:\n <mask>             print(\"Can't open %s: %s\" % (filename, err))\n <mask>             return False\n <mask>         # The code below essentially uses f's iterator-ness!\n <mask>         lineno = 0\n <mask> \n <mask>         # Expect the two #include lines\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove             print(\"Can't open %s: %s\" % (filename, err))\n </s> add             print(f\"Can't open {filename}: {err}\") </s> remove                 print(\"%s(%s): can't parse %s\" % (filename, lineno, line.strip()))\n </s> add                 print(f\"{filename}({lineno}): can't parse {line.strip()}\") </s> remove             return bytes()\n </s> add             return b'' </s> remove TokenEater = Callable[[int, Text, Coord, Coord, Text], None]\n </s> add TokenEater = Callable[[int, str, Coord, Coord, str], None] </s> remove     used_names: Optional[Set[Text]]\n </s> add     used_names: Optional[Set[str]] </s> remove         self, filename: Path, encoding: Optional[Text] = None, debug: bool = False\n </s> add         self, filename: Path, encoding: Optional[str] = None, debug: bool = False", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace replace", "code_tokens": " <mask>     Iterable,\n <mask>     List,\n <mask>     Optional,\n <mask>     Text,\n <mask>     Iterator,\n <mask>     Tuple,\n <mask>     TypeVar,\n <mask>     Generic,\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     Text,\n </s> add  </s> remove     Text,\n </s> add  </s> remove     Text,\n </s> add  </s> remove     Text,\n </s> add  </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union\n </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         else:\n <mask>             return True\n <mask> \n <mask> \n <mask> class Driver(object):\n <mask>     def __init__(self, grammar: Grammar, logger: Optional[Logger] = None) -> None:\n <mask>         self.grammar = grammar\n <mask>         if logger is None:\n <mask>             logger = logging.getLogger(__name__)\n <mask>         self.logger = logger\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def __init__(self, filename: Path, stream: Optional[IO[Text]] = None) -> None:\n </s> add     def __init__(self, filename: Path, stream: Optional[IO[str]] = None) -> None: </s> remove class Symbols(object):\n </s> add class Symbols: </s> remove     gt: Text = \"Grammar.txt\",\n    gp: Optional[Text] = None,\n </s> add     gt: str = \"Grammar.txt\",\n    gp: Optional[str] = None, </s> remove     first: Dict[Text, Optional[Dict[Text, int]]]\n </s> add     first: Dict[str, Optional[Dict[str, int]]] </s> remove def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> Text:\n </s> add def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> str: </s> remove     stream: IO[Text]\n </s> add     stream: IO[str]", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace", "code_tokens": " <mask>         assert p.rootnode is not None\n <mask>         return p.rootnode\n <mask> \n <mask>     def parse_stream_raw(self, stream: IO[Text], debug: bool = False) -> NL:\n <mask>         \"\"\"Parse a stream and return the syntax tree.\"\"\"\n <mask>         tokens = tokenize.generate_tokens(stream.readline, grammar=self.grammar)\n <mask>         return self.parse_tokens(tokens, debug)\n <mask> \n <mask>     def parse_stream(self, stream: IO[Text], debug: bool = False) -> NL:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def parse_string(self, text: Text, debug: bool = False) -> NL:\n </s> add     def parse_string(self, text: str, debug: bool = False) -> NL: </s> remove         with io.open(filename, \"r\", encoding=encoding) as stream:\n </s> add         with open(filename, encoding=encoding) as stream: </s> remove         self, filename: Path, encoding: Optional[Text] = None, debug: bool = False\n </s> add         self, filename: Path, encoding: Optional[str] = None, debug: bool = False </s> remove     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None:\n </s> add     def add_token(self, tok_type: int, tok_val: str, raw: bool = False) -> None: </s> remove     def __init__(self, filename: Path, stream: Optional[IO[Text]] = None) -> None:\n </s> add     def __init__(self, filename: Path, stream: Optional[IO[str]] = None) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep replace keep keep replace keep keep", "code_tokens": " <mask> \n <mask>     def parse_file(\n <mask>         self, filename: Path, encoding: Optional[Text] = None, debug: bool = False\n <mask>     ) -> NL:\n <mask>         \"\"\"Parse a file and return the syntax tree.\"\"\"\n <mask>         with io.open(filename, \"r\", encoding=encoding) as stream:\n <mask>             return self.parse_stream(stream, debug)\n <mask> \n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def parse_string(self, text: Text, debug: bool = False) -> NL:\n </s> add     def parse_string(self, text: str, debug: bool = False) -> NL: </s> remove     def parse_stream(self, stream: IO[Text], debug: bool = False) -> NL:\n </s> add     def parse_stream(self, stream: IO[str], debug: bool = False) -> NL: </s> remove     def parse_stream_raw(self, stream: IO[Text], debug: bool = False) -> NL:\n </s> add     def parse_stream_raw(self, stream: IO[str], debug: bool = False) -> NL: </s> remove     gt: Text = \"Grammar.txt\",\n    gp: Optional[Text] = None,\n </s> add     gt: str = \"Grammar.txt\",\n    gp: Optional[str] = None, </s> remove     def __init__(self, filename: Path, stream: Optional[IO[Text]] = None) -> None:\n </s> add     def __init__(self, filename: Path, stream: Optional[IO[str]] = None) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Parse a file and return the syntax tree.\"\"\"\n <mask>         with io.open(filename, \"r\", encoding=encoding) as stream:\n <mask>             return self.parse_stream(stream, debug)\n <mask> \n <mask>     def parse_string(self, text: Text, debug: bool = False) -> NL:\n <mask>         \"\"\"Parse a string and return the syntax tree.\"\"\"\n <mask>         tokens = tokenize.generate_tokens(\n <mask>             io.StringIO(text).readline, grammar=self.grammar\n <mask>         )\n <mask>         return self.parse_tokens(tokens, debug)\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove         with io.open(filename, \"r\", encoding=encoding) as stream:\n </s> add         with open(filename, encoding=encoding) as stream: </s> remove         self, filename: Path, encoding: Optional[Text] = None, debug: bool = False\n </s> add         self, filename: Path, encoding: Optional[str] = None, debug: bool = False </s> remove     def parse_stream(self, stream: IO[Text], debug: bool = False) -> NL:\n </s> add     def parse_stream(self, stream: IO[str], debug: bool = False) -> NL: </s> remove     def parse_stream_raw(self, stream: IO[Text], debug: bool = False) -> NL:\n </s> add     def parse_stream_raw(self, stream: IO[str], debug: bool = False) -> NL: </s> remove     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]:\n </s> add     def _partially_consume_prefix(self, prefix: str, column: int) -> Tuple[str, str]: </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             io.StringIO(text).readline, grammar=self.grammar\n <mask>         )\n <mask>         return self.parse_tokens(tokens, debug)\n <mask> \n <mask>     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]:\n <mask>         lines: List[str] = []\n <mask>         current_line = \"\"\n <mask>         current_column = 0\n <mask>         wait_for_nl = False\n <mask>         for char in prefix:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def parse_string(self, text: Text, debug: bool = False) -> NL:\n </s> add     def parse_string(self, text: str, debug: bool = False) -> NL: </s> remove def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> Text:\n </s> add def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> str: </s> remove     def prefix(self, prefix: Text) -> None:\n </s> add     def prefix(self, prefix: str) -> None: </s> remove @lru_cache()\n </s> add @lru_cache </s> remove         prefix: Optional[Text] = None,\n </s> add         prefix: Optional[str] = None, </s> remove     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None:\n </s> add     def compat(self, token: Tuple[int, str], iterable: Iterable[TokenInfo]) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 wait_for_nl = True\n <mask>         return \"\".join(lines), current_line\n <mask> \n <mask> \n <mask> def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> Text:\n <mask>     head, tail = os.path.splitext(gt)\n <mask>     if tail == \".txt\":\n <mask>         tail = \"\"\n <mask>     name = head + tail + \".\".join(map(str, sys.version_info)) + \".pickle\"\n <mask>     if cache_dir:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove def escape(m: Match[Text]) -> Text:\n </s> add def escape(m: Match[str]) -> str: </s> remove     return set(x + y for x in l for y in l + (\"\",) if x.casefold() != y.casefold())\n </s> add     return {x + y for x in l for y in l + (\"\",) if x.casefold() != y.casefold()} </s> remove     package: str, grammar_source: Text, cache_dir: Optional[Path] = None\n </s> add     package: str, grammar_source: str, cache_dir: Optional[Path] = None </s> remove     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]:\n </s> add     def _partially_consume_prefix(self, prefix: str, column: int) -> Tuple[str, str]: </s> remove     def get_suffix(self) -> Text:\n </s> add     def get_suffix(self) -> str: </s> remove class NFAState(object):\n    arcs: List[Tuple[Optional[Text], \"NFAState\"]]\n </s> add class NFAState:\n    arcs: List[Tuple[Optional[str], \"NFAState\"]]", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         return name\n <mask> \n <mask> \n <mask> def load_grammar(\n <mask>     gt: Text = \"Grammar.txt\",\n <mask>     gp: Optional[Text] = None,\n <mask>     save: bool = True,\n <mask>     force: bool = False,\n <mask>     logger: Optional[Logger] = None,\n <mask> ) -> Grammar:\n <mask>     \"\"\"Load the grammar (maybe from a pickle).\"\"\"\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def determine_route(self, value: Optional[Text] = None, force: bool = False) -> Optional[int]:\n </s> add     def determine_route(self, value: Optional[str] = None, force: bool = False) -> Optional[int]: </s> remove         self, filename: Path, encoding: Optional[Text] = None, debug: bool = False\n </s> add         self, filename: Path, encoding: Optional[str] = None, debug: bool = False </s> remove     def parse_stream(self, stream: IO[Text], debug: bool = False) -> NL:\n </s> add     def parse_stream(self, stream: IO[str], debug: bool = False) -> NL: </s> remove         with io.open(filename, \"r\", encoding=encoding) as stream:\n </s> add         with open(filename, encoding=encoding) as stream: </s> remove class Driver(object):\n </s> add class Driver: </s> remove         content: Optional[Text] = None,\n </s> add         content: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         g.load(gp)\n <mask>     return g\n <mask> \n <mask> \n <mask> def _newer(a: Text, b: Text) -> bool:\n <mask>     \"\"\"Inquire whether file a was written since file b.\"\"\"\n <mask>     if not os.path.exists(a):\n <mask>         return False\n <mask>     if not os.path.exists(b):\n <mask>         return True\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove def main(*args: Text) -> bool:\n </s> add def main(*args: str) -> bool: </s> remove         with io.open(filename, \"r\", encoding=encoding) as stream:\n </s> add         with open(filename, encoding=encoding) as stream: </s> remove         self, filename: Path, encoding: Optional[Text] = None, debug: bool = False\n </s> add         self, filename: Path, encoding: Optional[str] = None, debug: bool = False </s> remove     def parse_string(self, text: Text, debug: bool = False) -> NL:\n </s> add     def parse_string(self, text: str, debug: bool = False) -> NL: </s> remove     def make_label(self, c: PgenGrammar, label: Text) -> int:\n </s> add     def make_label(self, c: PgenGrammar, label: str) -> int: </s> remove     def addtoken(self, type: int, value: Text, context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: str, context: Context) -> bool:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return os.path.getmtime(a) >= os.path.getmtime(b)\n <mask> \n <mask> \n <mask> def load_packaged_grammar(\n <mask>     package: str, grammar_source: Text, cache_dir: Optional[Path] = None\n <mask> ) -> grammar.Grammar:\n <mask>     \"\"\"Normally, loads a pickled grammar by doing\n <mask>         pkgutil.get_data(package, pickled_grammar)\n <mask>     where *pickled_grammar* is computed from *grammar_source* by adding the\n <mask>     Python version and using a ``.pickle`` extension.\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove def untokenize(iterable: Iterable[TokenInfo]) -> Text:\n </s> add def untokenize(iterable: Iterable[TokenInfo]) -> str: </s> remove def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> Text:\n </s> add def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> str: </s> remove     used_names: Optional[Set[Text]]\n </s> add     used_names: Optional[Set[str]] </s> remove     def addtoken(self, type: int, value: Text, context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: str, context: Context) -> bool: </s> remove     def parse_string(self, text: Text, debug: bool = False) -> NL:\n </s> add     def parse_string(self, text: str, debug: bool = False) -> NL: </s> remove     gt: Text = \"Grammar.txt\",\n    gp: Optional[Text] = None,\n </s> add     gt: str = \"Grammar.txt\",\n    gp: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     g.loads(data)\n <mask>     return g\n <mask> \n <mask> \n <mask> def main(*args: Text) -> bool:\n <mask>     \"\"\"Main program, when run as a script: produce grammar pickle files.\n <mask> \n <mask>     Calls load_grammar for each argument, a path to a grammar text file.\n <mask>     \"\"\"\n <mask>     if not args:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove def _newer(a: Text, b: Text) -> bool:\n </s> add def _newer(a: str, b: str) -> bool: </s> remove class Symbols(object):\n </s> add class Symbols: </s> remove     readline: Callable[[], Text], grammar: Optional[Grammar] = None\n </s> add     readline: Callable[[], str], grammar: Optional[Grammar] = None </s> remove     def make_label(self, c: PgenGrammar, label: Text) -> int:\n </s> add     def make_label(self, c: PgenGrammar, label: str) -> int: </s> remove     package: str, grammar_source: Text, cache_dir: Optional[Path] = None\n </s> add     package: str, grammar_source: str, cache_dir: Optional[Path] = None </s> remove     gt: Text = \"Grammar.txt\",\n    gp: Optional[Text] = None,\n </s> add     gt: str = \"Grammar.txt\",\n    gp: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> # Python imports\n <mask> import os\n <mask> import pickle\n <mask> import tempfile\n <mask> from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union\n <mask> \n <mask> # Local imports\n <mask> from . import token\n <mask> \n <mask> _P = TypeVar(\"_P\", bound=\"Grammar\")\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove from .pgen2 import token\n </s> add  </s> remove Label = Tuple[int, Optional[Text]]\n </s> add Label = Tuple[int, Optional[str]] </s> remove     Text,\n </s> add  </s> remove import copy\n </s> add  </s> remove     TypeVar,\n    Generic,\n </s> add  </s> remove from typing import Dict, Match, Text\n </s> add from typing import Dict, Match", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/grammar.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> # Local imports\n <mask> from . import token\n <mask> \n <mask> _P = TypeVar(\"_P\", bound=\"Grammar\")\n <mask> Label = Tuple[int, Optional[Text]]\n <mask> DFA = List[List[Tuple[int, int]]]\n <mask> DFAS = Tuple[DFA, Dict[int, int]]\n <mask> Path = Union[str, \"os.PathLike[str]\"]\n <mask> \n <mask> \n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove Results = Dict[Text, NL]\n </s> add Results = Dict[str, NL] </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union\n </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union </s> remove class Grammar(object):\n </s> add class Grammar: </s> remove Context = Tuple[Text, Tuple[int, int]]\nRawNode = Tuple[int, Optional[Text], Optional[Context], Optional[List[NL]]]\n </s> add Context = Tuple[str, Tuple[int, int]]\nRawNode = Tuple[int, Optional[str], Optional[Context], Optional[List[NL]]] </s> remove _type_reprs: Dict[int, Union[Text, int]] = {}\n </s> add _type_reprs: Dict[int, Union[str, int]] = {} </s> remove def type_repr(type_num: int) -> Union[Text, int]:\n </s> add def type_repr(type_num: int) -> Union[str, int]:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/grammar.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> DFAS = Tuple[DFA, Dict[int, int]]\n <mask> Path = Union[str, \"os.PathLike[str]\"]\n <mask> \n <mask> \n <mask> class Grammar(object):\n <mask>     \"\"\"Pgen parsing tables conversion class.\n <mask> \n <mask>     Once initialized, this class supplies the grammar tables for the\n <mask>     parsing engine implemented by parse.py.  The parsing engine\n <mask>     accesses the instance variables directly.  The class here does not\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove Label = Tuple[int, Optional[Text]]\n </s> add Label = Tuple[int, Optional[str]] </s> remove import copy\n </s> add  </s> remove class Parser(object):\n </s> add class Parser: </s> remove class Base(object):\n </s> add class Base: </s> remove Results = Dict[Text, NL]\n </s> add Results = Dict[str, NL] </s> remove class Symbols(object):\n </s> add class Symbols:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/grammar.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \"\"\"Safely evaluate Python string literals without using eval().\"\"\"\n <mask> \n <mask> import re\n <mask> \n <mask> from typing import Dict, Match, Text\n <mask> \n <mask> \n <mask> simple_escapes: Dict[Text, Text] = {\n <mask>     \"a\": \"\\a\",\n <mask>     \"b\": \"\\b\",\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove simple_escapes: Dict[Text, Text] = {\n </s> add simple_escapes: Dict[str, str] = { </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union\n </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union </s> remove import sys\n </s> add  </s> remove     Text,\n </s> add  </s> remove import copy\n </s> add  </s> remove from .pgen2 import token\n </s> add ", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/literals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from typing import Dict, Match, Text\n <mask> \n <mask> \n <mask> simple_escapes: Dict[Text, Text] = {\n <mask>     \"a\": \"\\a\",\n <mask>     \"b\": \"\\b\",\n <mask>     \"f\": \"\\f\",\n <mask>     \"n\": \"\\n\",\n <mask>     \"r\": \"\\r\",\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove from typing import Dict, Match, Text\n </s> add from typing import Dict, Match </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union\n </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union </s> remove     Text,\n </s> add  </s> remove import sys\n </s> add  </s> remove from .pgen2 import token\n </s> add  </s> remove import copy\n </s> add ", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/literals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\\\\\": \"\\\\\",\n <mask> }\n <mask> \n <mask> \n <mask> def escape(m: Match[Text]) -> Text:\n <mask>     all, tail = m.group(0, 1)\n <mask>     assert all.startswith(\"\\\\\")\n <mask>     esc = simple_escapes.get(tail)\n <mask>     if esc is not None:\n <mask>         return esc\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> Text:\n </s> add def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> str: </s> remove     def __repr__(self) -> Text:\n </s> add     def __repr__(self) -> str: </s> remove     def __repr__(self) -> Text:\n </s> add     def __repr__(self) -> str: </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None:\n </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> remove     def expect(self, type: int, value: Optional[Any] = None) -> Text:\n </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str: </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None:\n </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/literals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             raise ValueError(\"invalid octal string escape ('\\\\%s')\" % tail) from None\n <mask>     return chr(i)\n <mask> \n <mask> \n <mask> def evalString(s: Text) -> Text:\n <mask>     assert s.startswith(\"'\") or s.startswith('\"'), repr(s[:1])\n <mask>     q = s[0]\n <mask>     if s[:3] == q * 3:\n <mask>         q = q * 3\n <mask>     assert s.endswith(q), repr(s[-len(q) :])\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def __repr__(self) -> Text:\n </s> add     def __repr__(self) -> str: </s> remove     def untokenize(self, iterable: Iterable[TokenInfo]) -> Text:\n </s> add     def untokenize(self, iterable: Iterable[TokenInfo]) -> str: </s> remove         return \"%s(%s, %r)\" % (\n </s> add         return \"{}({}, {!r})\".format( </s> remove     def __repr__(self) -> Text:\n </s> add     def __repr__(self) -> str: </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None:\n </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> remove     def expect(self, type: int, value: Optional[Any] = None) -> Text:\n </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/literals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> See Parser/parser.c in the Python distribution for additional info on\n <mask> how this parsing engine works.\n <mask> \n <mask> \"\"\"\n <mask> import copy\n <mask> from contextlib import contextmanager\n <mask> \n <mask> # Local imports\n <mask> from . import grammar, token, tokenize\n <mask> from typing import (\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union\n </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union </s> remove from .pgen2 import token\n </s> add  </s> remove     TypeVar,\n    Generic,\n </s> add  </s> remove import sys\n </s> add  </s> remove from typing import Dict, Match, Text\n </s> add from typing import Dict, Match </s> remove     Text,\n </s> add ", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from typing import (\n <mask>     cast,\n <mask>     Any,\n <mask>     Optional,\n <mask>     Text,\n <mask>     Union,\n <mask>     Tuple,\n <mask>     Dict,\n <mask>     List,\n <mask>     Iterator,\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union\n </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union </s> remove     Text,\n </s> add  </s> remove     Text,\n </s> add  </s> remove     Text,\n </s> add  </s> remove     Text,\n </s> add  </s> remove     TypeVar,\n    Generic,\n </s> add ", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> if TYPE_CHECKING:\n <mask>     from blib2to3.pgen2.driver import TokenProxy\n <mask> \n <mask> \n <mask> Results = Dict[Text, NL]\n <mask> Convert = Callable[[Grammar, RawNode], Union[Node, Leaf]]\n <mask> DFA = List[List[Tuple[int, int]]]\n <mask> DFAS = Tuple[DFA, Dict[int, int]]\n <mask> \n <mask> \n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove Label = Tuple[int, Optional[Text]]\n </s> add Label = Tuple[int, Optional[str]] </s> remove _type_reprs: Dict[int, Union[Text, int]] = {}\n </s> add _type_reprs: Dict[int, Union[str, int]] = {} </s> remove class Grammar(object):\n </s> add class Grammar: </s> remove _Results = Dict[Text, NL]\n </s> add _Results = Dict[str, NL] </s> remove def type_repr(type_num: int) -> Union[Text, int]:\n </s> add def type_repr(type_num: int) -> Union[str, int]: </s> remove     first: Dict[Text, Optional[Dict[Text, int]]]\n </s> add     first: Dict[str, Optional[Dict[str, int]]]", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             yield\n <mask>         finally:\n <mask>             self.parser.is_backtracking = is_backtracking\n <mask> \n <mask>     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None:\n <mask>         func: Callable[..., Any]\n <mask>         if raw:\n <mask>             func = self.parser._addtoken\n <mask>         else:\n <mask>             func = self.parser.addtoken\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def determine_route(self, value: Optional[Text] = None, force: bool = False) -> Optional[int]:\n </s> add     def determine_route(self, value: Optional[str] = None, force: bool = False) -> Optional[int]: </s> remove     def parse_stream_raw(self, stream: IO[Text], debug: bool = False) -> NL:\n </s> add     def parse_stream_raw(self, stream: IO[str], debug: bool = False) -> NL: </s> remove     def parse_stream(self, stream: IO[Text], debug: bool = False) -> NL:\n </s> add     def parse_stream(self, stream: IO[str], debug: bool = False) -> NL: </s> remove     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None:\n </s> add     def shift(self, type: int, value: str, newstate: int, context: Context) -> None: </s> remove     def parse_string(self, text: Text, debug: bool = False) -> NL:\n </s> add     def parse_string(self, text: str, debug: bool = False) -> NL: </s> remove         with io.open(filename, \"r\", encoding=encoding) as stream:\n </s> add         with open(filename, encoding=encoding) as stream:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 if raw:\n <mask>                     args.insert(0, ilabel)\n <mask>                 func(*args)\n <mask> \n <mask>     def determine_route(self, value: Optional[Text] = None, force: bool = False) -> Optional[int]:\n <mask>         alive_ilabels = self.ilabels\n <mask>         if len(alive_ilabels) == 0:\n <mask>             *_, most_successful_ilabel = self._dead_ilabels\n <mask>             raise ParseError(\"bad input\", most_successful_ilabel, value, self.context)\n <mask> \n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None:\n </s> add     def add_token(self, tok_type: int, tok_val: str, raw: bool = False) -> None: </s> remove     def parse_stream_raw(self, stream: IO[Text], debug: bool = False) -> NL:\n </s> add     def parse_stream_raw(self, stream: IO[str], debug: bool = False) -> NL: </s> remove     gt: Text = \"Grammar.txt\",\n    gp: Optional[Text] = None,\n </s> add     gt: str = \"Grammar.txt\",\n    gp: Optional[str] = None, </s> remove     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None:\n </s> add     def shift(self, type: int, value: str, newstate: int, context: Context) -> None: </s> remove     def parse_stream(self, stream: IO[Text], debug: bool = False) -> NL:\n </s> add     def parse_stream(self, stream: IO[str], debug: bool = False) -> NL: </s> remove         value: Text,\n </s> add         value: str,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace keep", "code_tokens": " <mask>     \"\"\"Exception to signal the parser is stuck.\"\"\"\n <mask> \n <mask>     def __init__(\n <mask>         self, msg: Text, type: Optional[int], value: Optional[Text], context: Context\n <mask>     ) -> None:\n <mask>         Exception.__init__(\n <mask>             self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n <mask>         )\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None:\n </s> add     def shift(self, type: int, value: str, newstate: int, context: Context) -> None: </s> remove     def classify(self, type: int, value: Text, context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: str, context: Context) -> List[int]: </s> remove     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: str, context: Context) -> bool: </s> remove     def addtoken(self, type: int, value: Text, context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: str, context: Context) -> bool: </s> remove         value: Text,\n </s> add         value: str,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.value = value\n <mask>         self.context = context\n <mask> \n <mask> \n <mask> class Parser(object):\n <mask>     \"\"\"Parser engine.\n <mask> \n <mask>     The proper usage sequence is:\n <mask> \n <mask>     p = Parser(grammar, [converter])  # create instance\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove             self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n </s> add             self, f\"{msg}: type={type!r}, value={value!r}, context={context!r}\" </s> remove class Grammar(object):\n </s> add class Grammar: </s> remove     def expect(self, type: int, value: Optional[Any] = None) -> Text:\n </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str: </s> remove _Results = Dict[Text, NL]\n </s> add _Results = Dict[str, NL] </s> remove class Symbols(object):\n </s> add class Symbols: </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[str] = None,\n        name: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.rootnode: Optional[NL] = None\n <mask>         self.used_names: Set[str] = set()\n <mask>         self.proxy = proxy\n <mask> \n <mask>     def addtoken(self, type: int, value: Text, context: Context) -> bool:\n <mask>         \"\"\"Add a token; return True iff this is the end of the program.\"\"\"\n <mask>         # Map from token to label\n <mask>         ilabels = self.classify(type, value, context)\n <mask>         assert len(ilabels) >= 1\n <mask> \n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: str, context: Context) -> bool: </s> remove     def classify(self, type: int, value: Text, context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: str, context: Context) -> List[int]: </s> remove     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None:\n </s> add     def shift(self, type: int, value: str, newstate: int, context: Context) -> None: </s> remove         self, msg: Text, type: Optional[int], value: Optional[Text], context: Context\n </s> add         self, msg: str, type: Optional[int], value: Optional[str], context: Context </s> remove     used_names: Optional[Set[Text]]\n </s> add     used_names: Optional[Set[str]] </s> remove             self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n </s> add             self, f\"{msg}: type={type!r}, value={value!r}, context={context!r}\"", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             assert ilabel is not None\n <mask> \n <mask>         return self._addtoken(ilabel, type, value, context)\n <mask> \n <mask>     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:\n <mask>         # Loop until the token is shifted; may raise exceptions\n <mask>         while True:\n <mask>             dfa, state, node = self.stack[-1]\n <mask>             states, first = dfa\n <mask>             arcs = states[state]\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None:\n </s> add     def shift(self, type: int, value: str, newstate: int, context: Context) -> None: </s> remove     def addtoken(self, type: int, value: Text, context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: str, context: Context) -> bool: </s> remove     def classify(self, type: int, value: Text, context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: str, context: Context) -> List[int]: </s> remove     def expect(self, type: int, value: Optional[Any] = None) -> Text:\n </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str: </s> remove         self, msg: Text, type: Optional[int], value: Optional[Text], context: Context\n </s> add         self, msg: str, type: Optional[int], value: Optional[str], context: Context </s> remove             self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n </s> add             self, f\"{msg}: type={type!r}, value={value!r}, context={context!r}\"", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 else:\n <mask>                     # No success finding a transition\n <mask>                     raise ParseError(\"bad input\", type, value, context)\n <mask> \n <mask>     def classify(self, type: int, value: Text, context: Context) -> List[int]:\n <mask>         \"\"\"Turn a token into a label.  (Internal)\n <mask> \n <mask>         Depending on whether the value is a soft-keyword or not,\n <mask>         this function may return multiple labels to choose from.\"\"\"\n <mask>         if type == token.NAME:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None:\n </s> add     def shift(self, type: int, value: str, newstate: int, context: Context) -> None: </s> remove     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: str, context: Context) -> bool: </s> remove     def addtoken(self, type: int, value: Text, context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: str, context: Context) -> bool: </s> remove     def expect(self, type: int, value: Optional[Any] = None) -> Text:\n </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str: </s> remove         self, msg: Text, type: Optional[int], value: Optional[Text], context: Context\n </s> add         self, msg: str, type: Optional[int], value: Optional[str], context: Context </s> remove             self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n </s> add             self, f\"{msg}: type={type!r}, value={value!r}, context={context!r}\"", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if ilabel is None:\n <mask>             raise ParseError(\"bad token\", type, value, context)\n <mask>         return [ilabel]\n <mask> \n <mask>     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None:\n <mask>         \"\"\"Shift a token.  (Internal)\"\"\"\n <mask>         if self.is_backtracking:\n <mask>             dfa, state, _ = self.stack[-1]\n <mask>             self.stack[-1] = (dfa, newstate, DUMMY_NODE)\n <mask>         else:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: str, context: Context) -> bool: </s> remove     def classify(self, type: int, value: Text, context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: str, context: Context) -> List[int]: </s> remove     def addtoken(self, type: int, value: Text, context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: str, context: Context) -> bool: </s> remove         self, msg: Text, type: Optional[int], value: Optional[Text], context: Context\n </s> add         self, msg: str, type: Optional[int], value: Optional[str], context: Context </s> remove     def expect(self, type: int, value: Optional[Any] = None) -> Text:\n </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str: </s> remove             self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n </s> add             self, f\"{msg}: type={type!r}, value={value!r}, context={context!r}\"", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     IO,\n <mask>     Iterator,\n <mask>     List,\n <mask>     Optional,\n <mask>     Text,\n <mask>     Tuple,\n <mask>     Union,\n <mask>     Sequence,\n <mask>     NoReturn,\n <mask> )\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     Text,\n </s> add  </s> remove     Text,\n </s> add  </s> remove     Text,\n </s> add  </s> remove     Text,\n </s> add  </s> remove     TypeVar,\n    Generic,\n </s> add  </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union\n </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep keep keep keep replace keep keep keep", "code_tokens": " <mask> class PgenGrammar(grammar.Grammar):\n <mask>     pass\n <mask> \n <mask> \n <mask> class ParserGenerator(object):\n <mask>     filename: Path\n <mask>     stream: IO[Text]\n <mask>     generator: Iterator[GoodTokenInfo]\n <mask>     first: Dict[Text, Optional[Dict[Text, int]]]\n <mask> \n <mask> \n <mask> class ParserGenerator(object):\n <mask>     filename: Path\n <mask>     stream: IO[Text]\n <mask>     generator: Iterator[GoodTokenInfo]\n <mask>     first: Dict[Text, Optional[Dict[Text, int]]]\n <mask> \n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     first: Dict[Text, Optional[Dict[Text, int]]]\n </s> add     first: Dict[str, Optional[Dict[str, int]]] </s> remove     def __init__(self, filename: Path, stream: Optional[IO[Text]] = None) -> None:\n </s> add     def __init__(self, filename: Path, stream: Optional[IO[str]] = None) -> None: </s> remove class Grammar(object):\n </s> add class Grammar: </s> remove class DFAState(object):\n </s> add class DFAState: </s> remove class BasePattern(object):\n </s> add class BasePattern:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep replace keep replace", "code_tokens": " <mask>     stream: IO[Text]\n <mask>     generator: Iterator[GoodTokenInfo]\n <mask>     first: Dict[Text, Optional[Dict[Text, int]]]\n <mask> \n <mask>     def __init__(self, filename: Path, stream: Optional[IO[Text]] = None) -> None:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     stream: IO[Text]\n </s> add     stream: IO[str] </s> remove class ParserGenerator(object):\n </s> add class ParserGenerator: </s> remove     def parse_stream(self, stream: IO[Text], debug: bool = False) -> NL:\n </s> add     def parse_stream(self, stream: IO[str], debug: bool = False) -> NL: </s> remove         with io.open(filename, \"r\", encoding=encoding) as stream:\n </s> add         with open(filename, encoding=encoding) as stream: </s> remove         self, filename: Path, encoding: Optional[Text] = None, debug: bool = False\n </s> add         self, filename: Path, encoding: Optional[str] = None, debug: bool = False", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             c.dfas[c.symbol2number[name]] = (states, self.make_first(c, name))\n <mask>         c.start = c.symbol2number[self.startsymbol]\n <mask>         return c\n <mask> \n <mask>     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]:\n <mask>         rawfirst = self.first[name]\n <mask>         assert rawfirst is not None\n <mask>         first = {}\n <mask>         for label in sorted(rawfirst):\n <mask>             ilabel = self.make_label(c, label)\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def make_label(self, c: PgenGrammar, label: Text) -> int:\n </s> add     def make_label(self, c: PgenGrammar, label: str) -> int: </s> remove     def calcfirst(self, name: Text) -> None:\n </s> add     def calcfirst(self, name: str) -> None: </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None:\n </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> remove _type_reprs: Dict[int, Union[Text, int]] = {}\n </s> add _type_reprs: Dict[int, Union[str, int]] = {} </s> remove     def parse(self) -> Tuple[Dict[Text, List[\"DFAState\"]], Text]:\n </s> add     def parse(self) -> Tuple[Dict[str, List[\"DFAState\"]], str]: </s> remove def type_repr(type_num: int) -> Union[Text, int]:\n </s> add def type_repr(type_num: int) -> Union[str, int]:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             ##assert ilabel not in first # XXX failed on <> ... !=\n <mask>             first[ilabel] = 1\n <mask>         return first\n <mask> \n <mask>     def make_label(self, c: PgenGrammar, label: Text) -> int:\n <mask>         # XXX Maybe this should be a method on a subclass of converter?\n <mask>         ilabel = len(c.labels)\n <mask>         if label[0].isalpha():\n <mask>             # Either a symbol name or a named token\n <mask>             if label in c.symbol2number:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]:\n </s> add     def make_first(self, c: PgenGrammar, name: str) -> Dict[int, int]: </s> remove     used_names: Optional[Set[Text]]\n </s> add     used_names: Optional[Set[str]] </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None:\n </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> remove     def classify(self, type: int, value: Text, context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: str, context: Context) -> List[int]: </s> remove     def addtoken(self, type: int, value: Text, context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: str, context: Context) -> bool: </s> remove     def calcfirst(self, name: Text) -> None:\n </s> add     def calcfirst(self, name: str) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             if name not in self.first:\n <mask>                 self.calcfirst(name)\n <mask>             # print name, self.first[name].keys()\n <mask> \n <mask>     def calcfirst(self, name: Text) -> None:\n <mask>         dfa = self.dfas[name]\n <mask>         self.first[name] = None  # dummy to detect left recursion\n <mask>         state = dfa[0]\n <mask>         totalset: Dict[str, int] = {}\n <mask>         overlapcheck = {}\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]:\n </s> add     def make_first(self, c: PgenGrammar, name: str) -> Dict[int, int]: </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None:\n </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> remove     name: Optional[Text] = None  # Optional name used to store match in results dict\n </s> add     name: Optional[str] = None  # Optional name used to store match in results dict </s> remove     def parse(self) -> Tuple[Dict[Text, List[\"DFAState\"]], Text]:\n </s> add     def parse(self) -> Tuple[Dict[str, List[\"DFAState\"]], str]: </s> remove _type_reprs: Dict[int, Union[Text, int]] = {}\n </s> add _type_reprs: Dict[int, Union[str, int]] = {} </s> remove     if type(_value) is type(0):\n </s> add     if type(_value) is int:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     )\n <mask>                 inverse[symbol] = label\n <mask>         self.first[name] = totalset\n <mask> \n <mask>     def parse(self) -> Tuple[Dict[Text, List[\"DFAState\"]], Text]:\n <mask>         dfas = {}\n <mask>         startsymbol: Optional[str] = None\n <mask>         # MSTART: (NEWLINE | RULE)* ENDMARKER\n <mask>         while self.type != token.ENDMARKER:\n <mask>             while self.type == token.NEWLINE:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def calcfirst(self, name: Text) -> None:\n </s> add     def calcfirst(self, name: str) -> None: </s> remove     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]:\n </s> add     def make_first(self, c: PgenGrammar, name: str) -> Dict[int, int]: </s> remove         return \"%s(%s)\" % (self.__class__.__name__, \", \".join(map(repr, args)))\n </s> add         return \"{}({})\".format(self.__class__.__name__, \", \".join(map(repr, args))) </s> remove     def expect(self, type: int, value: Optional[Any] = None) -> Text:\n </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str: </s> remove     def __repr__(self) -> Text:\n </s> add     def __repr__(self) -> str: </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None:\n </s> add     def addarc(self, next: \"DFAState\", label: str) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     states.append(st)\n <mask>                 state.addarc(st, label)\n <mask>         return states  # List of DFAState instances; first one is start\n <mask> \n <mask>     def dump_nfa(self, name: Text, start: \"NFAState\", finish: \"NFAState\") -> None:\n <mask>         print(\"Dump of NFA for\", name)\n <mask>         todo = [start]\n <mask>         for i, state in enumerate(todo):\n <mask>             print(\"  State\", i, state is finish and \"(final)\" or \"\")\n <mask>             for label, next in state.arcs:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def dump_dfa(self, name: Text, dfa: Sequence[\"DFAState\"]) -> None:\n </s> add     def dump_dfa(self, name: str, dfa: Sequence[\"DFAState\"]) -> None: </s> remove     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]:\n </s> add     def make_first(self, c: PgenGrammar, name: str) -> Dict[int, int]: </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None:\n </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None: </s> remove     def calcfirst(self, name: Text) -> None:\n </s> add     def calcfirst(self, name: str) -> None: </s> remove     def make_label(self, c: PgenGrammar, label: Text) -> int:\n </s> add     def make_label(self, c: PgenGrammar, label: str) -> int: </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None:\n </s> add     def addarc(self, next: \"DFAState\", label: str) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     print(\"    -> %d\" % j)\n <mask>                 else:\n <mask>                     print(\"    %s -> %d\" % (label, j))\n <mask> \n <mask>     def dump_dfa(self, name: Text, dfa: Sequence[\"DFAState\"]) -> None:\n <mask>         print(\"Dump of DFA for\", name)\n <mask>         for i, state in enumerate(dfa):\n <mask>             print(\"  State\", i, state.isfinal and \"(final)\" or \"\")\n <mask>             for label, next in sorted(state.arcs.items()):\n <mask>                 print(\"    %s -> %d\" % (label, dfa.index(next)))\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def dump_nfa(self, name: Text, start: \"NFAState\", finish: \"NFAState\") -> None:\n </s> add     def dump_nfa(self, name: str, start: \"NFAState\", finish: \"NFAState\") -> None: </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None:\n </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None: </s> remove     def calcfirst(self, name: Text) -> None:\n </s> add     def calcfirst(self, name: str) -> None: </s> remove     def __repr__(self) -> Text:\n </s> add     def __repr__(self) -> str: </s> remove class NFAState(object):\n    arcs: List[Tuple[Optional[Text], \"NFAState\"]]\n </s> add class NFAState:\n    arcs: List[Tuple[Optional[str], \"NFAState\"]] </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 \"expected (...) or NAME or STRING, got %s/%s\", self.type, self.value\n <mask>             )\n <mask>             assert False\n <mask> \n <mask>     def expect(self, type: int, value: Optional[Any] = None) -> Text:\n <mask>         if self.type != type or (value is not None and self.value != value):\n <mask>             self.raise_error(\n <mask>                 \"expected %s/%s, got %s/%s\", type, value, self.type, self.value\n <mask>             )\n <mask>         value = self.value\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove             self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n </s> add             self, f\"{msg}: type={type!r}, value={value!r}, context={context!r}\" </s> remove     def classify(self, type: int, value: Text, context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: str, context: Context) -> List[int]: </s> remove class Parser(object):\n </s> add class Parser: </s> remove     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: str, context: Context) -> bool: </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None:\n </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None: </s> remove     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None:\n </s> add     def shift(self, type: int, value: str, newstate: int, context: Context) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 msg = \" \".join([msg] + list(map(str, args)))\n <mask>         raise SyntaxError(msg, (self.filename, self.end[0], self.end[1], self.line))\n <mask> \n <mask> \n <mask> class NFAState(object):\n <mask>     arcs: List[Tuple[Optional[Text], \"NFAState\"]]\n <mask> \n <mask>     def __init__(self) -> None:\n <mask>         self.arcs = []  # list of (label, NFAState) pairs\n <mask> \n <mask>     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None:\n </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None: </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None:\n </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> remove     tokens: List[Text]\n </s> add     tokens: List[str] </s> remove def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> Text:\n </s> add def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> str: </s> remove     arcs: Dict[Text, \"DFAState\"]\n </s> add     arcs: Dict[str, \"DFAState\"] </s> remove class DFAState(object):\n </s> add class DFAState:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def __init__(self) -> None:\n <mask>         self.arcs = []  # list of (label, NFAState) pairs\n <mask> \n <mask>     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None:\n <mask>         assert label is None or isinstance(label, str)\n <mask>         assert isinstance(next, NFAState)\n <mask>         self.arcs.append((label, next))\n <mask> \n <mask> \n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove class NFAState(object):\n    arcs: List[Tuple[Optional[Text], \"NFAState\"]]\n </s> add class NFAState:\n    arcs: List[Tuple[Optional[str], \"NFAState\"]] </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None:\n </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> remove class DFAState(object):\n </s> add class DFAState: </s> remove     arcs: Dict[Text, \"DFAState\"]\n </s> add     arcs: Dict[str, \"DFAState\"] </s> remove     def make_label(self, c: PgenGrammar, label: Text) -> int:\n </s> add     def make_label(self, c: PgenGrammar, label: str) -> int: </s> remove     def dump_nfa(self, name: Text, start: \"NFAState\", finish: \"NFAState\") -> None:\n </s> add     def dump_nfa(self, name: str, start: \"NFAState\", finish: \"NFAState\") -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         assert isinstance(next, NFAState)\n <mask>         self.arcs.append((label, next))\n <mask> \n <mask> \n <mask> class DFAState(object):\n <mask>     nfaset: Dict[NFAState, Any]\n <mask>     isfinal: bool\n <mask>     arcs: Dict[Text, \"DFAState\"]\n <mask> \n <mask>     def __init__(self, nfaset: Dict[NFAState, Any], final: NFAState) -> None:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     arcs: Dict[Text, \"DFAState\"]\n </s> add     arcs: Dict[str, \"DFAState\"] </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None:\n </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None: </s> remove class NFAState(object):\n    arcs: List[Tuple[Optional[Text], \"NFAState\"]]\n </s> add class NFAState:\n    arcs: List[Tuple[Optional[str], \"NFAState\"]] </s> remove     stream: IO[Text]\n </s> add     stream: IO[str] </s> remove     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None:\n </s> add     def add_token(self, tok_type: int, tok_val: str, raw: bool = False) -> None: </s> remove     first: Dict[Text, Optional[Dict[Text, int]]]\n </s> add     first: Dict[str, Optional[Dict[str, int]]]", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> class DFAState(object):\n <mask>     nfaset: Dict[NFAState, Any]\n <mask>     isfinal: bool\n <mask>     arcs: Dict[Text, \"DFAState\"]\n <mask> \n <mask>     def __init__(self, nfaset: Dict[NFAState, Any], final: NFAState) -> None:\n <mask>         assert isinstance(nfaset, dict)\n <mask>         assert isinstance(next(iter(nfaset)), NFAState)\n <mask>         assert isinstance(final, NFAState)\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove class DFAState(object):\n </s> add class DFAState: </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None:\n </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None: </s> remove class NFAState(object):\n    arcs: List[Tuple[Optional[Text], \"NFAState\"]]\n </s> add class NFAState:\n    arcs: List[Tuple[Optional[str], \"NFAState\"]] </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None:\n </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> remove     stream: IO[Text]\n </s> add     stream: IO[str] </s> remove     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None:\n </s> add     def add_token(self, tok_type: int, tok_val: str, raw: bool = False) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.nfaset = nfaset\n <mask>         self.isfinal = final in nfaset\n <mask>         self.arcs = {}  # map from label to DFAState\n <mask> \n <mask>     def addarc(self, next: \"DFAState\", label: Text) -> None:\n <mask>         assert isinstance(label, str)\n <mask>         assert label not in self.arcs\n <mask>         assert isinstance(next, DFAState)\n <mask>         self.arcs[label] = next\n <mask> \n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None:\n </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None: </s> remove     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]:\n </s> add     def make_first(self, c: PgenGrammar, name: str) -> Dict[int, int]: </s> remove class NFAState(object):\n    arcs: List[Tuple[Optional[Text], \"NFAState\"]]\n </s> add class NFAState:\n    arcs: List[Tuple[Optional[str], \"NFAState\"]] </s> remove     def calcfirst(self, name: Text) -> None:\n </s> add     def calcfirst(self, name: str) -> None: </s> remove     def make_label(self, c: PgenGrammar, label: Text) -> int:\n </s> add     def make_label(self, c: PgenGrammar, label: str) -> int: </s> remove     def addtoken(self, type: int, value: Text, context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: str, context: Context) -> bool:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \"\"\"Token constants (from \"token.h\").\"\"\"\n <mask> \n <mask> import sys\n <mask> from typing import Dict\n <mask> \n <mask> from typing import Final\n <mask> \n <mask> #  Taken from Python (r53757) and modified to include some tokens\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union\n </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union </s> remove from typing import Dict, Match, Text\n </s> add from typing import Dict, Match </s> remove import copy\n </s> add  </s> remove from .pgen2 import token\n </s> add  </s> remove     Text,\n </s> add  </s> remove simple_escapes: Dict[Text, Text] = {\n </s> add simple_escapes: Dict[str, str] = {", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/token.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> # --end constants--\n <mask> \n <mask> tok_name: Final[Dict[int, str]] = {}\n <mask> for _name, _value in list(globals().items()):\n <mask>     if type(_value) is type(0):\n <mask>         tok_name[_value] = _name\n <mask> \n <mask> \n <mask> def ISTERMINAL(x: int) -> bool:\n <mask>     return x < NT_OFFSET\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove def type_repr(type_num: int) -> Union[Text, int]:\n </s> add def type_repr(type_num: int) -> Union[str, int]: </s> remove     return set(x + y for x in l for y in l + (\"\",) if x.casefold() != y.casefold())\n </s> add     return {x + y for x in l for y in l + (\"\",) if x.casefold() != y.casefold()} </s> remove _type_reprs: Dict[int, Union[Text, int]] = {}\n </s> add _type_reprs: Dict[int, Union[str, int]] = {} </s> remove     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]:\n </s> add     def _partially_consume_prefix(self, prefix: str, column: int) -> Tuple[str, str]: </s> remove     def calcfirst(self, name: Text) -> None:\n </s> add     def calcfirst(self, name: str) -> None: </s> remove     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]:\n </s> add     def make_first(self, c: PgenGrammar, name: str) -> Dict[int, int]:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/token.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     Iterator,\n <mask>     List,\n <mask>     Optional,\n <mask>     Set,\n <mask>     Text,\n <mask>     Tuple,\n <mask>     Pattern,\n <mask>     Union,\n <mask>     cast,\n <mask> )\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     Text,\n </s> add  </s> remove     Text,\n </s> add  </s> remove     Text,\n </s> add  </s> remove     Text,\n </s> add  </s> remove     TypeVar,\n    Generic,\n </s> add  </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union\n </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return group(*choices) + \"?\"\n <mask> \n <mask> \n <mask> def _combinations(*l: str) -> Set[str]:\n <mask>     return set(x + y for x in l for y in l + (\"\",) if x.casefold() != y.casefold())\n <mask> \n <mask> \n <mask> Whitespace = r\"[ \\f\\t]*\"\n <mask> Comment = r\"#[^\\r\\n]*\"\n <mask> Ignore = Whitespace + any(r\"\\\\\\r?\\n\" + Whitespace) + maybe(Comment)\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> Text:\n </s> add def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> str: </s> remove     def get_suffix(self) -> Text:\n </s> add     def get_suffix(self) -> str: </s> remove class NFAState(object):\n    arcs: List[Tuple[Optional[Text], \"NFAState\"]]\n </s> add class NFAState:\n    arcs: List[Tuple[Optional[str], \"NFAState\"]] </s> remove     if type(_value) is type(0):\n </s> add     if type(_value) is int: </s> remove     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]:\n </s> add     def make_first(self, c: PgenGrammar, name: str) -> Dict[int, int]: </s> remove     def make_label(self, c: PgenGrammar, label: Text) -> int:\n </s> add     def make_label(self, c: PgenGrammar, label: str) -> int:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Coord = Tuple[int, int]\n <mask> \n <mask> \n <mask> def printtoken(\n <mask>     type: int, token: Text, srow_col: Coord, erow_col: Coord, line: Text\n <mask> ) -> None:  # for testing\n <mask>     (srow, scol) = srow_col\n <mask>     (erow, ecol) = erow_col\n <mask>     print(\n <mask>         \"%d,%d-%d,%d:\\t%s\\t%s\" % (srow, scol, erow, ecol, tok_name[type], repr(token))\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove TokenEater = Callable[[int, Text, Coord, Coord, Text], None]\n </s> add TokenEater = Callable[[int, str, Coord, Coord, str], None] </s> remove GoodTokenInfo = Tuple[int, Text, Coord, Coord, Text]\n </s> add GoodTokenInfo = Tuple[int, str, Coord, Coord, str] </s> remove def tokenize_loop(readline: Callable[[], Text], tokeneater: TokenEater) -> None:\n </s> add def tokenize_loop(readline: Callable[[], str], tokeneater: TokenEater) -> None: </s> remove                 Tuple[int, Text, Coord, Coord, Text], t\n </s> add                 Tuple[int, str, Coord, Coord, str], t </s> remove     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None:\n </s> add     def compat(self, token: Tuple[int, str], iterable: Iterable[TokenInfo]) -> None: </s> remove def tokenize(readline: Callable[[], Text], tokeneater: TokenEater = printtoken) -> None:\n </s> add def tokenize(readline: Callable[[], str], tokeneater: TokenEater = printtoken) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"%d,%d-%d,%d:\\t%s\\t%s\" % (srow, scol, erow, ecol, tok_name[type], repr(token))\n <mask>     )\n <mask> \n <mask> \n <mask> TokenEater = Callable[[int, Text, Coord, Coord, Text], None]\n <mask> \n <mask> \n <mask> def tokenize(readline: Callable[[], Text], tokeneater: TokenEater = printtoken) -> None:\n <mask>     \"\"\"\n <mask>     The tokenize() function accepts two parameters: one representing the\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove def tokenize(readline: Callable[[], Text], tokeneater: TokenEater = printtoken) -> None:\n </s> add def tokenize(readline: Callable[[], str], tokeneater: TokenEater = printtoken) -> None: </s> remove     type: int, token: Text, srow_col: Coord, erow_col: Coord, line: Text\n </s> add     type: int, token: str, srow_col: Coord, erow_col: Coord, line: str </s> remove def tokenize_loop(readline: Callable[[], Text], tokeneater: TokenEater) -> None:\n </s> add def tokenize_loop(readline: Callable[[], str], tokeneater: TokenEater) -> None: </s> remove     readline: Callable[[], Text], grammar: Optional[Grammar] = None\n </s> add     readline: Callable[[], str], grammar: Optional[Grammar] = None </s> remove                 Tuple[int, Text, Coord, Coord, Text], t\n </s> add                 Tuple[int, str, Coord, Coord, str], t </s> remove GoodTokenInfo = Tuple[int, Text, Coord, Coord, Text]\n </s> add GoodTokenInfo = Tuple[int, str, Coord, Coord, str]", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> TokenEater = Callable[[int, Text, Coord, Coord, Text], None]\n <mask> \n <mask> \n <mask> def tokenize(readline: Callable[[], Text], tokeneater: TokenEater = printtoken) -> None:\n <mask>     \"\"\"\n <mask>     The tokenize() function accepts two parameters: one representing the\n <mask>     input stream, and one providing an output mechanism for tokenize().\n <mask> \n <mask>     The first parameter, readline, must be a callable object which provides\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove TokenEater = Callable[[int, Text, Coord, Coord, Text], None]\n </s> add TokenEater = Callable[[int, str, Coord, Coord, str], None] </s> remove     readline: Callable[[], Text], grammar: Optional[Grammar] = None\n </s> add     readline: Callable[[], str], grammar: Optional[Grammar] = None </s> remove def tokenize_loop(readline: Callable[[], Text], tokeneater: TokenEater) -> None:\n </s> add def tokenize_loop(readline: Callable[[], str], tokeneater: TokenEater) -> None: </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> remove                 Tuple[int, Text, Coord, Coord, Text], t\n </s> add                 Tuple[int, str, Coord, Coord, str], t </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[str] = None,\n        name: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace", "code_tokens": " <mask> \n <mask> # backwards compatible interface\n <mask> def tokenize_loop(readline: Callable[[], Text], tokeneater: TokenEater) -> None:\n <mask>     for token_info in generate_tokens(readline):\n <mask>         tokeneater(*token_info)\n <mask> \n <mask> \n <mask> GoodTokenInfo = Tuple[int, Text, Coord, Coord, Text]\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove TokenEater = Callable[[int, Text, Coord, Coord, Text], None]\n </s> add TokenEater = Callable[[int, str, Coord, Coord, str], None] </s> remove def tokenize(readline: Callable[[], Text], tokeneater: TokenEater = printtoken) -> None:\n </s> add def tokenize(readline: Callable[[], str], tokeneater: TokenEater = printtoken) -> None: </s> remove                 Tuple[int, Text, Coord, Coord, Text], t\n </s> add                 Tuple[int, str, Coord, Coord, str], t </s> remove     type: int, token: Text, srow_col: Coord, erow_col: Coord, line: Text\n </s> add     type: int, token: str, srow_col: Coord, erow_col: Coord, line: str </s> remove     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None:\n </s> add     def compat(self, token: Tuple[int, str], iterable: Iterable[TokenInfo]) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> TokenInfo = Union[Tuple[int, str], GoodTokenInfo]\n <mask> \n <mask> \n <mask> class Untokenizer:\n <mask>     tokens: List[Text]\n <mask>     prev_row: int\n <mask>     prev_col: int\n <mask> \n <mask>     def __init__(self) -> None:\n <mask>         self.tokens = []\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove GoodTokenInfo = Tuple[int, Text, Coord, Coord, Text]\n </s> add GoodTokenInfo = Tuple[int, str, Coord, Coord, str] </s> remove         content: Optional[Text] = None,\n </s> add         content: Optional[str] = None, </s> remove class NFAState(object):\n    arcs: List[Tuple[Optional[Text], \"NFAState\"]]\n </s> add class NFAState:\n    arcs: List[Tuple[Optional[str], \"NFAState\"]] </s> remove         name: Optional[Text] = None,\n </s> add         name: Optional[str] = None, </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None:\n </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None: </s> remove class Symbols(object):\n </s> add class Symbols:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         col_offset = col - self.prev_col\n <mask>         if col_offset:\n <mask>             self.tokens.append(\" \" * col_offset)\n <mask> \n <mask>     def untokenize(self, iterable: Iterable[TokenInfo]) -> Text:\n <mask>         for t in iterable:\n <mask>             if len(t) == 2:\n <mask>                 self.compat(cast(Tuple[int, str], t), iterable)\n <mask>                 break\n <mask>             tok_type, token, start, end, line = cast(\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove                 Tuple[int, Text, Coord, Coord, Text], t\n </s> add                 Tuple[int, str, Coord, Coord, str], t </s> remove     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None:\n </s> add     def compat(self, token: Tuple[int, str], iterable: Iterable[TokenInfo]) -> None: </s> remove def evalString(s: Text) -> Text:\n </s> add def evalString(s: str) -> str: </s> remove def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> Text:\n </s> add def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> str: </s> remove     def determine_route(self, value: Optional[Text] = None, force: bool = False) -> Optional[int]:\n </s> add     def determine_route(self, value: Optional[str] = None, force: bool = False) -> Optional[int]: </s> remove                 print(\"%s(%s): can't parse %s\" % (filename, lineno, line.strip()))\n </s> add                 print(f\"{filename}({lineno}): can't parse {line.strip()}\")", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             if len(t) == 2:\n <mask>                 self.compat(cast(Tuple[int, str], t), iterable)\n <mask>                 break\n <mask>             tok_type, token, start, end, line = cast(\n <mask>                 Tuple[int, Text, Coord, Coord, Text], t\n <mask>             )\n <mask>             self.add_whitespace(start)\n <mask>             self.tokens.append(token)\n <mask>             self.prev_row, self.prev_col = end\n <mask>             if tok_type in (NEWLINE, NL):\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def untokenize(self, iterable: Iterable[TokenInfo]) -> Text:\n </s> add     def untokenize(self, iterable: Iterable[TokenInfo]) -> str: </s> remove GoodTokenInfo = Tuple[int, Text, Coord, Coord, Text]\n </s> add GoodTokenInfo = Tuple[int, str, Coord, Coord, str] </s> remove def tokenize_loop(readline: Callable[[], Text], tokeneater: TokenEater) -> None:\n </s> add def tokenize_loop(readline: Callable[[], str], tokeneater: TokenEater) -> None: </s> remove TokenEater = Callable[[int, Text, Coord, Coord, Text], None]\n </s> add TokenEater = Callable[[int, str, Coord, Coord, str], None] </s> remove     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None:\n </s> add     def compat(self, token: Tuple[int, str], iterable: Iterable[TokenInfo]) -> None: </s> remove     type: int, token: Text, srow_col: Coord, erow_col: Coord, line: Text\n </s> add     type: int, token: str, srow_col: Coord, erow_col: Coord, line: str", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 self.prev_row += 1\n <mask>                 self.prev_col = 0\n <mask>         return \"\".join(self.tokens)\n <mask> \n <mask>     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None:\n <mask>         startline = False\n <mask>         indents = []\n <mask>         toks_append = self.tokens.append\n <mask>         toknum, tokval = token\n <mask>         if toknum in (NAME, NUMBER):\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def untokenize(self, iterable: Iterable[TokenInfo]) -> Text:\n </s> add     def untokenize(self, iterable: Iterable[TokenInfo]) -> str: </s> remove     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]:\n </s> add     def _partially_consume_prefix(self, prefix: str, column: int) -> Tuple[str, str]: </s> remove                 Tuple[int, Text, Coord, Coord, Text], t\n </s> add                 Tuple[int, str, Coord, Coord, str], t </s> remove     type: int, token: Text, srow_col: Coord, erow_col: Coord, line: Text\n </s> add     type: int, token: str, srow_col: Coord, erow_col: Coord, line: str </s> remove                 print(\"%s(%s): can't parse %s\" % (filename, lineno, line.strip()))\n </s> add                 print(f\"{filename}({lineno}): can't parse {line.strip()}\") </s> remove def tokenize_loop(readline: Callable[[], Text], tokeneater: TokenEater) -> None:\n </s> add def tokenize_loop(readline: Callable[[], str], tokeneater: TokenEater) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def read_or_stop() -> bytes:\n <mask>         try:\n <mask>             return readline()\n <mask>         except StopIteration:\n <mask>             return bytes()\n <mask> \n <mask>     def find_cookie(line: bytes) -> Optional[str]:\n <mask>         try:\n <mask>             line_string = line.decode(\"ascii\")\n <mask>         except UnicodeDecodeError:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove             print(\"Can't open %s: %s\" % (filename, err))\n </s> add             print(f\"Can't open {filename}: {err}\") </s> remove             print(\"Can't open %s: %s\" % (filename, err))\n </s> add             print(f\"Can't open {filename}: {err}\") </s> remove @lru_cache()\n </s> add @lru_cache </s> remove     def prefix(self, prefix: Text) -> None:\n </s> add     def prefix(self, prefix: str) -> None: </s> remove     def prefix(self, prefix: Text) -> None:\n </s> add     def prefix(self, prefix: str) -> None: </s> remove     readline: Callable[[], Text], grammar: Optional[Grammar] = None\n </s> add     readline: Callable[[], str], grammar: Optional[Grammar] = None", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     return default, [first, second]\n <mask> \n <mask> \n <mask> def untokenize(iterable: Iterable[TokenInfo]) -> Text:\n <mask>     \"\"\"Transform tokens back into Python source code.\n <mask> \n <mask>     Each element returned by the iterable must be a token sequence\n <mask>     with at least two elements, a token number and token value.  If\n <mask>     only two tokens are passed, the resulting output is poor.\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove def tokenize(readline: Callable[[], Text], tokeneater: TokenEater = printtoken) -> None:\n </s> add def tokenize(readline: Callable[[], str], tokeneater: TokenEater = printtoken) -> None: </s> remove     used_names: Optional[Set[Text]]\n </s> add     used_names: Optional[Set[str]] </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[str] = None,\n        name: Optional[str] = None, </s> remove         with io.open(filename, \"r\", encoding=encoding) as stream:\n </s> add         with open(filename, encoding=encoding) as stream: </s> remove     def parse_string(self, text: Text, debug: bool = False) -> NL:\n </s> add     def parse_string(self, text: str, debug: bool = False) -> NL:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return ut.untokenize(iterable)\n <mask> \n <mask> \n <mask> def generate_tokens(\n <mask>     readline: Callable[[], Text], grammar: Optional[Grammar] = None\n <mask> ) -> Iterator[GoodTokenInfo]:\n <mask>     \"\"\"\n <mask>     The generate_tokens() generator requires one argument, readline, which\n <mask>     must be a callable object which provides the same interface as the\n <mask>     readline() method of built-in file objects. Each call to the function\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove def tokenize(readline: Callable[[], Text], tokeneater: TokenEater = printtoken) -> None:\n </s> add def tokenize(readline: Callable[[], str], tokeneater: TokenEater = printtoken) -> None: </s> remove TokenEater = Callable[[int, Text, Coord, Coord, Text], None]\n </s> add TokenEater = Callable[[int, str, Coord, Coord, str], None] </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> remove def untokenize(iterable: Iterable[TokenInfo]) -> Text:\n </s> add def untokenize(iterable: Iterable[TokenInfo]) -> str: </s> remove         with io.open(filename, \"r\", encoding=encoding) as stream:\n </s> add         with open(filename, encoding=encoding) as stream: </s> remove def tokenize_loop(readline: Callable[[], Text], tokeneater: TokenEater) -> None:\n </s> add def tokenize_loop(readline: Callable[[], str], tokeneater: TokenEater) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from typing import Union\n <mask> \n <mask> # Local imports\n <mask> from .pgen2 import token\n <mask> from .pgen2 import driver\n <mask> \n <mask> from .pgen2.grammar import Grammar\n <mask> \n <mask> # Moved into initialize because mypyc can't handle __file__ (XXX bug)\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union\n </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union </s> remove import copy\n </s> add  </s> remove import sys\n </s> add  </s> remove from typing import Dict, Match, Text\n </s> add from typing import Dict, Match </s> remove Label = Tuple[int, Optional[Text]]\n </s> add Label = Tuple[int, Optional[str]] </s> remove     TypeVar,\n    Generic,\n </s> add ", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pygram.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> # _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__),\n <mask> #                                      \"PatternGrammar.txt\")\n <mask> \n <mask> \n <mask> class Symbols(object):\n <mask>     def __init__(self, grammar: Grammar) -> None:\n <mask>         \"\"\"Initializer.\n <mask> \n <mask>         Creates an attribute for each grammar symbol (nonterminal),\n <mask>         whose value is the symbol's type (an int >= 256).\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove class Driver(object):\n </s> add class Driver: </s> remove     name: Optional[Text] = None  # Optional name used to store match in results dict\n </s> add     name: Optional[str] = None  # Optional name used to store match in results dict </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> remove def main(*args: Text) -> bool:\n </s> add def main(*args: str) -> bool: </s> remove     tokens: List[Text]\n </s> add     tokens: List[str] </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[str] = None,\n        name: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pygram.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     Dict,\n <mask>     Iterator,\n <mask>     List,\n <mask>     Optional,\n <mask>     Text,\n <mask>     Tuple,\n <mask>     TypeVar,\n <mask>     Union,\n <mask>     Set,\n <mask>     Iterable,\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     Text,\n </s> add  </s> remove     Text,\n </s> add  </s> remove     Text,\n </s> add  </s> remove     Text,\n </s> add  </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union\n </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union </s> remove     TypeVar,\n    Generic,\n </s> add ", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from io import StringIO\n <mask> \n <mask> HUGE: int = 0x7FFFFFFF  # maximum repeat count, default max\n <mask> \n <mask> _type_reprs: Dict[int, Union[Text, int]] = {}\n <mask> \n <mask> \n <mask> def type_repr(type_num: int) -> Union[Text, int]:\n <mask>     global _type_reprs\n <mask>     if not _type_reprs:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove def type_repr(type_num: int) -> Union[Text, int]:\n </s> add def type_repr(type_num: int) -> Union[str, int]: </s> remove     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]:\n </s> add     def make_first(self, c: PgenGrammar, name: str) -> Dict[int, int]: </s> remove Results = Dict[Text, NL]\n </s> add Results = Dict[str, NL] </s> remove Label = Tuple[int, Optional[Text]]\n </s> add Label = Tuple[int, Optional[str]] </s> remove     if type(_value) is type(0):\n </s> add     if type(_value) is int: </s> remove     def calcfirst(self, name: Text) -> None:\n </s> add     def calcfirst(self, name: str) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> _type_reprs: Dict[int, Union[Text, int]] = {}\n <mask> \n <mask> \n <mask> def type_repr(type_num: int) -> Union[Text, int]:\n <mask>     global _type_reprs\n <mask>     if not _type_reprs:\n <mask>         from .pygram import python_symbols\n <mask> \n <mask>         # printing tokens is possible but not as useful\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove _type_reprs: Dict[int, Union[Text, int]] = {}\n </s> add _type_reprs: Dict[int, Union[str, int]] = {} </s> remove     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]:\n </s> add     def make_first(self, c: PgenGrammar, name: str) -> Dict[int, int]: </s> remove     if type(_value) is type(0):\n </s> add     if type(_value) is int: </s> remove Results = Dict[Text, NL]\n </s> add Results = Dict[str, NL] </s> remove Label = Tuple[int, Optional[Text]]\n </s> add Label = Tuple[int, Optional[str]] </s> remove     def calcfirst(self, name: Text) -> None:\n </s> add     def calcfirst(self, name: str) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep replace replace keep keep replace keep keep keep", "code_tokens": " <mask> _P = TypeVar(\"_P\", bound=\"Base\")\n <mask> \n <mask> NL = Union[\"Node\", \"Leaf\"]\n <mask> Context = Tuple[Text, Tuple[int, int]]\n <mask> RawNode = Tuple[int, Optional[Text], Optional[Context], Optional[List[NL]]]\n <mask> \n <mask> \n <mask> class Base(object):\n <mask> \n <mask>     \"\"\"\n <mask>     Abstract base class for Node and Leaf.\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove Label = Tuple[int, Optional[Text]]\n </s> add Label = Tuple[int, Optional[str]] </s> remove GoodTokenInfo = Tuple[int, Text, Coord, Coord, Text]\n </s> add GoodTokenInfo = Tuple[int, str, Coord, Coord, str] </s> remove class Grammar(object):\n </s> add class Grammar: </s> remove     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None:\n </s> add     def compat(self, token: Tuple[int, str], iterable: Iterable[TokenInfo]) -> None: </s> remove class BasePattern(object):\n </s> add class BasePattern:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return NotImplemented\n <mask>         return self._eq(other)\n <mask> \n <mask>     @property\n <mask>     def prefix(self) -> Text:\n <mask>         raise NotImplementedError\n <mask> \n <mask>     def _eq(self: _P, other: _P) -> bool:\n <mask>         \"\"\"\n <mask>         Compare two nodes for equality.\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove         return \"%s(%s)\" % (self.__class__.__name__, \", \".join(map(repr, args)))\n </s> add         return \"{}({})\".format(self.__class__.__name__, \", \".join(map(repr, args))) </s> remove def main(*args: Text) -> bool:\n </s> add def main(*args: str) -> bool: </s> remove def untokenize(iterable: Iterable[TokenInfo]) -> Text:\n </s> add def untokenize(iterable: Iterable[TokenInfo]) -> str: </s> remove def _newer(a: Text, b: Text) -> bool:\n </s> add def _newer(a: str, b: str) -> bool:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if self.parent is None:\n <mask>             return 0\n <mask>         return 1 + self.parent.depth()\n <mask> \n <mask>     def get_suffix(self) -> Text:\n <mask>         \"\"\"\n <mask>         Return the string immediately following the invocant node. This is\n <mask>         effectively equivalent to node.next_sibling.prefix\n <mask>         \"\"\"\n <mask>         next_sib = self.next_sibling\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def __str__(self) -> Text:\n </s> add     def __str__(self) -> str: </s> remove     def __str__(self) -> Text:\n </s> add     def __str__(self) -> str: </s> remove def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> Text:\n </s> add def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> str: </s> remove     def addtoken(self, type: int, value: Text, context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: str, context: Context) -> bool: </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None:\n </s> add     def compat(self, token: Tuple[int, str], iterable: Iterable[TokenInfo]) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     \"\"\"Concrete implementation for interior nodes.\"\"\"\n <mask> \n <mask>     fixers_applied: Optional[List[Any]]\n <mask>     used_names: Optional[Set[Text]]\n <mask> \n <mask>     def __init__(\n <mask>         self,\n <mask>         type: int,\n <mask>         children: List[NL],\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     value: Text\n </s> add     value: str </s> remove         prefix: Optional[Text] = None,\n </s> add         prefix: Optional[str] = None, </s> remove         value: Text,\n </s> add         value: str, </s> remove         prefix: Optional[Text] = None,\n </s> add         prefix: Optional[str] = None, </s> remove         self, msg: Text, type: Optional[int], value: Optional[Text], context: Context\n </s> add         self, msg: str, type: Optional[int], value: Optional[str], context: Context </s> remove             self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n </s> add             self, f\"{msg}: type={type!r}, value={value!r}, context={context!r}\"", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self,\n <mask>         type: int,\n <mask>         children: List[NL],\n <mask>         context: Optional[Any] = None,\n <mask>         prefix: Optional[Text] = None,\n <mask>         fixers_applied: Optional[List[Any]] = None,\n <mask>     ) -> None:\n <mask>         \"\"\"\n <mask>         Initializer.\n <mask> \n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove         prefix: Optional[Text] = None,\n </s> add         prefix: Optional[str] = None, </s> remove         value: Text,\n </s> add         value: str, </s> remove         name: Optional[Text] = None,\n </s> add         name: Optional[str] = None, </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[str] = None,\n        name: Optional[str] = None, </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> remove     used_names: Optional[Set[Text]]\n </s> add     used_names: Optional[Set[str]]", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep replace keep keep replace keep keep keep", "code_tokens": " <mask>             self.fixers_applied = None\n <mask> \n <mask>     def __repr__(self) -> Text:\n <mask>         \"\"\"Return a canonical string representation.\"\"\"\n <mask>         assert self.type is not None\n <mask>         return \"%s(%s, %r)\" % (\n <mask>             self.__class__.__name__,\n <mask>             type_repr(self.type),\n <mask>             self.children,\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove         return \"%s(%s, %r)\" % (\n </s> add         return \"{}({}, {!r})\".format( </s> remove     def __repr__(self) -> Text:\n </s> add     def __repr__(self) -> str: </s> remove     def __str__(self) -> Text:\n </s> add     def __str__(self) -> str: </s> remove         return \"%s(%s)\" % (self.__class__.__name__, \", \".join(map(repr, args)))\n </s> add         return \"{}({})\".format(self.__class__.__name__, \", \".join(map(repr, args))) </s> remove def evalString(s: Text) -> Text:\n </s> add def evalString(s: str) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             type_repr(self.type),\n <mask>             self.children,\n <mask>         )\n <mask> \n <mask>     def __str__(self) -> Text:\n <mask>         \"\"\"\n <mask>         Return a pretty string representation.\n <mask> \n <mask>         This reproduces the input source exactly.\n <mask>         \"\"\"\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def __str__(self) -> Text:\n </s> add     def __str__(self) -> str: </s> remove     def get_suffix(self) -> Text:\n </s> add     def get_suffix(self) -> str: </s> remove         return \"%s(%s, %r)\" % (\n </s> add         return \"{}({}, {!r})\".format( </s> remove     def __repr__(self) -> Text:\n </s> add     def __repr__(self) -> str: </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove def untokenize(iterable: Iterable[TokenInfo]) -> Text:\n </s> add def untokenize(iterable: Iterable[TokenInfo]) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         for child in self.children:\n <mask>             yield from child.pre_order()\n <mask> \n <mask>     @property\n <mask>     def prefix(self) -> Text:\n <mask>         \"\"\"\n <mask>         The whitespace and comments preceding this node in the input.\n <mask>         \"\"\"\n <mask>         if not self.children:\n <mask>             return \"\"\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove     def prefix(self, prefix: Text) -> None:\n </s> add     def prefix(self, prefix: str) -> None: </s> remove     used_names: Optional[Set[Text]]\n </s> add     used_names: Optional[Set[str]] </s> remove import copy\n </s> add  </s> remove     def get_suffix(self) -> Text:\n </s> add     def get_suffix(self) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return \"\"\n <mask>         return self.children[0].prefix\n <mask> \n <mask>     @prefix.setter\n <mask>     def prefix(self, prefix: Text) -> None:\n <mask>         if self.children:\n <mask>             self.children[0].prefix = prefix\n <mask> \n <mask>     def set_child(self, i: int, child: NL) -> None:\n <mask>         \"\"\"\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def prefix(self, prefix: Text) -> None:\n </s> add     def prefix(self, prefix: str) -> None: </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]:\n </s> add     def _partially_consume_prefix(self, prefix: str, column: int) -> Tuple[str, str]: </s> remove         prefix: Optional[Text] = None,\n </s> add         prefix: Optional[str] = None, </s> remove     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None:\n </s> add     def shift(self, type: int, value: str, newstate: int, context: Context) -> None: </s> remove         prefix: Optional[Text] = None,\n </s> add         prefix: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace keep keep keep", "code_tokens": " <mask>     \"\"\"Concrete implementation for leaf nodes.\"\"\"\n <mask> \n <mask>     # Default values for instance variables\n <mask>     value: Text\n <mask>     fixers_applied: List[Any]\n <mask>     bracket_depth: int\n <mask>     # Changed later in brackets.py\n <mask>     opening_bracket: Optional[\"Leaf\"] = None\n <mask>     used_names: Optional[Set[Text]]\n <mask>     _prefix = \"\"  # Whitespace and comments preceding this token in the input\n <mask>     lineno: int = 0  # Line where this token starts in the input\n <mask>     column: int = 0  # Column where this token starts in the input\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove     used_names: Optional[Set[Text]]\n </s> add     used_names: Optional[Set[str]] </s> remove     def addtoken(self, type: int, value: Text, context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: str, context: Context) -> bool: </s> remove     def make_label(self, c: PgenGrammar, label: Text) -> int:\n </s> add     def make_label(self, c: PgenGrammar, label: str) -> int:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace keep keep", "code_tokens": " <mask> \n <mask>     def __init__(\n <mask>         self,\n <mask>         type: int,\n <mask>         value: Text,\n <mask>         context: Optional[Context] = None,\n <mask>         prefix: Optional[Text] = None,\n <mask>         fixers_applied: List[Any] = [],\n <mask>         opening_bracket: Optional[\"Leaf\"] = None,\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove         prefix: Optional[Text] = None,\n </s> add         prefix: Optional[str] = None, </s> remove         content: Optional[Text] = None,\n </s> add         content: Optional[str] = None, </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[str] = None,\n        name: Optional[str] = None, </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> remove         name: Optional[Text] = None,\n </s> add         name: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Return a canonical string representation.\"\"\"\n <mask>         from .pgen2.token import tok_name\n <mask> \n <mask>         assert self.type is not None\n <mask>         return \"%s(%s, %r)\" % (\n <mask>             self.__class__.__name__,\n <mask>             tok_name.get(self.type, self.type),\n <mask>             self.value,\n <mask>         )\n <mask> \n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove         return \"%s(%s, %r)\" % (\n </s> add         return \"{}({}, {!r})\".format( </s> remove     def __repr__(self) -> Text:\n </s> add     def __repr__(self) -> str: </s> remove     def __str__(self) -> Text:\n </s> add     def __str__(self) -> str: </s> remove     def __repr__(self) -> Text:\n </s> add     def __repr__(self) -> str: </s> remove         return \"%s(%s)\" % (self.__class__.__name__, \", \".join(map(repr, args)))\n </s> add         return \"{}({})\".format(self.__class__.__name__, \", \".join(map(repr, args))) </s> remove @lru_cache()\n </s> add @lru_cache", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             tok_name.get(self.type, self.type),\n <mask>             self.value,\n <mask>         )\n <mask> \n <mask>     def __str__(self) -> Text:\n <mask>         \"\"\"\n <mask>         Return a pretty string representation.\n <mask> \n <mask>         This reproduces the input source exactly.\n <mask>         \"\"\"\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def __str__(self) -> Text:\n </s> add     def __str__(self) -> str: </s> remove     def get_suffix(self) -> Text:\n </s> add     def get_suffix(self) -> str: </s> remove         return \"%s(%s, %r)\" % (\n </s> add         return \"{}({}, {!r})\".format( </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove def untokenize(iterable: Iterable[TokenInfo]) -> Text:\n </s> add def untokenize(iterable: Iterable[TokenInfo]) -> str: </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Return a pre-order iterator for the tree.\"\"\"\n <mask>         yield self\n <mask> \n <mask>     @property\n <mask>     def prefix(self) -> Text:\n <mask>         \"\"\"\n <mask>         The whitespace and comments preceding this token in the input.\n <mask>         \"\"\"\n <mask>         return self._prefix\n <mask> \n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove     used_names: Optional[Set[Text]]\n </s> add     used_names: Optional[Set[str]] </s> remove     def __str__(self) -> Text:\n </s> add     def __str__(self) -> str: </s> remove     def __str__(self) -> Text:\n </s> add     def __str__(self) -> str: </s> remove     def prefix(self, prefix: Text) -> None:\n </s> add     def prefix(self, prefix: str) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         return self._prefix\n <mask> \n <mask>     @prefix.setter\n <mask>     def prefix(self, prefix: Text) -> None:\n <mask>         self.changed()\n <mask>         self._prefix = prefix\n <mask> \n <mask> \n <mask> def convert(gr: Grammar, raw_node: RawNode) -> NL:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def prefix(self, prefix: Text) -> None:\n </s> add     def prefix(self, prefix: str) -> None: </s> remove     def prefix(self) -> Text:\n </s> add     def prefix(self) -> str: </s> remove     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]:\n </s> add     def _partially_consume_prefix(self, prefix: str, column: int) -> Tuple[str, str]: </s> remove     def parse_stream_raw(self, stream: IO[Text], debug: bool = False) -> NL:\n </s> add     def parse_stream_raw(self, stream: IO[str], debug: bool = False) -> NL: </s> remove class Driver(object):\n </s> add class Driver: </s> remove     def parse_stream(self, stream: IO[Text], debug: bool = False) -> NL:\n </s> add     def parse_stream(self, stream: IO[str], debug: bool = False) -> NL:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     else:\n <mask>         return Leaf(type, value or \"\", context=context)\n <mask> \n <mask> \n <mask> _Results = Dict[Text, NL]\n <mask> \n <mask> \n <mask> class BasePattern(object):\n <mask> \n <mask>     \"\"\"\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove class BasePattern(object):\n </s> add class BasePattern: </s> remove Results = Dict[Text, NL]\n </s> add Results = Dict[str, NL] </s> remove class Parser(object):\n </s> add class Parser: </s> remove class Driver(object):\n </s> add class Driver: </s> remove     def expect(self, type: int, value: Optional[Any] = None) -> Text:\n </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str: </s> remove class Symbols(object):\n </s> add class Symbols:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> _Results = Dict[Text, NL]\n <mask> \n <mask> \n <mask> class BasePattern(object):\n <mask> \n <mask>     \"\"\"\n <mask>     A pattern is a tree matching pattern.\n <mask> \n <mask>     It looks for a specific node type (token or symbol), and\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove _Results = Dict[Text, NL]\n </s> add _Results = Dict[str, NL] </s> remove     name: Optional[Text] = None  # Optional name used to store match in results dict\n </s> add     name: Optional[str] = None  # Optional name used to store match in results dict </s> remove Results = Dict[Text, NL]\n </s> add Results = Dict[str, NL] </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[str] = None,\n        name: Optional[str] = None, </s> remove class Base(object):\n </s> add class Base: </s> remove     def expect(self, type: int, value: Optional[Any] = None) -> Text:\n </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     # Defaults for instance variables\n <mask>     type: Optional[int]\n <mask>     type = None  # Node type (token if < 256, symbol if >= 256)\n <mask>     content: Any = None  # Optional content matching pattern\n <mask>     name: Optional[Text] = None  # Optional name used to store match in results dict\n <mask> \n <mask>     def __new__(cls, *args, **kwds):\n <mask>         \"\"\"Constructor that prevents BasePattern from being instantiated.\"\"\"\n <mask>         assert cls is not BasePattern, \"Cannot instantiate BasePattern\"\n <mask>         return object.__new__(cls)\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def __repr__(self) -> Text:\n </s> add     def __repr__(self) -> str: </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> remove     def calcfirst(self, name: Text) -> None:\n </s> add     def calcfirst(self, name: str) -> None: </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[str] = None,\n        name: Optional[str] = None, </s> remove     value: Text\n </s> add     value: str </s> remove class BasePattern(object):\n </s> add class BasePattern:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace keep keep", "code_tokens": " <mask>         return object.__new__(cls)\n <mask> \n <mask>     def __repr__(self) -> Text:\n <mask>         assert self.type is not None\n <mask>         args = [type_repr(self.type), self.content, self.name]\n <mask>         while args and args[-1] is None:\n <mask>             del args[-1]\n <mask>         return \"%s(%s)\" % (self.__class__.__name__, \", \".join(map(repr, args)))\n <mask> \n <mask>     def _submatch(self, node, results=None) -> bool:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def __repr__(self) -> Text:\n </s> add     def __repr__(self) -> str: </s> remove         return \"%s(%s, %r)\" % (\n </s> add         return \"{}({}, {!r})\".format( </s> remove     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: str, context: Context) -> bool: </s> remove     def parse(self) -> Tuple[Dict[Text, List[\"DFAState\"]], Text]:\n </s> add     def parse(self) -> Tuple[Dict[str, List[\"DFAState\"]], str]: </s> remove def escape(m: Match[Text]) -> Text:\n </s> add def escape(m: Match[str]) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> class LeafPattern(BasePattern):\n <mask>     def __init__(\n <mask>         self,\n <mask>         type: Optional[int] = None,\n <mask>         content: Optional[Text] = None,\n <mask>         name: Optional[Text] = None,\n <mask>     ) -> None:\n <mask>         \"\"\"\n <mask>         Initializer.  Takes optional type, content, and name.\n <mask> \n <mask>         The type, if given must be a token type (< 256).  If not given,\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> remove         content: Optional[Text] = None,\n </s> add         content: Optional[str] = None, </s> remove         name: Optional[Text] = None,\n </s> add         name: Optional[str] = None, </s> remove         prefix: Optional[Text] = None,\n </s> add         prefix: Optional[str] = None, </s> remove         prefix: Optional[Text] = None,\n </s> add         prefix: Optional[str] = None, </s> remove         value: Text,\n </s> add         value: str,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def __init__(\n <mask>         self,\n <mask>         type: Optional[int] = None,\n <mask>         content: Optional[Iterable[Text]] = None,\n <mask>         name: Optional[Text] = None,\n <mask>     ) -> None:\n <mask>         \"\"\"\n <mask>         Initializer.  Takes optional type, content, and name.\n <mask> \n <mask>         The type, if given, must be a symbol type (>= 256).  If the\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[str] = None,\n        name: Optional[str] = None, </s> remove         content: Optional[Text] = None,\n </s> add         content: Optional[str] = None, </s> remove         name: Optional[Text] = None,\n </s> add         name: Optional[str] = None, </s> remove         prefix: Optional[Text] = None,\n </s> add         prefix: Optional[str] = None, </s> remove         prefix: Optional[Text] = None,\n </s> add         prefix: Optional[str] = None, </s> remove         value: Text,\n </s> add         value: str,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep replace keep keep replace keep", "code_tokens": " <mask>         self,\n <mask>         content: Optional[Text] = None,\n <mask>         min: int = 0,\n <mask>         max: int = HUGE,\n <mask>         name: Optional[Text] = None,\n <mask>     ) -> None:\n </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[str] = None,\n        name: Optional[str] = None, </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None,\n </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> remove         prefix: Optional[Text] = None,\n </s> add         prefix: Optional[str] = None, </s> remove         prefix: Optional[Text] = None,\n </s> add         prefix: Optional[str] = None, </s> remove         value: Text,\n </s> add         value: str,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep replace keep keep keep replace keep keep keep", "code_tokens": " <mask>         python-version: [3.7]\n <mask>         os: [ubuntu-16.04, windows-2019]\n <mask>         include:\n <mask>           - os: windows-2019\n <mask>             pathsep: \";\"\n <mask>             executable_suffix: \".exe\"\n <mask>             executable_mime: \"application/vnd.microsoft.portable-executable\"\n <mask>           - os: ubuntu-16.04\n <mask>             pathsep: \":\"\n </s> Build macOS releases (#2198)\n\n* Add macOS release target\r\n* Update ubuntu runner\r\n\r\nUbuntu 16.04 runner environment is deprecated\r\nhttps://github.blog/changelog/2021-04-29-github-actions-ubuntu-16-04-lts-virtual-environment-will-be-removed-on-september-20-2021/ </s> remove           - os: ubuntu-16.04\n </s> add           - os: ubuntu-20.04 </s> remove             executable_suffix: \".elf\"\n </s> add             asset_name: black_linux </s> add           - os: macos-latest\n            pathsep: \":\"\n            asset_name: black_macos\n            executable_mime: \"application/x-mach-binary\" </s> remove           python -m PyInstaller -F --name black${{ matrix.executable_suffix }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py\n </s> add           python -m PyInstaller -F --name ${{ matrix.asset_name }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py </s> remove           asset_path: dist/black${{ matrix.executable_suffix }}\n          asset_name: black${{ matrix.executable_suffix }}\n </s> add           asset_path: dist/${{ matrix.asset_name }}\n          asset_name: ${{ matrix.asset_name }}", "html_url": "https://github.com/psf/black/commit/0b9b7dbdab8c14bb8c33165583e3b540046944e7", "file_name": ".github/workflows/upload_binary.yml"}
{"docstring_tokens": "keep replace keep replace keep", "code_tokens": " <mask>             executable_mime: \"application/vnd.microsoft.portable-executable\"\n <mask>           - os: ubuntu-16.04\n <mask>             pathsep: \":\"\n <mask>             executable_suffix: \".elf\"\n <mask>             executable_mime: \"application/x-executable\"\n </s> Build macOS releases (#2198)\n\n* Add macOS release target\r\n* Update ubuntu runner\r\n\r\nUbuntu 16.04 runner environment is deprecated\r\nhttps://github.blog/changelog/2021-04-29-github-actions-ubuntu-16-04-lts-virtual-environment-will-be-removed-on-september-20-2021/ </s> remove             executable_suffix: \".exe\"\n </s> add             asset_name: black_windows.exe </s> add           - os: macos-latest\n            pathsep: \":\"\n            asset_name: black_macos\n            executable_mime: \"application/x-mach-binary\" </s> remove         os: [ubuntu-16.04, windows-2019]\n </s> add         os: [windows-2019, ubuntu-20.04, macos-latest] </s> remove           python -m PyInstaller -F --name black${{ matrix.executable_suffix }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py\n </s> add           python -m PyInstaller -F --name ${{ matrix.asset_name }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py </s> remove           asset_path: dist/black${{ matrix.executable_suffix }}\n          asset_name: black${{ matrix.executable_suffix }}\n </s> add           asset_path: dist/${{ matrix.asset_name }}\n          asset_name: ${{ matrix.asset_name }}", "html_url": "https://github.com/psf/black/commit/0b9b7dbdab8c14bb8c33165583e3b540046944e7", "file_name": ".github/workflows/upload_binary.yml"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>             pathsep: \":\"\n <mask>             asset_name: black_linux\n <mask>             executable_mime: \"application/x-executable\"\n <mask> \n <mask>     steps:\n <mask>       - uses: actions/checkout@v2\n <mask> \n </s> Build macOS releases (#2198)\n\n* Add macOS release target\r\n* Update ubuntu runner\r\n\r\nUbuntu 16.04 runner environment is deprecated\r\nhttps://github.blog/changelog/2021-04-29-github-actions-ubuntu-16-04-lts-virtual-environment-will-be-removed-on-september-20-2021/ </s> remove             executable_suffix: \".elf\"\n </s> add             asset_name: black_linux </s> remove           - os: ubuntu-16.04\n </s> add           - os: ubuntu-20.04 </s> remove             executable_suffix: \".exe\"\n </s> add             asset_name: black_windows.exe </s> remove         os: [ubuntu-16.04, windows-2019]\n </s> add         os: [windows-2019, ubuntu-20.04, macos-latest] </s> remove           python -m PyInstaller -F --name black${{ matrix.executable_suffix }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py\n </s> add           python -m PyInstaller -F --name ${{ matrix.asset_name }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py </s> remove           asset_path: dist/black${{ matrix.executable_suffix }}\n          asset_name: black${{ matrix.executable_suffix }}\n </s> add           asset_path: dist/${{ matrix.asset_name }}\n          asset_name: ${{ matrix.asset_name }}", "html_url": "https://github.com/psf/black/commit/0b9b7dbdab8c14bb8c33165583e3b540046944e7", "file_name": ".github/workflows/upload_binary.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>           python -m pip install pyinstaller\n <mask> \n <mask>       - name: Build binary\n <mask>         run: |\n <mask>           python -m PyInstaller -F --name black${{ matrix.executable_suffix }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py\n <mask> \n <mask>       - name: Upload binary as release asset\n <mask>         uses: actions/upload-release-asset@v1\n <mask>         env:\n <mask>           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n </s> Build macOS releases (#2198)\n\n* Add macOS release target\r\n* Update ubuntu runner\r\n\r\nUbuntu 16.04 runner environment is deprecated\r\nhttps://github.blog/changelog/2021-04-29-github-actions-ubuntu-16-04-lts-virtual-environment-will-be-removed-on-september-20-2021/ </s> remove           asset_path: dist/black${{ matrix.executable_suffix }}\n          asset_name: black${{ matrix.executable_suffix }}\n </s> add           asset_path: dist/${{ matrix.asset_name }}\n          asset_name: ${{ matrix.asset_name }} </s> add           - os: macos-latest\n            pathsep: \":\"\n            asset_name: black_macos\n            executable_mime: \"application/x-mach-binary\" </s> remove             executable_suffix: \".elf\"\n </s> add             asset_name: black_linux </s> remove           - os: ubuntu-16.04\n </s> add           - os: ubuntu-20.04 </s> remove             executable_suffix: \".exe\"\n </s> add             asset_name: black_windows.exe </s> remove         os: [ubuntu-16.04, windows-2019]\n </s> add         os: [windows-2019, ubuntu-20.04, macos-latest]", "html_url": "https://github.com/psf/black/commit/0b9b7dbdab8c14bb8c33165583e3b540046944e7", "file_name": ".github/workflows/upload_binary.yml"}
{"docstring_tokens": "keep keep keep keep replace replace keep", "code_tokens": " <mask>         env:\n <mask>           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n <mask>         with:\n <mask>           upload_url: ${{ github.event.release.upload_url }}\n <mask>           asset_path: dist/black${{ matrix.executable_suffix }}\n <mask>           asset_name: black${{ matrix.executable_suffix }}\n <mask>           asset_content_type: ${{ matrix.executable_mime }}\n </s> Build macOS releases (#2198)\n\n* Add macOS release target\r\n* Update ubuntu runner\r\n\r\nUbuntu 16.04 runner environment is deprecated\r\nhttps://github.blog/changelog/2021-04-29-github-actions-ubuntu-16-04-lts-virtual-environment-will-be-removed-on-september-20-2021/ </s> remove           python -m PyInstaller -F --name black${{ matrix.executable_suffix }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py\n </s> add           python -m PyInstaller -F --name ${{ matrix.asset_name }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py </s> add           - os: macos-latest\n            pathsep: \":\"\n            asset_name: black_macos\n            executable_mime: \"application/x-mach-binary\" </s> remove             executable_suffix: \".elf\"\n </s> add             asset_name: black_linux </s> remove             executable_suffix: \".exe\"\n </s> add             asset_name: black_windows.exe </s> remove           - os: ubuntu-16.04\n </s> add           - os: ubuntu-20.04 </s> remove         os: [ubuntu-16.04, windows-2019]\n </s> add         os: [windows-2019, ubuntu-20.04, macos-latest]", "html_url": "https://github.com/psf/black/commit/0b9b7dbdab8c14bb8c33165583e3b540046944e7", "file_name": ".github/workflows/upload_binary.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 if leaf.bracket_depth <= depth_limit:\n <mask>                     return True\n <mask>         return False\n <mask> \n <mask>     def contains_inner_type_comments(self) -> bool:\n <mask>         ignored_ids = set()\n <mask>         try:\n <mask>             last_leaf = self.leaves[-1]\n <mask>             ignored_ids.add(id(last_leaf))\n <mask>             if last_leaf.type == token.COMMA or (\n </s> Don't allow type comments to be merged behind regular comments (#1027)\n\nType comments only apply if they are the first comment on the line,\r\nwhich means that allowing them to be pushed behind a regular comment\r\nwhen joining lines is a semantic change (and, indeed, one that black\r\ncatches and fails on). </s> remove                     return True\n </s> add                     if leaf_id not in ignored_ids or comment_seen:\n                        return True\n\n            comment_seen = True </s> remove         not line.contains_inner_type_comments()\n </s> add         not line.contains_uncollapsable_type_comments() </s> remove             if leaf_id in ignored_ids:\n                continue\n\n </s> add  </s> add         # A type comment is uncollapsable if it is attached to a leaf\n        # that isn't at the end of the line (since that could cause it\n        # to get associated to a different argument) or if there are\n        # comments before it (since that could cause it to get hidden\n        # behind a comment.\n        comment_seen = False </s> add def f(\n    x,  # not a type comment\n    y,  # type: int\n):\n    # type: (...) -> None\n    pass\n\n\ndef f(\n    x,  # not a type comment\n):  # type: (int) -> None\n    pass\n\n", "html_url": "https://github.com/psf/black/commit/0c44220e216f6d253087f96341110c693d3ef2d4", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         except IndexError:\n <mask>             return False\n <mask> \n <mask>         for leaf_id, comments in self.comments.items():\n <mask>             for comment in comments:\n <mask>                 if is_type_comment(comment):\n <mask>                     if leaf_id not in ignored_ids or comment_seen:\n <mask>                         return True\n <mask> \n </s> Don't allow type comments to be merged behind regular comments (#1027)\n\nType comments only apply if they are the first comment on the line,\r\nwhich means that allowing them to be pushed behind a regular comment\r\nwhen joining lines is a semantic change (and, indeed, one that black\r\ncatches and fails on). </s> remove             if leaf_id in ignored_ids:\n                continue\n\n </s> add  </s> remove                     return True\n </s> add                     if leaf_id not in ignored_ids or comment_seen:\n                        return True\n\n            comment_seen = True </s> remove     def contains_inner_type_comments(self) -> bool:\n </s> add     def contains_uncollapsable_type_comments(self) -> bool: </s> remove         not line.contains_inner_type_comments()\n </s> add         not line.contains_uncollapsable_type_comments() </s> add def f(\n    x,  # not a type comment\n    y,  # type: int\n):\n    # type: (...) -> None\n    pass\n\n\ndef f(\n    x,  # not a type comment\n):  # type: (int) -> None\n    pass\n\n", "html_url": "https://github.com/psf/black/commit/0c44220e216f6d253087f96341110c693d3ef2d4", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep keep replace keep", "code_tokens": " <mask>             return False\n <mask> \n <mask>         for leaf_id, comments in self.comments.items():\n <mask>             if leaf_id in ignored_ids:\n <mask>                 continue\n <mask> \n <mask>             for comment in comments:\n <mask>                 if is_type_comment(comment):\n <mask>                     return True\n <mask> \n </s> Don't allow type comments to be merged behind regular comments (#1027)\n\nType comments only apply if they are the first comment on the line,\r\nwhich means that allowing them to be pushed behind a regular comment\r\nwhen joining lines is a semantic change (and, indeed, one that black\r\ncatches and fails on). </s> add         # A type comment is uncollapsable if it is attached to a leaf\n        # that isn't at the end of the line (since that could cause it\n        # to get associated to a different argument) or if there are\n        # comments before it (since that could cause it to get hidden\n        # behind a comment.\n        comment_seen = False </s> remove     def contains_inner_type_comments(self) -> bool:\n </s> add     def contains_uncollapsable_type_comments(self) -> bool: </s> remove         not line.contains_inner_type_comments()\n </s> add         not line.contains_uncollapsable_type_comments() </s> add def f(\n    x,  # not a type comment\n    y,  # type: int\n):\n    # type: (...) -> None\n    pass\n\n\ndef f(\n    x,  # not a type comment\n):  # type: (int) -> None\n    pass\n\n", "html_url": "https://github.com/psf/black/commit/0c44220e216f6d253087f96341110c693d3ef2d4", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     line_str = str(line).strip(\"\\n\")\n <mask> \n <mask>     if (\n <mask>         not line.contains_inner_type_comments()\n <mask>         and not line.should_explode\n <mask>         and is_line_short_enough(line, line_length=line_length, line_str=line_str)\n <mask>     ):\n <mask>         yield line\n <mask>         return\n </s> Don't allow type comments to be merged behind regular comments (#1027)\n\nType comments only apply if they are the first comment on the line,\r\nwhich means that allowing them to be pushed behind a regular comment\r\nwhen joining lines is a semantic change (and, indeed, one that black\r\ncatches and fails on). </s> remove     def contains_inner_type_comments(self) -> bool:\n </s> add     def contains_uncollapsable_type_comments(self) -> bool: </s> add def f(\n    x,  # not a type comment\n    y,  # type: int\n):\n    # type: (...) -> None\n    pass\n\n\ndef f(\n    x,  # not a type comment\n):  # type: (int) -> None\n    pass\n\n </s> remove                     return True\n </s> add                     if leaf_id not in ignored_ids or comment_seen:\n                        return True\n\n            comment_seen = True </s> add         # A type comment is uncollapsable if it is attached to a leaf\n        # that isn't at the end of the line (since that could cause it\n        # to get associated to a different argument) or if there are\n        # comments before it (since that could cause it to get hidden\n        # behind a comment.\n        comment_seen = False </s> remove             if leaf_id in ignored_ids:\n                continue\n\n </s> add ", "html_url": "https://github.com/psf/black/commit/0c44220e216f6d253087f96341110c693d3ef2d4", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def func(\n <mask>     a=some_list[0],  # type: int\n <mask> ):  # type: () -> int\n <mask>     c = call(\n <mask>         0.0123,\n <mask>         0.0456,\n </s> Don't allow type comments to be merged behind regular comments (#1027)\n\nType comments only apply if they are the first comment on the line,\r\nwhich means that allowing them to be pushed behind a regular comment\r\nwhen joining lines is a semantic change (and, indeed, one that black\r\ncatches and fails on). </s> add         # A type comment is uncollapsable if it is attached to a leaf\n        # that isn't at the end of the line (since that could cause it\n        # to get associated to a different argument) or if there are\n        # comments before it (since that could cause it to get hidden\n        # behind a comment.\n        comment_seen = False </s> remove         not line.contains_inner_type_comments()\n </s> add         not line.contains_uncollapsable_type_comments() </s> remove     def contains_inner_type_comments(self) -> bool:\n </s> add     def contains_uncollapsable_type_comments(self) -> bool: </s> remove                     return True\n </s> add                     if leaf_id not in ignored_ids or comment_seen:\n                        return True\n\n            comment_seen = True </s> remove             if leaf_id in ignored_ids:\n                continue\n\n </s> add ", "html_url": "https://github.com/psf/black/commit/0c44220e216f6d253087f96341110c693d3ef2d4", "file_name": "tests/data/comments6.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     Note: this usually looks weird, only use this for function definitions.\n <mask>     Prefer RHS otherwise.  This is why this function is not symmetrical with\n <mask>     :func:`right_hand_split` which also handles optional parentheses.\n <mask>     \"\"\"\n <mask>     head = Line(depth=line.depth)\n <mask>     body = Line(depth=line.depth + 1, inside_brackets=True)\n <mask>     tail = Line(depth=line.depth)\n <mask>     tail_leaves: List[Leaf] = []\n <mask>     body_leaves: List[Leaf] = []\n <mask>     head_leaves: List[Leaf] = []\n <mask>     current_leaves = head_leaves\n <mask>     matching_bracket = None\n </s> Refactor left_hand_split and right_hand_split to deduplicate line building logic </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth)\n </s> add  </s> remove     # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True)\n </s> add     head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove def right_hand_split(  # noqa C901\n </s> add def right_hand_split( </s> remove     if line.is_import and len(body_leaves) == 1:\n        body_leaves.append(Leaf(token.COMMA, \",\"))\n\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True)\n    assert opening_bracket and closing_bracket\n </s> add     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    if not head_leaves:\n        # No `head` means the split failed. Either `tail` has all content or\n </s> add     if not (opening_bracket and closing_bracket and head_leaves):\n        # If there is no opening or closing_bracket that means the split failed and\n        # all content is in the tail.  Otherwise, if `head_leaves` are empty, it means", "html_url": "https://github.com/psf/black/commit/0c5c5374313566dd9047c3e992a3c23a7ea4b8f2", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         if current_leaves is head_leaves:\n <mask>             if leaf.type in OPENING_BRACKETS:\n <mask>                 matching_bracket = leaf\n <mask>                 current_leaves = body_leaves\n <mask>     # Since body is a new indent level, remove spurious leading whitespace.\n <mask>     if body_leaves:\n <mask>         normalize_prefix(body_leaves[0], inside_brackets=True)\n <mask>     # Build the new lines.\n <mask>     for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n <mask>         for leaf in leaves:\n <mask>             result.append(leaf, preformatted=True)\n <mask>             for comment_after in line.comments_after(leaf):\n <mask>                 result.append(comment_after, preformatted=True)\n <mask>     bracket_split_succeeded_or_raise(head, body, tail)\n <mask>     for result in (head, body, tail):\n <mask>         if result:\n <mask>             yield result\n <mask> \n </s> Refactor left_hand_split and right_hand_split to deduplicate line building logic </s> remove     if line.is_import and len(body_leaves) == 1:\n        body_leaves.append(Leaf(token.COMMA, \",\"))\n\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True)\n    assert opening_bracket and closing_bracket\n </s> add     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    if not head_leaves:\n        # No `head` means the split failed. Either `tail` has all content or\n </s> add     if not (opening_bracket and closing_bracket and head_leaves):\n        # If there is no opening or closing_bracket that means the split failed and\n        # all content is in the tail.  Otherwise, if `head_leaves` are empty, it means </s> remove def right_hand_split(  # noqa C901\n </s> add def right_hand_split( </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth)\n </s> add  </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth)\n </s> add ", "html_url": "https://github.com/psf/black/commit/0c5c5374313566dd9047c3e992a3c23a7ea4b8f2", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if result:\n <mask>             yield result\n <mask> \n <mask> \n <mask> def right_hand_split(  # noqa C901\n <mask>     line: Line, line_length: int, py36: bool = False, omit: Collection[LeafID] = ()\n <mask> ) -> Iterator[Line]:\n <mask>     \"\"\"Split line into many lines, starting with the last matching bracket pair.\n <mask> \n <mask>     If the split was by optional parentheses, attempt splitting without them, too.\n </s> Refactor left_hand_split and right_hand_split to deduplicate line building logic </s> remove     # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True)\n </s> add     head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    if not head_leaves:\n        # No `head` means the split failed. Either `tail` has all content or\n </s> add     if not (opening_bracket and closing_bracket and head_leaves):\n        # If there is no opening or closing_bracket that means the split failed and\n        # all content is in the tail.  Otherwise, if `head_leaves` are empty, it means </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth)\n </s> add  </s> remove     if line.is_import and len(body_leaves) == 1:\n        body_leaves.append(Leaf(token.COMMA, \",\"))\n\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True)\n    assert opening_bracket and closing_bracket\n </s> add     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth)\n </s> add ", "html_url": "https://github.com/psf/black/commit/0c5c5374313566dd9047c3e992a3c23a7ea4b8f2", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     this split.\n <mask> \n <mask>     Note: running this function modifies `bracket_depth` on the leaves of `line`.\n <mask>     \"\"\"\n <mask>     head = Line(depth=line.depth)\n <mask>     body = Line(depth=line.depth + 1, inside_brackets=True)\n <mask>     tail = Line(depth=line.depth)\n <mask>     tail_leaves: List[Leaf] = []\n <mask>     body_leaves: List[Leaf] = []\n <mask>     head_leaves: List[Leaf] = []\n <mask>     current_leaves = tail_leaves\n <mask>     opening_bracket = None\n </s> Refactor left_hand_split and right_hand_split to deduplicate line building logic </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth)\n </s> add  </s> remove     # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True)\n </s> add     head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove     if line.is_import and len(body_leaves) == 1:\n        body_leaves.append(Leaf(token.COMMA, \",\"))\n\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True)\n    assert opening_bracket and closing_bracket\n </s> add     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    if not head_leaves:\n        # No `head` means the split failed. Either `tail` has all content or\n </s> add     if not (opening_bracket and closing_bracket and head_leaves):\n        # If there is no opening or closing_bracket that means the split failed and\n        # all content is in the tail.  Otherwise, if `head_leaves` are empty, it means </s> remove def right_hand_split(  # noqa C901\n </s> add def right_hand_split(", "html_url": "https://github.com/psf/black/commit/0c5c5374313566dd9047c3e992a3c23a7ea4b8f2", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace replace replace replace replace keep keep keep replace replace replace replace replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask>                 opening_bracket = leaf.opening_bracket\n <mask>                 closing_bracket = leaf\n <mask>                 current_leaves = body_leaves\n <mask>     tail_leaves.reverse()\n <mask>     body_leaves.reverse()\n <mask>     head_leaves.reverse()\n <mask>     # Since body is a new indent level, remove spurious leading whitespace.\n <mask>     if body_leaves:\n <mask>         normalize_prefix(body_leaves[0], inside_brackets=True)\n <mask>     if not head_leaves:\n <mask>         # No `head` means the split failed. Either `tail` has all content or\n <mask>         # the matching `opening_bracket` wasn't available on `line` anymore.\n <mask>         raise CannotSplit(\"No brackets found\")\n <mask> \n <mask>     if line.is_import and len(body_leaves) == 1:\n <mask>         body_leaves.append(Leaf(token.COMMA, \",\"))\n <mask> \n <mask>     # Build the new lines.\n <mask>     for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n <mask>         for leaf in leaves:\n <mask>             result.append(leaf, preformatted=True)\n <mask>             for comment_after in line.comments_after(leaf):\n <mask>                 result.append(comment_after, preformatted=True)\n <mask>     assert opening_bracket and closing_bracket\n <mask>     body.should_explode = should_explode(body, opening_bracket)\n <mask>     bracket_split_succeeded_or_raise(head, body, tail)\n <mask>     if (\n <mask>         # the body shouldn't be exploded\n </s> Refactor left_hand_split and right_hand_split to deduplicate line building logic </s> remove     # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True)\n </s> add     head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove def right_hand_split(  # noqa C901\n </s> add def right_hand_split( </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth)\n </s> add  </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth)\n </s> add ", "html_url": "https://github.com/psf/black/commit/0c5c5374313566dd9047c3e992a3c23a7ea4b8f2", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep", "code_tokens": " <mask> \n <mask> [flake8]\n <mask> ignore = E266, E501\n <mask> max-line-length = 80\n <mask> max-complexity = 12\n <mask> select = B,C,E,F,W,T4,B9\n </s> Add flake8 to CI, too </s> remove def whitespace(leaf: Leaf) -> str:\n </s> add def whitespace(leaf: Leaf) -> str:  # noqa C901 </s> add - if [[ $TRAVIS_PYTHON_VERSION == '3.6-dev' ]]; then flake8 black.py tests/test_black.py; fi </s> remove - pip install mypy\n </s> add - pip install flake8 flake8-bugbear mypy", "html_url": "https://github.com/psf/black/commit/0de0851a47cc36173028b52743caff0af0344278", "file_name": ".flake8"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> sudo: false\n <mask> language: python\n <mask> cache: pip\n <mask> before_script:\n <mask> - pip install mypy\n <mask> - pip install -e .\n <mask> script:\n <mask> - python setup.py test\n <mask> - if [[ $TRAVIS_PYTHON_VERSION == '3.6' ]]; then mypy black.py tests/test_black.py; fi\n <mask> notifications:\n </s> Add flake8 to CI, too </s> add - if [[ $TRAVIS_PYTHON_VERSION == '3.6-dev' ]]; then flake8 black.py tests/test_black.py; fi </s> remove def whitespace(leaf: Leaf) -> str:\n </s> add def whitespace(leaf: Leaf) -> str:  # noqa C901 </s> remove max-complexity = 12\n </s> add max-complexity = 15", "html_url": "https://github.com/psf/black/commit/0de0851a47cc36173028b52743caff0af0344278", "file_name": ".travis.yml"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> - pip install -e .\n <mask> script:\n <mask> - python setup.py test\n <mask> - if [[ $TRAVIS_PYTHON_VERSION == '3.6' ]]; then mypy black.py tests/test_black.py; fi\n <mask> notifications:\n <mask>   on_success: change\n <mask>   on_failure: always\n <mask> matrix:\n <mask>   include:\n <mask>     - python: 3.6\n </s> Add flake8 to CI, too </s> remove - pip install mypy\n </s> add - pip install flake8 flake8-bugbear mypy </s> remove def whitespace(leaf: Leaf) -> str:\n </s> add def whitespace(leaf: Leaf) -> str:  # noqa C901 </s> remove max-complexity = 12\n </s> add max-complexity = 15", "html_url": "https://github.com/psf/black/commit/0de0851a47cc36173028b52743caff0af0344278", "file_name": ".travis.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS\n <mask> ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, token.COLON, STANDALONE_COMMENT}\n <mask> \n <mask> \n <mask> def whitespace(leaf: Leaf) -> str:\n <mask>     \"\"\"Return whitespace prefix if needed for the given `leaf`.\"\"\"\n <mask>     NO = ''\n <mask>     SPACE = ' '\n <mask>     DOUBLESPACE = '  '\n <mask>     t = leaf.type\n </s> Add flake8 to CI, too </s> add - if [[ $TRAVIS_PYTHON_VERSION == '3.6-dev' ]]; then flake8 black.py tests/test_black.py; fi </s> remove - pip install mypy\n </s> add - pip install flake8 flake8-bugbear mypy </s> remove max-complexity = 12\n </s> add max-complexity = 15", "html_url": "https://github.com/psf/black/commit/0de0851a47cc36173028b52743caff0af0344278", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> from click.core import ParameterSource\n <mask> from mypy_extensions import mypyc_attr\n <mask> from pathspec.patterns.gitwildmatch import GitWildMatchPatternError\n <mask> \n <mask> from _black_version import version as __version__\n <mask> from black.cache import Cache, get_cache_info, read_cache, write_cache\n </s> Apply .gitignore correctly in every source entry (#3336)\n\nWhen passing multiple src directories, the root gitignore was only\r\napplied to the first processed source. The reason is that, in the\r\nfirst source, exclude is `None`, but then the value gets overridden by\r\n`re_compile_maybe_verbose(DEFAULT_EXCLUDES)`, so in the next iteration\r\nwhere the source is a directory, the condition is not met and sets the\r\nvalue of `gitignore` to `None`.\r\n\r\nTo fix this problem, we store a boolean indicating if `exclude` is\r\n`None` and set the value of `exclude` to its default value if that's\r\nthe case. This makes sure that the flow enters the correct condition on\r\nfollowing iterations and also keeps the original value if the condition\r\nis not met.\r\n\r\nAlso, the value of `gitignore` is initialized as `None` and overriden\r\nif necessary. The value of `root_gitignore` is always calculated to\r\navoid using additional variables (at the small cost of additional\r\ncomputations).\r\n\r\nSigned-off-by: Antonio Ossa Guerra <aaossa@uc.cl> </s> add     def test_gitignore_used_on_multiple_sources(self) -> None:\n        root = Path(DATA_DIR / \"gitignore_used_on_multiple_sources\")\n        expected = [\n            root / \"dir1\" / \"b.py\",\n            root / \"dir2\" / \"b.py\",\n        ]\n        ctx = FakeContext()\n        ctx.obj[\"root\"] = root\n        src = [root / \"dir1\", root / \"dir2\"]\n        assert_collected_sources(src, expected, ctx=ctx)\n </s> remove                 if gitignore != p_gitignore:\n                    gitignore += p_gitignore\n            else:\n                gitignore = None\n </s> add                 if root_gitignore == p_gitignore:\n                    gitignore = root_gitignore\n                else:\n                    gitignore = root_gitignore + p_gitignore </s> remove             if exclude is None:\n                exclude = re_compile_maybe_verbose(DEFAULT_EXCLUDES)\n                gitignore = get_gitignore(root)\n </s> add             if exclude_is_None: </s> add     exclude_is_None = exclude is None\n    exclude = re_compile_maybe_verbose(DEFAULT_EXCLUDES) if exclude is None else exclude\n    gitignore = None  # type: Optional[PathSpec]\n    root_gitignore = get_gitignore(root)\n", "html_url": "https://github.com/psf/black/commit/0e9d29ab73d608a79028e22a713ee717b5dcca96", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     \"\"\"Compute the set of files to be formatted.\"\"\"\n <mask>     sources: Set[Path] = set()\n <mask>     root = ctx.obj[\"root\"]\n <mask> \n <mask>     for s in src:\n <mask>         if s == \"-\" and stdin_filename:\n <mask>             p = Path(stdin_filename)\n <mask>             is_stdin = True\n </s> Apply .gitignore correctly in every source entry (#3336)\n\nWhen passing multiple src directories, the root gitignore was only\r\napplied to the first processed source. The reason is that, in the\r\nfirst source, exclude is `None`, but then the value gets overridden by\r\n`re_compile_maybe_verbose(DEFAULT_EXCLUDES)`, so in the next iteration\r\nwhere the source is a directory, the condition is not met and sets the\r\nvalue of `gitignore` to `None`.\r\n\r\nTo fix this problem, we store a boolean indicating if `exclude` is\r\n`None` and set the value of `exclude` to its default value if that's\r\nthe case. This makes sure that the flow enters the correct condition on\r\nfollowing iterations and also keeps the original value if the condition\r\nis not met.\r\n\r\nAlso, the value of `gitignore` is initialized as `None` and overriden\r\nif necessary. The value of `root_gitignore` is always calculated to\r\navoid using additional variables (at the small cost of additional\r\ncomputations).\r\n\r\nSigned-off-by: Antonio Ossa Guerra <aaossa@uc.cl> </s> remove                 if gitignore != p_gitignore:\n                    gitignore += p_gitignore\n            else:\n                gitignore = None\n </s> add                 if root_gitignore == p_gitignore:\n                    gitignore = root_gitignore\n                else:\n                    gitignore = root_gitignore + p_gitignore </s> add     def test_gitignore_used_on_multiple_sources(self) -> None:\n        root = Path(DATA_DIR / \"gitignore_used_on_multiple_sources\")\n        expected = [\n            root / \"dir1\" / \"b.py\",\n            root / \"dir2\" / \"b.py\",\n        ]\n        ctx = FakeContext()\n        ctx.obj[\"root\"] = root\n        src = [root / \"dir1\", root / \"dir2\"]\n        assert_collected_sources(src, expected, ctx=ctx)\n </s> remove             if exclude is None:\n                exclude = re_compile_maybe_verbose(DEFAULT_EXCLUDES)\n                gitignore = get_gitignore(root)\n </s> add             if exclude_is_None: </s> add from pathspec import PathSpec", "html_url": "https://github.com/psf/black/commit/0e9d29ab73d608a79028e22a713ee717b5dcca96", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep replace replace replace replace keep keep keep", "code_tokens": " <mask>                 continue\n <mask> \n <mask>             sources.add(p)\n <mask>         elif p.is_dir():\n <mask>             if exclude is None:\n <mask>                 exclude = re_compile_maybe_verbose(DEFAULT_EXCLUDES)\n <mask>                 gitignore = get_gitignore(root)\n <mask>                 p_gitignore = get_gitignore(p)\n <mask>                 # No need to use p's gitignore if it is identical to root's gitignore\n <mask>                 # (i.e. root and p point to the same directory).\n <mask>                 if gitignore != p_gitignore:\n <mask>                     gitignore += p_gitignore\n <mask>             else:\n <mask>                 gitignore = None\n <mask>             sources.update(\n <mask>                 gen_python_files(\n <mask>                     p.iterdir(),\n </s> Apply .gitignore correctly in every source entry (#3336)\n\nWhen passing multiple src directories, the root gitignore was only\r\napplied to the first processed source. The reason is that, in the\r\nfirst source, exclude is `None`, but then the value gets overridden by\r\n`re_compile_maybe_verbose(DEFAULT_EXCLUDES)`, so in the next iteration\r\nwhere the source is a directory, the condition is not met and sets the\r\nvalue of `gitignore` to `None`.\r\n\r\nTo fix this problem, we store a boolean indicating if `exclude` is\r\n`None` and set the value of `exclude` to its default value if that's\r\nthe case. This makes sure that the flow enters the correct condition on\r\nfollowing iterations and also keeps the original value if the condition\r\nis not met.\r\n\r\nAlso, the value of `gitignore` is initialized as `None` and overriden\r\nif necessary. The value of `root_gitignore` is always calculated to\r\navoid using additional variables (at the small cost of additional\r\ncomputations).\r\n\r\nSigned-off-by: Antonio Ossa Guerra <aaossa@uc.cl> </s> add     exclude_is_None = exclude is None\n    exclude = re_compile_maybe_verbose(DEFAULT_EXCLUDES) if exclude is None else exclude\n    gitignore = None  # type: Optional[PathSpec]\n    root_gitignore = get_gitignore(root)\n </s> add     def test_gitignore_used_on_multiple_sources(self) -> None:\n        root = Path(DATA_DIR / \"gitignore_used_on_multiple_sources\")\n        expected = [\n            root / \"dir1\" / \"b.py\",\n            root / \"dir2\" / \"b.py\",\n        ]\n        ctx = FakeContext()\n        ctx.obj[\"root\"] = root\n        src = [root / \"dir1\", root / \"dir2\"]\n        assert_collected_sources(src, expected, ctx=ctx)\n </s> add from pathspec import PathSpec", "html_url": "https://github.com/psf/black/commit/0e9d29ab73d608a79028e22a713ee717b5dcca96", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         assert_collected_sources(src, expected, ctx=ctx, extend_exclude=r\"/exclude/\")\n <mask> \n <mask>     @patch(\"black.find_project_root\", lambda *args: (THIS_DIR.resolve(), None))\n <mask>     def test_exclude_for_issue_1572(self) -> None:\n <mask>         # Exclude shouldn't touch files that were explicitly given to Black through the\n <mask>         # CLI. Exclude is supposed to only apply to the recursive discovery of files.\n </s> Apply .gitignore correctly in every source entry (#3336)\n\nWhen passing multiple src directories, the root gitignore was only\r\napplied to the first processed source. The reason is that, in the\r\nfirst source, exclude is `None`, but then the value gets overridden by\r\n`re_compile_maybe_verbose(DEFAULT_EXCLUDES)`, so in the next iteration\r\nwhere the source is a directory, the condition is not met and sets the\r\nvalue of `gitignore` to `None`.\r\n\r\nTo fix this problem, we store a boolean indicating if `exclude` is\r\n`None` and set the value of `exclude` to its default value if that's\r\nthe case. This makes sure that the flow enters the correct condition on\r\nfollowing iterations and also keeps the original value if the condition\r\nis not met.\r\n\r\nAlso, the value of `gitignore` is initialized as `None` and overriden\r\nif necessary. The value of `root_gitignore` is always calculated to\r\navoid using additional variables (at the small cost of additional\r\ncomputations).\r\n\r\nSigned-off-by: Antonio Ossa Guerra <aaossa@uc.cl> </s> remove             if exclude is None:\n                exclude = re_compile_maybe_verbose(DEFAULT_EXCLUDES)\n                gitignore = get_gitignore(root)\n </s> add             if exclude_is_None: </s> add     exclude_is_None = exclude is None\n    exclude = re_compile_maybe_verbose(DEFAULT_EXCLUDES) if exclude is None else exclude\n    gitignore = None  # type: Optional[PathSpec]\n    root_gitignore = get_gitignore(root)\n </s> remove                 if gitignore != p_gitignore:\n                    gitignore += p_gitignore\n            else:\n                gitignore = None\n </s> add                 if root_gitignore == p_gitignore:\n                    gitignore = root_gitignore\n                else:\n                    gitignore = root_gitignore + p_gitignore </s> add from pathspec import PathSpec", "html_url": "https://github.com/psf/black/commit/0e9d29ab73d608a79028e22a713ee717b5dcca96", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask>                 next_token_type, next_token_value, *_ = proxy.eat(counter)\n <mask>                 if next_token_type == tokenize.OP:\n <mask>                     next_token_type = grammar.opmap[next_token_value]\n <mask> \n <mask>                 recorder.add_token(next_token_type, next_token_value)\n <mask>                 counter += 1\n </s> Fix handling of standalone match/case with newlines/comments (#2760)\n\nResolves #2759 </s> remove         perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1\n </s> add         perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1, </s> remove         very_complex=True, perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1\n </s> add         very_complex=True,\n        perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1,", "html_url": "https://github.com/psf/black/commit/0f26a0369efc7305a1a0120355f78d85b3030e56", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         perhaps_even_loooooooooooooooooooooooooooooooooooooong=-   1\n <mask>     ): print(1)\n <mask>     case c(\n <mask>         very_complex=True,\n <mask>         perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1\n <mask>     ): print(2)\n <mask>     case a: pass\n <mask> \n <mask> # output\n <mask> \n </s> Fix handling of standalone match/case with newlines/comments (#2760)\n\nResolves #2759 </s> remove         very_complex=True, perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1\n </s> add         very_complex=True,\n        perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1, </s> add                 if next_token_type in (tokenize.COMMENT, tokenize.NL):\n                    counter += 1\n                    continue\n", "html_url": "https://github.com/psf/black/commit/0f26a0369efc7305a1a0120355f78d85b3030e56", "file_name": "tests/data/pattern_matching_style.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         very_complex=True, perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1\n <mask>     ):\n <mask>         print(1)\n <mask>     case c(\n <mask>         very_complex=True, perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1\n <mask>     ):\n <mask>         print(2)\n <mask>     case a:\n <mask>         pass\n </s> Fix handling of standalone match/case with newlines/comments (#2760)\n\nResolves #2759 </s> remove         perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1\n </s> add         perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1, </s> add                 if next_token_type in (tokenize.COMMENT, tokenize.NL):\n                    counter += 1\n                    continue\n", "html_url": "https://github.com/psf/black/commit/0f26a0369efc7305a1a0120355f78d85b3030e56", "file_name": "tests/data/pattern_matching_style.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from blib2to3 import pygram, pytree\n <mask> from blib2to3.pgen2 import driver, token\n <mask> from blib2to3.pgen2.parse import ParseError\n <mask> \n <mask> __version__ = \"18.4a3\"\n <mask> DEFAULT_LINE_LENGTH = 88\n <mask> \n <mask> # types\n <mask> syms = pygram.python_symbols\n <mask> FileContent = str\n </s> 18.4a4 hotfix: don't populate the cache on --check\n\nFixes #175 </s> remove             if write_back != WriteBack.DIFF and changed is not Changed.NO:\n </s> add             if write_back == WriteBack.YES and changed is not Changed.NO: </s> remove     if write_back != WriteBack.DIFF and formatted:\n </s> add     if write_back == WriteBack.YES and formatted:", "html_url": "https://github.com/psf/black/commit/0f3ecb7e500f9668a7f9ec74a43d8d565df6e2ea", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     src, line_length=line_length, fast=fast, write_back=write_back\n <mask>                 )\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>             if write_back != WriteBack.DIFF and changed is not Changed.NO:\n <mask>                 write_cache(cache, [src], line_length)\n <mask>         report.done(src, changed)\n <mask>     except Exception as exc:\n <mask>         report.failed(src, str(exc))\n <mask> \n </s> 18.4a4 hotfix: don't populate the cache on --check\n\nFixes #175 </s> remove     if write_back != WriteBack.DIFF and formatted:\n </s> add     if write_back == WriteBack.YES and formatted: </s> remove __version__ = \"18.4a3\"\n </s> add __version__ = \"18.4a4\"", "html_url": "https://github.com/psf/black/commit/0f3ecb7e500f9668a7f9ec74a43d8d565df6e2ea", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 report.done(src, Changed.YES if task.result() else Changed.NO)\n <mask> \n <mask>     if cancelled:\n <mask>         await asyncio.gather(*cancelled, loop=loop, return_exceptions=True)\n <mask>     if write_back != WriteBack.DIFF and formatted:\n <mask>         write_cache(cache, formatted, line_length)\n <mask> \n <mask> \n <mask> def format_file_in_place(\n <mask>     src: Path,\n </s> 18.4a4 hotfix: don't populate the cache on --check\n\nFixes #175 </s> remove             if write_back != WriteBack.DIFF and changed is not Changed.NO:\n </s> add             if write_back == WriteBack.YES and changed is not Changed.NO: </s> remove __version__ = \"18.4a3\"\n </s> add __version__ = \"18.4a4\"", "html_url": "https://github.com/psf/black/commit/0f3ecb7e500f9668a7f9ec74a43d8d565df6e2ea", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> # Legacy name, left for integrations.\n <mask> FileMode = Mode\n <mask> \n <mask> \n <mask> def read_pyproject_toml(\n <mask>     ctx: click.Context, param: click.Parameter, value: Optional[str]\n <mask> ) -> Optional[str]:\n <mask>     \"\"\"Inject Black configuration from \"pyproject.toml\" into defaults in `ctx`.\n </s> Add --workers CLI parameter (fixes #2513) (#2514)\n\nFixes #2513 </s> remove     worker_count = os.cpu_count()\n </s> add     worker_count = workers if workers is not None else DEFAULT_WORKERS </s> remove     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\"\n </s> add     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: Mode,\n    report: \"Report\",\n    workers: Optional[int], </s> add     workers: int, </s> add @click.option(\n    \"-W\",\n    \"--workers\",\n    type=click.IntRange(min=1),\n    default=DEFAULT_WORKERS,\n    show_default=True,\n    help=\"Number of parallel workers\",\n)", "html_url": "https://github.com/psf/black/commit/0fd353f1639c580c32599bf435902d08dbd9a560", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     ),\n <mask> )\n <mask> @click.option(\n <mask>     \"-q\",\n <mask>     \"--quiet\",\n <mask>     is_flag=True,\n </s> Add --workers CLI parameter (fixes #2513) (#2514)\n\nFixes #2513 </s> add     workers: int, </s> add DEFAULT_WORKERS = os.cpu_count()\n </s> remove     worker_count = os.cpu_count()\n </s> add     worker_count = workers if workers is not None else DEFAULT_WORKERS </s> remove     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\"\n </s> add     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: Mode,\n    report: \"Report\",\n    workers: Optional[int],", "html_url": "https://github.com/psf/black/commit/0fd353f1639c580c32599bf435902d08dbd9a560", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     force_exclude: Optional[Pattern],\n <mask>     stdin_filename: Optional[str],\n <mask>     src: Tuple[str, ...],\n <mask>     config: Optional[str],\n <mask> ) -> None:\n <mask>     \"\"\"The uncompromising code formatter.\"\"\"\n <mask>     if config and verbose:\n </s> Add --workers CLI parameter (fixes #2513) (#2514)\n\nFixes #2513 </s> remove     worker_count = os.cpu_count()\n </s> add     worker_count = workers if workers is not None else DEFAULT_WORKERS </s> remove     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\"\n </s> add     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: Mode,\n    report: \"Report\",\n    workers: Optional[int], </s> add DEFAULT_WORKERS = os.cpu_count()\n </s> add @click.option(\n    \"-W\",\n    \"--workers\",\n    type=click.IntRange(min=1),\n    default=DEFAULT_WORKERS,\n    show_default=True,\n    help=\"Number of parallel workers\",\n)", "html_url": "https://github.com/psf/black/commit/0fd353f1639c580c32599bf435902d08dbd9a560", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def reformat_many(\n <mask>     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\"\n <mask> ) -> None:\n <mask>     \"\"\"Reformat multiple files using a ProcessPoolExecutor.\"\"\"\n <mask>     executor: Executor\n <mask>     loop = asyncio.get_event_loop()\n <mask>     worker_count = os.cpu_count()\n <mask>     if sys.platform == \"win32\":\n <mask>         # Work around https://bugs.python.org/issue26903\n </s> Add --workers CLI parameter (fixes #2513) (#2514)\n\nFixes #2513 </s> add DEFAULT_WORKERS = os.cpu_count()\n </s> add     workers: int, </s> add @click.option(\n    \"-W\",\n    \"--workers\",\n    type=click.IntRange(min=1),\n    default=DEFAULT_WORKERS,\n    show_default=True,\n    help=\"Number of parallel workers\",\n)", "html_url": "https://github.com/psf/black/commit/0fd353f1639c580c32599bf435902d08dbd9a560", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         for line in f:\n <mask>             lineno += 1\n <mask>             mo = re.match(r\"^#define\\s+(\\w+)\\s+(\\d+)$\", line)\n <mask>             if not mo and line.strip():\n <mask>                 print(\"%s(%s): can't parse %s\" % (filename, lineno,\n <mask>                                                   line.strip()))\n <mask>             else:\n <mask>                 symbol, number = mo.groups()\n <mask>                 number = int(number)\n <mask>                 assert symbol not in self.symbol2number\n <mask>                 assert number not in self.number2symbol\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n            mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$',\n                          line)\n </s> add             lineno, line = lineno + 1, next(f)\n            mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$', line) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove     type = None    # int: token number (< 256) or symbol number (>= 256)\n </s> add     type = None  # int: token number (< 256) or symbol number (>= 256) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # The code below essentially uses f's iterator-ness!\n <mask>         lineno = 0\n <mask> \n <mask>         # Expect the two #include lines\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == '#include \"pgenheaders.h\"\\n', (lineno, line)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == '#include \"grammar.h\"\\n', (lineno, line)\n <mask> \n <mask>         # Parse the state definitions\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         # Expect the two #include lines\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == '#include \"pgenheaders.h\"\\n', (lineno, line)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == '#include \"grammar.h\"\\n', (lineno, line)\n <mask> \n <mask>         # Parse the state definitions\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         allarcs = {}\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace replace keep", "code_tokens": " <mask>         assert line == '#include \"grammar.h\"\\n', (lineno, line)\n <mask> \n <mask>         # Parse the state definitions\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         allarcs = {}\n <mask>         states = []\n <mask>         while line.startswith(\"static arc \"):\n <mask>             while line.startswith(\"static arc \"):\n <mask>                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\",\n <mask>                               line)\n <mask>                 assert mo, (lineno, line)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace", "code_tokens": " <mask>                 arcs = []\n <mask>                 for _ in range(k):\n <mask>                     lineno, line = lineno+1, next(f)\n <mask>                     mo = re.match(r\"\\s+{(\\d+), (\\d+)},$\", line)\n <mask>                     assert mo, (lineno, line)\n <mask>                     i, j = list(map(int, mo.groups()))\n <mask>                     arcs.append((i, j))\n <mask>                 lineno, line = lineno+1, next(f)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\",\n                              line)\n </s> add                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\", line) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     arcs.append((i, j))\n <mask>                 lineno, line = lineno+1, next(f)\n <mask>                 assert line == \"};\\n\", (lineno, line)\n <mask>                 allarcs[(n, m)] = arcs\n <mask>                 lineno, line = lineno+1, next(f)\n <mask>             mo = re.match(r\"static state states_(\\d+)\\[(\\d+)\\] = {$\", line)\n <mask>             assert mo, (lineno, line)\n <mask>             s, t = list(map(int, mo.groups()))\n <mask>             assert s == len(states), (lineno, line)\n <mask>             state = []\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove                     lineno, line = lineno+1, next(f)\n </s> add                     lineno, line = lineno + 1, next(f) </s> remove                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\",\n                              line)\n </s> add                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\", line) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             s, t = list(map(int, mo.groups()))\n <mask>             assert s == len(states), (lineno, line)\n <mask>             state = []\n <mask>             for _ in range(t):\n <mask>                 lineno, line = lineno+1, next(f)\n <mask>                 mo = re.match(r\"\\s+{(\\d+), arcs_(\\d+)_(\\d+)},$\", line)\n <mask>                 assert mo, (lineno, line)\n <mask>                 k, n, m = list(map(int, mo.groups()))\n <mask>                 arcs = allarcs[n, m]\n <mask>                 assert k == len(arcs), (lineno, line)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                     lineno, line = lineno+1, next(f)\n </s> add                     lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\",\n                              line)\n </s> add                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\", line) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep replace keep replace", "code_tokens": " <mask>                 state.append(arcs)\n <mask>             states.append(state)\n <mask>             lineno, line = lineno+1, next(f)\n <mask>             assert line == \"};\\n\", (lineno, line)\n <mask>             lineno, line = lineno+1, next(f)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         mo = re.match(r\"static dfa dfas\\[(\\d+)\\] = {$\", line)\n <mask>         assert mo, (lineno, line)\n <mask>         ndfas = int(mo.group(1))\n <mask>         for i in range(ndfas):\n <mask>             lineno, line = lineno+1, next(f)\n <mask>             mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$',\n <mask>                           line)\n <mask>             assert mo, (lineno, line)\n <mask>             symbol = mo.group(2)\n <mask>             number, x, y, z = list(map(int, mo.group(1, 3, 4, 5)))\n <mask>             assert self.symbol2number[symbol] == number, (lineno, line)\n <mask>             assert self.number2symbol[number] == symbol, (lineno, line)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             assert self.number2symbol[number] == symbol, (lineno, line)\n <mask>             assert x == 0, (lineno, line)\n <mask>             state = states[z]\n <mask>             assert y == len(state), (lineno, line)\n <mask>             lineno, line = lineno+1, next(f)\n <mask>             mo = re.match(r'\\s+(\"(?:\\\\\\d\\d\\d)*\")},$', line)\n <mask>             assert mo, (lineno, line)\n <mask>             first = {}\n <mask>             rawbitset = eval(mo.group(1))\n <mask>             for i, c in enumerate(rawbitset):\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n            mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$',\n                          line)\n </s> add             lineno, line = lineno + 1, next(f)\n            mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$', line) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep replace replace keep replace keep", "code_tokens": " <mask>                 for j in range(8):\n <mask>                     if byte & (1<<j):\n <mask>                         first[i*8 + j] = 1\n <mask>             dfas[number] = (state, first)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == \"};\\n\", (lineno, line)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace", "code_tokens": " <mask>         labels = []\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         mo = re.match(r\"static label labels\\[(\\d+)\\] = {$\", line)\n <mask>         assert mo, (lineno, line)\n <mask>         nlabels = int(mo.group(1))\n <mask>         for i in range(nlabels):\n <mask>             lineno, line = lineno+1, next(f)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>                 y = eval(y)\n <mask>             labels.append((x, y))\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == \"};\\n\", (lineno, line)\n <mask>         self.labels = labels\n <mask> \n <mask>         # Parse the grammar struct\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == \"grammar _PyParser_Grammar = {\\n\", (lineno, line)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         mo = re.match(r\"\\s+(\\d+),$\", line)\n <mask>         assert mo, (lineno, line)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace keep keep", "code_tokens": " <mask>         assert line == \"grammar _PyParser_Grammar = {\\n\", (lineno, line)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         mo = re.match(r\"\\s+(\\d+),$\", line)\n <mask>         assert mo, (lineno, line)\n <mask>         ndfas = int(mo.group(1))\n <mask>         assert ndfas == len(self.dfas)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == \"\\tdfas,\\n\", (lineno, line)\n <mask>         lineno, line = lineno+1, next(f)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         ndfas = int(mo.group(1))\n <mask>         assert ndfas == len(self.dfas)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == \"\\tdfas,\\n\", (lineno, line)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         mo = re.match(r\"\\s+{(\\d+), labels},$\", line)\n <mask>         assert mo, (lineno, line)\n <mask>         nlabels = int(mo.group(1))\n <mask>         assert nlabels == len(self.labels), (lineno, line)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         mo = re.match(r\"\\s+(\\d+)$\", line)\n <mask>         assert mo, (lineno, line)\n <mask>         start = int(mo.group(1))\n <mask>         assert start in self.number2symbol, (lineno, line)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace keep", "code_tokens": " <mask>         start = int(mo.group(1))\n <mask>         assert start in self.number2symbol, (lineno, line)\n <mask>         self.start = start\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == \"};\\n\", (lineno, line)\n <mask>         try:\n <mask>             lineno, line = lineno+1, next(f)\n <mask>         except StopIteration:\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             assert 0, (lineno, line)\n <mask> \n <mask>     def finish_off(self):\n <mask>         \"\"\"Create additional useful structures.  (Internal).\"\"\"\n <mask>         self.keywords = {} # map from keyword strings to arc labels\n <mask>         self.tokens = {}   # map from numeric token values to arc labels\n <mask>         for ilabel, (type, value) in enumerate(self.labels):\n <mask>             if type == token.NAME and value is not None:\n <mask>                 self.keywords[value] = ilabel\n <mask>             elif value is None:\n <mask>                 self.tokens[type] = ilabel\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         self.first = {} # map from symbol name to set of tokens\n </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove         self.arcs = {} # map from label to DFAState\n </s> add         self.arcs = {}  # map from label to DFAState </s> remove         self.gettoken() # Initialize lookahead\n </s> add         self.gettoken()  # Initialize lookahead </s> remove         self.used_names = set() # Aliased to self.rootnode.used_names in pop()\n </s> add         self.used_names = set()  # Aliased to self.rootnode.used_names in pop() </s> remove                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\",\n                              line)\n </s> add                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\", line) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> from . import grammar, parse, token, tokenize, pgen\n <mask> \n <mask> \n <mask> class Driver(object):\n <mask> \n <mask>     def __init__(\n <mask>         self,\n <mask>         grammar,\n <mask>         convert=None,\n <mask>         logger=None,\n <mask>     ):\n <mask>         self.grammar = grammar\n <mask>         if logger is None:\n <mask>             logger = logging.getLogger(__name__)\n <mask>         self.logger = logger\n <mask>         self.convert = convert\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove def load_grammar(gt=\"Grammar.txt\", gp=None,\n                 save=True, force=False, logger=None):\n </s> add def load_grammar(gt=\"Grammar.txt\", gp=None, save=True, force=False, logger=None): </s> remove _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__),\n                                     \"PatternGrammar.txt\")\n </s> add _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__), \"PatternGrammar.txt\") </s> remove __all__ = [x for x in dir(token) if x[0] != '_'] + [\"tokenize\",\n           \"generate_tokens\", \"untokenize\"]\n </s> add __all__ = [x for x in dir(token) if x[0] != \"_\"] + [\n    \"tokenize\",\n    \"generate_tokens\",\n    \"untokenize\",\n] </s> remove             if type(val) == int: _type_reprs[val] = name\n </s> add             if type(val) == int:\n                _type_reprs[val] = name </s> add class ParserGenerator(object): </s> remove class ParserGenerator(object):\n </s> add ", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 continue\n <mask>             if type == token.OP:\n <mask>                 type = grammar.opmap[value]\n <mask>             if debug:\n <mask>                 self.logger.debug(\"%s %r (prefix=%r)\",\n <mask>                                   token.tok_name[type], value, prefix)\n <mask>             if type == token.INDENT:\n <mask>                 indent_columns.append(len(value))\n <mask>                 _prefix = prefix + value\n <mask>                 prefix = \"\"\n <mask>                 value = \"\"\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             self.raise_error(\"expected %s/%s, got %s/%s\",\n                             type, value, self.type, self.value)\n </s> add             self.raise_error(\n                \"expected %s/%s, got %s/%s\", type, value, self.type, self.value\n            ) </s> remove         Exception.__init__(self, \"%s: type=%r, value=%r, context=%r\" %\n                           (msg, type, value, context))\n </s> add         Exception.__init__(\n            self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n        ) </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels\n </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove     def __init__(self, type, value,\n                 context=None,\n                 prefix=None,\n                 fixers_applied=[]):\n </s> add     def __init__(self, type, value, context=None, prefix=None, fixers_applied=[]): </s> remove     type = None     # Node type (token if < 256, symbol if >= 256)\n </s> add     type = None  # Node type (token if < 256, symbol if >= 256) </s> remove                         res = ''.join(lines)\n                        return res, prefix[len(res):]\n </s> add                         res = \"\".join(lines)\n                        return res, prefix[len(res) :]", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 lineno += 1\n <mask>                 column = 0\n <mask>         else:\n <mask>             # We never broke out -- EOF is too soon (how can this happen???)\n <mask>             raise parse.ParseError(\"incomplete input\",\n <mask>                                    type, value, (prefix, start))\n <mask>         return p.rootnode\n <mask> \n <mask>     def parse_stream_raw(self, stream, debug=False):\n <mask>         \"\"\"Parse a stream and return the syntax tree.\"\"\"\n <mask>         tokens = tokenize.generate_tokens(stream.readline, grammar=self.grammar)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             io.StringIO(text).readline,\n            grammar=self.grammar\n </s> add             io.StringIO(text).readline, grammar=self.grammar </s> remove     def __init__(self, type, value,\n                 context=None,\n                 prefix=None,\n                 fixers_applied=[]):\n </s> add     def __init__(self, type, value, context=None, prefix=None, fixers_applied=[]): </s> remove                         raise ParseError(\"too much input\",\n                                         type, value, context)\n </s> add                         raise ParseError(\"too much input\", type, value, context) </s> remove     lineno = 0    # Line where this token starts in the input\n    column = 0    # Column where this token starts in the input\n </s> add     lineno = 0  # Line where this token starts in the input\n    column = 0  # Column where this token starts in the input </s> remove         self.used_names = set() # Aliased to self.rootnode.used_names in pop()\n </s> add         self.used_names = set()  # Aliased to self.rootnode.used_names in pop() </s> remove             while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ': column = column + 1\n                elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f': column = 0\n                else: break\n </s> add             while pos < max:  # measure leading whitespace\n                if line[pos] == \" \":\n                    column = column + 1\n                elif line[pos] == \"\\t\":\n                    column = (column // tabsize + 1) * tabsize\n                elif line[pos] == \"\\f\":\n                    column = 0\n                else:\n                    break", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def parse_string(self, text, debug=False):\n <mask>         \"\"\"Parse a string and return the syntax tree.\"\"\"\n <mask>         tokens = tokenize.generate_tokens(\n <mask>             io.StringIO(text).readline,\n <mask>             grammar=self.grammar\n <mask>         )\n <mask>         return self.parse_tokens(tokens, debug)\n <mask> \n <mask>     def _partially_consume_prefix(self, prefix, column):\n <mask>         lines = []\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             raise parse.ParseError(\"incomplete input\",\n                                   type, value, (prefix, start))\n </s> add             raise parse.ParseError(\"incomplete input\", type, value, (prefix, start)) </s> remove         return \"%s(%s, %r)\" % (self.__class__.__name__,\n                               type_repr(self.type),\n                               self.children)\n </s> add         return \"%s(%s, %r)\" % (\n            self.__class__.__name__,\n            type_repr(self.type),\n            self.children,\n        ) </s> remove         return Node(self.type, [ch.clone() for ch in self.children],\n                    fixers_applied=self.fixers_applied)\n </s> add         return Node(\n            self.type,\n            [ch.clone() for ch in self.children],\n            fixers_applied=self.fixers_applied,\n        ) </s> remove         return \"%s(%s, %r)\" % (self.__class__.__name__,\n                               tok_name.get(self.type, self.type),\n                               self.value)\n </s> add         return \"%s(%s, %r)\" % (\n            self.__class__.__name__,\n            tok_name.get(self.type, self.type),\n            self.value,\n        ) </s> remove     def __init__(self, type, value,\n                 context=None,\n                 prefix=None,\n                 fixers_applied=[]):\n </s> add     def __init__(self, type, value, context=None, prefix=None, fixers_applied=[]): </s> remove     default = 'utf-8'\n </s> add     default = \"utf-8\"\n", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep replace keep replace replace keep keep", "code_tokens": " <mask>         for char in prefix:\n <mask>             current_line += char\n <mask>             if wait_for_nl:\n <mask>                 if char == '\\n':\n <mask>                     if current_line.strip() and current_column < column:\n <mask>                         res = ''.join(lines)\n <mask>                         return res, prefix[len(res):]\n <mask> \n <mask>                     lines.append(current_line)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             elif char in ' \\t':\n </s> add             elif char in \" \\t\": </s> remove             elif char == '\\n':\n </s> add             elif char == \"\\n\": </s> remove         return ''.join(lines), current_line\n </s> add         return \"\".join(lines), current_line </s> remove             if subpattern is not None and  self.name == subpattern.name:\n </s> add             if subpattern is not None and self.name == subpattern.name: </s> remove                 raise SyntaxError('encoding problem: utf-8')\n            encoding += '-sig'\n </s> add                 raise SyntaxError(\"encoding problem: utf-8\")\n            encoding += \"-sig\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep keep", "code_tokens": " <mask>                     current_line = \"\"\n <mask>                     current_column = 0\n <mask>                     wait_for_nl = False\n <mask>             elif char in ' \\t':\n <mask>                 current_column += 1\n <mask>             elif char == '\\n':\n <mask>                 # unexpected empty line\n <mask>                 current_column = 0\n <mask>             else:\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                         res = ''.join(lines)\n                        return res, prefix[len(res):]\n </s> add                         res = \"\".join(lines)\n                        return res, prefix[len(res) :] </s> remove                 if char == '\\n':\n </s> add                 if char == \"\\n\": </s> remove         return ''.join(lines), current_line\n </s> add         return \"\".join(lines), current_line </s> remove             while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ': column = column + 1\n                elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f': column = 0\n                else: break\n </s> add             while pos < max:  # measure leading whitespace\n                if line[pos] == \" \":\n                    column = column + 1\n                elif line[pos] == \"\\t\":\n                    column = (column // tabsize + 1) * tabsize\n                elif line[pos] == \"\\f\":\n                    column = 0\n                else:\n                    break </s> remove             if not line: break\n </s> add             if not line:\n                break", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 current_column = 0\n <mask>             else:\n <mask>                 # indent is finished\n <mask>                 wait_for_nl = True\n <mask>         return ''.join(lines), current_line\n <mask> \n <mask> \n <mask> def _generate_pickle_name(gt, cache_dir=None):\n <mask>     head, tail = os.path.splitext(gt)\n <mask>     if tail == \".txt\":\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             elif char == '\\n':\n </s> add             elif char == \"\\n\": </s> remove                         res = ''.join(lines)\n                        return res, prefix[len(res):]\n </s> add                         res = \"\".join(lines)\n                        return res, prefix[len(res) :] </s> remove             elif char in ' \\t':\n </s> add             elif char in \" \\t\": </s> remove                 if char == '\\n':\n </s> add                 if char == \"\\n\": </s> remove     __hash__ = None # For Py3 compatibility.\n </s> add     __hash__ = None  # For Py3 compatibility.\n </s> remove         else:                                  # continued statement\n </s> add         else:  # continued statement", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     else:\n <mask>         return name\n <mask> \n <mask> \n <mask> def load_grammar(gt=\"Grammar.txt\", gp=None,\n <mask>                  save=True, force=False, logger=None):\n <mask>     \"\"\"Load the grammar (maybe from a pickle).\"\"\"\n <mask>     if logger is None:\n <mask>         logger = logging.getLogger(__name__)\n <mask>     gp = _generate_pickle_name(gt) if gp is None else gp\n <mask>     if force or not _newer(gp, gt):\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove \n    def __init__(\n        self,\n        grammar,\n        convert=None,\n        logger=None,\n    ):\n </s> add     def __init__(self, grammar, convert=None, logger=None): </s> remove     logging.basicConfig(level=logging.INFO, stream=sys.stdout,\n                        format='%(message)s')\n </s> add     logging.basicConfig(level=logging.INFO, stream=sys.stdout, format=\"%(message)s\") </s> remove         if (self.content is not None and\n            len(self.content) == 1 and len(self.content[0]) == 1):\n </s> add         if (\n            self.content is not None\n            and len(self.content) == 1\n            and len(self.content[0]) == 1\n        ): </s> remove         self.first = {} # map from symbol name to set of tokens\n </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove             if type(val) == int: _type_reprs[val] = name\n </s> add             if type(val) == int:\n                _type_reprs[val] = name </s> remove             if subpattern is not None and  self.name == subpattern.name:\n </s> add             if subpattern is not None and self.name == subpattern.name:", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     Calls load_grammar for each argument, a path to a grammar text file.\n <mask>     \"\"\"\n <mask>     if not args:\n <mask>         args = sys.argv[1:]\n <mask>     logging.basicConfig(level=logging.INFO, stream=sys.stdout,\n <mask>                         format='%(message)s')\n <mask>     for gt in args:\n <mask>         load_grammar(gt, save=True, force=True)\n <mask>     return True\n <mask> \n <mask> if __name__ == \"__main__\":\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove def load_grammar(gt=\"Grammar.txt\", gp=None,\n                 save=True, force=False, logger=None):\n </s> add def load_grammar(gt=\"Grammar.txt\", gp=None, save=True, force=False, logger=None): </s> remove         #print token.tok_name[self.type], repr(self.value)\n </s> add         # print token.tok_name[self.type], repr(self.value) </s> remove if __name__ == '__main__':                     # testing\n </s> add if __name__ == \"__main__\":  # testing </s> remove         with tempfile.NamedTemporaryFile(dir=os.path.dirname(filename), delete=False) as f:\n </s> add         with tempfile.NamedTemporaryFile(\n            dir=os.path.dirname(filename), delete=False\n        ) as f: </s> remove     type = None     # Node type (token if < 256, symbol if >= 256)\n </s> add     type = None  # Node type (token if < 256, symbol if >= 256) </s> remove     __hash__ = None # For Py3 compatibility.\n </s> add     __hash__ = None  # For Py3 compatibility.", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.async_keywords = False\n <mask> \n <mask>     def dump(self, filename):\n <mask>         \"\"\"Dump the grammar tables to a pickle file.\"\"\"\n <mask>         with tempfile.NamedTemporaryFile(dir=os.path.dirname(filename), delete=False) as f:\n <mask>             pickle.dump(self.__dict__, f, pickle.HIGHEST_PROTOCOL)\n <mask>         os.replace(f.name, filename)\n <mask> \n <mask>     def load(self, filename):\n <mask>         \"\"\"Load the grammar tables from a pickle file.\"\"\"\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove def load_grammar(gt=\"Grammar.txt\", gp=None,\n                 save=True, force=False, logger=None):\n </s> add def load_grammar(gt=\"Grammar.txt\", gp=None, save=True, force=False, logger=None): </s> remove __author__ = 'Ka-Ping Yee <ping@lfw.org>'\n__credits__ = \\\n    'GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro'\n </s> add __author__ = \"Ka-Ping Yee <ping@lfw.org>\"\n__credits__ = \"GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro\" </s> remove     logging.basicConfig(level=logging.INFO, stream=sys.stdout,\n                        format='%(message)s')\n </s> add     logging.basicConfig(level=logging.INFO, stream=sys.stdout, format=\"%(message)s\") </s> remove         self.used_names = set() # Aliased to self.rootnode.used_names in pop()\n </s> add         self.used_names = set()  # Aliased to self.rootnode.used_names in pop() </s> remove _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__),\n                                     \"PatternGrammar.txt\")\n </s> add _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__), \"PatternGrammar.txt\") </s> remove \n    def __init__(\n        self,\n        grammar,\n        convert=None,\n        logger=None,\n    ):\n </s> add     def __init__(self, grammar, convert=None, logger=None):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/grammar.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         Copy the grammar.\n <mask>         \"\"\"\n <mask>         new = self.__class__()\n <mask>         for dict_attr in (\"symbol2number\", \"number2symbol\", \"dfas\", \"keywords\",\n <mask>                           \"tokens\", \"symbol2label\"):\n <mask>             setattr(new, dict_attr, getattr(self, dict_attr).copy())\n <mask>         new.labels = self.labels[:]\n <mask>         new.states = self.states[:]\n <mask>         new.start = self.start\n <mask>         new.async_keywords = self.async_keywords\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     default = 'utf-8'\n </s> add     default = \"utf-8\"\n </s> remove     numchars = '0123456789'\n    contstr, needcont = '', 0\n </s> add     numchars = \"0123456789\"\n    contstr, needcont = \"\", 0 </s> remove     __hash__ = None # For Py3 compatibility.\n </s> add     __hash__ = None  # For Py3 compatibility. </s> remove     type = None    # int: token number (< 256) or symbol number (>= 256)\n </s> add     type = None  # int: token number (< 256) or symbol number (>= 256) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/grammar.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \"\"\"Safely evaluate Python string literals without using eval().\"\"\"\n <mask> \n <mask> import regex as re\n <mask> \n <mask> simple_escapes = {\"a\": \"\\a\",\n <mask>                   \"b\": \"\\b\",\n <mask>                   \"f\": \"\\f\",\n <mask>                   \"n\": \"\\n\",\n <mask>                   \"r\": \"\\r\",\n <mask>                   \"t\": \"\\t\",\n <mask>                   \"v\": \"\\v\",\n <mask>                   \"'\": \"'\",\n <mask>                   '\"': '\"',\n <mask>                   \"\\\\\": \"\\\\\"}\n <mask> \n <mask> def escape(m):\n <mask>     all, tail = m.group(0, 1)\n <mask>     assert all.startswith(\"\\\\\")\n <mask>     esc = simple_escapes.get(tail)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove __author__ = 'Ka-Ping Yee <ping@lfw.org>'\n__credits__ = \\\n    'GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro'\n </s> add __author__ = \"Ka-Ping Yee <ping@lfw.org>\"\n__credits__ = \"GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro\" </s> remove     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE,\n                                                  cache_dir)\n </s> add     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE, cache_dir) </s> remove         return ''.join(lines), current_line\n </s> add         return \"\".join(lines), current_line </s> remove endprogs = {\"'\": re.compile(Single), '\"': re.compile(Double),\n            \"'''\": single3prog, '\"\"\"': double3prog,\n            **{f\"{prefix}'''\": single3prog for prefix in _strprefixes},\n            **{f'{prefix}\"\"\"': double3prog for prefix in _strprefixes},\n            **{prefix: None for prefix in _strprefixes}}\n </s> add endprogs = {\n    \"'\": re.compile(Single),\n    '\"': re.compile(Double),\n    \"'''\": single3prog,\n    '\"\"\"': double3prog,\n    **{f\"{prefix}'''\": single3prog for prefix in _strprefixes},\n    **{f'{prefix}\"\"\"': double3prog for prefix in _strprefixes},\n    **{prefix: None for prefix in _strprefixes},\n} </s> remove             if type(val) == int: _type_reprs[val] = name\n </s> add             if type(val) == int:\n                _type_reprs[val] = name </s> remove     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = True\n </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = (\n        True\n    )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/literals.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def evalString(s):\n <mask>     assert s.startswith(\"'\") or s.startswith('\"'), repr(s[:1])\n <mask>     q = s[0]\n <mask>     if s[:3] == q*3:\n <mask>         q = q*3\n <mask>     assert s.endswith(q), repr(s[-len(q):])\n <mask>     assert len(s) >= 2*len(q)\n <mask>     s = s[len(q):-len(q)]\n <mask>     return re.sub(r\"\\\\(\\'|\\\"|\\\\|[abfnrtv]|x.{0,2}|[0-7]{1,3})\", escape, s)\n <mask> \n <mask> def test():\n <mask>     for i in range(256):\n <mask>         c = chr(i)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n            mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$',\n                          line)\n </s> add             lineno, line = lineno + 1, next(f)\n            mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$', line) </s> remove                     if byte & (1<<j):\n                        first[i*8 + j] = 1\n </s> add                     if byte & (1 << j):\n                        first[i * 8 + j] = 1", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/literals.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> class ParseError(Exception):\n <mask>     \"\"\"Exception to signal the parser is stuck.\"\"\"\n <mask> \n <mask>     def __init__(self, msg, type, value, context):\n <mask>         Exception.__init__(self, \"%s: type=%r, value=%r, context=%r\" %\n <mask>                            (msg, type, value, context))\n <mask>         self.msg = msg\n <mask>         self.type = type\n <mask>         self.value = value\n <mask>         self.context = context\n <mask> \n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             self.raise_error(\"expected %s/%s, got %s/%s\",\n                             type, value, self.type, self.value)\n </s> add             self.raise_error(\n                \"expected %s/%s, got %s/%s\", type, value, self.type, self.value\n            ) </s> remove     def __init__(self, type, value,\n                 context=None,\n                 prefix=None,\n                 fixers_applied=[]):\n </s> add     def __init__(self, type, value, context=None, prefix=None, fixers_applied=[]): </s> remove         self.used_names = set() # Aliased to self.rootnode.used_names in pop()\n </s> add         self.used_names = set()  # Aliased to self.rootnode.used_names in pop() </s> remove                 self.logger.debug(\"%s %r (prefix=%r)\",\n                                  token.tok_name[type], value, prefix)\n </s> add                 self.logger.debug(\n                    \"%s %r (prefix=%r)\", token.tok_name[type], value, prefix\n                ) </s> remove             self.raise_error(\"expected (...) or NAME or STRING, got %s/%s\",\n                             self.type, self.value)\n </s> add             self.raise_error(\n                \"expected (...) or NAME or STRING, got %s/%s\", self.type, self.value\n            ) </s> remove                         raise ParseError(\"too much input\",\n                                         type, value, context)\n </s> add                         raise ParseError(\"too much input\", type, value, context)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         newnode = (start, None, None, [])\n <mask>         stackentry = (self.grammar.dfas[start], 0, newnode)\n <mask>         self.stack = [stackentry]\n <mask>         self.rootnode = None\n <mask>         self.used_names = set() # Aliased to self.rootnode.used_names in pop()\n <mask> \n <mask>     def addtoken(self, type, value, context):\n <mask>         \"\"\"Add a token; return True iff this is the end of the program.\"\"\"\n <mask>         # Map from token to label\n <mask>         ilabel = self.classify(type, value, context)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         Exception.__init__(self, \"%s: type=%r, value=%r, context=%r\" %\n                           (msg, type, value, context))\n </s> add         Exception.__init__(\n            self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n        ) </s> remove     def __init__(self, type, value,\n                 context=None,\n                 prefix=None,\n                 fixers_applied=[]):\n </s> add     def __init__(self, type, value, context=None, prefix=None, fixers_applied=[]): </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels\n </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove     lineno = 0    # Line where this token starts in the input\n    column = 0    # Column where this token starts in the input\n </s> add     lineno = 0  # Line where this token starts in the input\n    column = 0  # Column where this token starts in the input </s> remove             raise parse.ParseError(\"incomplete input\",\n                                   type, value, (prefix, start))\n </s> add             raise parse.ParseError(\"incomplete input\", type, value, (prefix, start)) </s> remove                         raise ParseError(\"too much input\",\n                                         type, value, context)\n </s> add                         raise ParseError(\"too much input\", type, value, context)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     itsstates, itsfirst = itsdfa\n <mask>                     if ilabel in itsfirst:\n <mask>                         # Push a symbol\n <mask>                         self.push(t, self.grammar.dfas[t], newstate, context)\n <mask>                         break # To continue the outer while loop\n <mask>             else:\n <mask>                 if (0, state) in arcs:\n <mask>                     # An accepting state, pop it and try something else\n <mask>                     self.pop()\n <mask>                     if not self.stack:\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                         raise ParseError(\"too much input\",\n                                         type, value, context)\n </s> add                         raise ParseError(\"too much input\", type, value, context) </s> remove                 itoken = grammar.opmap[value] # Fails if unknown token\n </s> add                 itoken = grammar.opmap[value]  # Fails if unknown token </s> remove             if not line: break\n </s> add             if not line:\n                break </s> remove             while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ': column = column + 1\n                elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f': column = 0\n                else: break\n </s> add             while pos < max:  # measure leading whitespace\n                if line[pos] == \" \":\n                    column = column + 1\n                elif line[pos] == \"\\t\":\n                    column = (column // tabsize + 1) * tabsize\n                elif line[pos] == \"\\f\":\n                    column = 0\n                else:\n                    break </s> remove             line = ''\n </s> add             line = \"\" </s> remove             while column < indents[-1]:        # count dedents\n </s> add             while column < indents[-1]:  # count dedents", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                     # An accepting state, pop it and try something else\n <mask>                     self.pop()\n <mask>                     if not self.stack:\n <mask>                         # Done parsing, but another token is input\n <mask>                         raise ParseError(\"too much input\",\n <mask>                                          type, value, context)\n <mask>                 else:\n <mask>                     # No success finding a transition\n <mask>                     raise ParseError(\"bad input\", type, value, context)\n <mask> \n <mask>     def classify(self, type, value, context):\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                         break # To continue the outer while loop\n </s> add                         break  # To continue the outer while loop </s> remove             raise parse.ParseError(\"incomplete input\",\n                                   type, value, (prefix, start))\n </s> add             raise parse.ParseError(\"incomplete input\", type, value, (prefix, start)) </s> remove     def __init__(self, type, value,\n                 context=None,\n                 prefix=None,\n                 fixers_applied=[]):\n </s> add     def __init__(self, type, value, context=None, prefix=None, fixers_applied=[]): </s> remove         Exception.__init__(self, \"%s: type=%r, value=%r, context=%r\" %\n                           (msg, type, value, context))\n </s> add         Exception.__init__(\n            self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n        ) </s> remove         self.used_names = set() # Aliased to self.rootnode.used_names in pop()\n </s> add         self.used_names = set()  # Aliased to self.rootnode.used_names in pop() </s> remove             self.raise_error(\"expected %s/%s, got %s/%s\",\n                             type, value, self.type, self.value)\n </s> add             self.raise_error(\n                \"expected %s/%s, got %s/%s\", type, value, self.type, self.value\n            )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> class PgenGrammar(grammar.Grammar):\n <mask>     pass\n <mask> \n <mask> class ParserGenerator(object):\n <mask> \n <mask>     def __init__(self, filename, stream=None):\n <mask>         close_stream = None\n <mask>         if stream is None:\n <mask>             stream = open(filename)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> add class ParserGenerator(object): </s> remove         self.gettoken() # Initialize lookahead\n </s> add         self.gettoken()  # Initialize lookahead </s> remove class StopTokenizing(Exception): pass\n </s> add class TokenError(Exception):\n    pass\n\n\nclass StopTokenizing(Exception):\n    pass\n </s> remove \n    def __init__(\n        self,\n        grammar,\n        convert=None,\n        logger=None,\n    ):\n </s> add     def __init__(self, grammar, convert=None, logger=None): </s> remove class TokenError(Exception): pass\n </s> add  </s> remove def printtoken(type, token, xxx_todo_changeme, xxx_todo_changeme1, line): # for testing\n </s> add def printtoken(type, token, xxx_todo_changeme, xxx_todo_changeme1, line):  # for testing", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> class PgenGrammar(grammar.Grammar):\n <mask>     pass\n <mask> \n <mask> \n <mask>     def __init__(self, filename, stream=None):\n <mask>         close_stream = None\n <mask>         if stream is None:\n <mask>             stream = open(filename)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove class ParserGenerator(object):\n </s> add  </s> remove         self.gettoken() # Initialize lookahead\n </s> add         self.gettoken()  # Initialize lookahead </s> remove \n    def __init__(\n        self,\n        grammar,\n        convert=None,\n        logger=None,\n    ):\n </s> add     def __init__(self, grammar, convert=None, logger=None): </s> remove     while 1:                                   # loop over lines in stream\n </s> add     while 1:  # loop over lines in stream </s> remove class StopTokenizing(Exception): pass\n </s> add class TokenError(Exception):\n    pass\n\n\nclass StopTokenizing(Exception):\n    pass\n </s> remove             line = ''\n </s> add             line = \"\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         self.filename = filename\n <mask>         self.stream = stream\n <mask>         self.generator = tokenize.generate_tokens(stream.readline)\n <mask>         self.gettoken() # Initialize lookahead\n <mask>         self.dfas, self.startsymbol = self.parse()\n <mask>         if close_stream is not None:\n <mask>             close_stream()\n <mask>         self.first = {} # map from symbol name to set of tokens\n <mask>         self.addfirstsets()\n <mask> \n <mask>     def make_grammar(self):\n <mask>         c = PgenGrammar()\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels\n </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove         self.arcs = {} # map from label to DFAState\n </s> add         self.arcs = {}  # map from label to DFAState </s> add class ParserGenerator(object): </s> remove class ParserGenerator(object):\n </s> add  </s> remove     name = None     # Optional name used to store match in results dict\n </s> add     name = None  # Optional name used to store match in results dict", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     c.keywords[value] = ilabel\n <mask>                     return ilabel\n <mask>             else:\n <mask>                 # An operator (any non-numeric token)\n <mask>                 itoken = grammar.opmap[value] # Fails if unknown token\n <mask>                 if itoken in c.tokens:\n <mask>                     return c.tokens[itoken]\n <mask>                 else:\n <mask>                     c.labels.append((itoken, None))\n <mask>                     c.tokens[itoken] = ilabel\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                         break # To continue the outer while loop\n </s> add                         break  # To continue the outer while loop </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels\n </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove         self.used_names = set() # Aliased to self.rootnode.used_names in pop()\n </s> add         self.used_names = set()  # Aliased to self.rootnode.used_names in pop() </s> remove         return ''.join(lines), current_line\n </s> add         return \"\".join(lines), current_line </s> remove         else:                                  # continued statement\n </s> add         else:  # continued statement </s> remove                     else:                                  # ordinary string\n </s> add                     else:  # ordinary string", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep replace keep keep keep replace keep keep keep", "code_tokens": " <mask>                 self.calcfirst(name)\n <mask>             #print name, self.first[name].keys()\n <mask> \n <mask>     def calcfirst(self, name):\n <mask>         dfa = self.dfas[name]\n <mask>         self.first[name] = None # dummy to detect left recursion\n <mask>         state = dfa[0]\n <mask>         totalset = {}\n <mask>         overlapcheck = {}\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             #self.dump_dfa(name, dfa)\n </s> add             # self.dump_dfa(name, dfa) </s> remove             #print name, oldlen, newlen\n </s> add             # print name, oldlen, newlen </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels\n </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove         self.first = {} # map from symbol name to set of tokens\n </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove         self.arcs = {} # map from label to DFAState\n </s> add         self.arcs = {}  # map from label to DFAState", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         inverse = {}\n <mask>         for label, itsfirst in overlapcheck.items():\n <mask>             for symbol in itsfirst:\n <mask>                 if symbol in inverse:\n <mask>                     raise ValueError(\"rule %s is ambiguous; %s is in the\"\n <mask>                                      \" first sets of %s as well as %s\" %\n <mask>                                      (name, symbol, label, inverse[symbol]))\n <mask>                 inverse[symbol] = label\n <mask>         self.first[name] = totalset\n <mask> \n <mask>     def parse(self):\n <mask>         dfas = {}\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         self.first[name] = None # dummy to detect left recursion\n </s> add         self.first[name] = None  # dummy to detect left recursion </s> remove         for state in states: # NB states grows while we're iterating\n </s> add         for state in states:  # NB states grows while we're iterating </s> remove         self.first = {} # map from symbol name to set of tokens\n </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove                 print(\"%s(%s): can't parse %s\" % (filename, lineno,\n                                                  line.strip()))\n </s> add                 print(\"%s(%s): can't parse %s\" % (filename, lineno, line.strip())) </s> remove         self.gettoken() # Initialize lookahead\n </s> add         self.gettoken()  # Initialize lookahead </s> remove #--end constants--\n </s> add # --end constants--", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace keep keep keep", "code_tokens": " <mask>             name = self.expect(token.NAME)\n <mask>             self.expect(token.OP, \":\")\n <mask>             a, z = self.parse_rhs()\n <mask>             self.expect(token.NEWLINE)\n <mask>             #self.dump_nfa(name, a, z)\n <mask>             dfa = self.make_dfa(a, z)\n <mask>             #self.dump_dfa(name, dfa)\n <mask>             oldlen = len(dfa)\n <mask>             self.simplify_dfa(dfa)\n <mask>             newlen = len(dfa)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             #print name, oldlen, newlen\n </s> add             # print name, oldlen, newlen </s> remove         while (self.value in (\"(\", \"[\") or\n               self.type in (token.NAME, token.STRING)):\n </s> add         while self.value in (\"(\", \"[\") or self.type in (token.NAME, token.STRING): </s> remove             #print name, self.first[name].keys()\n </s> add             # print name, self.first[name].keys() </s> remove             lineno, line = lineno+1, next(f)\n            mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$',\n                          line)\n </s> add             lineno, line = lineno + 1, next(f)\n            mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$', line) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             oldlen = len(dfa)\n <mask>             self.simplify_dfa(dfa)\n <mask>             newlen = len(dfa)\n <mask>             dfas[name] = dfa\n <mask>             #print name, oldlen, newlen\n <mask>             if startsymbol is None:\n <mask>                 startsymbol = name\n <mask>         return dfas, startsymbol\n <mask> \n <mask>     def make_dfa(self, start, finish):\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             #self.dump_dfa(name, dfa)\n </s> add             # self.dump_dfa(name, dfa) </s> remove             #self.dump_nfa(name, a, z)\n </s> add             # self.dump_nfa(name, a, z) </s> remove             #print name, self.first[name].keys()\n </s> add             # print name, self.first[name].keys() </s> remove         return states # List of DFAState instances; first one is start\n </s> add         return states  # List of DFAState instances; first one is start </s> remove         self.first[name] = None # dummy to detect left recursion\n </s> add         self.first[name] = None  # dummy to detect left recursion </s> remove             if type(val) == int: _type_reprs[val] = name\n </s> add             if type(val) == int:\n                _type_reprs[val] = name", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             for label, next in state.arcs:\n <mask>                 if label is None:\n <mask>                     addclosure(next, base)\n <mask>         states = [DFAState(closure(start), finish)]\n <mask>         for state in states: # NB states grows while we're iterating\n <mask>             arcs = {}\n <mask>             for nfastate in state.nfaset:\n <mask>                 for label, next in nfastate.arcs:\n <mask>                     if label is not None:\n <mask>                         addclosure(next, arcs.setdefault(label, {}))\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         self.first[name] = None # dummy to detect left recursion\n </s> add         self.first[name] = None  # dummy to detect left recursion </s> remove                     raise ValueError(\"rule %s is ambiguous; %s is in the\"\n                                     \" first sets of %s as well as %s\" %\n                                     (name, symbol, label, inverse[symbol]))\n </s> add                     raise ValueError(\n                        \"rule %s is ambiguous; %s is in the\"\n                        \" first sets of %s as well as %s\"\n                        % (name, symbol, label, inverse[symbol])\n                    ) </s> remove         return states # List of DFAState instances; first one is start\n </s> add         return states  # List of DFAState instances; first one is start </s> remove                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\",\n                              line)\n </s> add                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\", line) </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels\n </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove     __hash__ = None # For Py3 compatibility.\n </s> add     __hash__ = None  # For Py3 compatibility.\n", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 else:\n <mask>                     st = DFAState(nfaset, finish)\n <mask>                     states.append(st)\n <mask>                 state.addarc(st, label)\n <mask>         return states # List of DFAState instances; first one is start\n <mask> \n <mask>     def dump_nfa(self, name, start, finish):\n <mask>         print(\"Dump of NFA for\", name)\n <mask>         todo = [start]\n <mask>         for i, state in enumerate(todo):\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             #print name, oldlen, newlen\n </s> add             # print name, oldlen, newlen </s> remove         for state in states: # NB states grows while we're iterating\n </s> add         for state in states:  # NB states grows while we're iterating </s> remove                     raise ValueError(\"rule %s is ambiguous; %s is in the\"\n                                     \" first sets of %s as well as %s\" %\n                                     (name, symbol, label, inverse[symbol]))\n </s> add                     raise ValueError(\n                        \"rule %s is ambiguous; %s is in the\"\n                        \" first sets of %s as well as %s\"\n                        % (name, symbol, label, inverse[symbol])\n                    ) </s> remove             #print name, self.first[name].keys()\n </s> add             # print name, self.first[name].keys() </s> remove     type = None    # int: token number (< 256) or symbol number (>= 256)\n </s> add     type = None  # int: token number (< 256) or symbol number (>= 256) </s> remove                         #print \"  unify\", i, j\n </s> add                         # print \"  unify\", i, j", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep replace keep keep keep keep", "code_tokens": " <mask>         changes = True\n <mask>         while changes:\n <mask>             changes = False\n <mask>             for i, state_i in enumerate(dfa):\n <mask>                 for j in range(i+1, len(dfa)):\n <mask>                     state_j = dfa[j]\n <mask>                     if state_i == state_j:\n <mask>                         #print \"  unify\", i, j\n <mask>                         del dfa[j]\n <mask>                         for state in dfa:\n <mask>                             state.unifystate(state_j, state_i)\n <mask>                         changes = True\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                     if byte & (1<<j):\n                        first[i*8 + j] = 1\n </s> add                     if byte & (1 << j):\n                        first[i * 8 + j] = 1 </s> remove                     lineno, line = lineno+1, next(f)\n </s> add                     lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f)\n </s> add                 lineno, line = lineno + 1, next(f) </s> remove             tokval += ' '\n </s> add             tokval += \" \" </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def parse_alt(self):\n <mask>         # ALT: ITEM+\n <mask>         a, b = self.parse_item()\n <mask>         while (self.value in (\"(\", \"[\") or\n <mask>                self.type in (token.NAME, token.STRING)):\n <mask>             c, d = self.parse_item()\n <mask>             b.addarc(c)\n <mask>             b = d\n <mask>         return a, b\n <mask> \n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             #self.dump_nfa(name, a, z)\n </s> add             # self.dump_nfa(name, a, z) </s> remove             #self.dump_dfa(name, dfa)\n </s> add             # self.dump_dfa(name, dfa) </s> remove             self.raise_error(\"expected (...) or NAME or STRING, got %s/%s\",\n                             self.type, self.value)\n </s> add             self.raise_error(\n                \"expected (...) or NAME or STRING, got %s/%s\", self.type, self.value\n            ) </s> remove             if pseudomatch:                                # scan for tokens\n </s> add             if pseudomatch:  # scan for tokens </s> remove     while 1:                                   # loop over lines in stream\n </s> add     while 1:  # loop over lines in stream </s> remove                 elif initial in single_quoted or \\\n                    token[:2] in single_quoted or \\\n                    token[:3] in single_quoted:\n                    if token[-1] == '\\n':                  # continued string\n </s> add                 elif (\n                    initial in single_quoted\n                    or token[:2] in single_quoted\n                    or token[:3] in single_quoted\n                ):\n                    if token[-1] == \"\\n\":  # continued string", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep replace replace keep keep keep replace replace", "code_tokens": " <mask>             return a, z\n <mask>         else:\n <mask>             self.raise_error(\"expected (...) or NAME or STRING, got %s/%s\",\n <mask>                              self.type, self.value)\n <mask> \n <mask>     def expect(self, type, value=None):\n <mask>         if self.type != type or (value is not None and self.value != value):\n <mask>             self.raise_error(\"expected %s/%s, got %s/%s\",\n <mask>                              type, value, self.type, self.value)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         while (self.value in (\"(\", \"[\") or\n               self.type in (token.NAME, token.STRING)):\n </s> add         while self.value in (\"(\", \"[\") or self.type in (token.NAME, token.STRING): </s> remove         Exception.__init__(self, \"%s: type=%r, value=%r, context=%r\" %\n                           (msg, type, value, context))\n </s> add         Exception.__init__(\n            self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n        ) </s> remove                         raise ParseError(\"too much input\",\n                                         type, value, context)\n </s> add                         raise ParseError(\"too much input\", type, value, context) </s> remove         return Leaf(self.type, self.value,\n                    (self.prefix, (self.lineno, self.column)),\n                    fixers_applied=self.fixers_applied)\n </s> add         return Leaf(\n            self.type,\n            self.value,\n            (self.prefix, (self.lineno, self.column)),\n            fixers_applied=self.fixers_applied,\n        ) </s> remove             raise parse.ParseError(\"incomplete input\",\n                                   type, value, (prefix, start))\n </s> add             raise parse.ParseError(\"incomplete input\", type, value, (prefix, start))", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         tup = next(self.generator)\n <mask>         while tup[0] in (tokenize.COMMENT, tokenize.NL):\n <mask>             tup = next(self.generator)\n <mask>         self.type, self.value, self.begin, self.end, self.line = tup\n <mask>         #print token.tok_name[self.type], repr(self.value)\n <mask> \n <mask>     def raise_error(self, msg, *args):\n <mask>         if args:\n <mask>             try:\n <mask>                 msg = msg % args\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         raise SyntaxError(msg, (self.filename, self.end[0],\n                                self.end[1], self.line))\n </s> add         raise SyntaxError(msg, (self.filename, self.end[0], self.end[1], self.line)) </s> remove         Exception.__init__(self, \"%s: type=%r, value=%r, context=%r\" %\n                           (msg, type, value, context))\n </s> add         Exception.__init__(\n            self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n        ) </s> remove     logging.basicConfig(level=logging.INFO, stream=sys.stdout,\n                        format='%(message)s')\n </s> add     logging.basicConfig(level=logging.INFO, stream=sys.stdout, format=\"%(message)s\") </s> remove class NFAState(object):\n </s> add  </s> remove             line = ''\n </s> add             line = \"\" </s> remove     while 1:                                   # loop over lines in stream\n </s> add     while 1:  # loop over lines in stream", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace", "code_tokens": " <mask>                 msg = msg % args\n <mask>             except:\n <mask>                 msg = \" \".join([msg] + list(map(str, args)))\n <mask>         raise SyntaxError(msg, (self.filename, self.end[0],\n <mask>                                 self.end[1], self.line))\n <mask> \n <mask> class NFAState(object):\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         #print token.tok_name[self.type], repr(self.value)\n </s> add         # print token.tok_name[self.type], repr(self.value) </s> remove         Exception.__init__(self, \"%s: type=%r, value=%r, context=%r\" %\n                           (msg, type, value, context))\n </s> add         Exception.__init__(\n            self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n        ) </s> remove                     raise ValueError(\"rule %s is ambiguous; %s is in the\"\n                                     \" first sets of %s as well as %s\" %\n                                     (name, symbol, label, inverse[symbol]))\n </s> add                     raise ValueError(\n                        \"rule %s is ambiguous; %s is in the\"\n                        \" first sets of %s as well as %s\"\n                        % (name, symbol, label, inverse[symbol])\n                    ) </s> remove class StopTokenizing(Exception): pass\n </s> add class TokenError(Exception):\n    pass\n\n\nclass StopTokenizing(Exception):\n    pass\n </s> add class NFAState(object):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask>     def __init__(self):\n <mask>         self.arcs = []  # list of (label, NFAState) pairs\n <mask> \n <mask>     def addarc(self, next, label=None):\n <mask>         assert label is None or isinstance(label, str)\n <mask>         assert isinstance(next, NFAState)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         self.arcs = [] # list of (label, NFAState) pairs\n </s> add         self.arcs = []  # list of (label, NFAState) pairs </s> remove class NFAState(object):\n </s> add  </s> remove         self.arcs = {} # map from label to DFAState\n </s> add         self.arcs = {}  # map from label to DFAState </s> remove class DFAState(object):\n </s> add  </s> remove         raise SyntaxError(msg, (self.filename, self.end[0],\n                                self.end[1], self.line))\n </s> add         raise SyntaxError(msg, (self.filename, self.end[0], self.end[1], self.line)) </s> add class DFAState(object):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> class NFAState(object):\n <mask> \n <mask>     def __init__(self):\n <mask>         self.arcs = [] # list of (label, NFAState) pairs\n <mask> \n <mask>     def addarc(self, next, label=None):\n <mask>         assert label is None or isinstance(label, str)\n <mask>         assert isinstance(next, NFAState)\n <mask>         self.arcs.append((label, next))\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> add class NFAState(object): </s> remove class NFAState(object):\n </s> add  </s> remove class DFAState(object):\n </s> add  </s> remove         self.arcs = {} # map from label to DFAState\n </s> add         self.arcs = {}  # map from label to DFAState </s> remove         raise SyntaxError(msg, (self.filename, self.end[0],\n                                self.end[1], self.line))\n </s> add         raise SyntaxError(msg, (self.filename, self.end[0], self.end[1], self.line)) </s> add class DFAState(object):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         assert label is None or isinstance(label, str)\n <mask>         assert isinstance(next, NFAState)\n <mask>         self.arcs.append((label, next))\n <mask> \n <mask> class DFAState(object):\n <mask> \n <mask>     def __init__(self, nfaset, final):\n <mask>         assert isinstance(nfaset, dict)\n <mask>         assert isinstance(next(iter(nfaset)), NFAState)\n <mask>         assert isinstance(final, NFAState)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> add class DFAState(object): </s> remove         self.arcs = [] # list of (label, NFAState) pairs\n </s> add         self.arcs = []  # list of (label, NFAState) pairs </s> add class NFAState(object): </s> remove         self.arcs = {} # map from label to DFAState\n </s> add         self.arcs = {}  # map from label to DFAState </s> remove class NFAState(object):\n </s> add  </s> remove     if s[:3] == q*3:\n        q = q*3\n    assert s.endswith(q), repr(s[-len(q):])\n    assert len(s) >= 2*len(q)\n    s = s[len(q):-len(q)]\n </s> add     if s[:3] == q * 3:\n        q = q * 3\n    assert s.endswith(q), repr(s[-len(q) :])\n    assert len(s) >= 2 * len(q)\n    s = s[len(q) : -len(q)]", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask>     def __init__(self, nfaset, final):\n <mask>         assert isinstance(nfaset, dict)\n <mask>         assert isinstance(next(iter(nfaset)), NFAState)\n <mask>         assert isinstance(final, NFAState)\n <mask>         self.nfaset = nfaset\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove class DFAState(object):\n </s> add  </s> remove         self.arcs = {} # map from label to DFAState\n </s> add         self.arcs = {}  # map from label to DFAState </s> remove         self.arcs = [] # list of (label, NFAState) pairs\n </s> add         self.arcs = []  # list of (label, NFAState) pairs </s> add class NFAState(object): </s> remove class NFAState(object):\n </s> add  </s> remove     if s[:3] == q*3:\n        q = q*3\n    assert s.endswith(q), repr(s[-len(q):])\n    assert len(s) >= 2*len(q)\n    s = s[len(q):-len(q)]\n </s> add     if s[:3] == q * 3:\n        q = q * 3\n    assert s.endswith(q), repr(s[-len(q) :])\n    assert len(s) >= 2 * len(q)\n    s = s[len(q) : -len(q)]", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         assert isinstance(next(iter(nfaset)), NFAState)\n <mask>         assert isinstance(final, NFAState)\n <mask>         self.nfaset = nfaset\n <mask>         self.isfinal = final in nfaset\n <mask>         self.arcs = {} # map from label to DFAState\n <mask> \n <mask>     def addarc(self, next, label):\n <mask>         assert isinstance(label, str)\n <mask>         assert label not in self.arcs\n <mask>         assert isinstance(next, DFAState)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> add class NFAState(object): </s> remove         self.arcs = [] # list of (label, NFAState) pairs\n </s> add         self.arcs = []  # list of (label, NFAState) pairs </s> add class DFAState(object): </s> remove class DFAState(object):\n </s> add  </s> remove class NFAState(object):\n </s> add  </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels\n </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>             if next is not other.arcs.get(label):\n <mask>                 return False\n <mask>         return True\n <mask> \n <mask>     __hash__ = None # For Py3 compatibility.\n <mask> \n <mask> def generate_grammar(filename=\"Grammar.txt\"):\n <mask>     p = ParserGenerator(filename)\n <mask>     return p.make_grammar()\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     __hash__ = None # For Py3 compatibility.\n </s> add     __hash__ = None  # For Py3 compatibility. </s> remove         return ''.join(lines), current_line\n </s> add         return \"\".join(lines), current_line </s> remove             line_string = line.decode('ascii')\n </s> add             line_string = line.decode(\"ascii\") </s> remove     default = 'utf-8'\n </s> add     default = \"utf-8\"\n </s> remove             if subpattern is not None and  self.name == subpattern.name:\n </s> add             if subpattern is not None and self.name == subpattern.name: </s> remove         default = 'utf-8-sig'\n </s> add         default = \"utf-8-sig\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> #  Taken from Python (r53757) and modified to include some tokens\n <mask> #   originally monkeypatched in by pgen2.tokenize\n <mask> \n <mask> #--start constants--\n <mask> ENDMARKER = 0\n <mask> NAME = 1\n <mask> NUMBER = 2\n <mask> STRING = 3\n <mask> NEWLINE = 4\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE,\n                                                  cache_dir)\n </s> add     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE, cache_dir) </s> remove         self.first = {} # map from symbol name to set of tokens\n </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove         self.gettoken() # Initialize lookahead\n </s> add         self.gettoken()  # Initialize lookahead </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels\n </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove #--end constants--\n </s> add # --end constants-- </s> remove             if pseudomatch:                                # scan for tokens\n </s> add             if pseudomatch:  # scan for tokens", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/token.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ERRORTOKEN = 58\n <mask> COLONEQUAL = 59\n <mask> N_TOKENS = 60\n <mask> NT_OFFSET = 256\n <mask> #--end constants--\n <mask> \n <mask> tok_name = {}\n <mask> for _name, _value in list(globals().items()):\n <mask>     if type(_value) is type(0):\n <mask>         tok_name[_value] = _name\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove #--start constants--\n </s> add # --start constants-- </s> remove         self.first[name] = None # dummy to detect left recursion\n </s> add         self.first[name] = None  # dummy to detect left recursion </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels\n </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove         self.first = {} # map from symbol name to set of tokens\n </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove         self.gettoken() # Initialize lookahead\n </s> add         self.gettoken()  # Initialize lookahead </s> remove                     raise ValueError(\"rule %s is ambiguous; %s is in the\"\n                                     \" first sets of %s as well as %s\" %\n                                     (name, symbol, label, inverse[symbol]))\n </s> add                     raise ValueError(\n                        \"rule %s is ambiguous; %s is in the\"\n                        \" first sets of %s as well as %s\"\n                        % (name, symbol, label, inverse[symbol])\n                    )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/token.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> are the same, except instead of generating tokens, tokeneater is a callback\n <mask> function to which the 5 fields described above are passed as 5 arguments,\n <mask> each time a new token is found.\"\"\"\n <mask> \n <mask> __author__ = 'Ka-Ping Yee <ping@lfw.org>'\n <mask> __credits__ = \\\n <mask>     'GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro'\n <mask> \n <mask> import regex as re\n <mask> from codecs import BOM_UTF8, lookup\n <mask> from blib2to3.pgen2.token import *\n <mask> \n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove __all__ = [x for x in dir(token) if x[0] != '_'] + [\"tokenize\",\n           \"generate_tokens\", \"untokenize\"]\n </s> add __all__ = [x for x in dir(token) if x[0] != \"_\"] + [\n    \"tokenize\",\n    \"generate_tokens\",\n    \"untokenize\",\n] </s> remove     numchars = '0123456789'\n    contstr, needcont = '', 0\n </s> add     numchars = \"0123456789\"\n    contstr, needcont = \"\", 0 </s> remove             if type(val) == int: _type_reprs[val] = name\n </s> add             if type(val) == int:\n                _type_reprs[val] = name </s> remove         with tempfile.NamedTemporaryFile(dir=os.path.dirname(filename), delete=False) as f:\n </s> add         with tempfile.NamedTemporaryFile(\n            dir=os.path.dirname(filename), delete=False\n        ) as f: </s> remove         self.used_names = set() # Aliased to self.rootnode.used_names in pop()\n </s> add         self.used_names = set()  # Aliased to self.rootnode.used_names in pop() </s> remove simple_escapes = {\"a\": \"\\a\",\n                  \"b\": \"\\b\",\n                  \"f\": \"\\f\",\n                  \"n\": \"\\n\",\n                  \"r\": \"\\r\",\n                  \"t\": \"\\t\",\n                  \"v\": \"\\v\",\n                  \"'\": \"'\",\n                  '\"': '\"',\n                  \"\\\\\": \"\\\\\"}\n </s> add simple_escapes = {\n    \"a\": \"\\a\",\n    \"b\": \"\\b\",\n    \"f\": \"\\f\",\n    \"n\": \"\\n\",\n    \"r\": \"\\r\",\n    \"t\": \"\\t\",\n    \"v\": \"\\v\",\n    \"'\": \"'\",\n    '\"': '\"',\n    \"\\\\\": \"\\\\\",\n}\n", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> from codecs import BOM_UTF8, lookup\n <mask> from blib2to3.pgen2.token import *\n <mask> \n <mask> from . import token\n <mask> __all__ = [x for x in dir(token) if x[0] != '_'] + [\"tokenize\",\n <mask>            \"generate_tokens\", \"untokenize\"]\n <mask> del token\n <mask> \n <mask> try:\n <mask>     bytes\n <mask> except NameError:\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove __author__ = 'Ka-Ping Yee <ping@lfw.org>'\n__credits__ = \\\n    'GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro'\n </s> add __author__ = \"Ka-Ping Yee <ping@lfw.org>\"\n__credits__ = \"GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro\" </s> remove             if type(val) == int: _type_reprs[val] = name\n </s> add             if type(val) == int:\n                _type_reprs[val] = name </s> remove \n    def __init__(\n        self,\n        grammar,\n        convert=None,\n        logger=None,\n    ):\n </s> add     def __init__(self, grammar, convert=None, logger=None): </s> remove _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__),\n                                     \"PatternGrammar.txt\")\n </s> add _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__), \"PatternGrammar.txt\") </s> remove     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE,\n                                                  cache_dir)\n </s> add     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE, cache_dir) </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels\n </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep replace replace replace keep keep", "code_tokens": " <mask>     # Support bytes type in Python <= 2.5, so 2to3 turns itself into\n <mask>     # valid Python 3 code.\n <mask>     bytes = str\n <mask> \n <mask> def group(*choices): return '(' + '|'.join(choices) + ')'\n <mask> def any(*choices): return group(*choices) + '*'\n <mask> def maybe(*choices): return group(*choices) + '?'\n <mask> def _combinations(*l):\n <mask>     return set(\n <mask>         x + y for x in l for y in l + (\"\",) if x.casefold() != y.casefold()\n <mask>     )\n <mask> \n <mask> Whitespace = r'[ \\f\\t]*'\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove Whitespace = r'[ \\f\\t]*'\nComment = r'#[^\\r\\n]*'\nIgnore = Whitespace + any(r'\\\\\\r?\\n' + Whitespace) + maybe(Comment)\nName = r'\\w+'  # this is invalid but it's fine because Name comes after Number in all groups\n </s> add  </s> remove __all__ = [x for x in dir(token) if x[0] != '_'] + [\"tokenize\",\n           \"generate_tokens\", \"untokenize\"]\n </s> add __all__ = [x for x in dir(token) if x[0] != \"_\"] + [\n    \"tokenize\",\n    \"generate_tokens\",\n    \"untokenize\",\n] </s> remove             if codec.name != 'utf-8':\n </s> add             if codec.name != \"utf-8\": </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove                 raise SyntaxError('encoding problem: utf-8')\n            encoding += '-sig'\n </s> add                 raise SyntaxError(\"encoding problem: utf-8\")\n            encoding += \"-sig\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep replace replace replace replace", "code_tokens": " <mask>     return set(\n <mask>         x + y for x in l for y in l + (\"\",) if x.casefold() != y.casefold()\n <mask>     )\n <mask> \n <mask> Whitespace = r'[ \\f\\t]*'\n <mask> Comment = r'#[^\\r\\n]*'\n <mask> Ignore = Whitespace + any(r'\\\\\\r?\\n' + Whitespace) + maybe(Comment)\n <mask> Name = r'\\w+'  # this is invalid but it's fine because Name comes after Number in all groups\n <mask> \n <mask> Binnumber = r'0[bB]_?[01]+(?:_[01]+)*'\n <mask> Hexnumber = r'0[xX]_?[\\da-fA-F]+(?:_[\\da-fA-F]+)*[lL]?'\n <mask> Octnumber = r'0[oO]?_?[0-7]+(?:_[0-7]+)*[lL]?'\n <mask> Decnumber = group(r'[1-9]\\d*(?:_\\d+)*[lL]?', '0[lL]?')\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     return set(\n        x + y for x in l for y in l + (\"\",) if x.casefold() != y.casefold()\n    )\n </s> add     return set(x + y for x in l for y in l + (\"\",) if x.casefold() != y.casefold()) </s> remove def group(*choices): return '(' + '|'.join(choices) + ')'\ndef any(*choices): return group(*choices) + '*'\ndef maybe(*choices): return group(*choices) + '?'\n </s> add def group(*choices):\n    return \"(\" + \"|\".join(choices) + \")\"\n\n\ndef any(*choices):\n    return group(*choices) + \"*\"\n\n\ndef maybe(*choices):\n    return group(*choices) + \"?\"\n\n </s> remove Exponent = r'[eE][-+]?\\d+(?:_\\d+)*'\nPointfloat = group(r'\\d+(?:_\\d+)*\\.(?:\\d+(?:_\\d+)*)?', r'\\.\\d+(?:_\\d+)*') + maybe(Exponent)\nExpfloat = r'\\d+(?:_\\d+)*' + Exponent\n </s> add Exponent = r\"[eE][-+]?\\d+(?:_\\d+)*\"\nPointfloat = group(r\"\\d+(?:_\\d+)*\\.(?:\\d+(?:_\\d+)*)?\", r\"\\.\\d+(?:_\\d+)*\") + maybe(\n    Exponent\n)\nExpfloat = r\"\\d+(?:_\\d+)*\" + Exponent </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep replace replace replace keep replace keep keep keep", "code_tokens": " <mask> Intnumber = group(Binnumber, Hexnumber, Octnumber, Decnumber)\n <mask> Exponent = r'[eE][-+]?\\d+(?:_\\d+)*'\n <mask> Pointfloat = group(r'\\d+(?:_\\d+)*\\.(?:\\d+(?:_\\d+)*)?', r'\\.\\d+(?:_\\d+)*') + maybe(Exponent)\n <mask> Expfloat = r'\\d+(?:_\\d+)*' + Exponent\n <mask> Floatnumber = group(Pointfloat, Expfloat)\n <mask> Imagnumber = group(r'\\d+(?:_\\d+)*[jJ]', Floatnumber + r'[jJ]')\n <mask> Number = group(Imagnumber, Floatnumber, Intnumber)\n <mask> \n <mask> # Tail end of ' string.\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove Binnumber = r'0[bB]_?[01]+(?:_[01]+)*'\nHexnumber = r'0[xX]_?[\\da-fA-F]+(?:_[\\da-fA-F]+)*[lL]?'\nOctnumber = r'0[oO]?_?[0-7]+(?:_[0-7]+)*[lL]?'\nDecnumber = group(r'[1-9]\\d*(?:_\\d+)*[lL]?', '0[lL]?')\n </s> add Whitespace = r\"[ \\f\\t]*\"\nComment = r\"#[^\\r\\n]*\"\nIgnore = Whitespace + any(r\"\\\\\\r?\\n\" + Whitespace) + maybe(Comment)\nName = r\"\\w+\"  # this is invalid but it's fine because Name comes after Number in all groups\n\nBinnumber = r\"0[bB]_?[01]+(?:_[01]+)*\"\nHexnumber = r\"0[xX]_?[\\da-fA-F]+(?:_[\\da-fA-F]+)*[lL]?\"\nOctnumber = r\"0[oO]?_?[0-7]+(?:_[0-7]+)*[lL]?\"\nDecnumber = group(r\"[1-9]\\d*(?:_\\d+)*[lL]?\", \"0[lL]?\") </s> remove String = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n               _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"')\n </s> add String = group(\n    _litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n    _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"',\n) </s> remove ContStr = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" +\n                group(\"'\", r'\\\\\\r?\\n'),\n                _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' +\n                group('\"', r'\\\\\\r?\\n'))\nPseudoExtras = group(r'\\\\\\r?\\n', Comment, Triple)\n </s> add ContStr = group(\n    _litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" + group(\"'\", r\"\\\\\\r?\\n\"),\n    _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' + group('\"', r\"\\\\\\r?\\n\"),\n)\nPseudoExtras = group(r\"\\\\\\r?\\n\", Comment, Triple) </s> remove Whitespace = r'[ \\f\\t]*'\nComment = r'#[^\\r\\n]*'\nIgnore = Whitespace + any(r'\\\\\\r?\\n' + Whitespace) + maybe(Comment)\nName = r'\\w+'  # this is invalid but it's fine because Name comes after Number in all groups\n </s> add  </s> remove         if contstr:                            # continued string\n </s> add         if contstr:  # continued string", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep replace replace keep keep keep keep replace replace replace replace keep keep keep keep", "code_tokens": " <mask> # Single-line ' or \" string.\n <mask> String = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n <mask>                _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"')\n <mask> \n <mask> # Because of leftmost-then-longest match semantics, be sure to put the\n <mask> # longest operators first (e.g., if = came before ==, == would get\n <mask> # recognized as two instances of =).\n <mask> Operator = group(r\"\\*\\*=?\", r\">>=?\", r\"<<=?\", r\"<>\", r\"!=\",\n <mask>                  r\"//=?\", r\"->\",\n <mask>                  r\"[+\\-*/%&@|^=<>:]=?\",\n <mask>                  r\"~\")\n <mask> \n <mask> Bracket = '[][(){}]'\n <mask> Special = group(r'\\r?\\n', r'[:;.,`@]')\n <mask> Funny = group(Operator, Bracket, Special)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove Bracket = '[][(){}]'\nSpecial = group(r'\\r?\\n', r'[:;.,`@]')\n </s> add Bracket = \"[][(){}]\"\nSpecial = group(r\"\\r?\\n\", r\"[:;.,`@]\") </s> remove ContStr = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" +\n                group(\"'\", r'\\\\\\r?\\n'),\n                _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' +\n                group('\"', r'\\\\\\r?\\n'))\nPseudoExtras = group(r'\\\\\\r?\\n', Comment, Triple)\n </s> add ContStr = group(\n    _litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" + group(\"'\", r\"\\\\\\r?\\n\"),\n    _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' + group('\"', r\"\\\\\\r?\\n\"),\n)\nPseudoExtras = group(r\"\\\\\\r?\\n\", Comment, Triple) </s> remove Imagnumber = group(r'\\d+(?:_\\d+)*[jJ]', Floatnumber + r'[jJ]')\n </s> add Imagnumber = group(r\"\\d+(?:_\\d+)*[jJ]\", Floatnumber + r\"[jJ]\") </s> remove     type = None    # int: token number (< 256) or symbol number (>= 256)\n </s> add     type = None  # int: token number (< 256) or symbol number (>= 256) </s> remove         self.first = {} # map from symbol name to set of tokens\n </s> add         self.first = {}  # map from symbol name to set of tokens", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                  r\"//=?\", r\"->\",\n <mask>                  r\"[+\\-*/%&@|^=<>:]=?\",\n <mask>                  r\"~\")\n <mask> \n <mask> Bracket = '[][(){}]'\n <mask> Special = group(r'\\r?\\n', r'[:;.,`@]')\n <mask> Funny = group(Operator, Bracket, Special)\n <mask> \n <mask> PlainToken = group(Number, Funny, String, Name)\n <mask> Token = Ignore + PlainToken\n <mask> \n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove Operator = group(r\"\\*\\*=?\", r\">>=?\", r\"<<=?\", r\"<>\", r\"!=\",\n                 r\"//=?\", r\"->\",\n                 r\"[+\\-*/%&@|^=<>:]=?\",\n                 r\"~\")\n </s> add Operator = group(\n    r\"\\*\\*=?\",\n    r\">>=?\",\n    r\"<<=?\",\n    r\"<>\",\n    r\"!=\",\n    r\"//=?\",\n    r\"->\",\n    r\"[+\\-*/%&@|^=<>:]=?\",\n    r\"~\",\n) </s> remove ContStr = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" +\n                group(\"'\", r'\\\\\\r?\\n'),\n                _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' +\n                group('\"', r'\\\\\\r?\\n'))\nPseudoExtras = group(r'\\\\\\r?\\n', Comment, Triple)\n </s> add ContStr = group(\n    _litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" + group(\"'\", r\"\\\\\\r?\\n\"),\n    _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' + group('\"', r\"\\\\\\r?\\n\"),\n)\nPseudoExtras = group(r\"\\\\\\r?\\n\", Comment, Triple) </s> remove Binnumber = r'0[bB]_?[01]+(?:_[01]+)*'\nHexnumber = r'0[xX]_?[\\da-fA-F]+(?:_[\\da-fA-F]+)*[lL]?'\nOctnumber = r'0[oO]?_?[0-7]+(?:_[0-7]+)*[lL]?'\nDecnumber = group(r'[1-9]\\d*(?:_\\d+)*[lL]?', '0[lL]?')\n </s> add Whitespace = r\"[ \\f\\t]*\"\nComment = r\"#[^\\r\\n]*\"\nIgnore = Whitespace + any(r\"\\\\\\r?\\n\" + Whitespace) + maybe(Comment)\nName = r\"\\w+\"  # this is invalid but it's fine because Name comes after Number in all groups\n\nBinnumber = r\"0[bB]_?[01]+(?:_[01]+)*\"\nHexnumber = r\"0[xX]_?[\\da-fA-F]+(?:_[\\da-fA-F]+)*[lL]?\"\nOctnumber = r\"0[oO]?_?[0-7]+(?:_[0-7]+)*[lL]?\"\nDecnumber = group(r\"[1-9]\\d*(?:_\\d+)*[lL]?\", \"0[lL]?\") </s> remove Whitespace = r'[ \\f\\t]*'\nComment = r'#[^\\r\\n]*'\nIgnore = Whitespace + any(r'\\\\\\r?\\n' + Whitespace) + maybe(Comment)\nName = r'\\w+'  # this is invalid but it's fine because Name comes after Number in all groups\n </s> add  </s> remove Exponent = r'[eE][-+]?\\d+(?:_\\d+)*'\nPointfloat = group(r'\\d+(?:_\\d+)*\\.(?:\\d+(?:_\\d+)*)?', r'\\.\\d+(?:_\\d+)*') + maybe(Exponent)\nExpfloat = r'\\d+(?:_\\d+)*' + Exponent\n </s> add Exponent = r\"[eE][-+]?\\d+(?:_\\d+)*\"\nPointfloat = group(r\"\\d+(?:_\\d+)*\\.(?:\\d+(?:_\\d+)*)?\", r\"\\.\\d+(?:_\\d+)*\") + maybe(\n    Exponent\n)\nExpfloat = r\"\\d+(?:_\\d+)*\" + Exponent </s> remove Imagnumber = group(r'\\d+(?:_\\d+)*[jJ]', Floatnumber + r'[jJ]')\n </s> add Imagnumber = group(r\"\\d+(?:_\\d+)*[jJ]\", Floatnumber + r\"[jJ]\")", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> PlainToken = group(Number, Funny, String, Name)\n <mask> Token = Ignore + PlainToken\n <mask> \n <mask> # First (or only) line of ' or \" string.\n <mask> ContStr = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" +\n <mask>                 group(\"'\", r'\\\\\\r?\\n'),\n <mask>                 _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' +\n <mask>                 group('\"', r'\\\\\\r?\\n'))\n <mask> PseudoExtras = group(r'\\\\\\r?\\n', Comment, Triple)\n <mask> PseudoToken = Whitespace + group(PseudoExtras, Number, Funny, ContStr, Name)\n <mask> \n <mask> tokenprog = re.compile(Token, re.UNICODE)\n <mask> pseudoprog = re.compile(PseudoToken, re.UNICODE)\n <mask> single3prog = re.compile(Single3)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove Bracket = '[][(){}]'\nSpecial = group(r'\\r?\\n', r'[:;.,`@]')\n </s> add Bracket = \"[][(){}]\"\nSpecial = group(r\"\\r?\\n\", r\"[:;.,`@]\") </s> remove String = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n               _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"')\n </s> add String = group(\n    _litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n    _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"',\n) </s> remove Imagnumber = group(r'\\d+(?:_\\d+)*[jJ]', Floatnumber + r'[jJ]')\n </s> add Imagnumber = group(r\"\\d+(?:_\\d+)*[jJ]\", Floatnumber + r\"[jJ]\") </s> remove Binnumber = r'0[bB]_?[01]+(?:_[01]+)*'\nHexnumber = r'0[xX]_?[\\da-fA-F]+(?:_[\\da-fA-F]+)*[lL]?'\nOctnumber = r'0[oO]?_?[0-7]+(?:_[0-7]+)*[lL]?'\nDecnumber = group(r'[1-9]\\d*(?:_\\d+)*[lL]?', '0[lL]?')\n </s> add Whitespace = r\"[ \\f\\t]*\"\nComment = r\"#[^\\r\\n]*\"\nIgnore = Whitespace + any(r\"\\\\\\r?\\n\" + Whitespace) + maybe(Comment)\nName = r\"\\w+\"  # this is invalid but it's fine because Name comes after Number in all groups\n\nBinnumber = r\"0[bB]_?[01]+(?:_[01]+)*\"\nHexnumber = r\"0[xX]_?[\\da-fA-F]+(?:_[\\da-fA-F]+)*[lL]?\"\nOctnumber = r\"0[oO]?_?[0-7]+(?:_[0-7]+)*[lL]?\"\nDecnumber = group(r\"[1-9]\\d*(?:_\\d+)*[lL]?\", \"0[lL]?\") </s> remove Exponent = r'[eE][-+]?\\d+(?:_\\d+)*'\nPointfloat = group(r'\\d+(?:_\\d+)*\\.(?:\\d+(?:_\\d+)*)?', r'\\.\\d+(?:_\\d+)*') + maybe(Exponent)\nExpfloat = r'\\d+(?:_\\d+)*' + Exponent\n </s> add Exponent = r\"[eE][-+]?\\d+(?:_\\d+)*\"\nPointfloat = group(r\"\\d+(?:_\\d+)*\\.(?:\\d+(?:_\\d+)*)?\", r\"\\.\\d+(?:_\\d+)*\") + maybe(\n    Exponent\n)\nExpfloat = r\"\\d+(?:_\\d+)*\" + Exponent </s> remove Whitespace = r'[ \\f\\t]*'\nComment = r'#[^\\r\\n]*'\nIgnore = Whitespace + any(r'\\\\\\r?\\n' + Whitespace) + maybe(Comment)\nName = r'\\w+'  # this is invalid but it's fine because Name comes after Number in all groups\n </s> add ", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep keep replace replace replace replace replace keep", "code_tokens": " <mask> double3prog = re.compile(Double3)\n <mask> \n <mask> _strprefixes = (\n <mask>     _combinations('r', 'R', 'f', 'F') |\n <mask>     _combinations('r', 'R', 'b', 'B') |\n <mask>     {'u', 'U', 'ur', 'uR', 'Ur', 'UR'}\n <mask> )\n <mask> \n <mask> endprogs = {\"'\": re.compile(Single), '\"': re.compile(Double),\n <mask>             \"'''\": single3prog, '\"\"\"': double3prog,\n <mask>             **{f\"{prefix}'''\": single3prog for prefix in _strprefixes},\n <mask>             **{f'{prefix}\"\"\"': double3prog for prefix in _strprefixes},\n <mask>             **{prefix: None for prefix in _strprefixes}}\n <mask> \n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     {\"'''\", '\"\"\"'} |\n    {f\"{prefix}'''\" for prefix in _strprefixes} |\n    {f'{prefix}\"\"\"' for prefix in _strprefixes}\n </s> add     {\"'''\", '\"\"\"'}\n    | {f\"{prefix}'''\" for prefix in _strprefixes}\n    | {f'{prefix}\"\"\"' for prefix in _strprefixes} </s> remove     {\"'\", '\"'} |\n    {f\"{prefix}'\" for prefix in _strprefixes} |\n    {f'{prefix}\"' for prefix in _strprefixes}\n </s> add     {\"'\", '\"'}\n    | {f\"{prefix}'\" for prefix in _strprefixes}\n    | {f'{prefix}\"' for prefix in _strprefixes} </s> remove                 self.logger.debug(\"%s %r (prefix=%r)\",\n                                  token.tok_name[type], value, prefix)\n </s> add                 self.logger.debug(\n                    \"%s %r (prefix=%r)\", token.tok_name[type], value, prefix\n                ) </s> remove     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = True\n </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = (\n        True\n    ) </s> remove         for dict_attr in (\"symbol2number\", \"number2symbol\", \"dfas\", \"keywords\",\n                          \"tokens\", \"symbol2label\"):\n </s> add         for dict_attr in (\n            \"symbol2number\",\n            \"number2symbol\",\n            \"dfas\",\n            \"keywords\",\n            \"tokens\",\n            \"symbol2label\",\n        ):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep keep replace replace replace keep", "code_tokens": " <mask>             **{prefix: None for prefix in _strprefixes}}\n <mask> \n <mask> triple_quoted = (\n <mask>     {\"'''\", '\"\"\"'} |\n <mask>     {f\"{prefix}'''\" for prefix in _strprefixes} |\n <mask>     {f'{prefix}\"\"\"' for prefix in _strprefixes}\n <mask> )\n <mask> single_quoted = (\n <mask>     {\"'\", '\"'} |\n <mask>     {f\"{prefix}'\" for prefix in _strprefixes} |\n <mask>     {f'{prefix}\"' for prefix in _strprefixes}\n <mask> )\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove endprogs = {\"'\": re.compile(Single), '\"': re.compile(Double),\n            \"'''\": single3prog, '\"\"\"': double3prog,\n            **{f\"{prefix}'''\": single3prog for prefix in _strprefixes},\n            **{f'{prefix}\"\"\"': double3prog for prefix in _strprefixes},\n            **{prefix: None for prefix in _strprefixes}}\n </s> add endprogs = {\n    \"'\": re.compile(Single),\n    '\"': re.compile(Double),\n    \"'''\": single3prog,\n    '\"\"\"': double3prog,\n    **{f\"{prefix}'''\": single3prog for prefix in _strprefixes},\n    **{f'{prefix}\"\"\"': double3prog for prefix in _strprefixes},\n    **{prefix: None for prefix in _strprefixes},\n} </s> remove     _combinations('r', 'R', 'f', 'F') |\n    _combinations('r', 'R', 'b', 'B') |\n    {'u', 'U', 'ur', 'uR', 'Ur', 'UR'}\n </s> add     _combinations(\"r\", \"R\", \"f\", \"F\")\n    | _combinations(\"r\", \"R\", \"b\", \"B\")\n    | {\"u\", \"U\", \"ur\", \"uR\", \"Ur\", \"UR\"} </s> remove                 self.logger.debug(\"%s %r (prefix=%r)\",\n                                  token.tok_name[type], value, prefix)\n </s> add                 self.logger.debug(\n                    \"%s %r (prefix=%r)\", token.tok_name[type], value, prefix\n                ) </s> remove     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = True\n </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = (\n        True\n    ) </s> remove         for dict_attr in (\"symbol2number\", \"number2symbol\", \"dfas\", \"keywords\",\n                          \"tokens\", \"symbol2label\"):\n </s> add         for dict_attr in (\n            \"symbol2number\",\n            \"number2symbol\",\n            \"dfas\",\n            \"keywords\",\n            \"tokens\",\n            \"symbol2label\",\n        ):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep replace keep replace keep keep keep keep", "code_tokens": " <mask> tabsize = 8\n <mask> \n <mask> class TokenError(Exception): pass\n <mask> \n <mask> class StopTokenizing(Exception): pass\n <mask> \n <mask> def printtoken(type, token, xxx_todo_changeme, xxx_todo_changeme1, line): # for testing\n <mask>     (srow, scol) = xxx_todo_changeme\n <mask>     (erow, ecol) = xxx_todo_changeme1\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove def printtoken(type, token, xxx_todo_changeme, xxx_todo_changeme1, line): # for testing\n </s> add def printtoken(type, token, xxx_todo_changeme, xxx_todo_changeme1, line):  # for testing </s> remove     print(\"%d,%d-%d,%d:\\t%s\\t%s\" % \\\n        (srow, scol, erow, ecol, tok_name[type], repr(token)))\n </s> add     print(\n        \"%d,%d-%d,%d:\\t%s\\t%s\" % (srow, scol, erow, ecol, tok_name[type], repr(token))\n    )\n </s> remove     {\"'\", '\"'} |\n    {f\"{prefix}'\" for prefix in _strprefixes} |\n    {f'{prefix}\"' for prefix in _strprefixes}\n </s> add     {\"'\", '\"'}\n    | {f\"{prefix}'\" for prefix in _strprefixes}\n    | {f'{prefix}\"' for prefix in _strprefixes} </s> add class ParserGenerator(object): </s> remove class ParserGenerator(object):\n </s> add ", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep keep keep keep replace replace keep keep keep keep", "code_tokens": " <mask> class TokenError(Exception): pass\n <mask> \n <mask> class StopTokenizing(Exception): pass\n <mask> \n <mask> def printtoken(type, token, xxx_todo_changeme, xxx_todo_changeme1, line): # for testing\n <mask>     (srow, scol) = xxx_todo_changeme\n <mask>     (erow, ecol) = xxx_todo_changeme1\n <mask>     print(\"%d,%d-%d,%d:\\t%s\\t%s\" % \\\n <mask>         (srow, scol, erow, ecol, tok_name[type], repr(token)))\n <mask> \n <mask> def printtoken(type, token, xxx_todo_changeme, xxx_todo_changeme1, line): # for testing\n <mask>     (srow, scol) = xxx_todo_changeme\n <mask>     (erow, ecol) = xxx_todo_changeme1\n <mask>     print(\"%d,%d-%d,%d:\\t%s\\t%s\" % \\\n <mask>         (srow, scol, erow, ecol, tok_name[type], repr(token)))\n <mask> \n <mask> def tokenize(readline, tokeneater=printtoken):\n <mask>     \"\"\"\n <mask>     The tokenize() function accepts two parameters: one representing the\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove class StopTokenizing(Exception): pass\n </s> add class TokenError(Exception):\n    pass\n\n\nclass StopTokenizing(Exception):\n    pass\n </s> remove class TokenError(Exception): pass\n </s> add  </s> remove class ParserGenerator(object):\n </s> add  </s> add class ParserGenerator(object): </s> remove                         strstart = (lnum, start)           # multiple lines\n </s> add                         strstart = (lnum, start)  # multiple lines", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> def tokenize_loop(readline, tokeneater):\n <mask>     for token_info in generate_tokens(readline):\n <mask>         tokeneater(*token_info)\n <mask> \n <mask> class Untokenizer:\n <mask> \n <mask>     def __init__(self):\n <mask>         self.tokens = []\n <mask>         self.prev_row = 1\n <mask>         self.prev_col = 0\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> add class Untokenizer: </s> remove class NFAState(object):\n </s> add  </s> remove         self.arcs = [] # list of (label, NFAState) pairs\n </s> add         self.arcs = []  # list of (label, NFAState) pairs </s> add class NFAState(object): </s> remove         raise SyntaxError(msg, (self.filename, self.end[0],\n                                self.end[1], self.line))\n </s> add         raise SyntaxError(msg, (self.filename, self.end[0], self.end[1], self.line)) </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels\n </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask>     def __init__(self):\n <mask>         self.tokens = []\n <mask>         self.prev_row = 1\n <mask>         self.prev_col = 0\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove class Untokenizer:\n </s> add  </s> remove         self.arcs = [] # list of (label, NFAState) pairs\n </s> add         self.arcs = []  # list of (label, NFAState) pairs </s> remove class NFAState(object):\n </s> add  </s> remove         raise SyntaxError(msg, (self.filename, self.end[0],\n                                self.end[1], self.line))\n </s> add         raise SyntaxError(msg, (self.filename, self.end[0], self.end[1], self.line)) </s> add class NFAState(object): </s> remove             elif char in ' \\t':\n </s> add             elif char in \" \\t\":", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         indents = []\n <mask>         toks_append = self.tokens.append\n <mask>         toknum, tokval = token\n <mask>         if toknum in (NAME, NUMBER):\n <mask>             tokval += ' '\n <mask>         if toknum in (NEWLINE, NL):\n <mask>             startline = True\n <mask>         for tok in iterable:\n <mask>             toknum, tokval = tok[:2]\n <mask> \n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 tokval += ' '\n </s> add                 tokval += \" \" </s> remove                     if token == 'async' and not stashed:\n </s> add                     if token == \"async\" and not stashed: </s> remove                     if token in ('def', 'for'):\n                        if (stashed\n                                and stashed[0] == NAME\n                                and stashed[1] == 'async'):\n </s> add                     if token in (\"def\", \"for\"):\n                        if stashed and stashed[0] == NAME and stashed[1] == \"async\": </s> remove             elif char == '\\n':\n </s> add             elif char == \"\\n\": </s> remove                             yield (ASYNC if token == 'async' else AWAIT,\n                                   token, spos, epos, line)\n </s> add                             yield (\n                                ASYNC if token == \"async\" else AWAIT,\n                                token,\n                                spos,\n                                epos,\n                                line,\n                            ) </s> remove         default = 'utf-8-sig'\n </s> add         default = \"utf-8-sig\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         for tok in iterable:\n <mask>             toknum, tokval = tok[:2]\n <mask> \n <mask>             if toknum in (NAME, NUMBER, ASYNC, AWAIT):\n <mask>                 tokval += ' '\n <mask> \n <mask>             if toknum == INDENT:\n <mask>                 indents.append(tokval)\n <mask>                 continue\n <mask>             elif toknum == DEDENT:\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             tokval += ' '\n </s> add             tokval += \" \" </s> remove                     if token == 'async' and not stashed:\n </s> add                     if token == \"async\" and not stashed: </s> remove                             yield (ASYNC if token == 'async' else AWAIT,\n                                   token, spos, epos, line)\n </s> add                             yield (\n                                ASYNC if token == \"async\" else AWAIT,\n                                token,\n                                spos,\n                                epos,\n                                line,\n                            ) </s> remove             if not line: break\n </s> add             if not line:\n                break </s> remove             elif char == '\\n':\n </s> add             elif char == \"\\n\": </s> remove             elif char in ' \\t':\n </s> add             elif char in \" \\t\":", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 toks_append(indents[-1])\n <mask>                 startline = False\n <mask>             toks_append(tokval)\n <mask> \n <mask> cookie_re = re.compile(r'^[ \\t\\f]*#.*?coding[:=][ \\t]*([-\\w.]+)', re.ASCII)\n <mask> blank_re = re.compile(br'^[ \\t\\f]*(?:[#\\r\\n]|$)', re.ASCII)\n <mask> \n <mask> def _get_normal_name(orig_enc):\n <mask>     \"\"\"Imitates get_normal_name in tokenizer.c.\"\"\"\n <mask>     # Only care about the first 12 characters.\n <mask>     enc = orig_enc[:12].lower().replace(\"_\", \"-\")\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     if enc in (\"latin-1\", \"iso-8859-1\", \"iso-latin-1\") or \\\n       enc.startswith((\"latin-1-\", \"iso-8859-1-\", \"iso-latin-1-\")):\n </s> add     if enc in (\"latin-1\", \"iso-8859-1\", \"iso-latin-1\") or enc.startswith(\n        (\"latin-1-\", \"iso-8859-1-\", \"iso-latin-1-\")\n    ): </s> remove     while 1:                                   # loop over lines in stream\n </s> add     while 1:  # loop over lines in stream </s> remove         else:                                  # continued statement\n </s> add         else:  # continued statement </s> remove         default = 'utf-8-sig'\n </s> add         default = \"utf-8-sig\" </s> remove Operator = group(r\"\\*\\*=?\", r\">>=?\", r\"<<=?\", r\"<>\", r\"!=\",\n                 r\"//=?\", r\"->\",\n                 r\"[+\\-*/%&@|^=<>:]=?\",\n                 r\"~\")\n </s> add Operator = group(\n    r\"\\*\\*=?\",\n    r\">>=?\",\n    r\"<<=?\",\n    r\"<>\",\n    r\"!=\",\n    r\"//=?\",\n    r\"->\",\n    r\"[+\\-*/%&@|^=<>:]=?\",\n    r\"~\",\n) </s> remove String = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n               _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"')\n </s> add String = group(\n    _litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n    _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"',\n)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     # Only care about the first 12 characters.\n <mask>     enc = orig_enc[:12].lower().replace(\"_\", \"-\")\n <mask>     if enc == \"utf-8\" or enc.startswith(\"utf-8-\"):\n <mask>         return \"utf-8\"\n <mask>     if enc in (\"latin-1\", \"iso-8859-1\", \"iso-latin-1\") or \\\n <mask>        enc.startswith((\"latin-1-\", \"iso-8859-1-\", \"iso-latin-1-\")):\n <mask>         return \"iso-8859-1\"\n <mask>     return orig_enc\n <mask> \n <mask> def detect_encoding(readline):\n <mask>     \"\"\"\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove cookie_re = re.compile(r'^[ \\t\\f]*#.*?coding[:=][ \\t]*([-\\w.]+)', re.ASCII)\nblank_re = re.compile(br'^[ \\t\\f]*(?:[#\\r\\n]|$)', re.ASCII)\n </s> add cookie_re = re.compile(r\"^[ \\t\\f]*#.*?coding[:=][ \\t]*([-\\w.]+)\", re.ASCII)\nblank_re = re.compile(br\"^[ \\t\\f]*(?:[#\\r\\n]|$)\", re.ASCII)\n </s> remove     default = 'utf-8'\n </s> add     default = \"utf-8\"\n </s> remove                 elif initial in single_quoted or \\\n                    token[:2] in single_quoted or \\\n                    token[:3] in single_quoted:\n                    if token[-1] == '\\n':                  # continued string\n </s> add                 elif (\n                    initial in single_quoted\n                    or token[:2] in single_quoted\n                    or token[:3] in single_quoted\n                ):\n                    if token[-1] == \"\\n\":  # continued string </s> remove                         endprog = (endprogs[initial] or endprogs[token[1]] or\n                                   endprogs[token[2]])\n </s> add                         endprog = (\n                            endprogs[initial]\n                            or endprogs[token[1]]\n                            or endprogs[token[2]]\n                        ) </s> remove                 raise SyntaxError('encoding problem: utf-8')\n            encoding += '-sig'\n </s> add                 raise SyntaxError(\"encoding problem: utf-8\")\n            encoding += \"-sig\" </s> remove         default = 'utf-8-sig'\n </s> add         default = \"utf-8-sig\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     If no encoding is specified, then the default of 'utf-8' will be returned.\n <mask>     \"\"\"\n <mask>     bom_found = False\n <mask>     encoding = None\n <mask>     default = 'utf-8'\n <mask>     def read_or_stop():\n <mask>         try:\n <mask>             return readline()\n <mask>         except StopIteration:\n <mask>             return bytes()\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         default = 'utf-8-sig'\n </s> add         default = \"utf-8-sig\" </s> remove             line_string = line.decode('ascii')\n </s> add             line_string = line.decode(\"ascii\") </s> remove                 raise SyntaxError('encoding problem: utf-8')\n            encoding += '-sig'\n </s> add                 raise SyntaxError(\"encoding problem: utf-8\")\n            encoding += \"-sig\" </s> remove     while 1:                                   # loop over lines in stream\n </s> add     while 1:  # loop over lines in stream </s> remove             line = ''\n </s> add             line = \"\" </s> remove     type = None    # int: token number (< 256) or symbol number (>= 256)\n </s> add     type = None  # int: token number (< 256) or symbol number (>= 256)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return bytes()\n <mask> \n <mask>     def find_cookie(line):\n <mask>         try:\n <mask>             line_string = line.decode('ascii')\n <mask>         except UnicodeDecodeError:\n <mask>             return None\n <mask>         match = cookie_re.match(line_string)\n <mask>         if not match:\n <mask>             return None\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     default = 'utf-8'\n </s> add     default = \"utf-8\"\n </s> remove     __hash__ = None # For Py3 compatibility.\n </s> add     __hash__ = None  # For Py3 compatibility.\n </s> remove     __hash__ = None # For Py3 compatibility.\n </s> add     __hash__ = None  # For Py3 compatibility. </s> remove     name = None     # Optional name used to store match in results dict\n </s> add     name = None  # Optional name used to store match in results dict </s> remove             if subpattern is not None and  self.name == subpattern.name:\n </s> add             if subpattern is not None and self.name == subpattern.name: </s> remove         if (self.content is not None and\n            len(self.content) == 1 and len(self.content[0]) == 1):\n </s> add         if (\n            self.content is not None\n            and len(self.content) == 1\n            and len(self.content[0]) == 1\n        ):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep keep keep keep replace replace keep", "code_tokens": " <mask>             # This behaviour mimics the Python interpreter\n <mask>             raise SyntaxError(\"unknown encoding: \" + encoding)\n <mask> \n <mask>         if bom_found:\n <mask>             if codec.name != 'utf-8':\n <mask>                 # This behaviour mimics the Python interpreter\n <mask>                 raise SyntaxError('encoding problem: utf-8')\n <mask>             encoding += '-sig'\n <mask>         return encoding\n <mask> \n <mask>         if bom_found:\n <mask>             if codec.name != 'utf-8':\n <mask>                 # This behaviour mimics the Python interpreter\n <mask>                 raise SyntaxError('encoding problem: utf-8')\n <mask>             encoding += '-sig'\n <mask>         return encoding\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         default = 'utf-8-sig'\n </s> add         default = \"utf-8-sig\" </s> remove     default = 'utf-8'\n </s> add     default = \"utf-8\"\n </s> remove def group(*choices): return '(' + '|'.join(choices) + ')'\ndef any(*choices): return group(*choices) + '*'\ndef maybe(*choices): return group(*choices) + '?'\n </s> add def group(*choices):\n    return \"(\" + \"|\".join(choices) + \")\"\n\n\ndef any(*choices):\n    return group(*choices) + \"*\"\n\n\ndef maybe(*choices):\n    return group(*choices) + \"?\"\n\n </s> remove             raise parse.ParseError(\"incomplete input\",\n                                   type, value, (prefix, start))\n </s> add             raise parse.ParseError(\"incomplete input\", type, value, (prefix, start)) </s> remove                 elif initial == '\\\\':                      # continued stmt\n </s> add                 elif initial == \"\\\\\":  # continued stmt", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     first = read_or_stop()\n <mask>     if first.startswith(BOM_UTF8):\n <mask>         bom_found = True\n <mask>         first = first[3:]\n <mask>         default = 'utf-8-sig'\n <mask>     if not first:\n <mask>         return default, []\n <mask> \n <mask>     encoding = find_cookie(first)\n <mask>     if encoding:\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 raise SyntaxError('encoding problem: utf-8')\n            encoding += '-sig'\n </s> add                 raise SyntaxError(\"encoding problem: utf-8\")\n            encoding += \"-sig\" </s> remove     default = 'utf-8'\n </s> add     default = \"utf-8\"\n </s> remove     __hash__ = None # For Py3 compatibility.\n </s> add     __hash__ = None  # For Py3 compatibility.\n </s> remove             tokval += ' '\n </s> add             tokval += \" \" </s> remove         return ''.join(lines), current_line\n </s> add         return \"\".join(lines), current_line </s> remove             line_string = line.decode('ascii')\n </s> add             line_string = line.decode(\"ascii\")", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     and the line on which the token was found. The line passed is the\n <mask>     logical line; continuation lines are included.\n <mask>     \"\"\"\n <mask>     lnum = parenlev = continued = 0\n <mask>     numchars = '0123456789'\n <mask>     contstr, needcont = '', 0\n <mask>     contline = None\n <mask>     indents = [0]\n <mask> \n <mask>     # If we know we're parsing 3.7+, we can unconditionally parse `async` and\n <mask>     # `await` as keywords.\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             elif needcont and line[-2:] != '\\\\\\n' and line[-3:] != '\\\\\\r\\n':\n                yield (ERRORTOKEN, contstr + line,\n                           strstart, (lnum, len(line)), contline)\n                contstr = ''\n </s> add             elif needcont and line[-2:] != \"\\\\\\n\" and line[-3:] != \"\\\\\\r\\n\":\n                yield (\n                    ERRORTOKEN,\n                    contstr + line,\n                    strstart,\n                    (lnum, len(line)),\n                    contline,\n                )\n                contstr = \"\" </s> remove                 yield (STRING, contstr + line[:end],\n                       strstart, (lnum, end), contline + line)\n                contstr, needcont = '', 0\n </s> add                 yield (\n                    STRING,\n                    contstr + line[:end],\n                    strstart,\n                    (lnum, end),\n                    contline + line,\n                )\n                contstr, needcont = \"\", 0 </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove     lineno = 0    # Line where this token starts in the input\n    column = 0    # Column where this token starts in the input\n </s> add     lineno = 0  # Line where this token starts in the input\n    column = 0  # Column where this token starts in the input </s> remove     while 1:                                   # loop over lines in stream\n </s> add     while 1:  # loop over lines in stream </s> remove __author__ = 'Ka-Ping Yee <ping@lfw.org>'\n__credits__ = \\\n    'GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro'\n </s> add __author__ = \"Ka-Ping Yee <ping@lfw.org>\"\n__credits__ = \"GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep replace keep keep keep replace keep", "code_tokens": " <mask>     async_def_nl = False\n <mask> \n <mask>     while 1:                                   # loop over lines in stream\n <mask>         try:\n <mask>             line = readline()\n <mask>         except StopIteration:\n <mask>             line = ''\n <mask>         lnum = lnum + 1\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         if contstr:                            # continued string\n </s> add         if contstr:  # continued string </s> remove     default = 'utf-8'\n </s> add     default = \"utf-8\"\n </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f)\n </s> add         lineno, line = lineno + 1, next(f) </s> remove     numchars = '0123456789'\n    contstr, needcont = '', 0\n </s> add     numchars = \"0123456789\"\n    contstr, needcont = \"\", 0", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             line = ''\n <mask>         lnum = lnum + 1\n <mask>         pos, max = 0, len(line)\n <mask> \n <mask>         if contstr:                            # continued string\n <mask>             if not line:\n <mask>                 raise TokenError(\"EOF in multi-line string\", strstart)\n <mask>             endmatch = endprog.match(line)\n <mask>             if endmatch:\n <mask>                 pos = end = endmatch.end(0)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             line = ''\n </s> add             line = \"\" </s> remove                 yield (STRING, contstr + line[:end],\n                       strstart, (lnum, end), contline + line)\n                contstr, needcont = '', 0\n </s> add                 yield (\n                    STRING,\n                    contstr + line[:end],\n                    strstart,\n                    (lnum, end),\n                    contline + line,\n                )\n                contstr, needcont = \"\", 0 </s> remove         else:                                  # continued statement\n </s> add         else:  # continued statement </s> remove                     if endmatch:                           # all on one line\n </s> add                     if endmatch:  # all on one line </s> remove     while 1:                                   # loop over lines in stream\n </s> add     while 1:  # loop over lines in stream </s> remove             if not line: break\n </s> add             if not line:\n                break", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep replace replace replace keep replace replace replace replace keep keep", "code_tokens": " <mask>                 pos = end = endmatch.end(0)\n <mask>                 yield (STRING, contstr + line[:end],\n <mask>                        strstart, (lnum, end), contline + line)\n <mask>                 contstr, needcont = '', 0\n <mask>                 contline = None\n <mask>             elif needcont and line[-2:] != '\\\\\\n' and line[-3:] != '\\\\\\r\\n':\n <mask>                 yield (ERRORTOKEN, contstr + line,\n <mask>                            strstart, (lnum, len(line)), contline)\n <mask>                 contstr = ''\n <mask>                 contline = None\n <mask>                 continue\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                         strstart = (lnum, start)           # multiple lines\n </s> add                         strstart = (lnum, start)  # multiple lines </s> remove                     else:                                  # ordinary string\n </s> add                     else:  # ordinary string </s> remove                 elif initial in single_quoted or \\\n                    token[:2] in single_quoted or \\\n                    token[:3] in single_quoted:\n                    if token[-1] == '\\n':                  # continued string\n </s> add                 elif (\n                    initial in single_quoted\n                    or token[:2] in single_quoted\n                    or token[:3] in single_quoted\n                ):\n                    if token[-1] == \"\\n\":  # continued string </s> remove     numchars = '0123456789'\n    contstr, needcont = '', 0\n </s> add     numchars = \"0123456789\"\n    contstr, needcont = \"\", 0 </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line)\n </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep replace keep replace replace replace replace replace keep keep", "code_tokens": " <mask>         elif parenlev == 0 and not continued:  # new statement\n <mask>             if not line: break\n <mask>             column = 0\n <mask>             while pos < max:                   # measure leading whitespace\n <mask>                 if line[pos] == ' ': column = column + 1\n <mask>                 elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n <mask>                 elif line[pos] == '\\f': column = 0\n <mask>                 else: break\n <mask>                 pos = pos + 1\n <mask>             if pos == max: break\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             if pos == max: break\n </s> add             if pos == max:\n                break </s> remove         else:                                  # continued statement\n </s> add         else:  # continued statement </s> remove                 yield (COMMENT, comment_token,\n                        (lnum, pos), (lnum, pos + len(comment_token)), line)\n                yield (NL, line[nl_pos:],\n                        (lnum, nl_pos), (lnum, len(line)), line)\n </s> add                 yield (\n                    COMMENT,\n                    comment_token,\n                    (lnum, pos),\n                    (lnum, pos + len(comment_token)),\n                    line,\n                )\n                yield (NL, line[nl_pos:], (lnum, nl_pos), (lnum, len(line)), line) </s> remove             if line[pos] == '#':               # skip comments\n                comment_token = line[pos:].rstrip('\\r\\n')\n </s> add             if line[pos] == \"#\":  # skip comments\n                comment_token = line[pos:].rstrip(\"\\r\\n\") </s> remove             if pseudomatch:                                # scan for tokens\n </s> add             if pseudomatch:  # scan for tokens", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n <mask>                 elif line[pos] == '\\f': column = 0\n <mask>                 else: break\n <mask>                 pos = pos + 1\n <mask>             if pos == max: break\n <mask> \n <mask>             if stashed:\n <mask>                 yield stashed\n <mask>                 stashed = None\n <mask> \n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ': column = column + 1\n                elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f': column = 0\n                else: break\n </s> add             while pos < max:  # measure leading whitespace\n                if line[pos] == \" \":\n                    column = column + 1\n                elif line[pos] == \"\\t\":\n                    column = (column // tabsize + 1) * tabsize\n                elif line[pos] == \"\\f\":\n                    column = 0\n                else:\n                    break </s> remove             if not line: break\n </s> add             if not line:\n                break </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line)\n </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line) </s> remove                     else:                                  # ordinary string\n </s> add                     else:  # ordinary string </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1\n </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1 </s> remove             if line[pos] == '#':               # skip comments\n                comment_token = line[pos:].rstrip('\\r\\n')\n </s> add             if line[pos] == \"#\":  # skip comments\n                comment_token = line[pos:].rstrip(\"\\r\\n\")", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace replace", "code_tokens": " <mask>                 yield stashed\n <mask>                 stashed = None\n <mask> \n <mask>             if line[pos] in '\\r\\n':            # skip blank lines\n <mask>                 yield (NL, line[pos:], (lnum, pos), (lnum, len(line)), line)\n <mask>                 continue\n <mask> \n <mask>             if line[pos] == '#':               # skip comments\n <mask>                 comment_token = line[pos:].rstrip('\\r\\n')\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 yield (COMMENT, comment_token,\n                        (lnum, pos), (lnum, pos + len(comment_token)), line)\n                yield (NL, line[nl_pos:],\n                        (lnum, nl_pos), (lnum, len(line)), line)\n </s> add                 yield (\n                    COMMENT,\n                    comment_token,\n                    (lnum, pos),\n                    (lnum, pos + len(comment_token)),\n                    line,\n                )\n                yield (NL, line[nl_pos:], (lnum, nl_pos), (lnum, len(line)), line) </s> remove                 elif initial == '\\\\':                      # continued stmt\n </s> add                 elif initial == \"\\\\\":  # continued stmt </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line)\n </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line) </s> remove                         strstart = (lnum, start)           # multiple lines\n </s> add                         strstart = (lnum, start)  # multiple lines </s> remove             if column > indents[-1]:           # count indents\n </s> add             if column > indents[-1]:  # count indents", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep replace keep", "code_tokens": " <mask> \n <mask>             if line[pos] == '#':               # skip comments\n <mask>                 comment_token = line[pos:].rstrip('\\r\\n')\n <mask>                 nl_pos = pos + len(comment_token)\n <mask>                 yield (COMMENT, comment_token,\n <mask>                         (lnum, pos), (lnum, pos + len(comment_token)), line)\n <mask>                 yield (NL, line[nl_pos:],\n <mask>                         (lnum, nl_pos), (lnum, len(line)), line)\n <mask>                 continue\n <mask> \n <mask>             if column > indents[-1]:           # count indents\n <mask>                 indents.append(column)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             if line[pos] == '#':               # skip comments\n                comment_token = line[pos:].rstrip('\\r\\n')\n </s> add             if line[pos] == \"#\":  # skip comments\n                comment_token = line[pos:].rstrip(\"\\r\\n\") </s> remove             if line[pos] in '\\r\\n':            # skip blank lines\n </s> add             if line[pos] in \"\\r\\n\":  # skip blank lines </s> remove             while column < indents[-1]:        # count dedents\n </s> add             while column < indents[-1]:  # count dedents </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line)\n </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line) </s> remove                 yield (DEDENT, '', (lnum, pos), (lnum, pos), line)\n </s> add                 yield (DEDENT, \"\", (lnum, pos), (lnum, pos), line)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask>             if column > indents[-1]:           # count indents\n <mask>                 indents.append(column)\n <mask>                 yield (INDENT, line[:pos], (lnum, 0), (lnum, pos), line)\n <mask> \n <mask>             while column < indents[-1]:        # count dedents\n <mask>                 if column not in indents:\n <mask>                     raise IndentationError(\n <mask>                         \"unindent does not match any outer indentation level\",\n <mask>                         (\"<tokenize>\", lnum, pos, line))\n <mask>                 indents = indents[:-1]\n <mask> \n <mask>                 if async_def and async_def_indent >= indents[-1]:\n <mask>                     async_def = False\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             if column > indents[-1]:           # count indents\n </s> add             if column > indents[-1]:  # count indents </s> remove                 yield (COMMENT, comment_token,\n                        (lnum, pos), (lnum, pos + len(comment_token)), line)\n                yield (NL, line[nl_pos:],\n                        (lnum, nl_pos), (lnum, len(line)), line)\n </s> add                 yield (\n                    COMMENT,\n                    comment_token,\n                    (lnum, pos),\n                    (lnum, pos + len(comment_token)),\n                    line,\n                )\n                yield (NL, line[nl_pos:], (lnum, nl_pos), (lnum, len(line)), line) </s> remove                 yield (DEDENT, '', (lnum, pos), (lnum, pos), line)\n </s> add                 yield (DEDENT, \"\", (lnum, pos), (lnum, pos), line) </s> remove         else:                                  # continued statement\n </s> add         else:  # continued statement </s> remove             while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ': column = column + 1\n                elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f': column = 0\n                else: break\n </s> add             while pos < max:  # measure leading whitespace\n                if line[pos] == \" \":\n                    column = column + 1\n                elif line[pos] == \"\\t\":\n                    column = (column // tabsize + 1) * tabsize\n                elif line[pos] == \"\\f\":\n                    column = 0\n                else:\n                    break", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     async_def = False\n <mask>                     async_def_nl = False\n <mask>                     async_def_indent = 0\n <mask> \n <mask>                 yield (DEDENT, '', (lnum, pos), (lnum, pos), line)\n <mask> \n <mask>             if async_def and async_def_nl and async_def_indent >= indents[-1]:\n <mask>                 async_def = False\n <mask>                 async_def_nl = False\n <mask>                 async_def_indent = 0\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         else:                                  # continued statement\n </s> add         else:  # continued statement </s> remove                         (\"<tokenize>\", lnum, pos, line))\n </s> add                         (\"<tokenize>\", lnum, pos, line),\n                    ) </s> remove     while 1:                                   # loop over lines in stream\n </s> add     while 1:  # loop over lines in stream </s> remove                             if token == 'def':\n </s> add                             if token == \"def\": </s> remove                             yield (ASYNC, stashed[1],\n                                   stashed[2], stashed[3],\n                                   stashed[4])\n </s> add                             yield (\n                                ASYNC,\n                                stashed[1],\n                                stashed[2],\n                                stashed[3],\n                                stashed[4],\n                            ) </s> remove                     if token in ('def', 'for'):\n                        if (stashed\n                                and stashed[0] == NAME\n                                and stashed[1] == 'async'):\n </s> add                     if token in (\"def\", \"for\"):\n                        if stashed and stashed[0] == NAME and stashed[1] == \"async\":", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 async_def = False\n <mask>                 async_def_nl = False\n <mask>                 async_def_indent = 0\n <mask> \n <mask>         else:                                  # continued statement\n <mask>             if not line:\n <mask>                 raise TokenError(\"EOF in multi-line statement\", (lnum, 0))\n <mask>             continued = 0\n <mask> \n <mask>         while pos < max:\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 yield (DEDENT, '', (lnum, pos), (lnum, pos), line)\n </s> add                 yield (DEDENT, \"\", (lnum, pos), (lnum, pos), line) </s> remove         if contstr:                            # continued string\n </s> add         if contstr:  # continued string </s> remove             while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ': column = column + 1\n                elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f': column = 0\n                else: break\n </s> add             while pos < max:  # measure leading whitespace\n                if line[pos] == \" \":\n                    column = column + 1\n                elif line[pos] == \"\\t\":\n                    column = (column // tabsize + 1) * tabsize\n                elif line[pos] == \"\\f\":\n                    column = 0\n                else:\n                    break </s> remove                         (\"<tokenize>\", lnum, pos, line))\n </s> add                         (\"<tokenize>\", lnum, pos, line),\n                    ) </s> remove             if not line: break\n </s> add             if not line:\n                break </s> remove             if pseudomatch:                                # scan for tokens\n </s> add             if pseudomatch:  # scan for tokens", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace replace keep keep keep", "code_tokens": " <mask>         while pos < max:\n <mask>             pseudomatch = pseudoprog.match(line, pos)\n <mask>             if pseudomatch:                                # scan for tokens\n <mask>                 start, end = pseudomatch.span(1)\n <mask>                 spos, epos, pos = (lnum, start), (lnum, end), end\n <mask>                 token, initial = line[start:end], line[start]\n <mask> \n <mask>                 if initial in numchars or \\\n <mask>                    (initial == '.' and token != '.'):      # ordinary number\n <mask>                     yield (NUMBER, token, spos, epos, line)\n <mask>                 elif initial in '\\r\\n':\n <mask>                     newline = NEWLINE\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 elif initial in '\\r\\n':\n </s> add                 elif initial in \"\\r\\n\": </s> remove                 elif initial == '#':\n </s> add                 elif initial == \"#\": </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1\n </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1 </s> remove                             yield (ASYNC if token == 'async' else AWAIT,\n                                   token, spos, epos, line)\n </s> add                             yield (\n                                ASYNC if token == \"async\" else AWAIT,\n                                token,\n                                spos,\n                                epos,\n                                line,\n                            ) </s> remove                         strstart = (lnum, start)           # multiple lines\n </s> add                         strstart = (lnum, start)  # multiple lines", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>                 if initial in numchars or \\\n <mask>                    (initial == '.' and token != '.'):      # ordinary number\n <mask>                     yield (NUMBER, token, spos, epos, line)\n <mask>                 elif initial in '\\r\\n':\n <mask>                     newline = NEWLINE\n <mask>                     if parenlev > 0:\n <mask>                         newline = NL\n <mask>                     elif async_def:\n <mask>                         async_def_nl = True\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 if initial in numchars or \\\n                   (initial == '.' and token != '.'):      # ordinary number\n </s> add                 if initial in numchars or (\n                    initial == \".\" and token != \".\"\n                ):  # ordinary number </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1\n </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1 </s> remove                 elif initial.isidentifier():               # ordinary name\n                    if token in ('async', 'await'):\n </s> add                 elif initial.isidentifier():  # ordinary name\n                    if token in (\"async\", \"await\"): </s> remove                             yield (ASYNC if token == 'async' else AWAIT,\n                                   token, spos, epos, line)\n </s> add                             yield (\n                                ASYNC if token == \"async\" else AWAIT,\n                                token,\n                                spos,\n                                epos,\n                                line,\n                            ) </s> remove                 elif initial == '#':\n </s> add                 elif initial == \"#\": </s> remove             if pseudomatch:                                # scan for tokens\n </s> add             if pseudomatch:  # scan for tokens", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                         yield stashed\n <mask>                         stashed = None\n <mask>                     yield (newline, token, spos, epos, line)\n <mask> \n <mask>                 elif initial == '#':\n <mask>                     assert not token.endswith(\"\\n\")\n <mask>                     if stashed:\n <mask>                         yield stashed\n <mask>                         stashed = None\n <mask>                     yield (COMMENT, token, spos, epos, line)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1\n </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1 </s> remove                 elif initial == '\\\\':                      # continued stmt\n </s> add                 elif initial == \"\\\\\":  # continued stmt </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line)\n </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line) </s> remove                 elif initial.isidentifier():               # ordinary name\n                    if token in ('async', 'await'):\n </s> add                 elif initial.isidentifier():  # ordinary name\n                    if token in (\"async\", \"await\"): </s> remove                     if endmatch:                           # all on one line\n </s> add                     if endmatch:  # all on one line </s> remove                             yield (ASYNC if token == 'async' else AWAIT,\n                                   token, spos, epos, line)\n </s> add                             yield (\n                                ASYNC if token == \"async\" else AWAIT,\n                                token,\n                                spos,\n                                epos,\n                                line,\n                            )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     yield (COMMENT, token, spos, epos, line)\n <mask>                 elif token in triple_quoted:\n <mask>                     endprog = endprogs[token]\n <mask>                     endmatch = endprog.match(line, pos)\n <mask>                     if endmatch:                           # all on one line\n <mask>                         pos = endmatch.end(0)\n <mask>                         token = line[start:pos]\n <mask>                         if stashed:\n <mask>                             yield stashed\n <mask>                             stashed = None\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 elif initial == '#':\n </s> add                 elif initial == \"#\": </s> remove                 elif initial.isidentifier():               # ordinary name\n                    if token in ('async', 'await'):\n </s> add                 elif initial.isidentifier():  # ordinary name\n                    if token in (\"async\", \"await\"): </s> remove                             yield (ASYNC if token == 'async' else AWAIT,\n                                   token, spos, epos, line)\n </s> add                             yield (\n                                ASYNC if token == \"async\" else AWAIT,\n                                token,\n                                spos,\n                                epos,\n                                line,\n                            ) </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line)\n </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line) </s> remove                     else:                                  # ordinary string\n </s> add                     else:  # ordinary string </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1\n </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace replace replace replace", "code_tokens": " <mask>                             stashed = None\n <mask>                         yield (STRING, token, spos, (lnum, pos), line)\n <mask>                     else:\n <mask>                         strstart = (lnum, start)           # multiple lines\n <mask>                         contstr = line[start:]\n <mask>                         contline = line\n <mask>                         break\n <mask>                 elif initial in single_quoted or \\\n <mask>                     token[:2] in single_quoted or \\\n <mask>                     token[:3] in single_quoted:\n <mask>                     if token[-1] == '\\n':                  # continued string\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                         endprog = (endprogs[initial] or endprogs[token[1]] or\n                                   endprogs[token[2]])\n </s> add                         endprog = (\n                            endprogs[initial]\n                            or endprogs[token[1]]\n                            or endprogs[token[2]]\n                        ) </s> remove                     else:                                  # ordinary string\n </s> add                     else:  # ordinary string </s> remove                 elif initial == '\\\\':                      # continued stmt\n </s> add                 elif initial == \"\\\\\":  # continued stmt </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1\n </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1 </s> remove                 if initial in numchars or \\\n                   (initial == '.' and token != '.'):      # ordinary number\n </s> add                 if initial in numchars or (\n                    initial == \".\" and token != \".\"\n                ):  # ordinary number", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep replace keep", "code_tokens": " <mask>                     token[:2] in single_quoted or \\\n <mask>                     token[:3] in single_quoted:\n <mask>                     if token[-1] == '\\n':                  # continued string\n <mask>                         strstart = (lnum, start)\n <mask>                         endprog = (endprogs[initial] or endprogs[token[1]] or\n <mask>                                    endprogs[token[2]])\n <mask>                         contstr, needcont = line[start:], 1\n <mask>                         contline = line\n <mask>                         break\n <mask>                     else:                                  # ordinary string\n <mask>                         if stashed:\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 elif initial in single_quoted or \\\n                    token[:2] in single_quoted or \\\n                    token[:3] in single_quoted:\n                    if token[-1] == '\\n':                  # continued string\n </s> add                 elif (\n                    initial in single_quoted\n                    or token[:2] in single_quoted\n                    or token[:3] in single_quoted\n                ):\n                    if token[-1] == \"\\n\":  # continued string </s> remove                         strstart = (lnum, start)           # multiple lines\n </s> add                         strstart = (lnum, start)  # multiple lines </s> remove         if contstr:                            # continued string\n </s> add         if contstr:  # continued string </s> remove                 if initial in numchars or \\\n                   (initial == '.' and token != '.'):      # ordinary number\n </s> add                 if initial in numchars or (\n                    initial == \".\" and token != \".\"\n                ):  # ordinary number </s> remove             if pseudomatch:                                # scan for tokens\n </s> add             if pseudomatch:  # scan for tokens", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace replace keep", "code_tokens": " <mask>                             yield stashed\n <mask>                             stashed = None\n <mask>                         yield (STRING, token, spos, epos, line)\n <mask>                 elif initial.isidentifier():               # ordinary name\n <mask>                     if token in ('async', 'await'):\n <mask>                         if async_keywords or async_def:\n <mask>                             yield (ASYNC if token == 'async' else AWAIT,\n <mask>                                    token, spos, epos, line)\n <mask>                             continue\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                     else:                                  # ordinary string\n </s> add                     else:  # ordinary string </s> remove                 elif initial == '#':\n </s> add                 elif initial == \"#\": </s> remove                     if token == 'async' and not stashed:\n </s> add                     if token == \"async\" and not stashed: </s> remove                     if endmatch:                           # all on one line\n </s> add                     if endmatch:  # all on one line </s> remove                 elif initial in '\\r\\n':\n </s> add                 elif initial in \"\\r\\n\":", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace replace replace replace keep keep keep keep", "code_tokens": " <mask>                             continue\n <mask> \n <mask>                     tok = (NAME, token, spos, epos, line)\n <mask>                     if token == 'async' and not stashed:\n <mask>                         stashed = tok\n <mask>                         continue\n <mask> \n <mask>                     if token in ('def', 'for'):\n <mask>                         if (stashed\n <mask>                                 and stashed[0] == NAME\n <mask>                                 and stashed[1] == 'async'):\n <mask> \n <mask>                             if token == 'def':\n <mask>                                 async_def = True\n <mask>                                 async_def_indent = indents[-1]\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                             if token == 'def':\n </s> add                             if token == \"def\": </s> remove                             yield (ASYNC if token == 'async' else AWAIT,\n                                   token, spos, epos, line)\n </s> add                             yield (\n                                ASYNC if token == \"async\" else AWAIT,\n                                token,\n                                spos,\n                                epos,\n                                line,\n                            ) </s> remove                 elif initial.isidentifier():               # ordinary name\n                    if token in ('async', 'await'):\n </s> add                 elif initial.isidentifier():  # ordinary name\n                    if token in (\"async\", \"await\"): </s> remove                             yield (ASYNC, stashed[1],\n                                   stashed[2], stashed[3],\n                                   stashed[4])\n </s> add                             yield (\n                                ASYNC,\n                                stashed[1],\n                                stashed[2],\n                                stashed[3],\n                                stashed[4],\n                            ) </s> remove                 if initial in numchars or \\\n                   (initial == '.' and token != '.'):      # ordinary number\n </s> add                 if initial in numchars or (\n                    initial == \".\" and token != \".\"\n                ):  # ordinary number", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace replace replace keep keep keep keep", "code_tokens": " <mask>                                 and stashed[0] == NAME\n <mask>                                 and stashed[1] == 'async'):\n <mask> \n <mask>                             if token == 'def':\n <mask>                                 async_def = True\n <mask>                                 async_def_indent = indents[-1]\n <mask> \n <mask>                             yield (ASYNC, stashed[1],\n <mask>                                    stashed[2], stashed[3],\n <mask>                                    stashed[4])\n <mask>                             stashed = None\n <mask> \n <mask>                     if stashed:\n <mask>                         yield stashed\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                     if token in ('def', 'for'):\n                        if (stashed\n                                and stashed[0] == NAME\n                                and stashed[1] == 'async'):\n </s> add                     if token in (\"def\", \"for\"):\n                        if stashed and stashed[0] == NAME and stashed[1] == \"async\": </s> remove                 elif initial == '#':\n </s> add                 elif initial == \"#\": </s> remove                 yield (DEDENT, '', (lnum, pos), (lnum, pos), line)\n </s> add                 yield (DEDENT, \"\", (lnum, pos), (lnum, pos), line) </s> remove                     if token == 'async' and not stashed:\n </s> add                     if token == \"async\" and not stashed: </s> remove                 elif initial == '\\\\':                      # continued stmt\n </s> add                 elif initial == \"\\\\\":  # continued stmt", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                         yield stashed\n <mask>                         stashed = None\n <mask> \n <mask>                     yield tok\n <mask>                 elif initial == '\\\\':                      # continued stmt\n <mask>                     # This yield is new; needed for better idempotency:\n <mask>                     if stashed:\n <mask>                         yield stashed\n <mask>                         stashed = None\n <mask>                     yield (NL, token, spos, (lnum, pos), line)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1\n </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1 </s> remove                 elif initial == '#':\n </s> add                 elif initial == \"#\": </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line)\n </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line) </s> remove                         strstart = (lnum, start)           # multiple lines\n </s> add                         strstart = (lnum, start)  # multiple lines </s> remove             if line[pos] in '\\r\\n':            # skip blank lines\n </s> add             if line[pos] in \"\\r\\n\":  # skip blank lines </s> remove                     else:                                  # ordinary string\n </s> add                     else:  # ordinary string", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                         stashed = None\n <mask>                     yield (NL, token, spos, (lnum, pos), line)\n <mask>                     continued = 1\n <mask>                 else:\n <mask>                     if initial in '([{': parenlev = parenlev + 1\n <mask>                     elif initial in ')]}': parenlev = parenlev - 1\n <mask>                     if stashed:\n <mask>                         yield stashed\n <mask>                         stashed = None\n <mask>                     yield (OP, token, spos, epos, line)\n <mask>             else:\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line)\n </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line) </s> remove                 elif initial == '\\\\':                      # continued stmt\n </s> add                 elif initial == \"\\\\\":  # continued stmt </s> remove                 elif initial == '#':\n </s> add                 elif initial == \"#\": </s> remove                     else:                                  # ordinary string\n </s> add                     else:  # ordinary string </s> remove                         strstart = (lnum, start)           # multiple lines\n </s> add                         strstart = (lnum, start)  # multiple lines </s> remove                 if initial in numchars or \\\n                   (initial == '.' and token != '.'):      # ordinary number\n </s> add                 if initial in numchars or (\n                    initial == \".\" and token != \".\"\n                ):  # ordinary number", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                         yield stashed\n <mask>                         stashed = None\n <mask>                     yield (OP, token, spos, epos, line)\n <mask>             else:\n <mask>                 yield (ERRORTOKEN, line[pos],\n <mask>                            (lnum, pos), (lnum, pos+1), line)\n <mask>                 pos = pos + 1\n <mask> \n <mask>     if stashed:\n <mask>         yield stashed\n <mask>         stashed = None\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1\n </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1 </s> remove                 elif initial == '#':\n </s> add                 elif initial == \"#\": </s> remove                 elif initial == '\\\\':                      # continued stmt\n </s> add                 elif initial == \"\\\\\":  # continued stmt </s> remove                     else:                                  # ordinary string\n </s> add                     else:  # ordinary string </s> remove                     if endmatch:                           # all on one line\n </s> add                     if endmatch:  # all on one line </s> remove                         strstart = (lnum, start)           # multiple lines\n </s> add                         strstart = (lnum, start)  # multiple lines", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep replace replace replace keep replace", "code_tokens": " <mask> \n <mask>     for indent in indents[1:]:                 # pop remaining indent levels\n <mask>         yield (DEDENT, '', (lnum, 0), (lnum, 0), '')\n <mask>     yield (ENDMARKER, '', (lnum, 0), (lnum, 0), '')\n <mask> \n <mask> if __name__ == '__main__':                     # testing\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     if len(sys.argv) > 1: tokenize(open(sys.argv[1]).readline)\n    else: tokenize(sys.stdin.readline)\n </s> add     if len(sys.argv) > 1:\n        tokenize(open(sys.argv[1]).readline)\n    else:\n        tokenize(sys.stdin.readline) </s> remove             if column > indents[-1]:           # count indents\n </s> add             if column > indents[-1]:  # count indents </s> remove                 yield (COMMENT, comment_token,\n                        (lnum, pos), (lnum, pos + len(comment_token)), line)\n                yield (NL, line[nl_pos:],\n                        (lnum, nl_pos), (lnum, len(line)), line)\n </s> add                 yield (\n                    COMMENT,\n                    comment_token,\n                    (lnum, pos),\n                    (lnum, pos + len(comment_token)),\n                    line,\n                )\n                yield (NL, line[nl_pos:], (lnum, nl_pos), (lnum, len(line)), line) </s> remove                 yield (DEDENT, '', (lnum, pos), (lnum, pos), line)\n </s> add                 yield (DEDENT, \"\", (lnum, pos), (lnum, pos), line) </s> remove             while column < indents[-1]:        # count dedents\n </s> add             while column < indents[-1]:  # count dedents", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace", "code_tokens": " <mask>     yield (ENDMARKER, '', (lnum, 0), (lnum, 0), '')\n <mask> \n <mask> if __name__ == '__main__':                     # testing\n <mask>     import sys\n <mask>     if len(sys.argv) > 1: tokenize(open(sys.argv[1]).readline)\n <mask>     else: tokenize(sys.stdin.readline)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove if __name__ == '__main__':                     # testing\n </s> add if __name__ == \"__main__\":  # testing </s> remove     for indent in indents[1:]:                 # pop remaining indent levels\n        yield (DEDENT, '', (lnum, 0), (lnum, 0), '')\n    yield (ENDMARKER, '', (lnum, 0), (lnum, 0), '')\n </s> add     for indent in indents[1:]:  # pop remaining indent levels\n        yield (DEDENT, \"\", (lnum, 0), (lnum, 0), \"\")\n    yield (ENDMARKER, \"\", (lnum, 0), (lnum, 0), \"\") </s> remove             if column > indents[-1]:           # count indents\n </s> add             if column > indents[-1]:  # count indents </s> remove                 yield (COMMENT, comment_token,\n                        (lnum, pos), (lnum, pos + len(comment_token)), line)\n                yield (NL, line[nl_pos:],\n                        (lnum, nl_pos), (lnum, len(line)), line)\n </s> add                 yield (\n                    COMMENT,\n                    comment_token,\n                    (lnum, pos),\n                    (lnum, pos + len(comment_token)),\n                    line,\n                )\n                yield (NL, line[nl_pos:], (lnum, nl_pos), (lnum, len(line)), line) </s> remove             while column < indents[-1]:        # count dedents\n </s> add             while column < indents[-1]:  # count dedents </s> remove             if line[pos] == '#':               # skip comments\n                comment_token = line[pos:].rstrip('\\r\\n')\n </s> add             if line[pos] == \"#\":  # skip comments\n                comment_token = line[pos:].rstrip(\"\\r\\n\")", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> from .pgen2 import driver\n <mask> \n <mask> # The grammar file\n <mask> _GRAMMAR_FILE = os.path.join(os.path.dirname(__file__), \"Grammar.txt\")\n <mask> _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__),\n <mask>                                      \"PatternGrammar.txt\")\n <mask> \n <mask> \n <mask> class Symbols(object):\n <mask> \n <mask>     def __init__(self, grammar):\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove \n    def __init__(\n        self,\n        grammar,\n        convert=None,\n        logger=None,\n    ):\n </s> add     def __init__(self, grammar, convert=None, logger=None): </s> remove             if type(val) == int: _type_reprs[val] = name\n </s> add             if type(val) == int:\n                _type_reprs[val] = name </s> remove class ParserGenerator(object):\n </s> add  </s> add class ParserGenerator(object): </s> remove     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE,\n                                                  cache_dir)\n </s> add     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE, cache_dir) </s> remove __all__ = [x for x in dir(token) if x[0] != '_'] + [\"tokenize\",\n           \"generate_tokens\", \"untokenize\"]\n </s> add __all__ = [x for x in dir(token) if x[0] != \"_\"] + [\n    \"tokenize\",\n    \"generate_tokens\",\n    \"untokenize\",\n]", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pygram.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     global pattern_grammar\n <mask>     global pattern_symbols\n <mask> \n <mask>     # Python 2\n <mask>     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE,\n <mask>                                                   cache_dir)\n <mask> \n <mask>     python_symbols = Symbols(python_grammar)\n <mask> \n <mask>     # Python 2 + from __future__ import print_function\n <mask>     python_grammar_no_print_statement = python_grammar.copy()\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = True\n </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = (\n        True\n    ) </s> remove     pattern_grammar = driver.load_packaged_grammar(\"blib2to3\", _PATTERN_GRAMMAR_FILE,\n                                                   cache_dir)\n </s> add     pattern_grammar = driver.load_packaged_grammar(\n        \"blib2to3\", _PATTERN_GRAMMAR_FILE, cache_dir\n    ) </s> remove #--start constants--\n </s> add # --start constants-- </s> remove             if type(val) == int: _type_reprs[val] = name\n </s> add             if type(val) == int:\n                _type_reprs[val] = name </s> remove _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__),\n                                     \"PatternGrammar.txt\")\n </s> add _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__), \"PatternGrammar.txt\") </s> remove                 raise SyntaxError('encoding problem: utf-8')\n            encoding += '-sig'\n </s> add                 raise SyntaxError(\"encoding problem: utf-8\")\n            encoding += \"-sig\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pygram.py"}
{"docstring_tokens": "keep replace keep replace replace", "code_tokens": " <mask>     )\n <mask>     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = True\n <mask> \n <mask>     pattern_grammar = driver.load_packaged_grammar(\"blib2to3\", _PATTERN_GRAMMAR_FILE,\n <mask>                                                    cache_dir)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE,\n                                                  cache_dir)\n </s> add     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE, cache_dir) </s> remove                             yield (ASYNC, stashed[1],\n                                   stashed[2], stashed[3],\n                                   stashed[4])\n </s> add                             yield (\n                                ASYNC,\n                                stashed[1],\n                                stashed[2],\n                                stashed[3],\n                                stashed[4],\n                            ) </s> remove         default = 'utf-8-sig'\n </s> add         default = \"utf-8-sig\" </s> remove         return ''.join(lines), current_line\n </s> add         return \"\".join(lines), current_line </s> remove             tokval += ' '\n </s> add             tokval += \" \"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pygram.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         from .pygram import python_symbols\n <mask>         # printing tokens is possible but not as useful\n <mask>         # from .pgen2 import token // token.__dict__.items():\n <mask>         for name, val in python_symbols.__dict__.items():\n <mask>             if type(val) == int: _type_reprs[val] = name\n <mask>     return _type_reprs.setdefault(type_num, type_num)\n <mask> \n <mask> class Base(object):\n <mask> \n <mask>     \"\"\"\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__),\n                                     \"PatternGrammar.txt\")\n </s> add _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__), \"PatternGrammar.txt\") </s> remove         self.first = {} # map from symbol name to set of tokens\n </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove __all__ = [x for x in dir(token) if x[0] != '_'] + [\"tokenize\",\n           \"generate_tokens\", \"untokenize\"]\n </s> add __all__ = [x for x in dir(token) if x[0] != \"_\"] + [\n    \"tokenize\",\n    \"generate_tokens\",\n    \"untokenize\",\n] </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels\n </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE,\n                                                  cache_dir)\n </s> add     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE, cache_dir) </s> remove __author__ = 'Ka-Ping Yee <ping@lfw.org>'\n__credits__ = \\\n    'GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro'\n </s> add __author__ = \"Ka-Ping Yee <ping@lfw.org>\"\n__credits__ = \"GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     A node may be a subnode of at most one parent.\n <mask>     \"\"\"\n <mask> \n <mask>     # Default values for instance variables\n <mask>     type = None    # int: token number (< 256) or symbol number (>= 256)\n <mask>     parent = None  # Parent node pointer, or None\n <mask>     children = ()  # Tuple of subnodes\n <mask>     was_changed = False\n <mask>     was_checked = False\n <mask> \n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     type = None     # Node type (token if < 256, symbol if >= 256)\n </s> add     type = None  # Node type (token if < 256, symbol if >= 256) </s> remove     name = None     # Optional name used to store match in results dict\n </s> add     name = None  # Optional name used to store match in results dict </s> remove     lineno = 0    # Line where this token starts in the input\n    column = 0    # Column where this token starts in the input\n </s> add     lineno = 0  # Line where this token starts in the input\n    column = 0  # Column where this token starts in the input </s> remove     default = 'utf-8'\n </s> add     default = \"utf-8\"\n </s> remove                 if initial in numchars or \\\n                   (initial == '.' and token != '.'):      # ordinary number\n </s> add                 if initial in numchars or (\n                    initial == \".\" and token != \".\"\n                ):  # ordinary number </s> remove     def __init__(self, type, value,\n                 context=None,\n                 prefix=None,\n                 fixers_applied=[]):\n </s> add     def __init__(self, type, value, context=None, prefix=None, fixers_applied=[]):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if self.__class__ is not other.__class__:\n <mask>             return NotImplemented\n <mask>         return self._eq(other)\n <mask> \n <mask>     __hash__ = None # For Py3 compatibility.\n <mask> \n <mask>     def _eq(self, other):\n <mask>         \"\"\"\n <mask>         Compare two nodes for equality.\n <mask> \n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     __hash__ = None # For Py3 compatibility.\n </s> add     __hash__ = None  # For Py3 compatibility.\n </s> remove     type = None     # Node type (token if < 256, symbol if >= 256)\n </s> add     type = None  # Node type (token if < 256, symbol if >= 256) </s> remove             if type(val) == int: _type_reprs[val] = name\n </s> add             if type(val) == int:\n                _type_reprs[val] = name </s> remove             line_string = line.decode('ascii')\n </s> add             line_string = line.decode(\"ascii\") </s> remove             if subpattern is not None and  self.name == subpattern.name:\n </s> add             if subpattern is not None and self.name == subpattern.name: </s> remove         if (self.content is not None and\n            len(self.content) == 1 and len(self.content[0]) == 1):\n </s> add         if (\n            self.content is not None\n            and len(self.content) == 1\n            and len(self.content[0]) == 1\n        ):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> class Node(Base):\n <mask> \n <mask>     \"\"\"Concrete implementation for interior nodes.\"\"\"\n <mask> \n <mask>     def __init__(self,type, children,\n <mask>                  context=None,\n <mask>                  prefix=None,\n <mask>                  fixers_applied=None):\n <mask>         \"\"\"\n <mask>         Initializer.\n <mask> \n <mask>         Takes a type constant (a symbol number >= 256), a sequence of\n <mask>         child nodes, and an optional context keyword argument.\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     def __init__(self, type, value,\n                 context=None,\n                 prefix=None,\n                 fixers_applied=[]):\n </s> add     def __init__(self, type, value, context=None, prefix=None, fixers_applied=[]): </s> remove     type = None     # Node type (token if < 256, symbol if >= 256)\n </s> add     type = None  # Node type (token if < 256, symbol if >= 256) </s> remove     type = None    # int: token number (< 256) or symbol number (>= 256)\n </s> add     type = None  # int: token number (< 256) or symbol number (>= 256) </s> remove     lineno = 0    # Line where this token starts in the input\n    column = 0    # Column where this token starts in the input\n </s> add     lineno = 0  # Line where this token starts in the input\n    column = 0  # Column where this token starts in the input </s> remove         return Node(self.type, [ch.clone() for ch in self.children],\n                    fixers_applied=self.fixers_applied)\n </s> add         return Node(\n            self.type,\n            [ch.clone() for ch in self.children],\n            fixers_applied=self.fixers_applied,\n        ) </s> remove                 print(\"%s(%s): can't parse %s\" % (filename, lineno,\n                                                  line.strip()))\n </s> add                 print(\"%s(%s): can't parse %s\" % (filename, lineno, line.strip()))", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             self.fixers_applied = None\n <mask> \n <mask>     def __repr__(self):\n <mask>         \"\"\"Return a canonical string representation.\"\"\"\n <mask>         return \"%s(%s, %r)\" % (self.__class__.__name__,\n <mask>                                type_repr(self.type),\n <mask>                                self.children)\n <mask> \n <mask>     def __unicode__(self):\n <mask>         \"\"\"\n <mask>         Return a pretty string representation.\n <mask> \n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         return \"%s(%s, %r)\" % (self.__class__.__name__,\n                               tok_name.get(self.type, self.type),\n                               self.value)\n </s> add         return \"%s(%s, %r)\" % (\n            self.__class__.__name__,\n            tok_name.get(self.type, self.type),\n            self.value,\n        ) </s> remove         return Node(self.type, [ch.clone() for ch in self.children],\n                    fixers_applied=self.fixers_applied)\n </s> add         return Node(\n            self.type,\n            [ch.clone() for ch in self.children],\n            fixers_applied=self.fixers_applied,\n        ) </s> remove             io.StringIO(text).readline,\n            grammar=self.grammar\n </s> add             io.StringIO(text).readline, grammar=self.grammar </s> remove     def __init__(self, type, value,\n                 context=None,\n                 prefix=None,\n                 fixers_applied=[]):\n </s> add     def __init__(self, type, value, context=None, prefix=None, fixers_applied=[]): </s> remove         return Leaf(self.type, self.value,\n                    (self.prefix, (self.lineno, self.column)),\n                    fixers_applied=self.fixers_applied)\n </s> add         return Leaf(\n            self.type,\n            self.value,\n            (self.prefix, (self.lineno, self.column)),\n            fixers_applied=self.fixers_applied,\n        ) </s> remove                     else:                                  # ordinary string\n </s> add                     else:  # ordinary string", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         return (self.type, self.children) == (other.type, other.children)\n <mask> \n <mask>     def clone(self):\n <mask>         \"\"\"Return a cloned (deep) copy of self.\"\"\"\n <mask>         return Node(self.type, [ch.clone() for ch in self.children],\n <mask>                     fixers_applied=self.fixers_applied)\n <mask> \n <mask>     def post_order(self):\n <mask>         \"\"\"Return a post-order iterator for the tree.\"\"\"\n <mask>         for child in self.children:\n <mask>             yield from child.post_order()\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         return Leaf(self.type, self.value,\n                    (self.prefix, (self.lineno, self.column)),\n                    fixers_applied=self.fixers_applied)\n </s> add         return Leaf(\n            self.type,\n            self.value,\n            (self.prefix, (self.lineno, self.column)),\n            fixers_applied=self.fixers_applied,\n        ) </s> remove         return \"%s(%s, %r)\" % (self.__class__.__name__,\n                               type_repr(self.type),\n                               self.children)\n </s> add         return \"%s(%s, %r)\" % (\n            self.__class__.__name__,\n            type_repr(self.type),\n            self.children,\n        ) </s> remove         return \"%s(%s, %r)\" % (self.__class__.__name__,\n                               tok_name.get(self.type, self.type),\n                               self.value)\n </s> add         return \"%s(%s, %r)\" % (\n            self.__class__.__name__,\n            tok_name.get(self.type, self.type),\n            self.value,\n        ) </s> remove             io.StringIO(text).readline,\n            grammar=self.grammar\n </s> add             io.StringIO(text).readline, grammar=self.grammar </s> remove     def __init__(self,type, children,\n                 context=None,\n                 prefix=None,\n                 fixers_applied=None):\n </s> add     def __init__(self, type, children, context=None, prefix=None, fixers_applied=None): </s> remove     logging.basicConfig(level=logging.INFO, stream=sys.stdout,\n                        format='%(message)s')\n </s> add     logging.basicConfig(level=logging.INFO, stream=sys.stdout, format=\"%(message)s\")", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep replace replace keep replace replace replace replace keep keep keep", "code_tokens": " <mask>     # Default values for instance variables\n <mask>     _prefix = \"\"  # Whitespace and comments preceding this token in the input\n <mask>     lineno = 0    # Line where this token starts in the input\n <mask>     column = 0    # Column where this token starts in the input\n <mask> \n <mask>     def __init__(self, type, value,\n <mask>                  context=None,\n <mask>                  prefix=None,\n <mask>                  fixers_applied=[]):\n <mask>         \"\"\"\n <mask>         Initializer.\n <mask> \n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             raise parse.ParseError(\"incomplete input\",\n                                   type, value, (prefix, start))\n </s> add             raise parse.ParseError(\"incomplete input\", type, value, (prefix, start)) </s> remove         self.used_names = set() # Aliased to self.rootnode.used_names in pop()\n </s> add         self.used_names = set()  # Aliased to self.rootnode.used_names in pop() </s> remove     type = None    # int: token number (< 256) or symbol number (>= 256)\n </s> add     type = None  # int: token number (< 256) or symbol number (>= 256) </s> remove                         raise ParseError(\"too much input\",\n                                         type, value, context)\n </s> add                         raise ParseError(\"too much input\", type, value, context) </s> remove     numchars = '0123456789'\n    contstr, needcont = '', 0\n </s> add     numchars = \"0123456789\"\n    contstr, needcont = \"\", 0", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def __repr__(self):\n <mask>         \"\"\"Return a canonical string representation.\"\"\"\n <mask>         from .pgen2.token import tok_name\n <mask>         return \"%s(%s, %r)\" % (self.__class__.__name__,\n <mask>                                tok_name.get(self.type, self.type),\n <mask>                                self.value)\n <mask> \n <mask>     def __unicode__(self):\n <mask>         \"\"\"\n <mask>         Return a pretty string representation.\n <mask> \n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         return \"%s(%s, %r)\" % (self.__class__.__name__,\n                               type_repr(self.type),\n                               self.children)\n </s> add         return \"%s(%s, %r)\" % (\n            self.__class__.__name__,\n            type_repr(self.type),\n            self.children,\n        ) </s> remove         return Leaf(self.type, self.value,\n                    (self.prefix, (self.lineno, self.column)),\n                    fixers_applied=self.fixers_applied)\n </s> add         return Leaf(\n            self.type,\n            self.value,\n            (self.prefix, (self.lineno, self.column)),\n            fixers_applied=self.fixers_applied,\n        ) </s> remove         return Node(self.type, [ch.clone() for ch in self.children],\n                    fixers_applied=self.fixers_applied)\n </s> add         return Node(\n            self.type,\n            [ch.clone() for ch in self.children],\n            fixers_applied=self.fixers_applied,\n        ) </s> remove             io.StringIO(text).readline,\n            grammar=self.grammar\n </s> add             io.StringIO(text).readline, grammar=self.grammar </s> remove     def __init__(self, type, value,\n                 context=None,\n                 prefix=None,\n                 fixers_applied=[]):\n </s> add     def __init__(self, type, value, context=None, prefix=None, fixers_applied=[]): </s> remove __author__ = 'Ka-Ping Yee <ping@lfw.org>'\n__credits__ = \\\n    'GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro'\n </s> add __author__ = \"Ka-Ping Yee <ping@lfw.org>\"\n__credits__ = \"GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         return (self.type, self.value) == (other.type, other.value)\n <mask> \n <mask>     def clone(self):\n <mask>         \"\"\"Return a cloned (deep) copy of self.\"\"\"\n <mask>         return Leaf(self.type, self.value,\n <mask>                     (self.prefix, (self.lineno, self.column)),\n <mask>                     fixers_applied=self.fixers_applied)\n <mask> \n <mask>     def leaves(self):\n <mask>         yield self\n <mask> \n <mask>     def post_order(self):\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         return Node(self.type, [ch.clone() for ch in self.children],\n                    fixers_applied=self.fixers_applied)\n </s> add         return Node(\n            self.type,\n            [ch.clone() for ch in self.children],\n            fixers_applied=self.fixers_applied,\n        ) </s> remove         return \"%s(%s, %r)\" % (self.__class__.__name__,\n                               tok_name.get(self.type, self.type),\n                               self.value)\n </s> add         return \"%s(%s, %r)\" % (\n            self.__class__.__name__,\n            tok_name.get(self.type, self.type),\n            self.value,\n        ) </s> remove         return \"%s(%s, %r)\" % (self.__class__.__name__,\n                               type_repr(self.type),\n                               self.children)\n </s> add         return \"%s(%s, %r)\" % (\n            self.__class__.__name__,\n            type_repr(self.type),\n            self.children,\n        ) </s> remove         if (self.min <= 1 and isinstance(subpattern, WildcardPattern) and\n            subpattern.min <= 1 and self.name == subpattern.name):\n            return WildcardPattern(subpattern.content,\n                                   self.min*subpattern.min,\n                                   self.max*subpattern.max,\n                                   subpattern.name)\n </s> add         if (\n            self.min <= 1\n            and isinstance(subpattern, WildcardPattern)\n            and subpattern.min <= 1\n            and self.name == subpattern.name\n        ):\n            return WildcardPattern(\n                subpattern.content,\n                self.min * subpattern.min,\n                self.max * subpattern.max,\n                subpattern.name,\n            ) </s> remove             self.raise_error(\"expected %s/%s, got %s/%s\",\n                             type, value, self.type, self.value)\n </s> add             self.raise_error(\n                \"expected %s/%s, got %s/%s\", type, value, self.type, self.value\n            ) </s> remove             self.raise_error(\"expected (...) or NAME or STRING, got %s/%s\",\n                             self.type, self.value)\n </s> add             self.raise_error(\n                \"expected (...) or NAME or STRING, got %s/%s\", self.type, self.value\n            )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     - WildcardPattern matches a sequence of nodes of variable length.\n <mask>     \"\"\"\n <mask> \n <mask>     # Defaults for instance variables\n <mask>     type = None     # Node type (token if < 256, symbol if >= 256)\n <mask>     content = None  # Optional content matching pattern\n <mask>     name = None     # Optional name used to store match in results dict\n <mask> \n <mask>     def __new__(cls, *args, **kwds):\n <mask>         \"\"\"Constructor that prevents BasePattern from being instantiated.\"\"\"\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     name = None     # Optional name used to store match in results dict\n </s> add     name = None  # Optional name used to store match in results dict </s> remove     type = None    # int: token number (< 256) or symbol number (>= 256)\n </s> add     type = None  # int: token number (< 256) or symbol number (>= 256) </s> remove         self.first = {} # map from symbol name to set of tokens\n </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove                 assert len(alt), repr(alt) # Can have empty alternatives\n </s> add                 assert len(alt), repr(alt)  # Can have empty alternatives </s> remove         self.gettoken() # Initialize lookahead\n </s> add         self.gettoken()  # Initialize lookahead </s> remove             #print name, self.first[name].keys()\n </s> add             # print name, self.first[name].keys()", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     # Defaults for instance variables\n <mask>     type = None     # Node type (token if < 256, symbol if >= 256)\n <mask>     content = None  # Optional content matching pattern\n <mask>     name = None     # Optional name used to store match in results dict\n <mask> \n <mask>     def __new__(cls, *args, **kwds):\n <mask>         \"\"\"Constructor that prevents BasePattern from being instantiated.\"\"\"\n <mask>         assert cls is not BasePattern, \"Cannot instantiate BasePattern\"\n <mask>         return object.__new__(cls)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     type = None     # Node type (token if < 256, symbol if >= 256)\n </s> add     type = None  # Node type (token if < 256, symbol if >= 256) </s> remove     type = None    # int: token number (< 256) or symbol number (>= 256)\n </s> add     type = None  # int: token number (< 256) or symbol number (>= 256) </s> remove         self.first = {} # map from symbol name to set of tokens\n </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove                 assert len(alt), repr(alt) # Can have empty alternatives\n </s> add                 assert len(alt), repr(alt)  # Can have empty alternatives </s> remove             #print name, self.first[name].keys()\n </s> add             # print name, self.first[name].keys() </s> remove         self.gettoken() # Initialize lookahead\n </s> add         self.gettoken()  # Initialize lookahead", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             content = tuple(map(tuple, content))  # Protect against alterations\n <mask>             # Check sanity of alternatives\n <mask>             assert len(content), repr(content)  # Can't have zero alternatives\n <mask>             for alt in content:\n <mask>                 assert len(alt), repr(alt) # Can have empty alternatives\n <mask>         self.content = content\n <mask>         self.min = min\n <mask>         self.max = max\n <mask>         self.name = name\n <mask> \n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     name = None     # Optional name used to store match in results dict\n </s> add     name = None  # Optional name used to store match in results dict </s> remove     type = None     # Node type (token if < 256, symbol if >= 256)\n </s> add     type = None  # Node type (token if < 256, symbol if >= 256) </s> remove         self.first = {} # map from symbol name to set of tokens\n </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove         self.gettoken() # Initialize lookahead\n </s> add         self.gettoken()  # Initialize lookahead </s> remove         self.arcs = [] # list of (label, NFAState) pairs\n </s> add         self.arcs = []  # list of (label, NFAState) pairs </s> remove             line = ''\n </s> add             line = \"\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep replace keep keep keep", "code_tokens": " <mask> \n <mask>     def optimize(self):\n <mask>         \"\"\"Optimize certain stacked wildcard patterns.\"\"\"\n <mask>         subpattern = None\n <mask>         if (self.content is not None and\n <mask>             len(self.content) == 1 and len(self.content[0]) == 1):\n <mask>             subpattern = self.content[0][0]\n <mask>         if self.min == 1 and self.max == 1:\n <mask>             if self.content is None:\n <mask>                 return NodePattern(name=self.name)\n <mask>             if subpattern is not None and  self.name == subpattern.name:\n <mask>                 return subpattern.optimize()\n <mask>         if (self.min <= 1 and isinstance(subpattern, WildcardPattern) and\n <mask>             subpattern.min <= 1 and self.name == subpattern.name):\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         if (self.min <= 1 and isinstance(subpattern, WildcardPattern) and\n            subpattern.min <= 1 and self.name == subpattern.name):\n            return WildcardPattern(subpattern.content,\n                                   self.min*subpattern.min,\n                                   self.max*subpattern.max,\n                                   subpattern.name)\n </s> add         if (\n            self.min <= 1\n            and isinstance(subpattern, WildcardPattern)\n            and subpattern.min <= 1\n            and self.name == subpattern.name\n        ):\n            return WildcardPattern(\n                subpattern.content,\n                self.min * subpattern.min,\n                self.max * subpattern.max,\n                subpattern.name,\n            ) </s> remove                     if token in ('def', 'for'):\n                        if (stashed\n                                and stashed[0] == NAME\n                                and stashed[1] == 'async'):\n </s> add                     if token in (\"def\", \"for\"):\n                        if stashed and stashed[0] == NAME and stashed[1] == \"async\": </s> remove                     if token == 'async' and not stashed:\n </s> add                     if token == \"async\" and not stashed: </s> remove             if not line: break\n </s> add             if not line:\n                break </s> remove             while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ': column = column + 1\n                elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f': column = 0\n                else: break\n </s> add             while pos < max:  # measure leading whitespace\n                if line[pos] == \" \":\n                    column = column + 1\n                elif line[pos] == \"\\t\":\n                    column = (column // tabsize + 1) * tabsize\n                elif line[pos] == \"\\f\":\n                    column = 0\n                else:\n                    break", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             if self.content is None:\n <mask>                 return NodePattern(name=self.name)\n <mask>             if subpattern is not None and  self.name == subpattern.name:\n <mask>                 return subpattern.optimize()\n <mask>         if (self.min <= 1 and isinstance(subpattern, WildcardPattern) and\n <mask>             subpattern.min <= 1 and self.name == subpattern.name):\n <mask>             return WildcardPattern(subpattern.content,\n <mask>                                    self.min*subpattern.min,\n <mask>                                    self.max*subpattern.max,\n <mask>                                    subpattern.name)\n <mask>         return self\n <mask> \n <mask>     def match(self, node, results=None):\n <mask>         \"\"\"Does this pattern exactly match a node?\"\"\"\n <mask>         return self.match_seq([node], results)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             if subpattern is not None and  self.name == subpattern.name:\n </s> add             if subpattern is not None and self.name == subpattern.name: </s> remove         if (self.content is not None and\n            len(self.content) == 1 and len(self.content[0]) == 1):\n </s> add         if (\n            self.content is not None\n            and len(self.content) == 1\n            and len(self.content[0]) == 1\n        ): </s> remove             raise parse.ParseError(\"incomplete input\",\n                                   type, value, (prefix, start))\n </s> add             raise parse.ParseError(\"incomplete input\", type, value, (prefix, start)) </s> remove             line_string = line.decode('ascii')\n </s> add             line_string = line.decode(\"ascii\") </s> remove def load_grammar(gt=\"Grammar.txt\", gp=None,\n                 save=True, force=False, logger=None):\n </s> add def load_grammar(gt=\"Grammar.txt\", gp=None, save=True, force=False, logger=None): </s> remove                         res = ''.join(lines)\n                        return res, prefix[len(res):]\n </s> add                         res = \"\".join(lines)\n                        return res, prefix[len(res) :]", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             yield 0, {}\n <mask>         if count < self.max:\n <mask>             for alt in self.content:\n <mask>                 for c0, r0 in generate_matches(alt, nodes):\n <mask>                     for c1, r1 in self._recursive_matches(nodes[c0:], count+1):\n <mask>                         r = {}\n <mask>                         r.update(r0)\n <mask>                         r.update(r1)\n <mask>                         yield c0 + c1, r\n <mask> \n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             if column > indents[-1]:           # count indents\n </s> add             if column > indents[-1]:  # count indents </s> remove             while column < indents[-1]:        # count dedents\n </s> add             while column < indents[-1]:  # count dedents </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels\n </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove         self.first[name] = None # dummy to detect left recursion\n </s> add         self.first[name] = None  # dummy to detect left recursion </s> remove             lineno, line = lineno+1, next(f)\n </s> add             lineno, line = lineno + 1, next(f) </s> remove         for state in states: # NB states grows while we're iterating\n </s> add         for state in states:  # NB states grows while we're iterating", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         result = runner.invoke(black.main, args)\n <mask>         self.assertEqual(result.exit_code, exit_code, msg=runner.stderr_bytes.decode())\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_empty(self) -> None:\n <mask>         source = expected = \"\"\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         source, expected = read_data(\"test_black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_FILE))\n </s> add         self.checkSourceFile(\"tests/test_black.py\") </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n </s> add  </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n </s> add  </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_setup(self) -> None:\n        source, expected = read_data(\"../setup\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"setup.py\"))\n\n </s> add  </s> remove         source, expected = read_data(\"../black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"black.py\"))\n </s> add         self.checkSourceFile(\"black.py\")\n\n    def test_pygram(self) -> None:\n        self.checkSourceFile(\"blib2to3/pygram.py\")\n\n    def test_pytree(self) -> None:\n        self.checkSourceFile(\"blib2to3/pytree.py\")\n\n    def test_conv(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/conv.py\")\n\n    def test_driver(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/driver.py\")\n\n    def test_grammar(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/grammar.py\")\n\n    def test_literals(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/literals.py\")\n\n    def test_parse(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/parse.py\")\n\n    def test_pgen(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/pgen.py\")\n\n    def test_tokenize(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/tokenize.py\")\n\n    def test_token(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/token.py\")\n\n    def test_setup(self) -> None:\n        self.checkSourceFile(\"setup.py\") </s> remove                 self.logger.debug(\"%s %r (prefix=%r)\",\n                                  token.tok_name[type], value, prefix)\n </s> add                 self.logger.debug(\n                    \"%s %r (prefix=%r)\", token.tok_name[type], value, prefix\n                )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         finally:\n <mask>             os.unlink(tmp_file)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_self(self) -> None:\n <mask>         source, expected = read_data(\"test_black\", data=False)\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         source, expected = read_data(\"test_black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_FILE))\n </s> add         self.checkSourceFile(\"tests/test_black.py\") </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n </s> add  </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def checkSourceFile(self, name: str) -> None:\n        path = THIS_DIR.parent / name\n        source, expected = read_data(str(path), data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(path))\n </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_setup(self) -> None:\n        source, expected = read_data(\"../setup\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"setup.py\"))\n\n </s> add  </s> remove         source, expected = read_data(\"../black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"black.py\"))\n </s> add         self.checkSourceFile(\"black.py\")\n\n    def test_pygram(self) -> None:\n        self.checkSourceFile(\"blib2to3/pygram.py\")\n\n    def test_pytree(self) -> None:\n        self.checkSourceFile(\"blib2to3/pytree.py\")\n\n    def test_conv(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/conv.py\")\n\n    def test_driver(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/driver.py\")\n\n    def test_grammar(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/grammar.py\")\n\n    def test_literals(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/literals.py\")\n\n    def test_parse(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/parse.py\")\n\n    def test_pgen(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/pgen.py\")\n\n    def test_tokenize(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/tokenize.py\")\n\n    def test_token(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/token.py\")\n\n    def test_setup(self) -> None:\n        self.checkSourceFile(\"setup.py\") </s> remove class ParserGenerator(object):\n </s> add ", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace keep replace keep keep keep keep", "code_tokens": " <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_self(self) -> None:\n <mask>         source, expected = read_data(\"test_black\", data=False)\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, black.FileMode())\n <mask>         self.assertFalse(ff(THIS_FILE))\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_black(self) -> None:\n <mask>         source, expected = read_data(\"../black\", data=False)\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n </s> add  </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def checkSourceFile(self, name: str) -> None:\n        path = THIS_DIR.parent / name\n        source, expected = read_data(str(path), data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(path))\n </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_setup(self) -> None:\n        source, expected = read_data(\"../setup\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"setup.py\"))\n\n </s> add  </s> remove         source, expected = read_data(\"../black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"black.py\"))\n </s> add         self.checkSourceFile(\"black.py\")\n\n    def test_pygram(self) -> None:\n        self.checkSourceFile(\"blib2to3/pygram.py\")\n\n    def test_pytree(self) -> None:\n        self.checkSourceFile(\"blib2to3/pytree.py\")\n\n    def test_conv(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/conv.py\")\n\n    def test_driver(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/driver.py\")\n\n    def test_grammar(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/grammar.py\")\n\n    def test_literals(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/literals.py\")\n\n    def test_parse(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/parse.py\")\n\n    def test_pgen(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/pgen.py\")\n\n    def test_tokenize(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/tokenize.py\")\n\n    def test_token(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/token.py\")\n\n    def test_setup(self) -> None:\n        self.checkSourceFile(\"setup.py\") </s> remove class ParserGenerator(object):\n </s> add ", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         self.assertFalse(ff(THIS_FILE))\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_black(self) -> None:\n <mask>         source, expected = read_data(\"../black\", data=False)\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, black.FileMode())\n <mask>         self.assertFalse(ff(THIS_DIR / \"..\" / \"black.py\"))\n <mask> \n <mask>     def test_piping(self) -> None:\n <mask>         source, expected = read_data(\"../black\", data=False)\n <mask>         result = BlackRunner().invoke(\n <mask>             black.main,\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         source, expected = read_data(\"test_black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_FILE))\n </s> add         self.checkSourceFile(\"tests/test_black.py\") </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n </s> add  </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_setup(self) -> None:\n        source, expected = read_data(\"../setup\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"setup.py\"))\n\n </s> add  </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def checkSourceFile(self, name: str) -> None:\n        path = THIS_DIR.parent / name\n        source, expected = read_data(str(path), data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(path))\n </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n </s> add  </s> remove class ParserGenerator(object):\n </s> add ", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         actual = diff_header.sub(\"[Deterministic header]\", result.output)\n <mask>         actual = actual.rstrip() + \"\\n\"  # the diff output has a trailing space\n <mask>         self.assertEqual(expected, actual)\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_setup(self) -> None:\n <mask>         source, expected = read_data(\"../setup\", data=False)\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, black.FileMode())\n <mask>         self.assertFalse(ff(THIS_DIR / \"..\" / \"setup.py\"))\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_function(self) -> None:\n <mask>         source, expected = read_data(\"function\")\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         source, expected = read_data(\"test_black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_FILE))\n </s> add         self.checkSourceFile(\"tests/test_black.py\") </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def checkSourceFile(self, name: str) -> None:\n        path = THIS_DIR.parent / name\n        source, expected = read_data(str(path), data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(path))\n </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n </s> add  </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n </s> add  </s> remove         source, expected = read_data(\"../black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"black.py\"))\n </s> add         self.checkSourceFile(\"black.py\")\n\n    def test_pygram(self) -> None:\n        self.checkSourceFile(\"blib2to3/pygram.py\")\n\n    def test_pytree(self) -> None:\n        self.checkSourceFile(\"blib2to3/pytree.py\")\n\n    def test_conv(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/conv.py\")\n\n    def test_driver(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/driver.py\")\n\n    def test_grammar(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/grammar.py\")\n\n    def test_literals(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/literals.py\")\n\n    def test_parse(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/parse.py\")\n\n    def test_pgen(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/pgen.py\")\n\n    def test_tokenize(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/tokenize.py\")\n\n    def test_token(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/token.py\")\n\n    def test_setup(self) -> None:\n        self.checkSourceFile(\"setup.py\") </s> remove             #print name, oldlen, newlen\n </s> add             # print name, oldlen, newlen", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"platformdirs>=2\",\n <mask>         \"tomli>=0.2.6,<2.0.0\",\n <mask>         \"typed-ast>=1.4.2; python_version < '3.8'\",\n <mask>         \"regex>=2020.1.8\",\n <mask>         \"pathspec>=0.8.1, <1\",\n <mask>         \"dataclasses>=0.6; python_version < '3.7'\",\n <mask>         \"typing_extensions>=3.10.0.0; python_version < '3.10'\",\n <mask>         \"mypy_extensions>=0.4.3\",\n <mask>     ],\n <mask>     extras_require={\n </s> Present a more user-friendly error if .gitignore is invalid (#2414)\n\nFixes #2359.\r\n\r\nThis commit now makes Black exit with an user-friendly error message if a\r\n.gitignore file couldn't be parsed -- a massive improvement over an opaque\r\ntraceback! </s> remove     return PathSpec.from_lines(\"gitwildmatch\", lines)\n </s> add     try:\n        return PathSpec.from_lines(\"gitwildmatch\", lines)\n    except GitWildMatchPatternError as e:\n        err(f\"Could not parse {gitignore}: {e}\")\n        raise </s> add from pathspec.patterns.gitwildmatch import GitWildMatchPatternError </s> add from pathspec.patterns.gitwildmatch import GitWildMatchPatternError", "html_url": "https://github.com/psf/black/commit/104aec555fae0883ef5b53709569bd9c4d420bc5", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> import io\n <mask> from multiprocessing import Manager, freeze_support\n <mask> import os\n <mask> from pathlib import Path\n <mask> import regex as re\n <mask> import signal\n <mask> import sys\n <mask> import tokenize\n <mask> import traceback\n <mask> from typing import (\n </s> Present a more user-friendly error if .gitignore is invalid (#2414)\n\nFixes #2359.\r\n\r\nThis commit now makes Black exit with an user-friendly error message if a\r\n.gitignore file couldn't be parsed -- a massive improvement over an opaque\r\ntraceback! </s> remove     return PathSpec.from_lines(\"gitwildmatch\", lines)\n </s> add     try:\n        return PathSpec.from_lines(\"gitwildmatch\", lines)\n    except GitWildMatchPatternError as e:\n        err(f\"Could not parse {gitignore}: {e}\")\n        raise </s> add from pathspec.patterns.gitwildmatch import GitWildMatchPatternError </s> remove         \"pathspec>=0.8.1, <1\",\n </s> add         \"pathspec>=0.9.0, <1\",", "html_url": "https://github.com/psf/black/commit/104aec555fae0883ef5b53709569bd9c4d420bc5", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from pathspec import PathSpec\n <mask> import tomli\n <mask> \n <mask> from black.output import err\n <mask> from black.report import Report\n <mask> from black.handle_ipynb_magics import jupyter_dependencies_are_installed\n <mask> \n </s> Present a more user-friendly error if .gitignore is invalid (#2414)\n\nFixes #2359.\r\n\r\nThis commit now makes Black exit with an user-friendly error message if a\r\n.gitignore file couldn't be parsed -- a massive improvement over an opaque\r\ntraceback! </s> remove     return PathSpec.from_lines(\"gitwildmatch\", lines)\n </s> add     try:\n        return PathSpec.from_lines(\"gitwildmatch\", lines)\n    except GitWildMatchPatternError as e:\n        err(f\"Could not parse {gitignore}: {e}\")\n        raise </s> add from pathspec.patterns.gitwildmatch import GitWildMatchPatternError </s> remove         \"pathspec>=0.8.1, <1\",\n </s> add         \"pathspec>=0.9.0, <1\",", "html_url": "https://github.com/psf/black/commit/104aec555fae0883ef5b53709569bd9c4d420bc5", "file_name": "src/black/files.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     lines: List[str] = []\n <mask>     if gitignore.is_file():\n <mask>         with gitignore.open(encoding=\"utf-8\") as gf:\n <mask>             lines = gf.readlines()\n <mask>     return PathSpec.from_lines(\"gitwildmatch\", lines)\n <mask> \n <mask> \n <mask> def normalize_path_maybe_ignore(\n <mask>     path: Path, root: Path, report: Report\n <mask> ) -> Optional[str]:\n </s> Present a more user-friendly error if .gitignore is invalid (#2414)\n\nFixes #2359.\r\n\r\nThis commit now makes Black exit with an user-friendly error message if a\r\n.gitignore file couldn't be parsed -- a massive improvement over an opaque\r\ntraceback! </s> add from pathspec.patterns.gitwildmatch import GitWildMatchPatternError </s> add from pathspec.patterns.gitwildmatch import GitWildMatchPatternError </s> remove         \"pathspec>=0.8.1, <1\",\n </s> add         \"pathspec>=0.9.0, <1\",", "html_url": "https://github.com/psf/black/commit/104aec555fae0883ef5b53709569bd9c4d420bc5", "file_name": "src/black/files.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. autofunction:: black.cache.filter_cached\n <mask> \n <mask> .. autofunction:: black.cache.get_cache_file\n <mask> \n <mask> .. autofunction:: black.cache.get_cache_info\n <mask> \n <mask> .. autofunction:: black.cache.read_cache\n </s> Allow setting custom cache directory on all platforms (#2739)\n\nFixes #2506\r\n\r\n``XDG_CACHE_HOME`` does not work on Windows. To allow for users to set a custom cache directory on all systems I added a new environment variable ``BLACK_CACHE_DIR`` to set the cache directory. The default remains the same so users will only notice a change if that environment variable is set.\r\n\r\nThe specific use case I have for this is I need to run black on in different processes at the same time. There is a race condition with the cache pickle file that made this rather difficult. A custom cache directory will remove the race condition.\r\n\r\nI created ``get_cache_dir`` function in order to test the logic. This is only used to set the ``CACHE_DIR`` constant. </s> remove from black.cache import get_cache_file\n </s> add from black.cache import get_cache_dir, get_cache_file </s> remove CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__))\n </s> add def get_cache_dir() -> Path:\n    \"\"\"Get the cache directory used by black.\n\n    Users can customize this directory on all systems using `BLACK_CACHE_DIR`\n    environment variable. By default, the cache directory is the user cache directory\n    under the black application.\n\n    This result is immediately set to a constant `black.cache.CACHE_DIR` as to avoid\n    repeated calls.\n    \"\"\"\n    # NOTE: Function mostly exists as a clean way to test getting the cache directory.\n    default_cache_dir = user_cache_dir(\"black\", version=__version__)\n    cache_dir = Path(os.environ.get(\"BLACK_CACHE_DIR\", default_cache_dir))\n    return cache_dir\n\n\nCACHE_DIR = get_cache_dir()", "html_url": "https://github.com/psf/black/commit/10677baa40f818ca06c6a9d5efa0dca052865bfb", "file_name": "docs/contributing/reference/reference_functions.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> CacheInfo = Tuple[Timestamp, FileSize]\n <mask> Cache = Dict[str, CacheInfo]\n <mask> \n <mask> \n <mask> CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__))\n <mask> \n <mask> \n <mask> def read_cache(mode: Mode) -> Cache:\n <mask>     \"\"\"Read the cache if it exists and is well formed.\n <mask> \n </s> Allow setting custom cache directory on all platforms (#2739)\n\nFixes #2506\r\n\r\n``XDG_CACHE_HOME`` does not work on Windows. To allow for users to set a custom cache directory on all systems I added a new environment variable ``BLACK_CACHE_DIR`` to set the cache directory. The default remains the same so users will only notice a change if that environment variable is set.\r\n\r\nThe specific use case I have for this is I need to run black on in different processes at the same time. There is a race condition with the cache pickle file that made this rather difficult. A custom cache directory will remove the race condition.\r\n\r\nI created ``get_cache_dir`` function in order to test the logic. This is only used to set the ``CACHE_DIR`` constant. </s> remove from black.cache import get_cache_file\n </s> add from black.cache import get_cache_dir, get_cache_file </s> add .. autofunction:: black.cache.get_cache_dir\n", "html_url": "https://github.com/psf/black/commit/10677baa40f818ca06c6a9d5efa0dca052865bfb", "file_name": "src/black/cache.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import black\n <mask> import black.files\n <mask> from black import Feature, TargetVersion\n <mask> from black import re_compile_maybe_verbose as compile_pattern\n <mask> from black.cache import get_cache_file\n <mask> from black.debug import DebugVisitor\n <mask> from black.output import color_diff, diff\n <mask> from black.report import Report\n <mask> \n <mask> # Import other test classes\n </s> Allow setting custom cache directory on all platforms (#2739)\n\nFixes #2506\r\n\r\n``XDG_CACHE_HOME`` does not work on Windows. To allow for users to set a custom cache directory on all systems I added a new environment variable ``BLACK_CACHE_DIR`` to set the cache directory. The default remains the same so users will only notice a change if that environment variable is set.\r\n\r\nThe specific use case I have for this is I need to run black on in different processes at the same time. There is a race condition with the cache pickle file that made this rather difficult. A custom cache directory will remove the race condition.\r\n\r\nI created ``get_cache_dir`` function in order to test the logic. This is only used to set the ``CACHE_DIR`` constant. </s> remove CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__))\n </s> add def get_cache_dir() -> Path:\n    \"\"\"Get the cache directory used by black.\n\n    Users can customize this directory on all systems using `BLACK_CACHE_DIR`\n    environment variable. By default, the cache directory is the user cache directory\n    under the black application.\n\n    This result is immediately set to a constant `black.cache.CACHE_DIR` as to avoid\n    repeated calls.\n    \"\"\"\n    # NOTE: Function mostly exists as a clean way to test getting the cache directory.\n    default_cache_dir = user_cache_dir(\"black\", version=__version__)\n    cache_dir = Path(os.environ.get(\"BLACK_CACHE_DIR\", default_cache_dir))\n    return cache_dir\n\n\nCACHE_DIR = get_cache_dir() </s> add .. autofunction:: black.cache.get_cache_dir\n", "html_url": "https://github.com/psf/black/commit/10677baa40f818ca06c6a9d5efa0dca052865bfb", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> @click.version_option(version=__version__)\n <mask> @click.argument(\n <mask>     'src',\n <mask>     nargs=-1,\n <mask>     type=click.Path(exists=True, file_okay=True, dir_okay=True, readable=True),\n <mask> )\n <mask> @click.pass_context\n <mask> def main(\n <mask>     ctx: click.Context, line_length: int, check: bool, fast: bool, src: List[str]\n <mask> ) -> None:\n </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast)\n </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]:\n </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()\n </s> add  </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove     return dst_contents, src_buffer.encoding\n </s> add     return dst_contents </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE)\n </s> add         self.assertFalse(ff(THIS_FILE))", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>             sources.extend(gen_python_files_in_dir(p))\n <mask>         elif p.is_file():\n <mask>             # if a file was explicitly given, we don't care about its extension\n <mask>             sources.append(p)\n <mask>         else:\n <mask>             err(f'invalid path: {s}')\n <mask>     if len(sources) == 0:\n <mask>         ctx.exit(0)\n </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove             changed = format_file_in_place(\n                p, line_length=line_length, fast=fast, write_back=not check\n            )\n </s> add             if not p.is_file() and str(p) == '-':\n                changed = format_stdin_to_stdout(line_length=line_length, fast=fast)\n            else:\n                changed = format_file_in_place(\n                    p, line_length=line_length, fast=fast, write_back=not check\n                ) </s> remove         raise NothingChanged(src)\n </s> add         raise NothingChanged </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()\n </s> add  </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]:\n </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> remove         raise NothingChanged(src)\n </s> add         raise NothingChanged </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     elif len(sources) == 1:\n <mask>         p = sources[0]\n <mask>         report = Report()\n <mask>         try:\n <mask>             changed = format_file_in_place(\n <mask>                 p, line_length=line_length, fast=fast, write_back=not check\n <mask>             )\n <mask>             report.done(p, changed)\n <mask>         except Exception as exc:\n <mask>             report.failed(p, str(exc))\n <mask>         ctx.exit(report.return_code)\n <mask>     else:\n </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> add         elif s == '-':\n            sources.append(Path('-')) </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast)\n </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]:\n </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()\n </s> add  </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE)\n </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'black.py'))\n\n    def test_piping(self) -> None:\n        source, expected = read_data('../black')\n        hold_stdin, hold_stdout = sys.stdin, sys.stdout\n        try:\n            sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = '<stdin>'\n            black.format_stdin_to_stdout(line_length=ll, fast=True)\n            sys.stdout.seek(0)\n            actual = sys.stdout.read()\n        finally:\n            sys.stdin, sys.stdout = hold_stdin, hold_stdout\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, line_length=ll)", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> ) -> bool:\n <mask>     \"\"\"Format the file and rewrite if changed. Return True if changed.\"\"\"\n <mask>     try:\n <mask>         contents = format_file_contents(\n <mask>             src_contents, line_length=line_length, fast=fast\n <mask>         )\n <mask>     except NothingChanged:\n </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast)\n </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]:\n </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> remove             changed = format_file_in_place(\n                p, line_length=line_length, fast=fast, write_back=not check\n            )\n </s> add             if not p.is_file() and str(p) == '-':\n                changed = format_stdin_to_stdout(line_length=line_length, fast=fast)\n            else:\n                changed = format_file_in_place(\n                    p, line_length=line_length, fast=fast, write_back=not check\n                ) </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()\n </s> add  </s> remove         with open(src, \"w\", encoding=encoding) as f:\n </s> add         with open(src, \"w\", encoding=src_buffer.encoding) as f: </s> remove         raise NothingChanged(src)\n </s> add         raise NothingChanged", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>     \"\"\"Format the file and rewrite if changed. Return True if changed.\"\"\"\n <mask>     try:\n <mask>         contents, encoding = format_file(src, line_length=line_length, fast=fast)\n <mask>     except NothingChanged:\n <mask>         return False\n <mask> \n <mask>     if write_back:\n <mask>         with open(src, \"w\", encoding=encoding) as f:\n <mask>             f.write(contents)\n <mask>     return True\n <mask> \n <mask> \n </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]:\n </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> remove             changed = format_file_in_place(\n                p, line_length=line_length, fast=fast, write_back=not check\n            )\n </s> add             if not p.is_file() and str(p) == '-':\n                changed = format_stdin_to_stdout(line_length=line_length, fast=fast)\n            else:\n                changed = format_file_in_place(\n                    p, line_length=line_length, fast=fast, write_back=not check\n                ) </s> remove     return dst_contents, src_buffer.encoding\n </s> add     return dst_contents </s> remove         raise NothingChanged(src)\n </s> add         raise NothingChanged", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep replace replace keep keep keep", "code_tokens": " <mask>     return True\n <mask> \n <mask> \n <mask> def format_file(\n <mask>     src: Path, line_length: int, fast: bool\n <mask> ) -> Tuple[FileContent, Encoding]:\n <mask>     \"\"\"Reformats a file and returns its contents and encoding.\"\"\"\n <mask>     with tokenize.open(src) as src_buffer:\n <mask>         src_contents = src_buffer.read()\n <mask>     if src_contents.strip() == '':\n <mask>         raise NothingChanged(src)\n <mask> \n </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove         raise NothingChanged(src)\n </s> add         raise NothingChanged </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast)\n </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove     return dst_contents, src_buffer.encoding\n </s> add     return dst_contents </s> remove         raise NothingChanged(src)\n </s> add         raise NothingChanged", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep keep keep keep replace keep keep", "code_tokens": " <mask>         src_contents = src_buffer.read()\n <mask>     if src_contents.strip() == '':\n <mask>         raise NothingChanged(src)\n <mask> \n <mask>     dst_contents = format_str(src_contents, line_length=line_length)\n <mask>     if src_contents == dst_contents:\n <mask>         raise NothingChanged(src)\n <mask> \n <mask>     dst_contents = format_str(src_contents, line_length=line_length)\n <mask>     if src_contents == dst_contents:\n <mask>         raise NothingChanged(src)\n <mask> \n <mask>     if not fast:\n </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()\n </s> add  </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]:\n </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> remove     return dst_contents, src_buffer.encoding\n </s> add     return dst_contents </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove             changed = format_file_in_place(\n                p, line_length=line_length, fast=fast, write_back=not check\n            )\n </s> add             if not p.is_file() and str(p) == '-':\n                changed = format_stdin_to_stdout(line_length=line_length, fast=fast)\n            else:\n                changed = format_file_in_place(\n                    p, line_length=line_length, fast=fast, write_back=not check\n                )", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     if not fast:\n <mask>         assert_equivalent(src_contents, dst_contents)\n <mask>         assert_stable(src_contents, dst_contents, line_length=line_length)\n <mask>     return dst_contents, src_buffer.encoding\n <mask> \n <mask> \n <mask> def format_str(src_contents: str, line_length: int) -> FileContent:\n <mask>     \"\"\"Reformats a string and returns new contents.\"\"\"\n <mask>     src_node = lib2to3_parse(src_contents)\n </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove         raise NothingChanged(src)\n </s> add         raise NothingChanged </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]:\n </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()\n </s> add  </s> remove         raise NothingChanged(src)\n </s> add         raise NothingChanged </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast)\n </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> remove             changed = format_file_in_place(\n                p, line_length=line_length, fast=fast, write_back=not check\n            )\n </s> add             if not p.is_file() and str(p) == '-':\n                changed = format_stdin_to_stdout(line_length=line_length, fast=fast)\n            else:\n                changed = format_file_in_place(\n                    p, line_length=line_length, fast=fast, write_back=not check\n                )", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> #!/usr/bin/env python3\n <mask> from functools import partial\n <mask> from pathlib import Path\n <mask> import sys\n <mask> from typing import Any, List, Tuple\n <mask> import unittest\n </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> add import sys </s> remove ff = partial(black.format_file, line_length=ll, fast=True)\n </s> add ff = partial(black.format_file_in_place, line_length=ll, fast=True) </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE)\n </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'setup.py')) </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]:\n </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> add         elif s == '-':\n            sources.append(Path('-')) </s> remove             changed = format_file_in_place(\n                p, line_length=line_length, fast=fast, write_back=not check\n            )\n </s> add             if not p.is_file() and str(p) == '-':\n                changed = format_stdin_to_stdout(line_length=line_length, fast=fast)\n            else:\n                changed = format_file_in_place(\n                    p, line_length=line_length, fast=fast, write_back=not check\n                )", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> #!/usr/bin/env python3\n <mask> from functools import partial\n <mask> from io import StringIO\n <mask> from pathlib import Path\n <mask> from typing import Any, List, Tuple\n <mask> import unittest\n <mask> from unittest.mock import patch\n <mask> \n <mask> from click import unstyle\n <mask> \n </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> add from io import StringIO </s> remove ff = partial(black.format_file, line_length=ll, fast=True)\n </s> add ff = partial(black.format_file_in_place, line_length=ll, fast=True) </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE)\n </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'setup.py')) </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]:\n </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> add         elif s == '-':\n            sources.append(Path('-')) </s> remove             changed = format_file_in_place(\n                p, line_length=line_length, fast=fast, write_back=not check\n            )\n </s> add             if not p.is_file() and str(p) == '-':\n                changed = format_stdin_to_stdout(line_length=line_length, fast=fast)\n            else:\n                changed = format_file_in_place(\n                    p, line_length=line_length, fast=fast, write_back=not check\n                )", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> import black\n <mask> \n <mask> ll = 88\n <mask> ff = partial(black.format_file, line_length=ll, fast=True)\n <mask> fs = partial(black.format_str, line_length=ll)\n <mask> THIS_FILE = Path(__file__)\n <mask> THIS_DIR = THIS_FILE.parent\n <mask> \n <mask> \n </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE)\n </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'black.py'))\n\n    def test_piping(self) -> None:\n        source, expected = read_data('../black')\n        hold_stdin, hold_stdout = sys.stdin, sys.stdout\n        try:\n            sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = '<stdin>'\n            black.format_stdin_to_stdout(line_length=ll, fast=True)\n            sys.stdout.seek(0)\n            actual = sys.stdout.read()\n        finally:\n            sys.stdin, sys.stdout = hold_stdin, hold_stdout\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, line_length=ll) </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE)\n </s> add         self.assertFalse(ff(THIS_FILE)) </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE)\n </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'setup.py')) </s> remove             changed = format_file_in_place(\n                p, line_length=line_length, fast=fast, write_back=not check\n            )\n </s> add             if not p.is_file() and str(p) == '-':\n                changed = format_stdin_to_stdout(line_length=line_length, fast=fast)\n            else:\n                changed = format_file_in_place(\n                    p, line_length=line_length, fast=fast, write_back=not check\n                ) </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast)\n </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, line_length=ll)\n <mask>         with self.assertRaises(black.NothingChanged):\n <mask>             ff(THIS_FILE)\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_black(self) -> None:\n <mask>         source, expected = read_data('../black')\n <mask>         actual = fs(source)\n </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE)\n </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'setup.py')) </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE)\n </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'black.py'))\n\n    def test_piping(self) -> None:\n        source, expected = read_data('../black')\n        hold_stdin, hold_stdout = sys.stdin, sys.stdout\n        try:\n            sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = '<stdin>'\n            black.format_stdin_to_stdout(line_length=ll, fast=True)\n            sys.stdout.seek(0)\n            actual = sys.stdout.read()\n        finally:\n            sys.stdin, sys.stdout = hold_stdin, hold_stdout\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, line_length=ll) </s> remove ff = partial(black.format_file, line_length=ll, fast=True)\n </s> add ff = partial(black.format_file_in_place, line_length=ll, fast=True) </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast)\n </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()\n </s> add ", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, line_length=ll)\n <mask>         with self.assertRaises(black.NothingChanged):\n <mask>             ff(THIS_FILE)\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_setup(self) -> None:\n <mask>         source, expected = read_data('../setup')\n <mask>         actual = fs(source)\n </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE)\n </s> add         self.assertFalse(ff(THIS_FILE)) </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE)\n </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'setup.py')) </s> remove ff = partial(black.format_file, line_length=ll, fast=True)\n </s> add ff = partial(black.format_file_in_place, line_length=ll, fast=True) </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast)\n </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()\n </s> add ", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, line_length=ll)\n <mask>         with self.assertRaises(black.NothingChanged):\n <mask>             ff(THIS_FILE)\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_function(self) -> None:\n <mask>         source, expected = read_data('function')\n <mask>         actual = fs(source)\n </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE)\n </s> add         self.assertFalse(ff(THIS_FILE)) </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE)\n </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'black.py'))\n\n    def test_piping(self) -> None:\n        source, expected = read_data('../black')\n        hold_stdin, hold_stdout = sys.stdin, sys.stdout\n        try:\n            sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = '<stdin>'\n            black.format_stdin_to_stdout(line_length=ll, fast=True)\n            sys.stdout.seek(0)\n            actual = sys.stdout.read()\n        finally:\n            sys.stdin, sys.stdout = hold_stdin, hold_stdout\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, line_length=ll) </s> remove ff = partial(black.format_file, line_length=ll, fast=True)\n </s> add ff = partial(black.format_file_in_place, line_length=ll, fast=True) </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast)\n </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()\n </s> add ", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> .. autofunction:: black.strings.normalize_string_quotes\n <mask> \n <mask> .. autofunction:: black.linegen.normalize_invisible_parens\n <mask> \n <mask> .. autofunction:: black.patch_click\n <mask> \n <mask> .. autofunction:: black.nodes.preceding_leaf\n <mask> \n <mask> .. autofunction:: black.re_compile_maybe_verbose\n <mask> \n <mask> .. autofunction:: black.linegen.should_split_line\n </s> Remove click patch (#3768)\n\nApparently this was only needed on Python 3.6. We've now dropped support\r\nfor 3.6 and 3.7. It's also not needed on new enough click. </s> remove     def test_shhh_click(self) -> None:\n        try:\n            from click import _unicodefun  # type: ignore\n        except ImportError:\n            self.skipTest(\"Incompatible Click version\")\n\n        if not hasattr(_unicodefun, \"_verify_python_env\"):\n            self.skipTest(\"Incompatible Click version\")\n\n        # First, let's see if Click is crashing with a preferred ASCII charset.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            with self.assertRaises(RuntimeError):\n                _unicodefun._verify_python_env()\n        # Now, let's silence Click...\n        black.patch_click()\n        # ...and confirm it's silent.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            try:\n                _unicodefun._verify_python_env()\n            except RuntimeError as re:\n                self.fail(f\"`patch_click()` failed, exception still raised: {re}\")\n\n </s> add  </s> remove     black.patch_click()\n </s> add  </s> remove     patch_click()\n </s> add  </s> remove def patch_click() -> None:\n    \"\"\"Make Click not crash on Python 3.6 with LANG=C.\n\n    On certain misconfigured environments, Python 3 selects the ASCII encoding as the\n    default which restricts paths that it can access during the lifetime of the\n    application.  Click refuses to work in this scenario by raising a RuntimeError.\n\n    In case of Black the likelihood that non-ASCII characters are going to be used in\n    file paths is minimal since it's Python source code.  Moreover, this crash was\n    spurious on Python 3.7 thanks to PEP 538 and PEP 540.\n    \"\"\"\n    modules: List[Any] = []\n    try:\n        from click import core\n    except ImportError:\n        pass\n    else:\n        modules.append(core)\n    try:\n        # Removed in Click 8.1.0 and newer; we keep this around for users who have\n        # older versions installed.\n        from click import _unicodefun  # type: ignore\n    except ImportError:\n        pass\n    else:\n        modules.append(_unicodefun)\n\n    for module in modules:\n        if hasattr(module, \"_verify_python3_env\"):\n            module._verify_python3_env = lambda: None\n        if hasattr(module, \"_verify_python_env\"):\n            module._verify_python_env = lambda: None\n\n\n </s> add ", "html_url": "https://github.com/psf/black/commit/114e8357e65384e17baaa3c31aa528371e15679b", "file_name": "docs/contributing/reference/reference_functions.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     yield\n <mask> \n <mask> \n <mask> def patch_click() -> None:\n <mask>     \"\"\"Make Click not crash on Python 3.6 with LANG=C.\n <mask> \n <mask>     On certain misconfigured environments, Python 3 selects the ASCII encoding as the\n <mask>     default which restricts paths that it can access during the lifetime of the\n <mask>     application.  Click refuses to work in this scenario by raising a RuntimeError.\n <mask> \n <mask>     In case of Black the likelihood that non-ASCII characters are going to be used in\n <mask>     file paths is minimal since it's Python source code.  Moreover, this crash was\n <mask>     spurious on Python 3.7 thanks to PEP 538 and PEP 540.\n <mask>     \"\"\"\n <mask>     modules: List[Any] = []\n <mask>     try:\n <mask>         from click import core\n <mask>     except ImportError:\n <mask>         pass\n <mask>     else:\n <mask>         modules.append(core)\n <mask>     try:\n <mask>         # Removed in Click 8.1.0 and newer; we keep this around for users who have\n <mask>         # older versions installed.\n <mask>         from click import _unicodefun  # type: ignore\n <mask>     except ImportError:\n <mask>         pass\n <mask>     else:\n <mask>         modules.append(_unicodefun)\n <mask> \n <mask>     for module in modules:\n <mask>         if hasattr(module, \"_verify_python3_env\"):\n <mask>             module._verify_python3_env = lambda: None\n <mask>         if hasattr(module, \"_verify_python_env\"):\n <mask>             module._verify_python_env = lambda: None\n <mask> \n <mask> \n <mask> def patched_main() -> None:\n <mask>     # PyInstaller patches multiprocessing to need freeze_support() even in non-Windows\n <mask>     # environments so just assume we always need to call it if frozen.\n <mask>     if getattr(sys, \"frozen\", False):\n <mask>         from multiprocessing import freeze_support\n </s> Remove click patch (#3768)\n\nApparently this was only needed on Python 3.6. We've now dropped support\r\nfor 3.6 and 3.7. It's also not needed on new enough click. </s> remove     def test_shhh_click(self) -> None:\n        try:\n            from click import _unicodefun  # type: ignore\n        except ImportError:\n            self.skipTest(\"Incompatible Click version\")\n\n        if not hasattr(_unicodefun, \"_verify_python_env\"):\n            self.skipTest(\"Incompatible Click version\")\n\n        # First, let's see if Click is crashing with a preferred ASCII charset.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            with self.assertRaises(RuntimeError):\n                _unicodefun._verify_python_env()\n        # Now, let's silence Click...\n        black.patch_click()\n        # ...and confirm it's silent.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            try:\n                _unicodefun._verify_python_env()\n            except RuntimeError as re:\n                self.fail(f\"`patch_click()` failed, exception still raised: {re}\")\n\n </s> add  </s> remove     patch_click()\n </s> add  </s> remove     black.patch_click()\n </s> add  </s> remove .. autofunction:: black.patch_click\n\n </s> add ", "html_url": "https://github.com/psf/black/commit/114e8357e65384e17baaa3c31aa528371e15679b", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         from multiprocessing import freeze_support\n <mask> \n <mask>         freeze_support()\n <mask> \n <mask>     patch_click()\n <mask>     main()\n <mask> \n <mask> \n <mask> if __name__ == \"__main__\":\n <mask>     patched_main()\n </s> Remove click patch (#3768)\n\nApparently this was only needed on Python 3.6. We've now dropped support\r\nfor 3.6 and 3.7. It's also not needed on new enough click. </s> remove     black.patch_click()\n </s> add  </s> remove def patch_click() -> None:\n    \"\"\"Make Click not crash on Python 3.6 with LANG=C.\n\n    On certain misconfigured environments, Python 3 selects the ASCII encoding as the\n    default which restricts paths that it can access during the lifetime of the\n    application.  Click refuses to work in this scenario by raising a RuntimeError.\n\n    In case of Black the likelihood that non-ASCII characters are going to be used in\n    file paths is minimal since it's Python source code.  Moreover, this crash was\n    spurious on Python 3.7 thanks to PEP 538 and PEP 540.\n    \"\"\"\n    modules: List[Any] = []\n    try:\n        from click import core\n    except ImportError:\n        pass\n    else:\n        modules.append(core)\n    try:\n        # Removed in Click 8.1.0 and newer; we keep this around for users who have\n        # older versions installed.\n        from click import _unicodefun  # type: ignore\n    except ImportError:\n        pass\n    else:\n        modules.append(_unicodefun)\n\n    for module in modules:\n        if hasattr(module, \"_verify_python3_env\"):\n            module._verify_python3_env = lambda: None\n        if hasattr(module, \"_verify_python_env\"):\n            module._verify_python_env = lambda: None\n\n\n </s> add  </s> remove     def test_shhh_click(self) -> None:\n        try:\n            from click import _unicodefun  # type: ignore\n        except ImportError:\n            self.skipTest(\"Incompatible Click version\")\n\n        if not hasattr(_unicodefun, \"_verify_python_env\"):\n            self.skipTest(\"Incompatible Click version\")\n\n        # First, let's see if Click is crashing with a preferred ASCII charset.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            with self.assertRaises(RuntimeError):\n                _unicodefun._verify_python_env()\n        # Now, let's silence Click...\n        black.patch_click()\n        # ...and confirm it's silent.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            try:\n                _unicodefun._verify_python_env()\n            except RuntimeError as re:\n                self.fail(f\"`patch_click()` failed, exception still raised: {re}\")\n\n </s> add  </s> remove .. autofunction:: black.patch_click\n\n </s> add ", "html_url": "https://github.com/psf/black/commit/114e8357e65384e17baaa3c31aa528371e15679b", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def patched_main() -> None:\n <mask>     maybe_install_uvloop()\n <mask>     freeze_support()\n <mask>     black.patch_click()\n <mask>     main()\n <mask> \n <mask> \n <mask> if __name__ == \"__main__\":\n <mask>     patched_main()\n </s> Remove click patch (#3768)\n\nApparently this was only needed on Python 3.6. We've now dropped support\r\nfor 3.6 and 3.7. It's also not needed on new enough click. </s> remove     patch_click()\n </s> add  </s> remove     def test_shhh_click(self) -> None:\n        try:\n            from click import _unicodefun  # type: ignore\n        except ImportError:\n            self.skipTest(\"Incompatible Click version\")\n\n        if not hasattr(_unicodefun, \"_verify_python_env\"):\n            self.skipTest(\"Incompatible Click version\")\n\n        # First, let's see if Click is crashing with a preferred ASCII charset.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            with self.assertRaises(RuntimeError):\n                _unicodefun._verify_python_env()\n        # Now, let's silence Click...\n        black.patch_click()\n        # ...and confirm it's silent.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            try:\n                _unicodefun._verify_python_env()\n            except RuntimeError as re:\n                self.fail(f\"`patch_click()` failed, exception still raised: {re}\")\n\n </s> add  </s> remove def patch_click() -> None:\n    \"\"\"Make Click not crash on Python 3.6 with LANG=C.\n\n    On certain misconfigured environments, Python 3 selects the ASCII encoding as the\n    default which restricts paths that it can access during the lifetime of the\n    application.  Click refuses to work in this scenario by raising a RuntimeError.\n\n    In case of Black the likelihood that non-ASCII characters are going to be used in\n    file paths is minimal since it's Python source code.  Moreover, this crash was\n    spurious on Python 3.7 thanks to PEP 538 and PEP 540.\n    \"\"\"\n    modules: List[Any] = []\n    try:\n        from click import core\n    except ImportError:\n        pass\n    else:\n        modules.append(core)\n    try:\n        # Removed in Click 8.1.0 and newer; we keep this around for users who have\n        # older versions installed.\n        from click import _unicodefun  # type: ignore\n    except ImportError:\n        pass\n    else:\n        modules.append(_unicodefun)\n\n    for module in modules:\n        if hasattr(module, \"_verify_python3_env\"):\n            module._verify_python3_env = lambda: None\n        if hasattr(module, \"_verify_python_env\"):\n            module._verify_python_env = lambda: None\n\n\n </s> add  </s> remove .. autofunction:: black.patch_click\n\n </s> add ", "html_url": "https://github.com/psf/black/commit/114e8357e65384e17baaa3c31aa528371e15679b", "file_name": "src/blackd/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     def test_assert_equivalent_different_asts(self) -> None:\n <mask>         with self.assertRaises(AssertionError):\n <mask>             black.assert_equivalent(\"{}\", \"None\")\n <mask> \n <mask>     def test_shhh_click(self) -> None:\n <mask>         try:\n <mask>             from click import _unicodefun  # type: ignore\n <mask>         except ImportError:\n <mask>             self.skipTest(\"Incompatible Click version\")\n <mask> \n <mask>         if not hasattr(_unicodefun, \"_verify_python_env\"):\n <mask>             self.skipTest(\"Incompatible Click version\")\n <mask> \n <mask>         # First, let's see if Click is crashing with a preferred ASCII charset.\n <mask>         with patch(\"locale.getpreferredencoding\") as gpe:\n <mask>             gpe.return_value = \"ASCII\"\n <mask>             with self.assertRaises(RuntimeError):\n <mask>                 _unicodefun._verify_python_env()\n <mask>         # Now, let's silence Click...\n <mask>         black.patch_click()\n <mask>         # ...and confirm it's silent.\n <mask>         with patch(\"locale.getpreferredencoding\") as gpe:\n <mask>             gpe.return_value = \"ASCII\"\n <mask>             try:\n <mask>                 _unicodefun._verify_python_env()\n <mask>             except RuntimeError as re:\n <mask>                 self.fail(f\"`patch_click()` failed, exception still raised: {re}\")\n <mask> \n <mask>     def test_root_logger_not_used_directly(self) -> None:\n <mask>         def fail(*args: Any, **kwargs: Any) -> None:\n <mask>             self.fail(\"Record created with root logger\")\n <mask> \n <mask>         with patch.multiple(\n </s> Remove click patch (#3768)\n\nApparently this was only needed on Python 3.6. We've now dropped support\r\nfor 3.6 and 3.7. It's also not needed on new enough click. </s> remove def patch_click() -> None:\n    \"\"\"Make Click not crash on Python 3.6 with LANG=C.\n\n    On certain misconfigured environments, Python 3 selects the ASCII encoding as the\n    default which restricts paths that it can access during the lifetime of the\n    application.  Click refuses to work in this scenario by raising a RuntimeError.\n\n    In case of Black the likelihood that non-ASCII characters are going to be used in\n    file paths is minimal since it's Python source code.  Moreover, this crash was\n    spurious on Python 3.7 thanks to PEP 538 and PEP 540.\n    \"\"\"\n    modules: List[Any] = []\n    try:\n        from click import core\n    except ImportError:\n        pass\n    else:\n        modules.append(core)\n    try:\n        # Removed in Click 8.1.0 and newer; we keep this around for users who have\n        # older versions installed.\n        from click import _unicodefun  # type: ignore\n    except ImportError:\n        pass\n    else:\n        modules.append(_unicodefun)\n\n    for module in modules:\n        if hasattr(module, \"_verify_python3_env\"):\n            module._verify_python3_env = lambda: None\n        if hasattr(module, \"_verify_python_env\"):\n            module._verify_python_env = lambda: None\n\n\n </s> add  </s> remove     black.patch_click()\n </s> add  </s> remove     patch_click()\n </s> add  </s> remove .. autofunction:: black.patch_click\n\n </s> add ", "html_url": "https://github.com/psf/black/commit/114e8357e65384e17baaa3c31aa528371e15679b", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> # Specify the target platform details in config, so your developers are\n <mask> # free to run mypy on Windows, Linux, or macOS and get consistent\n <mask> # results.\n <mask> python_version=3.6\n <mask> platform=linux\n <mask> \n <mask> mypy_path=src\n <mask> \n <mask> show_column_numbers=True\n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> remove         elif isinstance(value, (ast.AST, ast3.AST, ast27.AST)):\n </s> add         # Note that we are referencing the typed-ast ASTs via global variables and not\n        # direct module attribute accesses because that breaks mypyc. It's probably\n        # something to do with the ast3 / ast27 variables being marked as Any leading\n        # mypy to think this branch is always taken, leaving the rest of the code\n        # unanalyzed. Tighting up the types for the typed-ast AST types avoids the\n        # mypyc crash.\n        elif isinstance(value, (ast.AST, ast3_AST, ast27_AST)): </s> add # Unreachable blocks have been an issue when compiling mypyc, let's try\n# to avoid 'em in the first place.\nwarn_unreachable=True\n </s> add         **post-note: the convert argument is ignored since for Black's\n        usage, convert will always be blib2to3.pytree.convert. Allowing\n        this to be dynamic hurts mypyc's ability to use early binding.\n        These docs are left for historical and informational value.\n </s> remove     MIN_SUBSTR_SIZE = 6\n </s> add     MIN_SUBSTR_SIZE: Final = 6 </s> remove             assert value is not None\n </s> add  </s> remove     numchars = \"0123456789\"\n </s> add     numchars: Final = \"0123456789\"", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "mypy.ini"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> warn_unused_ignores=True\n <mask> disallow_any_generics=True\n <mask> \n <mask> # The following are off by default.  Flip them on if you feel\n <mask> # adventurous.\n <mask> disallow_untyped_defs=True\n <mask> check_untyped_defs=True\n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> add [mypy-black]\n# The following is because of `patch_click()`. Remove when\n# we drop Python 3.6 support.\nwarn_unused_ignores=False\n </s> remove     numchars = \"0123456789\"\n </s> add     numchars: Final = \"0123456789\" </s> remove platform=linux\n </s> add  </s> remove @dataclass\n </s> add # This isn't a dataclass because @dataclass + Generic breaks mypyc.\n# See also https://github.com/mypyc/mypyc/issues/827. </s> remove     MIN_SUBSTR_SIZE = 6\n </s> add     MIN_SUBSTR_SIZE: Final = 6 </s> remove class StringSplitter(CustomSplitMapMixin, BaseStringSplitter):\n </s> add class StringSplitter(BaseStringSplitter, CustomSplitMapMixin):", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "mypy.ini"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> # No incremental mode\n <mask> cache_dir=/dev/null\n <mask> \n <mask> [mypy-black_primer.*]\n <mask> # Until we're not supporting 3.6 primer needs this\n <mask> disallow_any_generics=False\n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> remove                 elif t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, self.grammar.dfas[t], newstate, context)\n                        break  # To continue the outer while loop\n </s> add  </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> add # diff-shades depends on being to monkeypatch this function to operate. I know it's\n# not ideal, but this shouldn't cause any issues ... hopefully. ~ichard26\n@mypyc_attr(patchable=True) </s> remove                 t, v = self.grammar.labels[i]\n                if ilabel == i:\n </s> add                 t = self.grammar.labels[i][0]\n                if t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, itsdfa, newstate, context)\n                        break  # To continue the outer while loop\n\n                elif ilabel == i: </s> remove             assert value is not None\n </s> add  </s> remove     stashed = None\n </s> add     stashed: Optional[GoodTokenInfo] = None", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "mypy.ini"}
{"docstring_tokens": "keep keep keep add", "code_tokens": " <mask>   \"no_python2: run when `python2` extra NOT installed\",\n <mask>   \"no_blackd: run when `d` extra NOT installed\",\n <mask>   \"no_jupyter: run when `jupyter` extra NOT installed\",\n <mask> ]\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove platform=linux\n </s> add  </s> remove class BracketMatchError(KeyError):\n </s> add class BracketMatchError(Exception): </s> add [mypy-black]\n# The following is because of `patch_click()`. Remove when\n# we drop Python 3.6 support.\nwarn_unused_ignores=False\n </s> add # Unreachable blocks have been an issue when compiling mypyc, let's try\n# to avoid 'em in the first place.\nwarn_unreachable=True\n </s> add     @pytest.mark.incompatible_with_mypyc </s> remove         elif isinstance(value, (ast.AST, ast3.AST, ast27.AST)):\n </s> add         # Note that we are referencing the typed-ast ASTs via global variables and not\n        # direct module attribute accesses because that breaks mypyc. It's probably\n        # something to do with the ast3 / ast27 variables being marked as Any leading\n        # mypy to think this branch is always taken, leaving the rest of the code\n        # unanalyzed. Tighting up the types for the typed-ast AST types avoids the\n        # mypyc crash.\n        elif isinstance(value, (ast.AST, ast3_AST, ast27_AST)):", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "pyproject.toml"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> import os\n <mask> \n <mask> assert sys.version_info >= (3, 6, 2), \"black requires Python 3.6.2+\"\n <mask> from pathlib import Path  # noqa E402\n <mask> \n <mask> CURRENT_DIR = Path(__file__).parent\n <mask> sys.path.insert(0, str(CURRENT_DIR))  # for setuptools.build_meta\n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> remove if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n </s> add if sys.version_info >= (3, 8): </s> add else:\n    from typing_extensions import Final\n\nfrom mypy_extensions import mypyc_attr </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> add if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> add from functools import lru_cache", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "setup.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> USE_MYPYC = False\n <mask> # To compile with mypyc, a mypyc checkout must be present on the PYTHONPATH\n <mask> if len(sys.argv) > 1 and sys.argv[1] == \"--use-mypyc\":\n <mask>     sys.argv.pop(1)\n <mask>     USE_MYPYC = True\n <mask> if os.getenv(\"BLACK_USE_MYPYC\", None) == \"1\":\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove         \"src/black/__init__.py\",\n        \"src/blib2to3/pytree.py\",\n        \"src/blib2to3/pygram.py\",\n        \"src/blib2to3/pgen2/parse.py\",\n        \"src/blib2to3/pgen2/grammar.py\",\n        \"src/blib2to3/pgen2/token.py\",\n        \"src/blib2to3/pgen2/driver.py\",\n        \"src/blib2to3/pgen2/pgen.py\",\n </s> add         str(p) for p in discovered if p.relative_to(src).as_posix() not in blocklist </s> remove                 t, v = self.grammar.labels[i]\n                if ilabel == i:\n </s> add                 t = self.grammar.labels[i][0]\n                if t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, itsdfa, newstate, context)\n                        break  # To continue the outer while loop\n\n                elif ilabel == i: </s> remove                 elif t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, self.grammar.dfas[t], newstate, context)\n                        break  # To continue the outer while loop\n </s> add  </s> add         # HACK: nested functions (like _rhs) compiled by mypyc don't retain their\n        # __name__ attribute which is needed in `run_transformer` further down.\n        # Unfortunately a nested class breaks mypyc too. So a class must be created\n        # via type ... https://github.com/mypyc/mypyc/issues/884\n        rhs = type(\"rhs\", (), {\"__call__\": _rhs})()\n </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove                     column = column + 1\n </s> add                     column += 1", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace replace replace replace replace keep keep replace replace keep keep keep keep", "code_tokens": " <mask> \n <mask> if USE_MYPYC:\n <mask>     mypyc_targets = [\n <mask>         \"src/black/__init__.py\",\n <mask>         \"src/blib2to3/pytree.py\",\n <mask>         \"src/blib2to3/pygram.py\",\n <mask>         \"src/blib2to3/pgen2/parse.py\",\n <mask>         \"src/blib2to3/pgen2/grammar.py\",\n <mask>         \"src/blib2to3/pgen2/token.py\",\n <mask>         \"src/blib2to3/pgen2/driver.py\",\n <mask>         \"src/blib2to3/pgen2/pgen.py\",\n <mask>     ]\n <mask> \n <mask>     from mypyc.build import mypycify\n <mask> \n <mask>     opt_level = os.getenv(\"MYPYC_OPT_LEVEL\", \"3\")\n <mask>     ext_modules = mypycify(mypyc_targets, opt_level=opt_level)\n <mask> else:\n <mask>     ext_modules = []\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     ext_modules = mypycify(mypyc_targets, opt_level=opt_level)\n </s> add     ext_modules = mypycify(mypyc_targets, opt_level=opt_level, verbose=True) </s> add markers = [\n  \"incompatible_with_mypyc: run when testing mypyc compiled black\"\n] </s> remove         indent_columns = []\n </s> add         indent_columns: List[int] = [] </s> remove                 for version in sorted(self.target_versions, key=lambda v: v.value)\n </s> add                 for version in sorted(self.target_versions, key=attrgetter(\"value\")) </s> add     @pytest.mark.incompatible_with_mypyc", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     from mypyc.build import mypycify\n <mask> \n <mask>     opt_level = os.getenv(\"MYPYC_OPT_LEVEL\", \"3\")\n <mask>     ext_modules = mypycify(mypyc_targets, opt_level=opt_level)\n <mask> else:\n <mask>     ext_modules = []\n <mask> \n <mask> setup(\n <mask>     name=\"black\",\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     from mypyc.build import mypycify\n\n </s> add  </s> remove         \"src/black/__init__.py\",\n        \"src/blib2to3/pytree.py\",\n        \"src/blib2to3/pygram.py\",\n        \"src/blib2to3/pgen2/parse.py\",\n        \"src/blib2to3/pgen2/grammar.py\",\n        \"src/blib2to3/pgen2/token.py\",\n        \"src/blib2to3/pgen2/driver.py\",\n        \"src/blib2to3/pgen2/pgen.py\",\n </s> add         str(p) for p in discovered if p.relative_to(src).as_posix() not in blocklist </s> remove         indent_columns = []\n </s> add         indent_columns: List[int] = [] </s> add     @pytest.mark.incompatible_with_mypyc </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> add if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     Tuple,\n <mask>     Union,\n <mask> )\n <mask> \n <mask> from dataclasses import replace\n <mask> import click\n <mask> \n <mask> from black.const import DEFAULT_LINE_LENGTH, DEFAULT_INCLUDES, DEFAULT_EXCLUDES\n <mask> from black.const import STDIN_PLACEHOLDER\n <mask> from black.nodes import STARS, syms, is_simple_decorator_expression\n </s> Implementing mypyc support pt. 2  (#2431) </s> add from dataclasses import replace\nfrom mypy_extensions import mypyc_attr </s> add from operator import attrgetter </s> remove from dataclasses import dataclass, field\n\n </s> add  </s> add from contextlib import contextmanager </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple\n </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> remove from blib2to3 import pygram, pytree\n </s> add from blib2to3 import pygram", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> )\n <mask> \n <mask> import click\n <mask> \n <mask> from black.const import DEFAULT_LINE_LENGTH, DEFAULT_INCLUDES, DEFAULT_EXCLUDES\n <mask> from black.const import STDIN_PLACEHOLDER\n <mask> from black.nodes import STARS, syms, is_simple_decorator_expression\n <mask> from black.lines import Line, EmptyLineTracker\n <mask> from black.linegen import transform_line, LineGenerator, LN\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove from dataclasses import replace\n </s> add  </s> add from operator import attrgetter </s> remove from dataclasses import dataclass, field\n\n </s> add  </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> add from mypy_extensions import mypyc_attr </s> add ast3: Any\nast27: Any\n", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> from _black_version import version as __version__\n <mask> \n <mask> # types\n <mask> FileContent = str\n <mask> Encoding = str\n <mask> NewLine = str\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove syms = pygram.python_symbols\n </s> add syms: Final = pygram.python_symbols </s> remove @dataclasses.dataclass\n </s> add # Unsurprisingly, subclassing ast.NodeVisitor means we can't use dataclasses here\n# as mypyc will generate broken code. </s> remove                 for version in sorted(self.target_versions, key=lambda v: v.value)\n </s> add                 for version in sorted(self.target_versions, key=attrgetter(\"value\")) </s> remove     ext_modules = mypycify(mypyc_targets, opt_level=opt_level)\n </s> add     ext_modules = mypycify(mypyc_targets, opt_level=opt_level, verbose=True) </s> remove     from mypyc.build import mypycify\n\n </s> add  </s> add if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     except re.error:\n <mask>         raise click.BadParameter(\"Not a valid regular expression\") from None\n <mask> \n <mask> \n <mask> @click.command(context_settings=dict(help_option_names=[\"-h\", \"--help\"]))\n <mask> @click.option(\"-c\", \"--code\", type=str, help=\"Format the code passed in as a string.\")\n <mask> @click.option(\n <mask>     \"-l\",\n <mask>     \"--line-length\",\n <mask>     type=int,\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove @dataclass\n </s> add # This isn't a dataclass because @dataclass + Generic breaks mypyc.\n# See also https://github.com/mypyc/mypyc/issues/827. </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> add     @pytest.mark.incompatible_with_mypyc </s> remove with open(black.__file__, \"r\", encoding=\"utf-8\") as _bf:\n    black_source_lines = _bf.readlines()\n </s> add try:\n    with open(black.__file__, \"r\", encoding=\"utf-8\") as _bf:\n        black_source_lines = _bf.readlines()\nexcept UnicodeDecodeError:\n    if not black.COMPILED:\n        raise </s> add @mypyc_attr(patchable=True) </s> remove         pyproject_toml = tomli.load(f)  # type: ignore  # due to deprecated API usage\n </s> add         pyproject_toml = tomli.loads(f.read())", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"Also emit messages to stderr about files that were not changed or were ignored\"\n <mask>         \" due to exclusion patterns.\"\n <mask>     ),\n <mask> )\n <mask> @click.version_option(version=__version__)\n <mask> @click.argument(\n <mask>     \"src\",\n <mask>     nargs=-1,\n <mask>     type=click.Path(\n <mask>         exists=True, file_okay=True, dir_okay=True, readable=True, allow_dash=True\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     NO = \"\"\n    SPACE = \" \"\n    DOUBLESPACE = \"  \"\n </s> add     NO: Final = \"\"\n    SPACE: Final = \" \"\n    DOUBLESPACE: Final = \"  \" </s> add     @pytest.mark.incompatible_with_mypyc </s> add @mypyc_attr(patchable=True) </s> remove         pyproject_toml = tomli.load(f)  # type: ignore  # due to deprecated API usage\n </s> add         pyproject_toml = tomli.loads(f.read()) </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> remove         transform.__name__ != \"rhs\"\n </s> add         transform.__class__.__name__ != \"rhs\"", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     skip_magic_trailing_comma: bool,\n <mask>     experimental_string_processing: bool,\n <mask>     quiet: bool,\n <mask>     verbose: bool,\n <mask>     required_version: str,\n <mask>     include: Pattern[str],\n <mask>     exclude: Optional[Pattern[str]],\n <mask>     extend_exclude: Optional[Pattern[str]],\n <mask>     force_exclude: Optional[Pattern[str]],\n <mask>     stdin_filename: Optional[str],\n </s> Implementing mypyc support pt. 2  (#2431) </s> add # diff-shades depends on being to monkeypatch this function to operate. I know it's\n# not ideal, but this shouldn't cause any issues ... hopefully. ~ichard26\n@mypyc_attr(patchable=True) </s> remove STRING_PREFIX_CHARS = \"furbFURB\"  # All possible string prefix characters.\n </s> add STRING_PREFIX_CHARS: Final = \"furbFURB\"  # All possible string prefix characters.\nSTRING_PREFIX_RE: Final = re.compile(\n    r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", re.DOTALL\n)\nFIRST_NON_WHITESPACE_RE: Final = re.compile(r\"\\s*\\t+\\s*(\\S)\") </s> remove with open(black.__file__, \"r\", encoding=\"utf-8\") as _bf:\n    black_source_lines = _bf.readlines()\n </s> add try:\n    with open(black.__file__, \"r\", encoding=\"utf-8\") as _bf:\n        black_source_lines = _bf.readlines()\nexcept UnicodeDecodeError:\n    if not black.COMPILED:\n        raise </s> add     @pytest.mark.incompatible_with_mypyc </s> remove class StringSplitter(CustomSplitMapMixin, BaseStringSplitter):\n </s> add class StringSplitter(BaseStringSplitter, CustomSplitMapMixin): </s> remove from blib2to3 import pygram, pytree\n </s> add from blib2to3 import pygram", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             traceback.print_exc()\n <mask>         report.failed(src, str(exc))\n <mask> \n <mask> \n <mask> def reformat_many(\n <mask>     sources: Set[Path],\n <mask>     fast: bool,\n <mask>     write_back: WriteBack,\n <mask>     mode: Mode,\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> remove     required_version: str,\n </s> add     required_version: Optional[str], </s> add     @pytest.mark.incompatible_with_mypyc </s> remove     __hash__ = None  # type: Any  # For Py3 compatibility.\n\n </s> add  </s> remove     cell_magic: Optional[CellMagic] = None\n </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic </s> remove     def add_token(\n        self, tok_type: int, tok_val: Optional[Text], raw: bool = False\n    ) -> None:\n </s> add     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     worker_count = workers if workers is not None else DEFAULT_WORKERS\n <mask>     if sys.platform == \"win32\":\n <mask>         # Work around https://bugs.python.org/issue26903\n <mask>         worker_count = min(worker_count, 60)\n <mask>     try:\n <mask>         executor = ProcessPoolExecutor(max_workers=worker_count)\n <mask>     except (ImportError, OSError):\n <mask>         # we arrive here if the underlying system does not support multi-processing\n <mask>         # like in AWS Lambda or Termux, in which case we gracefully fallback to\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove         lnum = lnum + 1\n </s> add         lnum += 1 </s> remove     stashed = None\n </s> add     stashed: Optional[GoodTokenInfo] = None </s> remove         drv = driver.Driver(grammar, pytree.convert)\n </s> add         drv = driver.Driver(grammar) </s> remove     numchars = \"0123456789\"\n </s> add     numchars: Final = \"0123456789\" </s> remove @click.command(context_settings=dict(help_option_names=[\"-h\", \"--help\"]))\n </s> add @click.command(\n    context_settings=dict(help_option_names=[\"-h\", \"--help\"]),\n    # While Click does set this field automatically using the docstring, mypyc\n    # (annoyingly) strips 'em so we need to set it here too.\n    help=\"The uncompromising code formatter.\",\n) </s> remove     NO = \"\"\n    SPACE = \" \"\n    DOUBLESPACE = \"  \"\n </s> add     NO: Final = \"\"\n    SPACE: Final = \" \"\n    DOUBLESPACE: Final = \"  \"", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> }\n <mask> DOT_PRIORITY: Final = 1\n <mask> \n <mask> \n <mask> class BracketMatchError(KeyError):\n <mask>     \"\"\"Raised when an opening bracket is unable to be matched to a closing bracket.\"\"\"\n <mask> \n <mask> \n <mask> @dataclass\n <mask> class BracketTracker:\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove @dataclass\n </s> add # This isn't a dataclass because @dataclass + Generic breaks mypyc.\n# See also https://github.com/mypyc/mypyc/issues/827. </s> remove     MIN_SUBSTR_SIZE = 6\n </s> add     MIN_SUBSTR_SIZE: Final = 6 </s> remove IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}\nOPENING_BRACKETS = set(BRACKET.keys())\nCLOSING_BRACKETS = set(BRACKET.values())\nBRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}\n </s> add IMPLICIT_TUPLE: Final = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET: Final = {\n    token.LPAR: token.RPAR,\n    token.LSQB: token.RSQB,\n    token.LBRACE: token.RBRACE,\n}\nOPENING_BRACKETS: Final = set(BRACKET.keys())\nCLOSING_BRACKETS: Final = set(BRACKET.values())\nBRACKETS: Final = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE: Final = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT} </s> remove \nFMT_OFF = {\"# fmt: off\", \"# fmt:off\", \"# yapf: disable\"}\nFMT_SKIP = {\"# fmt: skip\", \"# fmt:skip\"}\nFMT_PASS = {*FMT_OFF, *FMT_SKIP}\nFMT_ON = {\"# fmt: on\", \"# fmt:on\", \"# yapf: enable\"}\n </s> add FMT_OFF: Final = {\"# fmt: off\", \"# fmt:off\", \"# yapf: disable\"}\nFMT_SKIP: Final = {\"# fmt: skip\", \"# fmt:skip\"}\nFMT_PASS: Final = {*FMT_OFF, *FMT_SKIP}\nFMT_ON: Final = {\"# fmt: on\", \"# fmt:on\", \"# yapf: enable\"} </s> add         # HACK: nested functions (like _rhs) compiled by mypyc don't retain their\n        # __name__ attribute which is needed in `run_transformer` further down.\n        # Unfortunately a nested class breaks mypyc too. So a class must be created\n        # via type ... https://github.com/mypyc/mypyc/issues/884\n        rhs = type(\"rhs\", (), {\"__call__\": _rhs})()\n </s> add         **post-note: the convert argument is ignored since for Black's\n        usage, convert will always be blib2to3.pytree.convert. Allowing\n        this to be dynamic hurts mypyc's ability to use early binding.\n        These docs are left for historical and informational value.\n", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/brackets.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> from functools import lru_cache\n <mask> import regex as re\n <mask> from typing import Iterator, List, Optional, Union\n <mask> \n <mask> from blib2to3.pytree import Node, Leaf\n <mask> from blib2to3.pgen2 import token\n <mask> \n <mask> from black.nodes import first_leaf_column, preceding_leaf, container_of\n </s> Implementing mypyc support pt. 2  (#2431) </s> add from functools import lru_cache </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple\n </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> remove from dataclasses import dataclass, field\n\n </s> add  </s> remove from blib2to3 import pygram, pytree\n </s> add from blib2to3 import pygram </s> add else:\n    from typing_extensions import Final\n\nfrom mypy_extensions import mypyc_attr </s> add import sys", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/comments.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> # types\n <mask> LN = Union[Leaf, Node]\n <mask> \n <mask> \n <mask> FMT_OFF = {\"# fmt: off\", \"# fmt:off\", \"# yapf: disable\"}\n <mask> FMT_SKIP = {\"# fmt: skip\", \"# fmt:skip\"}\n <mask> FMT_PASS = {*FMT_OFF, *FMT_SKIP}\n <mask> FMT_ON = {\"# fmt: on\", \"# fmt:on\", \"# yapf: enable\"}\n <mask> \n <mask> \n <mask> @dataclass\n <mask> class ProtoComment:\n <mask>     \"\"\"Describes a piece of syntax that is a comment.\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove syms = pygram.python_symbols\n </s> add syms: Final = pygram.python_symbols </s> remove         p = parse.Parser(self.grammar, self.convert)\n </s> add         p = parse.Parser(self.grammar) </s> remove         self.convert = convert\n </s> add  </s> remove class BracketMatchError(KeyError):\n </s> add class BracketMatchError(Exception): </s> remove     def parse_tokens(self, tokens: Iterable[Any], debug: bool = False) -> NL:\n </s> add     def parse_tokens(self, tokens: Iterable[GoodTokenInfo], debug: bool = False) -> NL: </s> remove         match = re.match(r\"\\s*\\t+\\s*(\\S)\", line)\n </s> add         match = FIRST_NON_WHITESPACE_RE.match(line)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/comments.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> )\n <mask> \n <mask> from pathspec import PathSpec\n <mask> from pathspec.patterns.gitwildmatch import GitWildMatchPatternError\n <mask> import tomli\n <mask> \n <mask> from black.output import err\n <mask> from black.report import Report\n </s> Implementing mypyc support pt. 2  (#2431) </s> add from dataclasses import replace\nfrom mypy_extensions import mypyc_attr </s> remove from dataclasses import replace\n </s> add  </s> add from contextlib import contextmanager </s> remove from blib2to3 import pygram, pytree\n </s> add from blib2to3 import pygram </s> add from operator import attrgetter </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/files.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         err(f\"Ignoring user configuration directory due to {e!r}\")\n <mask>         return None\n <mask> \n <mask> \n <mask> def parse_pyproject_toml(path_config: str) -> Dict[str, Any]:\n <mask>     \"\"\"Parse a pyproject toml file, pulling out relevant parts for Black\n <mask> \n <mask>     If parsing fails, will raise a tomli.TOMLDecodeError\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove         pyproject_toml = tomli.load(f)  # type: ignore  # due to deprecated API usage\n </s> add         pyproject_toml = tomli.loads(f.read()) </s> add         **post-note: the convert argument is ignored since for Black's\n        usage, convert will always be blib2to3.pytree.convert. Allowing\n        this to be dynamic hurts mypyc's ability to use early binding.\n        These docs are left for historical and informational value.\n </s> remove     stashed = None\n </s> add     stashed: Optional[GoodTokenInfo] = None </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> remove             assert value is not None\n </s> add  </s> remove         self.convert = convert\n </s> add ", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/files.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     If parsing fails, will raise a tomli.TOMLDecodeError\n <mask>     \"\"\"\n <mask>     with open(path_config, encoding=\"utf8\") as f:\n <mask>         pyproject_toml = tomli.load(f)  # type: ignore  # due to deprecated API usage\n <mask>     config = pyproject_toml.get(\"tool\", {}).get(\"black\", {})\n <mask>     return {k.replace(\"--\", \"\").replace(\"-\", \"_\"): v for k, v in config.items()}\n <mask> \n <mask> \n <mask> @lru_cache()\n </s> Implementing mypyc support pt. 2  (#2431) </s> add @mypyc_attr(patchable=True) </s> remove     stashed = None\n </s> add     stashed: Optional[GoodTokenInfo] = None </s> remove                     assert t < 256\n </s> add  </s> remove     NO = \"\"\n    SPACE = \" \"\n    DOUBLESPACE = \"  \"\n </s> add     NO: Final = \"\"\n    SPACE: Final = \" \"\n    DOUBLESPACE: Final = \"  \" </s> remove                 t, v = self.grammar.labels[i]\n                if ilabel == i:\n </s> add                 t = self.grammar.labels[i][0]\n                if t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, itsdfa, newstate, context)\n                        break  # To continue the outer while loop\n\n                elif ilabel == i: </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__()", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/files.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return f\"%%{self.name} {self.params}\"\n <mask>         return f\"%%{self.name}\"\n <mask> \n <mask> \n <mask> @dataclasses.dataclass\n <mask> class CellMagicFinder(ast.NodeVisitor):\n <mask>     \"\"\"Find cell magics.\n <mask> \n <mask>     Note that the source of the abstract syntax tree\n <mask>     will already have been processed by IPython's\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove @dataclasses.dataclass\n </s> add # Unsurprisingly, subclassing ast.NodeVisitor means we can't use dataclasses here\n# as mypyc will generate broken code. </s> remove @dataclass\n </s> add # This isn't a dataclass because @dataclass + Generic breaks mypyc.\n# See also https://github.com/mypyc/mypyc/issues/827. </s> remove class StringParenWrapper(CustomSplitMapMixin, BaseStringSplitter):\n </s> add class StringParenWrapper(BaseStringSplitter, CustomSplitMapMixin): </s> remove class StringSplitter(CustomSplitMapMixin, BaseStringSplitter):\n </s> add class StringSplitter(BaseStringSplitter, CustomSplitMapMixin): </s> remove         return self.prefix + str(self.value)\n </s> add         return self._prefix + str(self.value) </s> remove     cell_magic: Optional[CellMagic] = None\n </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/handle_ipynb_magics.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     and we look for instances of the latter.\n <mask>     \"\"\"\n <mask> \n <mask>     cell_magic: Optional[CellMagic] = None\n <mask> \n <mask>     def visit_Expr(self, node: ast.Expr) -> None:\n <mask>         \"\"\"Find cell magic, extract header and body.\"\"\"\n <mask>         if (\n <mask>             isinstance(node.value, ast.Call)\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     magics: Dict[int, List[OffsetAndMagic]] = dataclasses.field(\n        default_factory=lambda: collections.defaultdict(list)\n    )\n </s> add     def __init__(self) -> None:\n        self.magics: Dict[int, List[OffsetAndMagic]] = collections.defaultdict(list) </s> remove     numchars = \"0123456789\"\n </s> add     numchars: Final = \"0123456789\" </s> remove     stashed = None\n </s> add     stashed: Optional[GoodTokenInfo] = None </s> remove @dataclasses.dataclass\n </s> add # Unsurprisingly, subclassing ast.NodeVisitor means we can't use dataclasses here\n# as mypyc will generate broken code. </s> remove @dataclasses.dataclass\n </s> add # ast.NodeVisitor + dataclass = breakage under mypyc. </s> add @mypyc_attr(allow_interpreted_subclasses=True)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/handle_ipynb_magics.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     col_offset: int\n <mask>     magic: str\n <mask> \n <mask> \n <mask> @dataclasses.dataclass\n <mask> class MagicFinder(ast.NodeVisitor):\n <mask>     \"\"\"Visit cell to look for get_ipython calls.\n <mask> \n <mask>     Note that the source of the abstract syntax tree\n <mask>     will already have been processed by IPython's\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove @dataclasses.dataclass\n </s> add # ast.NodeVisitor + dataclass = breakage under mypyc. </s> remove @dataclass\n </s> add # This isn't a dataclass because @dataclass + Generic breaks mypyc.\n# See also https://github.com/mypyc/mypyc/issues/827. </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> add # Unreachable blocks have been an issue when compiling mypyc, let's try\n# to avoid 'em in the first place.\nwarn_unreachable=True\n </s> remove     cell_magic: Optional[CellMagic] = None\n </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic </s> add         **post-note: the convert argument is ignored since for Black's\n        usage, convert will always be blib2to3.pytree.convert. Allowing\n        this to be dynamic hurts mypyc's ability to use early binding.\n        These docs are left for historical and informational value.\n", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/handle_ipynb_magics.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     and we look for instances of the latter (and likewise for other\n <mask>     types of magics).\n <mask>     \"\"\"\n <mask> \n <mask>     magics: Dict[int, List[OffsetAndMagic]] = dataclasses.field(\n <mask>         default_factory=lambda: collections.defaultdict(list)\n <mask>     )\n <mask> \n <mask>     def visit_Assign(self, node: ast.Assign) -> None:\n <mask>         \"\"\"Look for system assign magics.\n <mask> \n <mask>         For example,\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     cell_magic: Optional[CellMagic] = None\n </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic </s> remove @dataclasses.dataclass\n </s> add # Unsurprisingly, subclassing ast.NodeVisitor means we can't use dataclasses here\n# as mypyc will generate broken code. </s> add @mypyc_attr(allow_interpreted_subclasses=True) </s> remove         match = re.match(r\"\\s*\\t+\\s*(\\S)\", line)\n </s> add         match = FIRST_NON_WHITESPACE_RE.match(line) </s> remove     stashed = None\n </s> add     stashed: Optional[GoodTokenInfo] = None </s> remove         elif isinstance(value, (ast.AST, ast3.AST, ast27.AST)):\n </s> add         # Note that we are referencing the typed-ast ASTs via global variables and not\n        # direct module attribute accesses because that breaks mypyc. It's probably\n        # something to do with the ast3 / ast27 variables being marked as Any leading\n        # mypy to think this branch is always taken, leaving the rest of the code\n        # unanalyzed. Tighting up the types for the typed-ast AST types avoids the\n        # mypyc crash.\n        elif isinstance(value, (ast.AST, ast3_AST, ast27_AST)):", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/handle_ipynb_magics.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> from functools import partial, wraps\n <mask> import sys\n <mask> from typing import Collection, Iterator, List, Optional, Set, Union\n <mask> \n <mask> from dataclasses import dataclass, field\n <mask> \n <mask> from black.nodes import WHITESPACE, RARROW, STATEMENT, STANDALONE_COMMENT\n <mask> from black.nodes import ASSIGNMENTS, OPENING_BRACKETS, CLOSING_BRACKETS\n <mask> from black.nodes import Visitor, syms, first_child_is_arith, ensure_visible\n <mask> from black.nodes import is_docstring, is_empty_tuple, is_one_tuple, is_one_tuple_between\n <mask> from black.nodes import is_walrus_assignment, is_yield, is_vararg, is_multiline_string\n </s> Implementing mypyc support pt. 2  (#2431) </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> remove from dataclasses import replace\n </s> add  </s> add from dataclasses import replace\nfrom mypy_extensions import mypyc_attr </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple\n </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> add ast3: Any\nast27: Any\n </s> add from operator import attrgetter", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> class CannotSplit(CannotTransform):\n <mask>     \"\"\"A readable split that fits the allotted line length is impossible.\"\"\"\n <mask> \n <mask> \n <mask> @dataclass\n <mask> class LineGenerator(Visitor[Line]):\n <mask>     \"\"\"Generates reformatted Line objects.  Empty lines are not emitted.\n <mask> \n <mask>     Note: destroys the tree it's visiting by mutating prefixes of its leaves\n <mask>     in ways that will no longer stringify to valid Python code on the tree.\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> remove @dataclasses.dataclass\n </s> add # ast.NodeVisitor + dataclass = breakage under mypyc. </s> remove @dataclasses.dataclass\n </s> add # Unsurprisingly, subclassing ast.NodeVisitor means we can't use dataclasses here\n# as mypyc will generate broken code. </s> remove class StringParenWrapper(CustomSplitMapMixin, BaseStringSplitter):\n </s> add class StringParenWrapper(BaseStringSplitter, CustomSplitMapMixin): </s> remove class StringSplitter(CustomSplitMapMixin, BaseStringSplitter):\n </s> add class StringSplitter(BaseStringSplitter, CustomSplitMapMixin): </s> add @mypyc_attr(allow_interpreted_subclasses=True)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     Note: destroys the tree it's visiting by mutating prefixes of its leaves\n <mask>     in ways that will no longer stringify to valid Python code on the tree.\n <mask>     \"\"\"\n <mask> \n <mask>     mode: Mode\n <mask>     remove_u_prefix: bool = False\n <mask>     current_line: Line = field(init=False)\n <mask> \n <mask>     def line(self, indent: int = 0) -> Iterator[Line]:\n <mask>         \"\"\"Generate a line.\n <mask> \n <mask>         If the line is empty, only emit if it makes sense.\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove @dataclass\n </s> add # This isn't a dataclass because @dataclass + Generic breaks mypyc.\n# See also https://github.com/mypyc/mypyc/issues/827. </s> remove     match = re.match(r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", s, re.DOTALL)\n </s> add     match = STRING_PREFIX_RE.match(s) </s> remove @dataclasses.dataclass\n </s> add # Unsurprisingly, subclassing ast.NodeVisitor means we can't use dataclasses here\n# as mypyc will generate broken code. </s> remove     numchars = \"0123456789\"\n </s> add     numchars: Final = \"0123456789\" </s> add     @pytest.mark.incompatible_with_mypyc </s> remove @dataclasses.dataclass\n </s> add # ast.NodeVisitor + dataclass = breakage under mypyc.", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     elif line.is_def:\n <mask>         transformers = [left_hand_split]\n <mask>     else:\n <mask> \n <mask>         def rhs(line: Line, features: Collection[Feature]) -> Iterator[Line]:\n <mask>             \"\"\"Wraps calls to `right_hand_split`.\n <mask> \n <mask>             The calls increasingly `omit` right-hand trailers (bracket pairs with\n <mask>             content), meaning the trailers get glued together to split on another\n <mask>             bracket pair instead.\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     MIN_SUBSTR_SIZE = 6\n </s> add     MIN_SUBSTR_SIZE: Final = 6 </s> remove platform=linux\n </s> add  </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> remove class BracketMatchError(KeyError):\n </s> add class BracketMatchError(Exception): </s> add # Unreachable blocks have been an issue when compiling mypyc, let's try\n# to avoid 'em in the first place.\nwarn_unreachable=True\n </s> remove         elif isinstance(value, (ast.AST, ast3.AST, ast27.AST)):\n </s> add         # Note that we are referencing the typed-ast ASTs via global variables and not\n        # direct module attribute accesses because that breaks mypyc. It's probably\n        # something to do with the ast3 / ast27 variables being marked as Any leading\n        # mypy to think this branch is always taken, leaving the rest of the code\n        # unanalyzed. Tighting up the types for the typed-ast AST types avoids the\n        # mypyc crash.\n        elif isinstance(value, (ast.AST, ast3_AST, ast27_AST)):", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>                 line, line_length=mode.line_length, features=features\n <mask>             )\n <mask> \n <mask>         if mode.experimental_string_processing:\n <mask>             if line.inside_brackets:\n <mask>                 transformers = [\n <mask>                     string_merge,\n <mask>                     string_paren_strip,\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove                 for version in sorted(self.target_versions, key=lambda v: v.value)\n </s> add                 for version in sorted(self.target_versions, key=attrgetter(\"value\")) </s> remove     STRING_OPERATORS = [\n </s> add     STRING_OPERATORS: Final = [ </s> remove                     (lnum, pos + len(comment_token)),\n </s> add                     (lnum, nl_pos), </s> remove         \"src/black/__init__.py\",\n        \"src/blib2to3/pytree.py\",\n        \"src/blib2to3/pygram.py\",\n        \"src/blib2to3/pgen2/parse.py\",\n        \"src/blib2to3/pgen2/grammar.py\",\n        \"src/blib2to3/pgen2/token.py\",\n        \"src/blib2to3/pgen2/driver.py\",\n        \"src/blib2to3/pgen2/pgen.py\",\n </s> add         str(p) for p in discovered if p.relative_to(src).as_posix() not in blocklist </s> remove         def rhs(line: Line, features: Collection[Feature]) -> Iterator[Line]:\n </s> add         def _rhs(\n            self: object, line: Line, features: Collection[Feature]\n        ) -> Iterator[Line]: </s> add markers = [\n  \"incompatible_with_mypyc: run when testing mypyc compiled black\"\n]", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         result.extend(transform_line(transformed_line, mode=mode, features=features))\n <mask> \n <mask>     if (\n <mask>         transform.__name__ != \"rhs\"\n <mask>         or not line.bracket_tracker.invisible\n <mask>         or any(bracket.value for bracket in line.bracket_tracker.invisible)\n <mask>         or line.contains_multiline_strings()\n <mask>         or result[0].contains_uncollapsable_type_comments()\n <mask>         or result[0].contains_unsplittable_type_ignore()\n </s> Implementing mypyc support pt. 2  (#2431) </s> add         **post-note: the convert argument is ignored since for Black's\n        usage, convert will always be blib2to3.pytree.convert. Allowing\n        this to be dynamic hurts mypyc's ability to use early binding.\n        These docs are left for historical and informational value.\n </s> remove             assert value is not None\n </s> add  </s> remove platform=linux\n </s> add  </s> add         # See note in docstring above. TL;DR this is ignored. </s> remove @click.version_option(version=__version__)\n </s> add @click.version_option(\n    version=__version__,\n    message=f\"%(prog)s, %(version)s (compiled: {'yes' if COMPILED else 'no'})\",\n) </s> add         assert worker_count is not None", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> from dataclasses import dataclass, field\n <mask> from enum import Enum\n <mask> from typing import Dict, Set\n <mask> \n <mask> from black.const import DEFAULT_LINE_LENGTH\n <mask> \n <mask> \n <mask> class TargetVersion(Enum):\n </s> Implementing mypyc support pt. 2  (#2431) </s> add from contextlib import contextmanager </s> remove from dataclasses import dataclass, field\n\n </s> add  </s> remove from dataclasses import replace\n </s> add  </s> add from dataclasses import replace\nfrom mypy_extensions import mypyc_attr </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> remove     Callable,\n </s> add ", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/mode.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def get_cache_key(self) -> str:\n <mask>         if self.target_versions:\n <mask>             version_str = \",\".join(\n <mask>                 str(version.value)\n <mask>                 for version in sorted(self.target_versions, key=lambda v: v.value)\n <mask>             )\n <mask>         else:\n <mask>             version_str = \"-\"\n <mask>         parts = [\n <mask>             version_str,\n </s> Implementing mypyc support pt. 2  (#2431) </s> add COMPILED = Path(__file__).suffix in (\".pyd\", \".so\")\n </s> remove         \"src/black/__init__.py\",\n        \"src/blib2to3/pytree.py\",\n        \"src/blib2to3/pygram.py\",\n        \"src/blib2to3/pgen2/parse.py\",\n        \"src/blib2to3/pgen2/grammar.py\",\n        \"src/blib2to3/pgen2/token.py\",\n        \"src/blib2to3/pgen2/driver.py\",\n        \"src/blib2to3/pgen2/pgen.py\",\n </s> add         str(p) for p in discovered if p.relative_to(src).as_posix() not in blocklist </s> remove     def add_token(\n        self, tok_type: int, tok_val: Optional[Text], raw: bool = False\n    ) -> None:\n </s> add     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None: </s> remove triple_quoted = (\n </s> add triple_quoted: Final = ( </s> remove STRING_PREFIX_CHARS = \"furbFURB\"  # All possible string prefix characters.\n </s> add STRING_PREFIX_CHARS: Final = \"furbFURB\"  # All possible string prefix characters.\nSTRING_PREFIX_RE: Final = re.compile(\n    r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", re.DOTALL\n)\nFIRST_NON_WHITESPACE_RE: Final = re.compile(r\"\\s*\\t+\\s*(\\S)\") </s> remove     STRING_OPERATORS = [\n </s> add     STRING_OPERATORS: Final = [", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/mode.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     TypeVar,\n <mask>     Union,\n <mask> )\n <mask> \n <mask> if sys.version_info < (3, 8):\n <mask>     from typing_extensions import Final\n <mask> else:\n <mask>     from typing import Final\n <mask> \n <mask> # lib2to3 fork\n <mask> from blib2to3.pytree import Node, Leaf, type_repr\n <mask> from blib2to3 import pygram\n </s> Implementing mypyc support pt. 2  (#2431) </s> add else:\n    from typing_extensions import Final\n\nfrom mypy_extensions import mypyc_attr </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple\n </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> remove from blib2to3 import pygram, pytree\n </s> add from blib2to3 import pygram </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> add from functools import lru_cache </s> add if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/nodes.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> if sys.version_info >= (3, 8):\n <mask>     from typing import Final\n <mask> \n <mask> # lib2to3 fork\n <mask> from blib2to3.pytree import Node, Leaf, type_repr\n <mask> from blib2to3 import pygram\n <mask> from blib2to3.pgen2 import token\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n </s> add if sys.version_info >= (3, 8): </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple\n </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> remove from blib2to3 import pygram, pytree\n </s> add from blib2to3 import pygram </s> add from functools import lru_cache </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/nodes.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from black.strings import has_triple_quotes\n <mask> \n <mask> \n <mask> pygram.initialize(CACHE_DIR)\n <mask> syms = pygram.python_symbols\n <mask> \n <mask> \n <mask> # types\n <mask> T = TypeVar(\"T\")\n <mask> LN = Union[Leaf, Node]\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove \nFMT_OFF = {\"# fmt: off\", \"# fmt:off\", \"# yapf: disable\"}\nFMT_SKIP = {\"# fmt: skip\", \"# fmt:skip\"}\nFMT_PASS = {*FMT_OFF, *FMT_SKIP}\nFMT_ON = {\"# fmt: on\", \"# fmt:on\", \"# yapf: enable\"}\n </s> add FMT_OFF: Final = {\"# fmt: off\", \"# fmt:off\", \"# yapf: disable\"}\nFMT_SKIP: Final = {\"# fmt: skip\", \"# fmt:skip\"}\nFMT_PASS: Final = {*FMT_OFF, *FMT_SKIP}\nFMT_ON: Final = {\"# fmt: on\", \"# fmt:on\", \"# yapf: enable\"} </s> add COMPILED = Path(__file__).suffix in (\".pyd\", \".so\")\n </s> add ast3: Any\nast27: Any\n </s> remove     ext_modules = mypycify(mypyc_targets, opt_level=opt_level)\n </s> add     ext_modules = mypycify(mypyc_targets, opt_level=opt_level, verbose=True) </s> remove     from mypyc.build import mypycify\n\n </s> add  </s> add if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/nodes.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"**=\",\n <mask>     \"//=\",\n <mask> }\n <mask> \n <mask> IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\n <mask> BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}\n <mask> OPENING_BRACKETS = set(BRACKET.keys())\n <mask> CLOSING_BRACKETS = set(BRACKET.values())\n <mask> BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS\n <mask> ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}\n <mask> \n <mask> RARROW = 55\n <mask> \n <mask> \n <mask> class Visitor(Generic[T]):\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove triple_quoted = (\n </s> add triple_quoted: Final = ( </s> add @mypyc_attr(allow_interpreted_subclasses=True) </s> remove single_quoted = (\n </s> add single_quoted: Final = ( </s> remove     RE_FEXPR = r\"\"\"\n </s> add     RE_FEXPR: Final = r\"\"\" </s> remove endprogs = {\n </s> add endprogs: Final = { </s> remove class BracketMatchError(KeyError):\n </s> add class BracketMatchError(Exception):", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/nodes.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> RARROW = 55\n <mask> \n <mask> \n <mask> class Visitor(Generic[T]):\n <mask>     \"\"\"Basic lib2to3 visitor that yields things of type `T` on `visit()`.\"\"\"\n <mask> \n <mask>     def visit(self, node: LN) -> Iterator[T]:\n <mask>         \"\"\"Main method to visit `node` and its children.\n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> add ast3_AST: Final[Type[ast3.AST]] = ast3.AST\nast27_AST: Final[Type[ast27.AST]] = ast27.AST\n\n </s> remove IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}\nOPENING_BRACKETS = set(BRACKET.keys())\nCLOSING_BRACKETS = set(BRACKET.values())\nBRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}\n </s> add IMPLICIT_TUPLE: Final = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET: Final = {\n    token.LPAR: token.RPAR,\n    token.LSQB: token.RSQB,\n    token.LBRACE: token.RBRACE,\n}\nOPENING_BRACKETS: Final = set(BRACKET.keys())\nCLOSING_BRACKETS: Final = set(BRACKET.values())\nBRACKETS: Final = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE: Final = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT} </s> remove @dataclass\n </s> add # This isn't a dataclass because @dataclass + Generic breaks mypyc.\n# See also https://github.com/mypyc/mypyc/issues/827. </s> remove     cell_magic: Optional[CellMagic] = None\n </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> remove     magics: Dict[int, List[OffsetAndMagic]] = dataclasses.field(\n        default_factory=lambda: collections.defaultdict(list)\n    )\n </s> add     def __init__(self) -> None:\n        self.magics: Dict[int, List[OffsetAndMagic]] = collections.defaultdict(list)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/nodes.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     `complex_subscript` signals whether the given leaf is part of a subscription\n <mask>     which has non-trivial arguments, like arithmetic expressions or function calls.\n <mask>     \"\"\"\n <mask>     NO = \"\"\n <mask>     SPACE = \" \"\n <mask>     DOUBLESPACE = \"  \"\n <mask>     t = leaf.type\n <mask>     p = leaf.parent\n <mask>     v = leaf.value\n <mask>     if t in ALWAYS_NO_SPACE:\n <mask>         return NO\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove                     column = column + 1\n </s> add                     column += 1 </s> remove                 t, v = self.grammar.labels[i]\n                if ilabel == i:\n </s> add                 t = self.grammar.labels[i][0]\n                if t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, itsdfa, newstate, context)\n                        break  # To continue the outer while loop\n\n                elif ilabel == i: </s> remove         p = parse.Parser(self.grammar, self.convert)\n </s> add         p = parse.Parser(self.grammar) </s> remove                     assert t < 256\n </s> add  </s> remove     def parse_tokens(self, tokens: Iterable[Any], debug: bool = False) -> NL:\n </s> add     def parse_tokens(self, tokens: Iterable[GoodTokenInfo], debug: bool = False) -> NL: </s> add         assert worker_count is not None", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/nodes.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def last_two_except(leaves: List[Leaf], omit: Collection[LeafID]) -> Tuple[Leaf, Leaf]:\n <mask>     \"\"\"Return (penultimate, last) leaves skipping brackets in `omit` and contents.\"\"\"\n <mask>     stop_after = None\n <mask>     last = None\n <mask>     for leaf in reversed(leaves):\n <mask>         if stop_after:\n <mask>             if leaf is stop_after:\n <mask>                 stop_after = None\n <mask>             continue\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     stashed = None\n </s> add     stashed: Optional[GoodTokenInfo] = None </s> remove     cell_magic: Optional[CellMagic] = None\n </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic </s> remove triple_quoted = (\n </s> add triple_quoted: Final = ( </s> remove     NO = \"\"\n    SPACE = \" \"\n    DOUBLESPACE = \"  \"\n </s> add     NO: Final = \"\"\n    SPACE: Final = \" \"\n    DOUBLESPACE: Final = \"  \" </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode)\n </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove         newnode = self.convert(self.grammar, popnode)\n        if newnode is not None:\n            if self.stack:\n                dfa, state, node = self.stack[-1]\n                assert node[-1] is not None\n                node[-1].append(newnode)\n            else:\n                self.rootnode = newnode\n                self.rootnode.used_names = self.used_names\n </s> add         newnode = convert(self.grammar, popnode)\n        if self.stack:\n            dfa, state, node = self.stack[-1]\n            assert node[-1] is not None\n            node[-1].append(newnode)\n        else:\n            self.rootnode = newnode\n            self.rootnode.used_names = self.used_names", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/nodes.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> from click import echo, style\n <mask> \n <mask> \n <mask> def _out(message: Optional[str] = None, nl: bool = True, **styles: Any) -> None:\n <mask>     if message is not None:\n <mask>         if \"bold\" not in styles:\n <mask>             styles[\"bold\"] = True\n <mask>         message = style(message, **styles)\n <mask>     echo(message, nl=nl, err=True)\n </s> Implementing mypyc support pt. 2  (#2431) </s> add @mypyc_attr(patchable=True) </s> add @mypyc_attr(patchable=True) </s> remove     def __init__(\n        self,\n        grammar: Grammar,\n        convert: Optional[_Convert] = None,\n        logger: Optional[Logger] = None,\n    ) -> None:\n </s> add     def __init__(self, grammar: Grammar, logger: Optional[Logger] = None) -> None: </s> remove         newnode = self.convert(self.grammar, popnode)\n        if newnode is not None:\n            if self.stack:\n                dfa, state, node = self.stack[-1]\n                assert node[-1] is not None\n                node[-1].append(newnode)\n            else:\n                self.rootnode = newnode\n                self.rootnode.used_names = self.used_names\n </s> add         newnode = convert(self.grammar, popnode)\n        if self.stack:\n            dfa, state, node = self.stack[-1]\n            assert node[-1] is not None\n            node[-1].append(newnode)\n        else:\n            self.rootnode = newnode\n            self.rootnode.used_names = self.used_names </s> remove     def determine_route(\n        self, value: Optional[Text] = None, force: bool = False\n    ) -> Optional[int]:\n </s> add     def determine_route(self, value: Text = None, force: bool = False) -> Optional[int]: </s> remove     def add_token(\n        self, tok_type: int, tok_val: Optional[Text], raw: bool = False\n    ) -> None:\n </s> add     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/output.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def _err(message: Optional[str] = None, nl: bool = True, **styles: Any) -> None:\n <mask>     if message is not None:\n <mask>         if \"fg\" not in styles:\n <mask>             styles[\"fg\"] = \"red\"\n <mask>         message = style(message, **styles)\n </s> Implementing mypyc support pt. 2  (#2431) </s> add @mypyc_attr(patchable=True) </s> add @mypyc_attr(patchable=True) </s> remove     def __init__(\n        self,\n        grammar: Grammar,\n        convert: Optional[_Convert] = None,\n        logger: Optional[Logger] = None,\n    ) -> None:\n </s> add     def __init__(self, grammar: Grammar, logger: Optional[Logger] = None) -> None: </s> remove         newnode = self.convert(self.grammar, popnode)\n        if newnode is not None:\n            if self.stack:\n                dfa, state, node = self.stack[-1]\n                assert node[-1] is not None\n                node[-1].append(newnode)\n            else:\n                self.rootnode = newnode\n                self.rootnode.used_names = self.used_names\n </s> add         newnode = convert(self.grammar, popnode)\n        if self.stack:\n            dfa, state, node = self.stack[-1]\n            assert node[-1] is not None\n            node[-1].append(newnode)\n        else:\n            self.rootnode = newnode\n            self.rootnode.used_names = self.used_names </s> remove     def determine_route(\n        self, value: Optional[Text] = None, force: bool = False\n    ) -> Optional[int]:\n </s> add     def determine_route(self, value: Text = None, force: bool = False) -> Optional[int]: </s> remove     def add_token(\n        self, tok_type: int, tok_val: Optional[Text], raw: bool = False\n    ) -> None:\n </s> add     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/output.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     echo(message, nl=nl, err=True)\n <mask> \n <mask> \n <mask> def out(message: Optional[str] = None, nl: bool = True, **styles: Any) -> None:\n <mask>     _out(message, nl=nl, **styles)\n <mask> \n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> add @mypyc_attr(patchable=True) </s> add @mypyc_attr(patchable=True) </s> remove     def determine_route(\n        self, value: Optional[Text] = None, force: bool = False\n    ) -> Optional[int]:\n </s> add     def determine_route(self, value: Text = None, force: bool = False) -> Optional[int]: </s> remove     def __init__(\n        self,\n        grammar: Grammar,\n        convert: Optional[_Convert] = None,\n        logger: Optional[Logger] = None,\n    ) -> None:\n </s> add     def __init__(self, grammar: Grammar, logger: Optional[Logger] = None) -> None: </s> remove     def add_token(\n        self, tok_type: int, tok_val: Optional[Text], raw: bool = False\n    ) -> None:\n </s> add     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None: </s> add     @pytest.mark.incompatible_with_mypyc", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/output.py"}
{"docstring_tokens": "keep replace keep keep keep replace keep keep keep", "code_tokens": " <mask> import sys\n <mask> from typing import Iterable, Iterator, List, Set, Union, Tuple\n <mask> \n <mask> # lib2to3 fork\n <mask> from blib2to3.pytree import Node, Leaf\n <mask> from blib2to3 import pygram, pytree\n <mask> from blib2to3.pgen2 import driver\n <mask> from blib2to3.pgen2.grammar import Grammar\n <mask> from blib2to3.pgen2.parse import ParseError\n </s> Implementing mypyc support pt. 2  (#2431) </s> add else:\n    from typing_extensions import Final\n\nfrom mypy_extensions import mypyc_attr </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> remove if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n </s> add if sys.version_info >= (3, 8): </s> add     cast, </s> remove from blib2to3.pytree import NL, Context, RawNode, Leaf, Node\n </s> add from blib2to3.pytree import convert, NL, Context, RawNode, Leaf, Node", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> from black.mode import TargetVersion, Feature, supports_feature\n <mask> from black.nodes import syms\n <mask> \n <mask> _IS_PYPY = platform.python_implementation() == \"PyPy\"\n <mask> \n <mask> try:\n <mask>     from typed_ast import ast3, ast27\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove from blib2to3 import pygram, pytree\n </s> add from blib2to3 import pygram </s> remove from dataclasses import dataclass, field\n\n </s> add  </s> remove from dataclasses import replace\n </s> add  </s> add from dataclasses import replace\nfrom mypy_extensions import mypyc_attr </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> remove syms = pygram.python_symbols\n </s> add syms: Final = pygram.python_symbols", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     if not src_txt.endswith(\"\\n\"):\n <mask>         src_txt += \"\\n\"\n <mask> \n <mask>     for grammar in get_grammars(set(target_versions)):\n <mask>         drv = driver.Driver(grammar, pytree.convert)\n <mask>         try:\n <mask>             result = drv.parse_string(src_txt, True)\n <mask>             break\n <mask> \n <mask>         except ParseError as pe:\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove         lnum = lnum + 1\n </s> add         lnum += 1 </s> remove with open(black.__file__, \"r\", encoding=\"utf-8\") as _bf:\n    black_source_lines = _bf.readlines()\n </s> add try:\n    with open(black.__file__, \"r\", encoding=\"utf-8\") as _bf:\n        black_source_lines = _bf.readlines()\nexcept UnicodeDecodeError:\n    if not black.COMPILED:\n        raise </s> add         assert worker_count is not None </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove     result = runner.invoke(black.main, args)\n </s> add     result = runner.invoke(black.main, args, catch_exceptions=False) </s> remove                     next_token_type = grammar.opmap[cast(str, next_token_value)]\n </s> add                     next_token_type = grammar.opmap[next_token_value]", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     raise SyntaxError(first_error)\n <mask> \n <mask> \n <mask> def stringify_ast(\n <mask>     node: Union[ast.AST, ast3.AST, ast27.AST], depth: int = 0\n <mask> ) -> Iterator[str]:\n <mask>     \"\"\"Simple visitor generating strings to compare ASTs by content.\"\"\"\n <mask> \n <mask>     node = fixup_ast_constants(node)\n </s> Implementing mypyc support pt. 2  (#2431) </s> add @mypyc_attr(allow_interpreted_subclasses=True) </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> remove class StringSplitter(CustomSplitMapMixin, BaseStringSplitter):\n </s> add class StringSplitter(BaseStringSplitter, CustomSplitMapMixin): </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove     def determine_route(\n        self, value: Optional[Text] = None, force: bool = False\n    ) -> Optional[int]:\n </s> add     def determine_route(self, value: Text = None, force: bool = False) -> Optional[int]: </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None:\n </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>                 elif isinstance(item, (ast.AST, ast3.AST, ast27.AST)):\n <mask>                     yield from stringify_ast(item, depth + 2)\n <mask> \n <mask>         elif isinstance(value, (ast.AST, ast3.AST, ast27.AST)):\n <mask>             yield from stringify_ast(value, depth + 2)\n <mask> \n <mask>         else:\n <mask>             # Constant strings may be indented across newlines, if they are\n <mask>             # docstrings; fold spaces after newlines when comparing. Similarly,\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove                         parenlev = parenlev - 1\n </s> add                         parenlev -= 1 </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove                         parenlev = parenlev + 1\n </s> add                         parenlev += 1 </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove                     column = column + 1\n </s> add                     column += 1 </s> remove                     (lnum, pos + len(comment_token)),\n </s> add                     (lnum, nl_pos),", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> import regex as re\n <mask> import sys\n <mask> from typing import List, Pattern\n <mask> \n <mask> if sys.version_info < (3, 8):\n <mask>     from typing_extensions import Final\n <mask> else:\n </s> Implementing mypyc support pt. 2  (#2431) </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> add if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple\n </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> remove if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n </s> add if sys.version_info >= (3, 8): </s> add else:\n    from typing_extensions import Final\n\nfrom mypy_extensions import mypyc_attr </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/strings.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> import sys\n <mask> from functools import lru_cache\n <mask> from typing import List, Pattern\n <mask> \n <mask> \n <mask> \n <mask> STRING_PREFIX_CHARS: Final = \"furbFURB\"  # All possible string prefix characters.\n <mask> STRING_PREFIX_RE: Final = re.compile(\n <mask>     r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", re.DOTALL\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove STRING_PREFIX_CHARS = \"furbFURB\"  # All possible string prefix characters.\n </s> add STRING_PREFIX_CHARS: Final = \"furbFURB\"  # All possible string prefix characters.\nSTRING_PREFIX_RE: Final = re.compile(\n    r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", re.DOTALL\n)\nFIRST_NON_WHITESPACE_RE: Final = re.compile(r\"\\s*\\t+\\s*(\\S)\") </s> add from functools import lru_cache </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple\n </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> remove     match = re.match(r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", s, re.DOTALL)\n </s> add     match = STRING_PREFIX_RE.match(s) </s> remove from dataclasses import dataclass, field\n\n </s> add ", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/strings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import sys\n <mask> from typing import List, Pattern\n <mask> \n <mask> \n <mask> STRING_PREFIX_CHARS = \"furbFURB\"  # All possible string prefix characters.\n <mask> \n <mask> \n <mask> def sub_twice(regex: Pattern[str], replacement: str, original: str) -> str:\n <mask>     \"\"\"Replace `regex` with `replacement` twice on `original`.\n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> add if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> add from functools import lru_cache </s> add     cast, </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple\n </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> add import sys </s> remove from dataclasses import dataclass, field\n\n </s> add ", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/strings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     lines = []\n <mask>     for line in s.splitlines():\n <mask>         # Find the index of the first non-whitespace character after a string of\n <mask>         # whitespace that includes at least one tab\n <mask>         match = re.match(r\"\\s*\\t+\\s*(\\S)\", line)\n <mask>         if match:\n <mask>             first_non_whitespace_idx = match.start(1)\n <mask> \n <mask>             lines.append(\n <mask>                 line[:first_non_whitespace_idx].expandtabs()\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove         p = parse.Parser(self.grammar, self.convert)\n </s> add         p = parse.Parser(self.grammar) </s> remove                 t, v = self.grammar.labels[i]\n                if ilabel == i:\n </s> add                 t = self.grammar.labels[i][0]\n                if t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, itsdfa, newstate, context)\n                        break  # To continue the outer while loop\n\n                elif ilabel == i: </s> remove     match = re.match(r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", s, re.DOTALL)\n </s> add     match = STRING_PREFIX_RE.match(s) </s> remove     numchars = \"0123456789\"\n </s> add     numchars: Final = \"0123456789\" </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> remove @dataclass\n </s> add # This isn't a dataclass because @dataclass + Generic breaks mypyc.\n# See also https://github.com/mypyc/mypyc/issues/827.", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/strings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"Make all string prefixes lowercase.\n <mask> \n <mask>     If remove_u_prefix is given, also removes any u prefix from the string.\n <mask>     \"\"\"\n <mask>     match = re.match(r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", s, re.DOTALL)\n <mask>     assert match is not None, f\"failed to match string {s!r}\"\n <mask>     orig_prefix = match.group(1)\n <mask>     new_prefix = orig_prefix.replace(\"F\", \"f\").replace(\"B\", \"b\").replace(\"U\", \"u\")\n <mask>     if remove_u_prefix:\n <mask>         new_prefix = new_prefix.replace(\"u\", \"\")\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove STRING_PREFIX_CHARS = \"furbFURB\"  # All possible string prefix characters.\n </s> add STRING_PREFIX_CHARS: Final = \"furbFURB\"  # All possible string prefix characters.\nSTRING_PREFIX_RE: Final = re.compile(\n    r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", re.DOTALL\n)\nFIRST_NON_WHITESPACE_RE: Final = re.compile(r\"\\s*\\t+\\s*(\\S)\") </s> remove         match = re.match(r\"\\s*\\t+\\s*(\\S)\", line)\n </s> add         match = FIRST_NON_WHITESPACE_RE.match(line) </s> add if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> remove     STRING_OPERATORS = [\n </s> add     STRING_OPERATORS: Final = [ </s> remove         lnum = lnum + 1\n </s> add         lnum += 1", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/strings.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def normalize_string_quotes(s: str) -> str:\n <mask>     \"\"\"Prefer double quotes but only if it doesn't cause more escaping.\n <mask> \n <mask>     Adds or removes backslashes as appropriate. Doesn't parse and fix\n <mask>     strings nested in f-strings.\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove                 if isinstance(item, WildcardPattern):\n                    self.wildcards = True\n </s> add                 # I don't even think this code is used anywhere, but it does cause\n                # unreachable errors from mypy. This function's signature does look\n                # odd though *shrug*.\n                if isinstance(item, WildcardPattern):  # type: ignore[unreachable]\n                    self.wildcards = True  # type: ignore[unreachable] </s> add # diff-shades depends on being to monkeypatch this function to operate. I know it's\n# not ideal, but this shouldn't cause any issues ... hopefully. ~ichard26\n@mypyc_attr(patchable=True) </s> remove     stashed = None\n </s> add     stashed: Optional[GoodTokenInfo] = None </s> remove STRING_PREFIX_CHARS = \"furbFURB\"  # All possible string prefix characters.\n </s> add STRING_PREFIX_CHARS: Final = \"furbFURB\"  # All possible string prefix characters.\nSTRING_PREFIX_RE: Final = re.compile(\n    r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", re.DOTALL\n)\nFIRST_NON_WHITESPACE_RE: Final = re.compile(r\"\\s*\\t+\\s*(\\S)\") </s> remove                 for version in sorted(self.target_versions, key=lambda v: v.value)\n </s> add                 for version in sorted(self.target_versions, key=attrgetter(\"value\")) </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__()", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/strings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             AND\n <mask>         * The target string is not a multiline (i.e. triple-quote) string.\n <mask>     \"\"\"\n <mask> \n <mask>     STRING_OPERATORS = [\n <mask>         token.EQEQUAL,\n <mask>         token.GREATER,\n <mask>         token.GREATEREQUAL,\n <mask>         token.LESS,\n <mask>         token.LESSEQUAL,\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     match = re.match(r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", s, re.DOTALL)\n </s> add     match = STRING_PREFIX_RE.match(s) </s> remove class StringParenWrapper(CustomSplitMapMixin, BaseStringSplitter):\n </s> add class StringParenWrapper(BaseStringSplitter, CustomSplitMapMixin): </s> remove class StringSplitter(CustomSplitMapMixin, BaseStringSplitter):\n </s> add class StringSplitter(BaseStringSplitter, CustomSplitMapMixin): </s> remove         lnum = lnum + 1\n </s> add         lnum += 1 </s> remove     numchars = \"0123456789\"\n </s> add     numchars: Final = \"0123456789\" </s> remove         \"src/black/__init__.py\",\n        \"src/blib2to3/pytree.py\",\n        \"src/blib2to3/pygram.py\",\n        \"src/blib2to3/pgen2/parse.py\",\n        \"src/blib2to3/pgen2/grammar.py\",\n        \"src/blib2to3/pgen2/token.py\",\n        \"src/blib2to3/pgen2/driver.py\",\n        \"src/blib2to3/pgen2/pgen.py\",\n </s> add         str(p) for p in discovered if p.relative_to(src).as_posix() not in blocklist", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         max_string_length = self.line_length - offset\n <mask>         return max_string_length\n <mask> \n <mask> \n <mask> class StringSplitter(CustomSplitMapMixin, BaseStringSplitter):\n <mask>     \"\"\"\n <mask>     StringTransformer that splits \"atom\" strings (i.e. strings which exist on\n <mask>     lines by themselves).\n <mask> \n <mask>     Requirements:\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove class StringParenWrapper(CustomSplitMapMixin, BaseStringSplitter):\n </s> add class StringParenWrapper(BaseStringSplitter, CustomSplitMapMixin): </s> add # Re(gex) does actually cache patterns internally but this still improves\n# performance on a long list literal of strings by 5-9% since lru_cache's\n# caching overhead is much lower.\n@lru_cache(maxsize=64)\ndef _cached_compile(pattern: str) -> re.Pattern:\n    return re.compile(pattern)\n\n </s> add ast3_AST: Final[Type[ast3.AST]] = ast3.AST\nast27_AST: Final[Type[ast27.AST]] = ast27.AST\n\n </s> remove @dataclass\n </s> add # This isn't a dataclass because @dataclass + Generic breaks mypyc.\n# See also https://github.com/mypyc/mypyc/issues/827. </s> remove @dataclasses.dataclass\n </s> add # ast.NodeVisitor + dataclass = breakage under mypyc. </s> remove     numchars = \"0123456789\"\n </s> add     numchars: Final = \"0123456789\"", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep replace keep replace", "code_tokens": " <mask>         CustomSplit objects and add them to the custom split map.\n <mask>     \"\"\"\n <mask> \n <mask>     MIN_SUBSTR_SIZE = 6\n <mask>     # Matches an \"f-expression\" (e.g. {var}) that might be found in an f-string.\n <mask>     RE_FEXPR = r\"\"\"\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove class BracketMatchError(KeyError):\n </s> add class BracketMatchError(Exception): </s> add # Unreachable blocks have been an issue when compiling mypyc, let's try\n# to avoid 'em in the first place.\nwarn_unreachable=True\n </s> add     @pytest.mark.incompatible_with_mypyc </s> add         **post-note: the convert argument is ignored since for Black's\n        usage, convert will always be blib2to3.pytree.convert. Allowing\n        this to be dynamic hurts mypyc's ability to use early binding.\n        These docs are left for historical and informational value.\n </s> remove     _goto: Dict[Tuple[ParserState, NodeType], ParserState] = {\n </s> add     _goto: Final[Dict[Tuple[ParserState, NodeType], ParserState]] = {", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             i += 1\n <mask>         return string_op_leaves\n <mask> \n <mask> \n <mask> class StringParenWrapper(CustomSplitMapMixin, BaseStringSplitter):\n <mask>     \"\"\"\n <mask>     StringTransformer that splits non-\"atom\" strings (i.e. strings that do not\n <mask>     exist on lines by themselves).\n <mask> \n <mask>     Requirements:\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove class StringSplitter(CustomSplitMapMixin, BaseStringSplitter):\n </s> add class StringSplitter(BaseStringSplitter, CustomSplitMapMixin): </s> remove @dataclass\n </s> add # This isn't a dataclass because @dataclass + Generic breaks mypyc.\n# See also https://github.com/mypyc/mypyc/issues/827. </s> add # Re(gex) does actually cache patterns internally but this still improves\n# performance on a long list literal of strings by 5-9% since lru_cache's\n# caching overhead is much lower.\n@lru_cache(maxsize=64)\ndef _cached_compile(pattern: str) -> re.Pattern:\n    return re.compile(pattern)\n\n </s> remove @dataclasses.dataclass\n </s> add # ast.NodeVisitor + dataclass = breakage under mypyc. </s> remove         elif isinstance(value, (ast.AST, ast3.AST, ast27.AST)):\n </s> add         # Note that we are referencing the typed-ast ASTs via global variables and not\n        # direct module attribute accesses because that breaks mypyc. It's probably\n        # something to do with the ast3 / ast27 variables being marked as Any leading\n        # mypy to think this branch is always taken, leaving the rest of the code\n        # unanalyzed. Tighting up the types for the typed-ast AST types avoids the\n        # mypyc crash.\n        elif isinstance(value, (ast.AST, ast3_AST, ast27_AST)): </s> add ast3_AST: Final[Type[ast3.AST]] = ast3.AST\nast27_AST: Final[Type[ast27.AST]] = ast27.AST\n\n", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         assert line.leaves[idx].type == token.PLUS\n <mask>         ```\n <mask>     \"\"\"\n <mask> \n <mask>     DEFAULT_TOKEN = -1\n <mask> \n <mask>     # String Parser States\n <mask>     START = 1\n <mask>     DOT = 2\n <mask>     NAME = 3\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     START = 1\n    DOT = 2\n    NAME = 3\n    PERCENT = 4\n    SINGLE_FMT_ARG = 5\n    LPAR = 6\n    RPAR = 7\n    DONE = 8\n </s> add     START: Final = 1\n    DOT: Final = 2\n    NAME: Final = 3\n    PERCENT: Final = 4\n    SINGLE_FMT_ARG: Final = 5\n    LPAR: Final = 6\n    RPAR: Final = 7\n    DONE: Final = 8 </s> remove                     column = column + 1\n </s> add                     column += 1 </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove         lnum = lnum + 1\n </s> add         lnum += 1 </s> remove                     next_token_type = grammar.opmap[cast(str, next_token_value)]\n </s> add                     next_token_type = grammar.opmap[next_token_value] </s> remove                         parenlev = parenlev + 1\n </s> add                         parenlev += 1", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace replace keep keep replace keep keep keep", "code_tokens": " <mask>     # String Parser States\n <mask>     START = 1\n <mask>     DOT = 2\n <mask>     NAME = 3\n <mask>     PERCENT = 4\n <mask>     SINGLE_FMT_ARG = 5\n <mask>     LPAR = 6\n <mask>     RPAR = 7\n <mask>     DONE = 8\n <mask> \n <mask>     # Lookup Table for Next State\n <mask>     _goto: Dict[Tuple[ParserState, NodeType], ParserState] = {\n <mask>         # A string trailer may start with '.' OR '%'.\n <mask>         (START, token.DOT): DOT,\n <mask>         (START, token.PERCENT): PERCENT,\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     DEFAULT_TOKEN = -1\n </s> add     DEFAULT_TOKEN: Final = 20210605 </s> remove         indent_columns = []\n </s> add         indent_columns: List[int] = [] </s> remove         lnum = lnum + 1\n </s> add         lnum += 1 </s> remove IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}\nOPENING_BRACKETS = set(BRACKET.keys())\nCLOSING_BRACKETS = set(BRACKET.values())\nBRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}\n </s> add IMPLICIT_TUPLE: Final = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET: Final = {\n    token.LPAR: token.RPAR,\n    token.LSQB: token.RSQB,\n    token.LBRACE: token.RBRACE,\n}\nOPENING_BRACKETS: Final = set(BRACKET.keys())\nCLOSING_BRACKETS: Final = set(BRACKET.values())\nBRACKETS: Final = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE: Final = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT} </s> remove         match = re.match(r\"\\s*\\t+\\s*(\\S)\", line)\n </s> add         match = FIRST_NON_WHITESPACE_RE.match(line)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         if not keep and work_path.exists():\n <mask>             LOG.debug(f\"Removing {work_path}\")\n <mask>             rmtree(work_path, onerror=lib.handle_PermissionError)\n <mask> \n <mask>     return -2\n <mask> \n <mask> \n <mask> @click.command(context_settings={\"help_option_names\": [\"-h\", \"--help\"]})\n <mask> @click.option(\n <mask>     \"-c\",\n <mask>     \"--config\",\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     result = runner.invoke(black.main, args)\n </s> add     result = runner.invoke(black.main, args, catch_exceptions=False) </s> remove                 elif t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, self.grammar.dfas[t], newstate, context)\n                        break  # To continue the outer while loop\n </s> add  </s> remove     __hash__ = None  # type: Any  # For Py3 compatibility.\n\n </s> add  </s> add def find_python_files(base: Path) -> List[Path]:\n    files = []\n    for entry in base.iterdir():\n        if entry.is_file() and entry.suffix == \".py\":\n            files.append(entry)\n        elif entry.is_dir():\n            files.extend(find_python_files(entry))\n\n    return files\n\n </s> remove             assert value is not None\n </s> add  </s> remove         p = parse.Parser(self.grammar, self.convert)\n </s> add         p = parse.Parser(self.grammar)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black_primer/cli.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> import pkgutil\n <mask> import sys\n <mask> from typing import (\n <mask>     Any,\n <mask>     IO,\n <mask>     Iterable,\n <mask>     List,\n <mask>     Optional,\n <mask>     Text,\n <mask>     Iterator,\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     Callable,\n </s> add  </s> add import sys </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple\n </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> remove from dataclasses import dataclass, field\n\n </s> add  </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> remove from blib2to3 import pygram, pytree\n </s> add from blib2to3 import pygram", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     Generic,\n <mask>     Union,\n <mask> )\n <mask> from dataclasses import dataclass, field\n <mask> \n <mask> # Pgen imports\n <mask> from . import grammar, parse, token, tokenize, pgen\n <mask> from logging import Logger\n <mask> from blib2to3.pytree import NL\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove from blib2to3.pytree import _Convert, NL\n </s> add from blib2to3.pytree import NL </s> remove from contextlib import contextmanager\n </s> add from blib2to3.pgen2.tokenize import GoodTokenInfo </s> add from operator import attrgetter </s> remove from dataclasses import dataclass, field\n\n </s> add  </s> remove from dataclasses import replace\n </s> add  </s> remove from blib2to3 import pygram, pytree\n </s> add from blib2to3 import pygram", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep replace keep replace keep", "code_tokens": " <mask> from . import grammar, parse, token, tokenize, pgen\n <mask> from logging import Logger\n <mask> from blib2to3.pytree import _Convert, NL\n <mask> from blib2to3.pgen2.grammar import Grammar\n <mask> from contextlib import contextmanager\n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> add from contextlib import contextmanager </s> remove from blib2to3.pytree import NL, Context, RawNode, Leaf, Node\n </s> add from blib2to3.pytree import convert, NL, Context, RawNode, Leaf, Node </s> remove from blib2to3 import pygram, pytree\n </s> add from blib2to3 import pygram </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> add else:\n    from typing_extensions import Final\n\nfrom mypy_extensions import mypyc_attr", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace replace replace keep keep keep keep replace keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> class Driver(object):\n <mask>     def __init__(\n <mask>         self,\n <mask>         grammar: Grammar,\n <mask>         convert: Optional[_Convert] = None,\n <mask>         logger: Optional[Logger] = None,\n <mask>     ) -> None:\n <mask>         self.grammar = grammar\n <mask>         if logger is None:\n <mask>             logger = logging.getLogger(__name__)\n <mask>         self.logger = logger\n <mask>         self.convert = convert\n <mask> \n <mask>     def parse_tokens(self, tokens: Iterable[Any], debug: bool = False) -> NL:\n <mask>         \"\"\"Parse a series of tokens and return the syntax tree.\"\"\"\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     def parse_tokens(self, tokens: Iterable[Any], debug: bool = False) -> NL:\n </s> add     def parse_tokens(self, tokens: Iterable[GoodTokenInfo], debug: bool = False) -> NL: </s> remove         p = parse.Parser(self.grammar, self.convert)\n </s> add         p = parse.Parser(self.grammar) </s> remove     def determine_route(\n        self, value: Optional[Text] = None, force: bool = False\n    ) -> Optional[int]:\n </s> add     def determine_route(self, value: Text = None, force: bool = False) -> Optional[int]: </s> remove     def add_token(\n        self, tok_type: int, tok_val: Optional[Text], raw: bool = False\n    ) -> None:\n </s> add     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None: </s> add @mypyc_attr(patchable=True)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         self.logger = logger\n <mask>         self.convert = convert\n <mask> \n <mask>     def parse_tokens(self, tokens: Iterable[Any], debug: bool = False) -> NL:\n <mask>         \"\"\"Parse a series of tokens and return the syntax tree.\"\"\"\n <mask>         # XXX Move the prefix computation into a wrapper around tokenize.\n <mask>         proxy = TokenProxy(tokens)\n <mask> \n <mask>         p = parse.Parser(self.grammar, self.convert)\n <mask>         p.setup(proxy=proxy)\n <mask> \n <mask>         lineno = 1\n <mask>         column = 0\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove         self.convert = convert\n </s> add  </s> remove         indent_columns = []\n </s> add         indent_columns: List[int] = [] </s> remove     def __init__(\n        self,\n        grammar: Grammar,\n        convert: Optional[_Convert] = None,\n        logger: Optional[Logger] = None,\n    ) -> None:\n </s> add     def __init__(self, grammar: Grammar, logger: Optional[Logger] = None) -> None: </s> remove                     column = column + 1\n </s> add                     column += 1 </s> remove     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         p.setup(proxy=proxy)\n <mask> \n <mask>         lineno = 1\n <mask>         column = 0\n <mask>         indent_columns = []\n <mask>         type = value = start = end = line_text = None\n <mask>         prefix = \"\"\n <mask> \n <mask>         for quintuple in proxy:\n <mask>             type, value, start, end, line_text = quintuple\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove         p = parse.Parser(self.grammar, self.convert)\n </s> add         p = parse.Parser(self.grammar) </s> remove             if p.addtoken(type, value, (prefix, start)):\n </s> add             if p.addtoken(cast(int, type), value, (prefix, start)): </s> remove                     column = column + 1\n </s> add                     column += 1 </s> remove     START = 1\n    DOT = 2\n    NAME = 3\n    PERCENT = 4\n    SINGLE_FMT_ARG = 5\n    LPAR = 6\n    RPAR = 7\n    DONE = 8\n </s> add     START: Final = 1\n    DOT: Final = 2\n    NAME: Final = 3\n    PERCENT: Final = 4\n    SINGLE_FMT_ARG: Final = 5\n    LPAR: Final = 6\n    RPAR: Final = 7\n    DONE: Final = 8 </s> remove         lnum = lnum + 1\n </s> add         lnum += 1 </s> remove                 pos = pos + 1\n </s> add                 pos += 1", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>                 type = grammar.opmap[value]\n <mask>             if debug:\n <mask>                 self.logger.debug(\n <mask>                     \"%s %r (prefix=%r)\", token.tok_name[type], value, prefix\n <mask>                 )\n <mask>             if type == token.INDENT:\n <mask>                 indent_columns.append(len(value))\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove             if p.addtoken(type, value, (prefix, start)):\n </s> add             if p.addtoken(cast(int, type), value, (prefix, start)): </s> remove         indent_columns = []\n </s> add         indent_columns: List[int] = [] </s> remove     def parse_tokens(self, tokens: Iterable[Any], debug: bool = False) -> NL:\n </s> add     def parse_tokens(self, tokens: Iterable[GoodTokenInfo], debug: bool = False) -> NL: </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> remove         self.convert = convert\n </s> add  </s> remove     def determine_route(\n        self, value: Optional[Text] = None, force: bool = False\n    ) -> Optional[int]:\n </s> add     def determine_route(self, value: Text = None, force: bool = False) -> Optional[int]:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 value = \"\"\n <mask>             elif type == token.DEDENT:\n <mask>                 _indent_col = indent_columns.pop()\n <mask>                 prefix, _prefix = self._partially_consume_prefix(prefix, _indent_col)\n <mask>             if p.addtoken(type, value, (prefix, start)):\n <mask>                 if debug:\n <mask>                     self.logger.debug(\"Stop.\")\n <mask>                 break\n <mask>             prefix = \"\"\n <mask>             if type in {token.INDENT, token.DEDENT}:\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove         indent_columns = []\n </s> add         indent_columns: List[int] = [] </s> add                 assert type is not None </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove     NO = \"\"\n    SPACE = \" \"\n    DOUBLESPACE = \"  \"\n </s> add     NO: Final = \"\"\n    SPACE: Final = \" \"\n    DOUBLESPACE: Final = \"  \" </s> remove                     column = column + 1\n </s> add                     column += 1 </s> remove         lnum = lnum + 1\n </s> add         lnum += 1", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     Set,\n <mask>     TYPE_CHECKING,\n <mask> )\n <mask> from blib2to3.pgen2.grammar import Grammar\n <mask> from blib2to3.pytree import NL, Context, RawNode, Leaf, Node\n <mask> \n <mask> if TYPE_CHECKING:\n <mask>     from blib2to3.driver import TokenProxy\n <mask> \n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> remove from blib2to3 import pygram, pytree\n </s> add from blib2to3 import pygram </s> remove from blib2to3.pytree import _Convert, NL\n </s> add from blib2to3.pytree import NL </s> remove from contextlib import contextmanager\n </s> add from blib2to3.pgen2.tokenize import GoodTokenInfo </s> remove if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n </s> add if sys.version_info >= (3, 8): </s> add else:\n    from typing_extensions import Final\n\nfrom mypy_extensions import mypyc_attr </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple\n </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             self._dead_ilabels.add(ilabel)\n <mask>         finally:\n <mask>             self.parser.stack = self._start_point\n <mask> \n <mask>     def add_token(\n <mask>         self, tok_type: int, tok_val: Optional[Text], raw: bool = False\n <mask>     ) -> None:\n <mask>         func: Callable[..., Any]\n <mask>         if raw:\n <mask>             func = self.parser._addtoken\n <mask>         else:\n <mask>             func = self.parser.addtoken\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     def determine_route(\n        self, value: Optional[Text] = None, force: bool = False\n    ) -> Optional[int]:\n </s> add     def determine_route(self, value: Text = None, force: bool = False) -> Optional[int]: </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None:\n </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove         assert value is not None\n        assert context is not None\n </s> add  </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove     def __init__(\n        self,\n        grammar: Grammar,\n        convert: Optional[_Convert] = None,\n        logger: Optional[Logger] = None,\n    ) -> None:\n </s> add     def __init__(self, grammar: Grammar, logger: Optional[Logger] = None) -> None: </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__()", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                 if raw:\n <mask>                     args.insert(0, ilabel)\n <mask>                 func(*args)\n <mask> \n <mask>     def determine_route(\n <mask>         self, value: Optional[Text] = None, force: bool = False\n <mask>     ) -> Optional[int]:\n <mask>         alive_ilabels = self.ilabels\n <mask>         if len(alive_ilabels) == 0:\n <mask>             *_, most_successful_ilabel = self._dead_ilabels\n <mask>             raise ParseError(\"bad input\", most_successful_ilabel, value, self.context)\n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     def add_token(\n        self, tok_type: int, tok_val: Optional[Text], raw: bool = False\n    ) -> None:\n </s> add     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None: </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None:\n </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove     def __init__(\n        self,\n        grammar: Grammar,\n        convert: Optional[_Convert] = None,\n        logger: Optional[Logger] = None,\n    ) -> None:\n </s> add     def __init__(self, grammar: Grammar, logger: Optional[Logger] = None) -> None: </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> add @mypyc_attr(patchable=True)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         up.\n <mask> \n <mask>         A concrete syntax tree node is a (type, value, context, nodes)\n <mask>         tuple, where type is the node type (a token or symbol number),\n <mask>         value is None for symbols and a string for tokens, context is\n <mask>         None or an opaque value used for error reporting (typically a\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove             assert value is not None\n </s> add  </s> remove         assert value is not None\n        assert context is not None\n </s> add  </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode)\n </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None:\n </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> add                 assert type is not None", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         self.grammar = grammar\n <mask>         self.convert = convert or lam_sub\n <mask> \n <mask>     def setup(self, proxy: \"TokenProxy\", start: Optional[int] = None) -> None:\n <mask>         \"\"\"Prepare for parsing.\n <mask> \n <mask>         This *must* be called before starting to parse.\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     def __init__(\n        self,\n        grammar: Grammar,\n        convert: Optional[_Convert] = None,\n        logger: Optional[Logger] = None,\n    ) -> None:\n </s> add     def __init__(self, grammar: Grammar, logger: Optional[Logger] = None) -> None: </s> remove         self.convert = convert\n </s> add  </s> remove     cell_magic: Optional[CellMagic] = None\n </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic </s> remove     def parse_tokens(self, tokens: Iterable[Any], debug: bool = False) -> NL:\n </s> add     def parse_tokens(self, tokens: Iterable[GoodTokenInfo], debug: bool = False) -> NL: </s> add         **post-note: the convert argument is ignored since for Black's\n        usage, convert will always be blib2to3.pytree.convert. Allowing\n        this to be dynamic hurts mypyc's ability to use early binding.\n        These docs are left for historical and informational value.\n </s> remove         indent_columns = []\n </s> add         indent_columns: List[int] = []", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.rootnode: Optional[NL] = None\n <mask>         self.used_names: Set[str] = set()\n <mask>         self.proxy = proxy\n <mask> \n <mask>     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool:\n <mask>         \"\"\"Add a token; return True iff this is the end of the program.\"\"\"\n <mask>         # Map from token to label\n <mask>         ilabels = self.classify(type, value, context)\n <mask>         assert len(ilabels) >= 1\n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None:\n </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> remove         assert value is not None\n        assert context is not None\n </s> add  </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode)\n </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove                 t, v = self.grammar.labels[i]\n                if ilabel == i:\n </s> add                 t = self.grammar.labels[i][0]\n                if t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, itsdfa, newstate, context)\n                        break  # To continue the outer while loop\n\n                elif ilabel == i:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     break\n <mask> \n <mask>                 next_token_type, next_token_value, *_ = proxy.eat(counter)\n <mask>                 if next_token_type == tokenize.OP:\n <mask>                     next_token_type = grammar.opmap[cast(str, next_token_value)]\n <mask> \n <mask>                 recorder.add_token(next_token_type, next_token_value)\n <mask>                 counter += 1\n <mask> \n <mask>             ilabel = cast(int, recorder.determine_route(next_token_value, force=force))\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove                     column = column + 1\n </s> add                     column += 1 </s> remove                         parenlev = parenlev + 1\n </s> add                         parenlev += 1 </s> remove         drv = driver.Driver(grammar, pytree.convert)\n </s> add         drv = driver.Driver(grammar) </s> remove                 t, v = self.grammar.labels[i]\n                if ilabel == i:\n </s> add                 t = self.grammar.labels[i][0]\n                if t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, itsdfa, newstate, context)\n                        break  # To continue the outer while loop\n\n                elif ilabel == i: </s> remove         lnum = lnum + 1\n </s> add         lnum += 1", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             assert ilabel is not None\n <mask> \n <mask>         return self._addtoken(ilabel, type, value, context)\n <mask> \n <mask>     def _addtoken(\n <mask>         self, ilabel: int, type: int, value: Optional[Text], context: Context\n <mask>     ) -> bool:\n <mask>         # Loop until the token is shifted; may raise exceptions\n <mask>         while True:\n <mask>             dfa, state, node = self.stack[-1]\n <mask>             states, first = dfa\n <mask>             arcs = states[state]\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None:\n </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove         assert value is not None\n        assert context is not None\n </s> add  </s> remove     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode)\n </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> remove                 elif t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, self.grammar.dfas[t], newstate, context)\n                        break  # To continue the outer while loop\n </s> add ", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace keep keep", "code_tokens": " <mask>             arcs = states[state]\n <mask>             # Look for a state with this label\n <mask>             for i, newstate in arcs:\n <mask>                 t, v = self.grammar.labels[i]\n <mask>                 if ilabel == i:\n <mask>                     # Look it up in the list of labels\n <mask>                     assert t < 256\n <mask>                     # Shift a token; we're done with it\n <mask>                     self.shift(type, value, newstate, context)\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove                 elif t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, self.grammar.dfas[t], newstate, context)\n                        break  # To continue the outer while loop\n </s> add  </s> remove     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> remove             assert value is not None\n </s> add  </s> remove         pyproject_toml = tomli.load(f)  # type: ignore  # due to deprecated API usage\n </s> add         pyproject_toml = tomli.loads(f.read()) </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                         dfa, state, node = self.stack[-1]\n <mask>                         states, first = dfa\n <mask>                     # Done with this token\n <mask>                     return False\n <mask>                 elif t >= 256:\n <mask>                     # See if it's a symbol and if we're in its first set\n <mask>                     itsdfa = self.grammar.dfas[t]\n <mask>                     itsstates, itsfirst = itsdfa\n <mask>                     if ilabel in itsfirst:\n <mask>                         # Push a symbol\n <mask>                         self.push(t, self.grammar.dfas[t], newstate, context)\n <mask>                         break  # To continue the outer while loop\n <mask>             else:\n <mask>                 if (0, state) in arcs:\n <mask>                     # An accepting state, pop it and try something else\n <mask>                     self.pop()\n <mask>                     if not self.stack:\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove                 t, v = self.grammar.labels[i]\n                if ilabel == i:\n </s> add                 t = self.grammar.labels[i][0]\n                if t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, itsdfa, newstate, context)\n                        break  # To continue the outer while loop\n\n                elif ilabel == i: </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove                     assert t < 256\n </s> add  </s> remove         newnode = self.convert(self.grammar, popnode)\n        if newnode is not None:\n            if self.stack:\n                dfa, state, node = self.stack[-1]\n                assert node[-1] is not None\n                node[-1].append(newnode)\n            else:\n                self.rootnode = newnode\n                self.rootnode.used_names = self.used_names\n </s> add         newnode = convert(self.grammar, popnode)\n        if self.stack:\n            dfa, state, node = self.stack[-1]\n            assert node[-1] is not None\n            node[-1].append(newnode)\n        else:\n            self.rootnode = newnode\n            self.rootnode.used_names = self.used_names </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode)\n </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> add def find_python_files(base: Path) -> List[Path]:\n    files = []\n    for entry in base.iterdir():\n        if entry.is_file() and entry.suffix == \".py\":\n            files.append(entry)\n        elif entry.is_dir():\n            files.extend(find_python_files(entry))\n\n    return files\n\n", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 else:\n <mask>                     # No success finding a transition\n <mask>                     raise ParseError(\"bad input\", type, value, context)\n <mask> \n <mask>     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]:\n <mask>         \"\"\"Turn a token into a label.  (Internal)\n <mask> \n <mask>         Depending on whether the value is a soft-keyword or not,\n <mask>         this function may return multiple labels to choose from.\"\"\"\n <mask>         if type == token.NAME:\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove             assert value is not None\n </s> add  </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None:\n </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove         assert value is not None\n        assert context is not None\n </s> add  </s> add         **post-note: the convert argument is ignored since for Black's\n        usage, convert will always be blib2to3.pytree.convert. Allowing\n        this to be dynamic hurts mypyc's ability to use early binding.\n        These docs are left for historical and informational value.\n", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         Depending on whether the value is a soft-keyword or not,\n <mask>         this function may return multiple labels to choose from.\"\"\"\n <mask>         if type == token.NAME:\n <mask>             # Keep a listing of all used names\n <mask>             assert value is not None\n <mask>             self.used_names.add(value)\n <mask>             # Check for reserved words\n <mask>             if value in self.grammar.keywords:\n <mask>                 return [self.grammar.keywords[value]]\n <mask>             elif value in self.grammar.soft_keywords:\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> add         **post-note: the convert argument is ignored since for Black's\n        usage, convert will always be blib2to3.pytree.convert. Allowing\n        this to be dynamic hurts mypyc's ability to use early binding.\n        These docs are left for historical and informational value.\n </s> remove         assert value is not None\n        assert context is not None\n </s> add  </s> remove             if p.addtoken(type, value, (prefix, start)):\n </s> add             if p.addtoken(cast(int, type), value, (prefix, start)): </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None:\n </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode)\n </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep replace replace keep", "code_tokens": " <mask>         if ilabel is None:\n <mask>             raise ParseError(\"bad token\", type, value, context)\n <mask>         return [ilabel]\n <mask> \n <mask>     def shift(\n <mask>         self, type: int, value: Optional[Text], newstate: int, context: Context\n <mask>     ) -> None:\n <mask>         \"\"\"Shift a token.  (Internal)\"\"\"\n <mask>         dfa, state, node = self.stack[-1]\n <mask>         assert value is not None\n <mask>         assert context is not None\n <mask>         rawnode: RawNode = (type, value, context, None)\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode)\n </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> remove         newnode = self.convert(self.grammar, popnode)\n        if newnode is not None:\n            if self.stack:\n                dfa, state, node = self.stack[-1]\n                assert node[-1] is not None\n                node[-1].append(newnode)\n            else:\n                self.rootnode = newnode\n                self.rootnode.used_names = self.used_names\n </s> add         newnode = convert(self.grammar, popnode)\n        if self.stack:\n            dfa, state, node = self.stack[-1]\n            assert node[-1] is not None\n            node[-1].append(newnode)\n        else:\n            self.rootnode = newnode\n            self.rootnode.used_names = self.used_names </s> remove     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         dfa, state, node = self.stack[-1]\n <mask>         assert value is not None\n <mask>         assert context is not None\n <mask>         rawnode: RawNode = (type, value, context, None)\n <mask>         newnode = self.convert(self.grammar, rawnode)\n <mask>         if newnode is not None:\n <mask>             assert node[-1] is not None\n <mask>             node[-1].append(newnode)\n <mask>         self.stack[-1] = (dfa, newstate, node)\n <mask> \n <mask>     def push(self, type: int, newdfa: DFAS, newstate: int, context: Context) -> None:\n <mask>         \"\"\"Push a nonterminal.  (Internal)\"\"\"\n <mask>         dfa, state, node = self.stack[-1]\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove         assert value is not None\n        assert context is not None\n </s> add  </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None:\n </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove         newnode = self.convert(self.grammar, popnode)\n        if newnode is not None:\n            if self.stack:\n                dfa, state, node = self.stack[-1]\n                assert node[-1] is not None\n                node[-1].append(newnode)\n            else:\n                self.rootnode = newnode\n                self.rootnode.used_names = self.used_names\n </s> add         newnode = convert(self.grammar, popnode)\n        if self.stack:\n            dfa, state, node = self.stack[-1]\n            assert node[-1] is not None\n            node[-1].append(newnode)\n        else:\n            self.rootnode = newnode\n            self.rootnode.used_names = self.used_names </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> remove     result = runner.invoke(black.main, args)\n </s> add     result = runner.invoke(black.main, args, catch_exceptions=False)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace", "code_tokens": " <mask> \n <mask>     def pop(self) -> None:\n <mask>         \"\"\"Pop a nonterminal.  (Internal)\"\"\"\n <mask>         popdfa, popstate, popnode = self.stack.pop()\n <mask>         newnode = self.convert(self.grammar, popnode)\n <mask>         if newnode is not None:\n <mask>             if self.stack:\n <mask>                 dfa, state, node = self.stack[-1]\n <mask>                 assert node[-1] is not None\n <mask>                 node[-1].append(newnode)\n <mask>             else:\n <mask>                 self.rootnode = newnode\n <mask>                 self.rootnode.used_names = self.used_names\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode)\n </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove         assert value is not None\n        assert context is not None\n </s> add  </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None:\n </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove                 elif t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, self.grammar.dfas[t], newstate, context)\n                        break  # To continue the outer while loop\n </s> add  </s> remove     result = runner.invoke(black.main, args)\n </s> add     result = runner.invoke(black.main, args, catch_exceptions=False)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> each time a new token is found.\"\"\"\n <mask> \n <mask> from typing import (\n <mask>     Callable,\n <mask>     Iterable,\n <mask>     Iterator,\n <mask>     List,\n <mask>     Optional,\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     Callable,\n </s> add  </s> add     cast, </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple\n </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> remove from blib2to3 import pygram, pytree\n </s> add from blib2to3 import pygram </s> remove from dataclasses import dataclass, field\n\n </s> add ", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     Pattern,\n <mask>     Union,\n <mask>     cast,\n <mask> )\n <mask> from blib2to3.pgen2.token import *\n <mask> from blib2to3.pgen2.grammar import Grammar\n <mask> \n <mask> __author__ = \"Ka-Ping Yee <ping@lfw.org>\"\n <mask> __credits__ = \"GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro\"\n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> remove from blib2to3 import pygram, pytree\n </s> add from blib2to3 import pygram </s> remove from contextlib import contextmanager\n </s> add from blib2to3.pgen2.tokenize import GoodTokenInfo </s> remove from blib2to3.pytree import _Convert, NL\n </s> add from blib2to3.pytree import NL </s> remove from blib2to3.pytree import NL, Context, RawNode, Leaf, Node\n </s> add from blib2to3.pytree import convert, NL, Context, RawNode, Leaf, Node </s> remove from dataclasses import replace\n </s> add  </s> add from contextlib import contextmanager", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> )\n <mask> PseudoExtras = group(r\"\\\\\\r?\\n\", Comment, Triple)\n <mask> PseudoToken = Whitespace + group(PseudoExtras, Number, Funny, ContStr, Name)\n <mask> \n <mask> pseudoprog = re.compile(PseudoToken, re.UNICODE)\n <mask> single3prog = re.compile(Single3)\n <mask> double3prog = re.compile(Double3)\n <mask> \n <mask> _strprefixes = (\n <mask>     _combinations(\"r\", \"R\", \"f\", \"F\")\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove endprogs = {\n </s> add endprogs: Final = { </s> remove triple_quoted = (\n </s> add triple_quoted: Final = ( </s> remove     result = runner.invoke(black.main, args)\n </s> add     result = runner.invoke(black.main, args, catch_exceptions=False) </s> remove single_quoted = (\n </s> add single_quoted: Final = ( </s> remove \n\n_Convert = Callable[[Grammar, RawNode], Any]\n </s> add  </s> remove     match = re.match(r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", s, re.DOTALL)\n </s> add     match = STRING_PREFIX_RE.match(s)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     | _combinations(\"r\", \"R\", \"b\", \"B\")\n <mask>     | {\"u\", \"U\", \"ur\", \"uR\", \"Ur\", \"UR\"}\n <mask> )\n <mask> \n <mask> endprogs = {\n <mask>     \"'\": re.compile(Single),\n <mask>     '\"': re.compile(Double),\n <mask>     \"'''\": single3prog,\n <mask>     '\"\"\"': double3prog,\n <mask>     **{f\"{prefix}'''\": single3prog for prefix in _strprefixes},\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove triple_quoted = (\n </s> add triple_quoted: Final = ( </s> remove single_quoted = (\n </s> add single_quoted: Final = ( </s> remove pseudoprog = re.compile(PseudoToken, re.UNICODE)\n </s> add pseudoprog: Final = re.compile(PseudoToken, re.UNICODE) </s> remove IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}\nOPENING_BRACKETS = set(BRACKET.keys())\nCLOSING_BRACKETS = set(BRACKET.values())\nBRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}\n </s> add IMPLICIT_TUPLE: Final = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET: Final = {\n    token.LPAR: token.RPAR,\n    token.LSQB: token.RSQB,\n    token.LBRACE: token.RBRACE,\n}\nOPENING_BRACKETS: Final = set(BRACKET.keys())\nCLOSING_BRACKETS: Final = set(BRACKET.values())\nBRACKETS: Final = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE: Final = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT} </s> remove     RE_FEXPR = r\"\"\"\n </s> add     RE_FEXPR: Final = r\"\"\" </s> remove     _goto: Dict[Tuple[ParserState, NodeType], ParserState] = {\n </s> add     _goto: Final[Dict[Tuple[ParserState, NodeType], ParserState]] = {", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace keep keep keep", "code_tokens": " <mask> \n <mask> triple_quoted = (\n <mask>     {\"'''\", '\"\"\"'}\n <mask>     | {f\"{prefix}'''\" for prefix in _strprefixes}\n <mask>     | {f'{prefix}\"\"\"' for prefix in _strprefixes}\n <mask> )\n <mask> single_quoted = (\n <mask>     {\"'\", '\"'}\n <mask>     | {f\"{prefix}'\" for prefix in _strprefixes}\n <mask>     | {f'{prefix}\"' for prefix in _strprefixes}\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove endprogs = {\n </s> add endprogs: Final = { </s> remove     RE_FEXPR = r\"\"\"\n </s> add     RE_FEXPR: Final = r\"\"\" </s> remove IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}\nOPENING_BRACKETS = set(BRACKET.keys())\nCLOSING_BRACKETS = set(BRACKET.values())\nBRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}\n </s> add IMPLICIT_TUPLE: Final = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET: Final = {\n    token.LPAR: token.RPAR,\n    token.LSQB: token.RSQB,\n    token.LBRACE: token.RBRACE,\n}\nOPENING_BRACKETS: Final = set(BRACKET.keys())\nCLOSING_BRACKETS: Final = set(BRACKET.values())\nBRACKETS: Final = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE: Final = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT} </s> remove         indent_columns = []\n </s> add         indent_columns: List[int] = [] </s> remove                 for version in sorted(self.target_versions, key=lambda v: v.value)\n </s> add                 for version in sorted(self.target_versions, key=attrgetter(\"value\"))", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     and the line on which the token was found. The line passed is the\n <mask>     logical line; continuation lines are included.\n <mask>     \"\"\"\n <mask>     lnum = parenlev = continued = 0\n <mask>     numchars = \"0123456789\"\n <mask>     contstr, needcont = \"\", 0\n <mask>     contline: Optional[str] = None\n <mask>     indents = [0]\n <mask> \n <mask>     # If we know we're parsing 3.7+, we can unconditionally parse `async` and\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     stashed = None\n </s> add     stashed: Optional[GoodTokenInfo] = None </s> remove         lnum = lnum + 1\n </s> add         lnum += 1 </s> remove         p = parse.Parser(self.grammar, self.convert)\n </s> add         p = parse.Parser(self.grammar) </s> remove     cell_magic: Optional[CellMagic] = None\n </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic </s> remove         match = re.match(r\"\\s*\\t+\\s*(\\S)\", line)\n </s> add         match = FIRST_NON_WHITESPACE_RE.match(line) </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__()", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     # If we know we're parsing 3.7+, we can unconditionally parse `async` and\n <mask>     # `await` as keywords.\n <mask>     async_keywords = False if grammar is None else grammar.async_keywords\n <mask>     # 'stashed' and 'async_*' are used for async/await parsing\n <mask>     stashed = None\n <mask>     async_def = False\n <mask>     async_def_indent = 0\n <mask>     async_def_nl = False\n <mask> \n <mask>     strstart: Tuple[int, int]\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     numchars = \"0123456789\"\n </s> add     numchars: Final = \"0123456789\" </s> remove                 elif t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, self.grammar.dfas[t], newstate, context)\n                        break  # To continue the outer while loop\n </s> add  </s> add         assert worker_count is not None </s> remove     cell_magic: Optional[CellMagic] = None\n </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic </s> remove         pyproject_toml = tomli.load(f)  # type: ignore  # due to deprecated API usage\n </s> add         pyproject_toml = tomli.loads(f.read()) </s> add def find_python_files(base: Path) -> List[Path]:\n    files = []\n    for entry in base.iterdir():\n        if entry.is_file() and entry.suffix == \".py\":\n            files.append(entry)\n        elif entry.is_dir():\n            files.extend(find_python_files(entry))\n\n    return files\n\n", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         try:\n <mask>             line = readline()\n <mask>         except StopIteration:\n <mask>             line = \"\"\n <mask>         lnum = lnum + 1\n <mask>         pos, max = 0, len(line)\n <mask> \n <mask>         if contstr:  # continued string\n <mask>             assert contline is not None\n <mask>             if not line:\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     numchars = \"0123456789\"\n </s> add     numchars: Final = \"0123456789\" </s> add         assert worker_count is not None </s> remove                         parenlev = parenlev + 1\n </s> add                         parenlev += 1 </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode)\n </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove     match = re.match(r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", s, re.DOTALL)\n </s> add     match = STRING_PREFIX_RE.match(s) </s> remove         drv = driver.Driver(grammar, pytree.convert)\n </s> add         drv = driver.Driver(grammar)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 break\n <mask>             column = 0\n <mask>             while pos < max:  # measure leading whitespace\n <mask>                 if line[pos] == \" \":\n <mask>                     column = column + 1\n <mask>                 elif line[pos] == \"\\t\":\n <mask>                     column = (column // tabsize + 1) * tabsize\n <mask>                 elif line[pos] == \"\\f\":\n <mask>                     column = 0\n <mask>                 else:\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove         indent_columns = []\n </s> add         indent_columns: List[int] = [] </s> remove         p = parse.Parser(self.grammar, self.convert)\n </s> add         p = parse.Parser(self.grammar) </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove                         parenlev = parenlev - 1\n </s> add                         parenlev -= 1 </s> remove                         parenlev = parenlev + 1\n </s> add                         parenlev += 1", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 elif line[pos] == \"\\f\":\n <mask>                     column = 0\n <mask>                 else:\n <mask>                     break\n <mask>                 pos = pos + 1\n <mask>             if pos == max:\n <mask>                 break\n <mask> \n <mask>             if stashed:\n <mask>                 yield stashed\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove                     column = column + 1\n </s> add                     column += 1 </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove                         parenlev = parenlev - 1\n </s> add                         parenlev -= 1 </s> remove                         parenlev = parenlev + 1\n </s> add                         parenlev += 1 </s> remove                     (lnum, pos + len(comment_token)),\n </s> add                     (lnum, nl_pos), </s> remove                     next_token_type = grammar.opmap[cast(str, next_token_value)]\n </s> add                     next_token_type = grammar.opmap[next_token_value]", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 yield (\n <mask>                     COMMENT,\n <mask>                     comment_token,\n <mask>                     (lnum, pos),\n <mask>                     (lnum, pos + len(comment_token)),\n <mask>                     line,\n <mask>                 )\n <mask>                 yield (NL, line[nl_pos:], (lnum, nl_pos), (lnum, len(line)), line)\n <mask>                 continue\n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove                         parenlev = parenlev + 1\n </s> add                         parenlev += 1 </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove                         parenlev = parenlev - 1\n </s> add                         parenlev -= 1 </s> remove \n\n_Convert = Callable[[Grammar, RawNode], Any]\n </s> add  </s> remove         elif isinstance(value, (ast.AST, ast3.AST, ast27.AST)):\n </s> add         # Note that we are referencing the typed-ast ASTs via global variables and not\n        # direct module attribute accesses because that breaks mypyc. It's probably\n        # something to do with the ast3 / ast27 variables being marked as Any leading\n        # mypy to think this branch is always taken, leaving the rest of the code\n        # unanalyzed. Tighting up the types for the typed-ast AST types avoids the\n        # mypyc crash.\n        elif isinstance(value, (ast.AST, ast3_AST, ast27_AST)):", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace keep keep keep", "code_tokens": " <mask>                     yield (NL, token, spos, (lnum, pos), line)\n <mask>                     continued = 1\n <mask>                 else:\n <mask>                     if initial in \"([{\":\n <mask>                         parenlev = parenlev + 1\n <mask>                     elif initial in \")]}\":\n <mask>                         parenlev = parenlev - 1\n <mask>                     if stashed:\n <mask>                         yield stashed\n <mask>                         stashed = None\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove                     (lnum, pos + len(comment_token)),\n </s> add                     (lnum, nl_pos), </s> remove         lnum = lnum + 1\n </s> add         lnum += 1 </s> remove     numchars = \"0123456789\"\n </s> add     numchars: Final = \"0123456789\"", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                         stashed = None\n <mask>                     yield (OP, token, spos, epos, line)\n <mask>             else:\n <mask>                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line)\n <mask>                 pos = pos + 1\n <mask> \n <mask>     if stashed:\n <mask>         yield stashed\n <mask>         stashed = None\n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> remove                         parenlev = parenlev + 1\n </s> add                         parenlev += 1 </s> remove                         parenlev = parenlev - 1\n </s> add                         parenlev -= 1 </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove                     (lnum, pos + len(comment_token)),\n </s> add                     (lnum, nl_pos), </s> remove                     column = column + 1\n </s> add                     column += 1 </s> remove \n\n_Convert = Callable[[Grammar, RawNode], Any]\n </s> add ", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> # mypy: allow-untyped-defs\n <mask> \n <mask> from typing import (\n <mask>     Any,\n <mask>     Callable,\n <mask>     Dict,\n <mask>     Iterator,\n <mask>     List,\n <mask>     Optional,\n <mask>     Text,\n </s> Implementing mypyc support pt. 2  (#2431) </s> add     cast, </s> add import sys </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple\n </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final\n </s> remove from dataclasses import dataclass, field\n\n </s> add  </s> remove from blib2to3 import pygram, pytree\n </s> add from blib2to3 import pygram", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         if self.__class__ is not other.__class__:\n <mask>             return NotImplemented\n <mask>         return self._eq(other)\n <mask> \n <mask>     __hash__ = None  # type: Any  # For Py3 compatibility.\n <mask> \n <mask>     @property\n <mask>     def prefix(self) -> Text:\n <mask>         raise NotImplementedError\n <mask> \n <mask>     def _eq(self: _P, other: _P) -> bool:\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None:\n </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]:\n </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode)\n </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove                 if isinstance(item, WildcardPattern):\n                    self.wildcards = True\n </s> add                 # I don't even think this code is used anywhere, but it does cause\n                # unreachable errors from mypy. This function's signature does look\n                # odd though *shrug*.\n                if isinstance(item, WildcardPattern):  # type: ignore[unreachable]\n                    self.wildcards = True  # type: ignore[unreachable]", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         Return a pretty string representation.\n <mask> \n <mask>         This reproduces the input source exactly.\n <mask>         \"\"\"\n <mask>         return self.prefix + str(self.value)\n <mask> \n <mask>     def _eq(self, other) -> bool:\n <mask>         \"\"\"Compare two nodes for equality.\"\"\"\n <mask>         return (self.type, self.value) == (other.type, other.value)\n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> remove @dataclasses.dataclass\n </s> add # ast.NodeVisitor + dataclass = breakage under mypyc. </s> remove     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> remove     __hash__ = None  # type: Any  # For Py3 compatibility.\n\n </s> add  </s> add def find_python_files(base: Path) -> List[Path]:\n    files = []\n    for entry in base.iterdir():\n        if entry.is_file() and entry.suffix == \".py\":\n            files.append(entry)\n        elif entry.is_dir():\n            files.extend(find_python_files(entry))\n\n    return files\n\n </s> remove             assert value is not None\n </s> add  </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             assert not isinstance(content, str), repr(content)\n <mask>             newcontent = list(content)\n <mask>             for i, item in enumerate(newcontent):\n <mask>                 assert isinstance(item, BasePattern), (i, item)\n <mask>                 if isinstance(item, WildcardPattern):\n <mask>                     self.wildcards = True\n <mask>         self.type = type\n <mask>         self.content = newcontent\n <mask>         self.name = name\n <mask> \n <mask>     def _submatch(self, node, results=None) -> bool:\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool:\n </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode)\n </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove         newnode = self.convert(self.grammar, popnode)\n        if newnode is not None:\n            if self.stack:\n                dfa, state, node = self.stack[-1]\n                assert node[-1] is not None\n                node[-1].append(newnode)\n            else:\n                self.rootnode = newnode\n                self.rootnode.used_names = self.used_names\n </s> add         newnode = convert(self.grammar, popnode)\n        if self.stack:\n            dfa, state, node = self.stack[-1]\n            assert node[-1] is not None\n            node[-1].append(newnode)\n        else:\n            self.rootnode = newnode\n            self.rootnode.used_names = self.used_names </s> add                 assert type is not None </s> remove     result = runner.invoke(black.main, args)\n </s> add     result = runner.invoke(black.main, args, catch_exceptions=False) </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool:\n </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace", "code_tokens": " <mask>                     r = {}\n <mask>                     r.update(r0)\n <mask>                     r.update(r1)\n <mask>                     yield c0 + c1, r\n <mask> \n <mask> \n <mask> _Convert = Callable[[Grammar, RawNode], Any]\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove                         parenlev = parenlev + 1\n </s> add                         parenlev += 1 </s> remove                         parenlev = parenlev - 1\n </s> add                         parenlev -= 1 </s> remove                 pos = pos + 1\n </s> add                 pos += 1 </s> remove     def add_token(\n        self, tok_type: int, tok_val: Optional[Text], raw: bool = False\n    ) -> None:\n </s> add     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None: </s> remove                     (lnum, pos + len(comment_token)),\n </s> add                     (lnum, nl_pos),", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ) -> None:\n <mask>     runner = BlackRunner()\n <mask>     if ignore_config:\n <mask>         args = [\"--verbose\", \"--config\", str(THIS_DIR / \"empty.toml\"), *args]\n <mask>     result = runner.invoke(black.main, args)\n <mask>     assert result.stdout_bytes is not None\n <mask>     assert result.stderr_bytes is not None\n <mask>     msg = (\n <mask>         f\"Failed with args: {args}\\n\"\n <mask>         f\"stdout: {result.stdout_bytes.decode()!r}\\n\"\n </s> Implementing mypyc support pt. 2  (#2431) </s> remove         assert value is not None\n        assert context is not None\n </s> add  </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode)\n </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove         newnode = self.convert(self.grammar, popnode)\n        if newnode is not None:\n            if self.stack:\n                dfa, state, node = self.stack[-1]\n                assert node[-1] is not None\n                node[-1].append(newnode)\n            else:\n                self.rootnode = newnode\n                self.rootnode.used_names = self.used_names\n </s> add         newnode = convert(self.grammar, popnode)\n        if self.stack:\n            dfa, state, node = self.stack[-1]\n            assert node[-1] is not None\n            node[-1].append(newnode)\n        else:\n            self.rootnode = newnode\n            self.rootnode.used_names = self.used_names </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None:\n </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove         lnum = lnum + 1\n </s> add         lnum += 1 </s> add                 assert type is not None", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         )\n <mask>         self.assertEqual({\"unicode_literals\", \"print\"}, black.get_future_imports(node))\n <mask> \n <mask>     def test_debug_visitor(self) -> None:\n <mask>         source, _ = read_data(\"debug_visitor.py\")\n <mask>         expected, _ = read_data(\"debug_visitor.out\")\n <mask>         out_lines = []\n <mask>         err_lines = []\n <mask> \n </s> Implementing mypyc support pt. 2  (#2431) </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> remove         indent_columns = []\n </s> add         indent_columns: List[int] = [] </s> remove     from mypyc.build import mypycify\n\n </s> add  </s> remove     ext_modules = mypycify(mypyc_targets, opt_level=opt_level)\n </s> add     ext_modules = mypycify(mypyc_targets, opt_level=opt_level, verbose=True) </s> remove         p = parse.Parser(self.grammar, self.convert)\n </s> add         p = parse.Parser(self.grammar)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         self.assertEqual(n.type, black.syms.file_input)\n <mask>         self.assertEqual(len(n.children), 1)\n <mask>         self.assertEqual(n.children[0].type, black.token.ENDMARKER)\n <mask> \n <mask>     @unittest.skipIf(os.environ.get(\"SKIP_AST_PRINT\"), \"user set SKIP_AST_PRINT\")\n <mask>     def test_assertFormatEqual(self) -> None:\n <mask>         out_lines = []\n <mask>         err_lines = []\n <mask> \n <mask>         def out(msg: str, **kwargs: Any) -> None:\n </s> Implementing mypyc support pt. 2  (#2431) </s> add     @pytest.mark.incompatible_with_mypyc </s> add @mypyc_attr(patchable=True) </s> add @mypyc_attr(patchable=True) </s> add @mypyc_attr(patchable=True) </s> add     @pytest.mark.incompatible_with_mypyc </s> remove         indent_columns = []\n </s> add         indent_columns: List[int] = []", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         actual = result.output\n <mask>         self.assertFormatEqual(actual, expected)\n <mask> \n <mask>     def test_reformat_one_with_stdin(self) -> None:\n <mask>         with patch(\n <mask>             \"black.format_stdin_to_stdout\",\n <mask>             return_value=lambda *args, **kwargs: black.Changed.YES,\n <mask>         ) as fsts:\n <mask>             report = MagicMock()\n </s> Implementing mypyc support pt. 2  (#2431) </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>             fsts.assert_called_once()\n <mask>             report.done.assert_called_with(path, black.Changed.YES)\n <mask> \n <mask>     def test_reformat_one_with_stdin_filename(self) -> None:\n <mask>         with patch(\n <mask>             \"black.format_stdin_to_stdout\",\n <mask>             return_value=lambda *args, **kwargs: black.Changed.YES,\n </s> Implementing mypyc support pt. 2  (#2431) </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>             report.done.assert_called_with(expected, black.Changed.YES)\n <mask> \n <mask>     def test_reformat_one_with_stdin_filename_pyi(self) -> None:\n <mask>         with patch(\n <mask>             \"black.format_stdin_to_stdout\",\n <mask>             return_value=lambda *args, **kwargs: black.Changed.YES,\n <mask>         ) as fsts:\n </s> Implementing mypyc support pt. 2  (#2431) </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>             # __BLACK_STDIN_FILENAME__ should have been stripped\n <mask>             report.done.assert_called_with(expected, black.Changed.YES)\n <mask> \n <mask>     def test_reformat_one_with_stdin_filename_ipynb(self) -> None:\n <mask>         with patch(\n <mask>             \"black.format_stdin_to_stdout\",\n <mask>             return_value=lambda *args, **kwargs: black.Changed.YES,\n <mask>         ) as fsts:\n <mask>             report = MagicMock()\n </s> Implementing mypyc support pt. 2  (#2431) </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>             # __BLACK_STDIN_FILENAME__ should have been stripped\n <mask>             report.done.assert_called_with(expected, black.Changed.YES)\n <mask> \n <mask>     def test_reformat_one_with_stdin_and_existing_path(self) -> None:\n <mask>         with patch(\n <mask>             \"black.format_stdin_to_stdout\",\n <mask>             return_value=lambda *args, **kwargs: black.Changed.YES,\n <mask>         ) as fsts:\n </s> Implementing mypyc support pt. 2  (#2431) </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> remove @dataclasses.dataclass\n </s> add # Unsurprisingly, subclassing ast.NodeVisitor means we can't use dataclasses here\n# as mypyc will generate broken code. </s> add     @pytest.mark.incompatible_with_mypyc", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         self.assertEqual(config[\"target_version\"], [\"py36\", \"py37\", \"py38\"])\n <mask>         self.assertEqual(config[\"exclude\"], r\"\\.pyi?$\")\n <mask>         self.assertEqual(config[\"include\"], r\"\\.py?$\")\n <mask> \n <mask>     def test_find_project_root(self) -> None:\n <mask>         with TemporaryDirectory() as workspace:\n <mask>             root = Path(workspace)\n <mask>             test_dir = root / \"test\"\n </s> Implementing mypyc support pt. 2  (#2431) </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> remove     result = runner.invoke(black.main, args)\n </s> add     result = runner.invoke(black.main, args, catch_exceptions=False) </s> add     @pytest.mark.incompatible_with_mypyc </s> remove with open(black.__file__, \"r\", encoding=\"utf-8\") as _bf:\n    black_source_lines = _bf.readlines()\n </s> add try:\n    with open(black.__file__, \"r\", encoding=\"utf-8\") as _bf:\n        black_source_lines = _bf.readlines()\nexcept UnicodeDecodeError:\n    if not black.COMPILED:\n        raise </s> add     @pytest.mark.incompatible_with_mypyc", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         assert output == result_diff, \"The output did not match the expected value.\"\n <mask>         assert result.exit_code == 0, \"The exit code is incorrect.\"\n <mask> \n <mask>     def test_code_option_safe(self) -> None:\n <mask>         \"\"\"Test that the code option throws an error when the sanity checks fail.\"\"\"\n <mask>         # Patch black.assert_equivalent to ensure the sanity checks fail\n <mask>         with patch.object(black, \"assert_equivalent\", side_effect=AssertionError):\n <mask>             code = 'print(\"Hello world\")'\n </s> Implementing mypyc support pt. 2  (#2431) </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> remove         elif isinstance(value, (ast.AST, ast3.AST, ast27.AST)):\n </s> add         # Note that we are referencing the typed-ast ASTs via global variables and not\n        # direct module attribute accesses because that breaks mypyc. It's probably\n        # something to do with the ast3 / ast27 variables being marked as Any leading\n        # mypy to think this branch is always taken, leaving the rest of the code\n        # unanalyzed. Tighting up the types for the typed-ast AST types avoids the\n        # mypyc crash.\n        elif isinstance(value, (ast.AST, ast3_AST, ast27_AST)): </s> remove     match = re.match(r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", s, re.DOTALL)\n </s> add     match = STRING_PREFIX_RE.match(s) </s> remove @dataclass\n </s> add # This isn't a dataclass because @dataclass + Generic breaks mypyc.\n# See also https://github.com/mypyc/mypyc/issues/827.", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>             self.compare_results(result, formatted, 0)\n <mask> \n <mask>     def test_code_option_config(self) -> None:\n <mask>         \"\"\"\n <mask>         Test that the code option finds the pyproject.toml in the current directory.\n <mask>         \"\"\"\n <mask>         with patch.object(black, \"parse_pyproject_toml\", return_value={}) as parse:\n </s> Implementing mypyc support pt. 2  (#2431) </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> remove     cell_magic: Optional[CellMagic] = None\n </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic </s> remove         elif isinstance(value, (ast.AST, ast3.AST, ast27.AST)):\n </s> add         # Note that we are referencing the typed-ast ASTs via global variables and not\n        # direct module attribute accesses because that breaks mypyc. It's probably\n        # something to do with the ast3 / ast27 variables being marked as Any leading\n        # mypy to think this branch is always taken, leaving the rest of the code\n        # unanalyzed. Tighting up the types for the typed-ast AST types avoids the\n        # mypyc crash.\n        elif isinstance(value, (ast.AST, ast3_AST, ast27_AST)): </s> remove     MIN_SUBSTR_SIZE = 6\n </s> add     MIN_SUBSTR_SIZE: Final = 6", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>             ), \"Incorrect config loaded.\"\n <mask> \n <mask>     def test_code_option_parent_config(self) -> None:\n <mask>         \"\"\"\n <mask>         Test that the code option finds the pyproject.toml in the parent directory.\n <mask>         \"\"\"\n </s> Implementing mypyc support pt. 2  (#2431) </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False)\n </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> remove     cell_magic: Optional[CellMagic] = None\n </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic </s> remove     MIN_SUBSTR_SIZE = 6\n </s> add     MIN_SUBSTR_SIZE: Final = 6 </s> remove     magics: Dict[int, List[OffsetAndMagic]] = dataclasses.field(\n        default_factory=lambda: collections.defaultdict(list)\n    )\n </s> add     def __init__(self) -> None:\n        self.magics: Dict[int, List[OffsetAndMagic]] = collections.defaultdict(list)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>             src, expected, exclude=r\"\\.pyi$\", extend_exclude=r\"\\.definitely_exclude\"\n <mask>         )\n <mask> \n <mask>     def test_symlink_out_of_root_directory(self) -> None:\n <mask>         path = MagicMock()\n <mask>         root = THIS_DIR.resolve()\n <mask>         child = MagicMock()\n <mask>         include = re.compile(black.DEFAULT_INCLUDES)\n </s> Implementing mypyc support pt. 2  (#2431) </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc </s> remove     def __init__(\n        self,\n        grammar: Grammar,\n        convert: Optional[_Convert] = None,\n        logger: Optional[Logger] = None,\n    ) -> None:\n </s> add     def __init__(self, grammar: Grammar, logger: Optional[Logger] = None) -> None: </s> remove     def add_token(\n        self, tok_type: int, tok_val: Optional[Text], raw: bool = False\n    ) -> None:\n </s> add     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             TargetVersion.PY27\n <mask>         }, non_python2_case\n <mask> \n <mask> \n <mask> with open(black.__file__, \"r\", encoding=\"utf-8\") as _bf:\n <mask>     black_source_lines = _bf.readlines()\n <mask> \n <mask> \n <mask> def tracefunc(\n <mask>     frame: types.FrameType, event: str, arg: Any\n <mask> ) -> Callable[[types.FrameType, str, Any], Any]:\n </s> Implementing mypyc support pt. 2  (#2431) </s> add     @pytest.mark.incompatible_with_mypyc </s> remove STRING_PREFIX_CHARS = \"furbFURB\"  # All possible string prefix characters.\n </s> add STRING_PREFIX_CHARS: Final = \"furbFURB\"  # All possible string prefix characters.\nSTRING_PREFIX_RE: Final = re.compile(\n    r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", re.DOTALL\n)\nFIRST_NON_WHITESPACE_RE: Final = re.compile(r\"\\s*\\t+\\s*(\\S)\") </s> add     @pytest.mark.incompatible_with_mypyc </s> remove     required_version: str,\n </s> add     required_version: Optional[str], </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>       github.event_name == 'push' || github.event.pull_request.head.repo.full_name !=\n <mask>       github.repository\n <mask> \n <mask>     runs-on: ubuntu-latest\n <mask>     strategy:\n <mask>       matrix:\n <mask>         python-version: [3.7]\n <mask> \n <mask>     steps:\n <mask>       - uses: actions/checkout@v2\n <mask> \n <mask>       - name: Set up Python ${{ matrix.python-version }}\n </s> Add a GitHub Action to build + Upload black to PyPI (#1848)\n\n* Add a GitHub Action to build + Upload black to PyPI\r\n- Build a wheel + sdist\r\n- Upload via twine using token stored in GitHub secrets </s> remove       - name: Set up Python ${{ matrix.python-version }}\n </s> add       - name: Set up Python </s> remove           python-version: ${{ matrix.python-version }}\n </s> add           python-version: 3.7 </s> remove     rev: 3.8.1\n </s> add     rev: 3.8.4", "html_url": "https://github.com/psf/black/commit/125ed5b2601f0e74ded03b666132e3c37ae8af07", "file_name": ".github/workflows/lint.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     steps:\n <mask>       - uses: actions/checkout@v2\n <mask> \n <mask>       - name: Set up Python ${{ matrix.python-version }}\n <mask>         uses: actions/setup-python@v2\n <mask>         with:\n <mask>           python-version: ${{ matrix.python-version }}\n <mask> \n <mask>       - name: Install dependencies\n </s> Add a GitHub Action to build + Upload black to PyPI (#1848)\n\n* Add a GitHub Action to build + Upload black to PyPI\r\n- Build a wheel + sdist\r\n- Upload via twine using token stored in GitHub secrets </s> remove           python-version: ${{ matrix.python-version }}\n </s> add           python-version: 3.7 </s> remove     strategy:\n      matrix:\n        python-version: [3.7]\n </s> add  </s> remove     rev: 3.8.1\n </s> add     rev: 3.8.4", "html_url": "https://github.com/psf/black/commit/125ed5b2601f0e74ded03b666132e3c37ae8af07", "file_name": ".github/workflows/lint.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>       - name: Set up Python ${{ matrix.python-version }}\n <mask>         uses: actions/setup-python@v2\n <mask>         with:\n <mask>           python-version: ${{ matrix.python-version }}\n <mask> \n <mask>       - name: Install dependencies\n <mask>         run: |\n <mask>           python -m pip install --upgrade pip\n <mask>           python -m pip install --upgrade pre-commit\n </s> Add a GitHub Action to build + Upload black to PyPI (#1848)\n\n* Add a GitHub Action to build + Upload black to PyPI\r\n- Build a wheel + sdist\r\n- Upload via twine using token stored in GitHub secrets </s> remove       - name: Set up Python ${{ matrix.python-version }}\n </s> add       - name: Set up Python </s> remove     strategy:\n      matrix:\n        python-version: [3.7]\n </s> add  </s> remove     rev: 3.8.1\n </s> add     rev: 3.8.4", "html_url": "https://github.com/psf/black/commit/125ed5b2601f0e74ded03b666132e3c37ae8af07", "file_name": ".github/workflows/lint.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         require_serial: true\n <mask>         types_or: [python, pyi]\n <mask> \n <mask>   - repo: https://gitlab.com/pycqa/flake8\n <mask>     rev: 3.8.1\n <mask>     hooks:\n <mask>       - id: flake8\n <mask>         additional_dependencies: [flake8-bugbear]\n <mask> \n <mask>   - repo: https://github.com/pre-commit/mirrors-mypy\n </s> Add a GitHub Action to build + Upload black to PyPI (#1848)\n\n* Add a GitHub Action to build + Upload black to PyPI\r\n- Build a wheel + sdist\r\n- Upload via twine using token stored in GitHub secrets </s> remove       - name: Set up Python ${{ matrix.python-version }}\n </s> add       - name: Set up Python </s> remove     strategy:\n      matrix:\n        python-version: [3.7]\n </s> add  </s> remove           python-version: ${{ matrix.python-version }}\n </s> add           python-version: 3.7", "html_url": "https://github.com/psf/black/commit/125ed5b2601f0e74ded03b666132e3c37ae8af07", "file_name": ".pre-commit-config.yaml"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     ),\n <mask> )\n <mask> @click.option(\n <mask>     \"--pyi\",\n <mask>     is_flag=True,\n <mask>     help=(\n <mask>         \"Format all input files like typing stubs regardless of file extension \"\n </s> Add back --py36 as a deprecated option (#750)\n\nThis partially reverts commit 21ab37a5d92c866a289320cba7c4689df70b3342. </s> remove         versions = set(target_version)\n </s> add         if py36:\n            err(f\"Cannot use both --target-version and --py36\")\n            ctx.exit(2)\n        else:\n            versions = set(target_version)\n    elif py36:\n        err(\n            \"--py36 is deprecated and will be removed in a future version. \"\n            \"Use --target-version py36 instead.\"\n        )\n        versions = PY36_VERSIONS </s> add     py36: bool,", "html_url": "https://github.com/psf/black/commit/129ebd53a66b4a8069321742aeecfafb44c76fd9", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     diff: bool,\n <mask>     fast: bool,\n <mask>     pyi: bool,\n <mask>     skip_string_normalization: bool,\n <mask>     quiet: bool,\n <mask>     verbose: bool,\n <mask>     include: str,\n <mask>     exclude: str,\n <mask>     src: Tuple[str],\n </s> Add back --py36 as a deprecated option (#750)\n\nThis partially reverts commit 21ab37a5d92c866a289320cba7c4689df70b3342. </s> remove         versions = set(target_version)\n </s> add         if py36:\n            err(f\"Cannot use both --target-version and --py36\")\n            ctx.exit(2)\n        else:\n            versions = set(target_version)\n    elif py36:\n        err(\n            \"--py36 is deprecated and will be removed in a future version. \"\n            \"Use --target-version py36 instead.\"\n        )\n        versions = PY36_VERSIONS </s> add @click.option(\n    \"--py36\",\n    is_flag=True,\n    help=(\n        \"Allow using Python 3.6-only syntax on all input files.  This will put \"\n        \"trailing commas in function signatures and calls also after *args and \"\n        \"**kwargs. Deprecated; use --target-version instead. \"\n        \"[default: per-file auto-detection]\"\n    ),\n)", "html_url": "https://github.com/psf/black/commit/129ebd53a66b4a8069321742aeecfafb44c76fd9", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ) -> None:\n <mask>     \"\"\"The uncompromising code formatter.\"\"\"\n <mask>     write_back = WriteBack.from_configuration(check=check, diff=diff)\n <mask>     if target_version:\n <mask>         versions = set(target_version)\n <mask>     else:\n <mask>         # We'll autodetect later.\n <mask>         versions = set()\n <mask>     mode = FileMode(\n <mask>         target_versions=versions,\n </s> Add back --py36 as a deprecated option (#750)\n\nThis partially reverts commit 21ab37a5d92c866a289320cba7c4689df70b3342. </s> add @click.option(\n    \"--py36\",\n    is_flag=True,\n    help=(\n        \"Allow using Python 3.6-only syntax on all input files.  This will put \"\n        \"trailing commas in function signatures and calls also after *args and \"\n        \"**kwargs. Deprecated; use --target-version instead. \"\n        \"[default: per-file auto-detection]\"\n    ),\n) </s> add     py36: bool,", "html_url": "https://github.com/psf/black/commit/129ebd53a66b4a8069321742aeecfafb44c76fd9", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         # justify pushing it all onto one line. Thus we\n <mask>         # (unfortunately) need to check the actual source lines and\n <mask>         # only report an unsplittable 'type: ignore' if this line was\n <mask>         # one line in the original code.\n <mask>         if self.leaves[0].lineno == self.leaves[-1].lineno:\n <mask>             for comment in self.comments.get(id(self.leaves[-1]), []):\n <mask>                 if is_type_comment(comment, \" ignore\"):\n <mask>                     return True\n <mask> \n <mask>         return False\n <mask> \n <mask>     def contains_multiline_strings(self) -> bool:\n <mask>         for leaf in self.leaves:\n </s> Fix missed cases in the `# type: ignore` logic (#1059)\n\nIn #1040 I had convinced myself that the type ignore logic didn't\r\nneed anything like the ignored_ids from the type comment logic, but I\r\nwas wrong, and we do.\r\n\r\nWe hit these cases in practice a bunch. </s> remove         parameters.children = [\n            parameters.what_if_this_was_actually_long.children[0],\n            body,\n            parameters.children[-1],\n        ]  # type: ignore\n </s> add         parameters.children = [parameters.what_if_this_was_actually_long.children[0], body, parameters.children[-1]]  # type: ignore </s> add AAAAAAAAAAAAA = [AAAAAAAAAAAAA] + SHARED_AAAAAAAAAAAAA + USER_AAAAAAAAAAAAA + AAAAAAAAAAAAA  # type: ignore\n\ncall_to_some_function_asdf(\n    foo,\n    [AAAAAAAAAAAAAAAAAAAAAAA, AAAAAAAAAAAAAAAAAAAAAAA, AAAAAAAAAAAAAAAAAAAAAAA, BBBBBBBBBBBB],  # type: ignore\n)", "html_url": "https://github.com/psf/black/commit/133609463459b2b6a98f08bcf41a07f6b14ab747", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             parameters.children[0],  # (2 what if this was actually long\n <mask>             body,\n <mask>             parameters.children[-1],  # )2\n <mask>         ]\n <mask>         parameters.children = [\n <mask>             parameters.what_if_this_was_actually_long.children[0],\n <mask>             body,\n <mask>             parameters.children[-1],\n <mask>         ]  # type: ignore\n <mask>     if (\n <mask>         self._proc is not None\n <mask>         # has the child process finished?\n <mask>         and self._returncode is None\n <mask>         # the child process has finished, but the\n </s> Fix missed cases in the `# type: ignore` logic (#1059)\n\nIn #1040 I had convinced myself that the type ignore logic didn't\r\nneed anything like the ignored_ids from the type comment logic, but I\r\nwas wrong, and we do.\r\n\r\nWe hit these cases in practice a bunch. </s> remove         if self.leaves[0].lineno == self.leaves[-1].lineno:\n            for comment in self.comments.get(id(self.leaves[-1]), []):\n                if is_type_comment(comment, \" ignore\"):\n                    return True\n </s> add         # Like in the type comment check above, we need to skip a black added\n        # trailing comma or invisible paren, since it will be the original leaf\n        # before it that has the original line number.\n        last_idx = -1\n        last_leaf = self.leaves[-1]\n        if len(self.leaves) > 2 and (\n            last_leaf.type == token.COMMA\n            or (last_leaf.type == token.RPAR and not last_leaf.value)\n        ):\n            last_idx = -2\n\n        if self.leaves[0].lineno == self.leaves[last_idx].lineno:\n            for node in self.leaves[last_idx:]:\n                for comment in self.comments.get(id(node), []):\n                    if is_type_comment(comment, \" ignore\"):\n                        return True </s> add AAAAAAAAAAAAA = [AAAAAAAAAAAAA] + SHARED_AAAAAAAAAAAAA + USER_AAAAAAAAAAAAA + AAAAAAAAAAAAA  # type: ignore\n\ncall_to_some_function_asdf(\n    foo,\n    [AAAAAAAAAAAAAAAAAAAAAAA, AAAAAAAAAAAAAAAAAAAAAAA, AAAAAAAAAAAAAAAAAAAAAAA, BBBBBBBBBBBB],  # type: ignore\n)", "html_url": "https://github.com/psf/black/commit/133609463459b2b6a98f08bcf41a07f6b14ab747", "file_name": "tests/data/comments2.py"}
{"docstring_tokens": "keep keep keep add", "code_tokens": " <mask>     )\n <mask> \n <mask> \n <mask> result = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"  # aaa\n </s> Fix missed cases in the `# type: ignore` logic (#1059)\n\nIn #1040 I had convinced myself that the type ignore logic didn't\r\nneed anything like the ignored_ids from the type comment logic, but I\r\nwas wrong, and we do.\r\n\r\nWe hit these cases in practice a bunch. </s> remove         parameters.children = [\n            parameters.what_if_this_was_actually_long.children[0],\n            body,\n            parameters.children[-1],\n        ]  # type: ignore\n </s> add         parameters.children = [parameters.what_if_this_was_actually_long.children[0], body, parameters.children[-1]]  # type: ignore </s> remove         if self.leaves[0].lineno == self.leaves[-1].lineno:\n            for comment in self.comments.get(id(self.leaves[-1]), []):\n                if is_type_comment(comment, \" ignore\"):\n                    return True\n </s> add         # Like in the type comment check above, we need to skip a black added\n        # trailing comma or invisible paren, since it will be the original leaf\n        # before it that has the original line number.\n        last_idx = -1\n        last_leaf = self.leaves[-1]\n        if len(self.leaves) > 2 and (\n            last_leaf.type == token.COMMA\n            or (last_leaf.type == token.RPAR and not last_leaf.value)\n        ):\n            last_idx = -2\n\n        if self.leaves[0].lineno == self.leaves[last_idx].lineno:\n            for node in self.leaves[last_idx:]:\n                for comment in self.comments.get(id(node), []):\n                    if is_type_comment(comment, \" ignore\"):\n                        return True", "html_url": "https://github.com/psf/black/commit/133609463459b2b6a98f08bcf41a07f6b14ab747", "file_name": "tests/data/comments6.py"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask>           python -m pip install -e \".[d]\"\n <mask> \n <mask>       - name: Unit tests\n <mask>         run: |\n <mask>           coverage run tests/test_black.py\n </s> Remove deprecated use of 'setup.py test' (#1275)\n\nSince setuptools v41.5.0 (27 Oct 2019), the 'test' command is formally\r\ndeprecated and should not be used. Now use unittest as the test entry\r\npoint. </s> remove   - TEST_CMD=\"coverage run tests/test_black.py\"\n </s> add   - TEST_CMD=\"coverage run -m unittest\" </s> remove     test_suite=\"tests.test_black\",\n </s> add ", "html_url": "https://github.com/psf/black/commit/1382eabb3f27d7c9cd5328fb7fddd1ded98121fb", "file_name": ".github/workflows/test.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>   pip: true\n <mask>   directories:\n <mask>     - $HOME/.cache/pre-commit\n <mask> env:\n <mask>   - TEST_CMD=\"coverage run tests/test_black.py\"\n <mask> install:\n <mask>   - pip install coverage coveralls pre-commit\n <mask>   - pip install -e '.[d]'\n <mask> script:\n <mask>   - $TEST_CMD\n </s> Remove deprecated use of 'setup.py test' (#1275)\n\nSince setuptools v41.5.0 (27 Oct 2019), the 'test' command is formally\r\ndeprecated and should not be used. Now use unittest as the test entry\r\npoint. </s> remove           coverage run tests/test_black.py\n </s> add           coverage run -m unittest </s> remove     test_suite=\"tests.test_black\",\n </s> add ", "html_url": "https://github.com/psf/black/commit/1382eabb3f27d7c9cd5328fb7fddd1ded98121fb", "file_name": ".travis.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"typing_extensions>=3.7.4\",\n <mask>         \"mypy_extensions>=0.4.3\",\n <mask>     ],\n <mask>     extras_require={\"d\": [\"aiohttp>=3.3.2\", \"aiohttp-cors\"]},\n <mask>     test_suite=\"tests.test_black\",\n <mask>     classifiers=[\n <mask>         \"Development Status :: 4 - Beta\",\n <mask>         \"Environment :: Console\",\n <mask>         \"Intended Audience :: Developers\",\n <mask>         \"License :: OSI Approved :: MIT License\",\n </s> Remove deprecated use of 'setup.py test' (#1275)\n\nSince setuptools v41.5.0 (27 Oct 2019), the 'test' command is formally\r\ndeprecated and should not be used. Now use unittest as the test entry\r\npoint. </s> remove   - TEST_CMD=\"coverage run tests/test_black.py\"\n </s> add   - TEST_CMD=\"coverage run -m unittest\" </s> remove           coverage run tests/test_black.py\n </s> add           coverage run -m unittest", "html_url": "https://github.com/psf/black/commit/1382eabb3f27d7c9cd5328fb7fddd1ded98121fb", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>       - name: Upload coverage to Coveralls\n <mask>         # Upload coverage if we are on the main repository and\n <mask>         # we're running on Linux (this action only supports Linux)\n <mask>         if: github.repository == 'psf/black' && matrix.os == 'ubuntu-latest'\n <mask>         uses: AndreMiras/coveralls-python-action@v20201129\n <mask>         with:\n <mask>           github-token: ${{ secrets.GITHUB_TOKEN }}\n <mask>           parallel: true\n <mask>           flag-name: py${{ matrix.python-version }}-${{ matrix.os }}\n </s> Disable coverage on pypy tests (#3777)\n\nThe pypy tests are reeeeaaally slow. Maybe this will help. </s> remove         ci: --numprocesses 1 \\\n        --cov --cov-append {posargs}\n    coverage report\n </s> add         ci: --numprocesses 1 </s> remove         ci: --numprocesses 1 \\\n        --cov {posargs}\n </s> add         ci: --numprocesses 1 </s> remove     coverage erase\n </s> add ", "html_url": "https://github.com/psf/black/commit/138769aa27d6bd86507a0cd98d9a5bf8f63a8e99", "file_name": ".github/workflows/test.yml"}
{"docstring_tokens": "keep replace keep keep keep replace replace keep keep", "code_tokens": " <mask>     pip install -e .[d]\n <mask>     coverage erase\n <mask>     pytest tests \\\n <mask>         --run-optional no_jupyter \\\n <mask>         !ci: --numprocesses auto \\\n <mask>         ci: --numprocesses 1 \\\n <mask>         --cov {posargs}\n <mask>     pip install -e .[jupyter]\n <mask>     pytest tests --run-optional jupyter \\\n </s> Disable coverage on pypy tests (#3777)\n\nThe pypy tests are reeeeaaally slow. Maybe this will help. </s> remove         ci: --numprocesses 1 \\\n        --cov --cov-append {posargs}\n    coverage report\n </s> add         ci: --numprocesses 1 </s> remove         if: github.repository == 'psf/black' && matrix.os == 'ubuntu-latest'\n </s> add         if:\n          github.repository == 'psf/black' && matrix.os == 'ubuntu-latest' &&\n          !startsWith(matrix.python-version, 'pypy')", "html_url": "https://github.com/psf/black/commit/138769aa27d6bd86507a0cd98d9a5bf8f63a8e99", "file_name": "tox.ini"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     pip install -e .[jupyter]\n <mask>     pytest tests --run-optional jupyter \\\n <mask>         -m jupyter \\\n <mask>         !ci: --numprocesses auto \\\n <mask>         ci: --numprocesses 1 \\\n <mask>         --cov --cov-append {posargs}\n <mask>     coverage report\n <mask> \n <mask> [testenv:{,ci-}311]\n <mask> setenv =\n <mask>   PYTHONPATH = {toxinidir}/src\n <mask>   AIOHTTP_NO_EXTENSIONS = 1\n </s> Disable coverage on pypy tests (#3777)\n\nThe pypy tests are reeeeaaally slow. Maybe this will help. </s> remove         ci: --numprocesses 1 \\\n        --cov {posargs}\n </s> add         ci: --numprocesses 1 </s> remove     coverage erase\n </s> add  </s> remove         if: github.repository == 'psf/black' && matrix.os == 'ubuntu-latest'\n </s> add         if:\n          github.repository == 'psf/black' && matrix.os == 'ubuntu-latest' &&\n          !startsWith(matrix.python-version, 'pypy')", "html_url": "https://github.com/psf/black/commit/138769aa27d6bd86507a0cd98d9a5bf8f63a8e99", "file_name": "tox.ini"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             if node.type not in WHITESPACE:\n <mask>                 self.current_line.append(node)\n <mask>         yield from super().visit_default(node)\n <mask> \n <mask>     def visit_atom(self, node: Node) -> Iterator[Line]:\n <mask>         # Always make parentheses invisible around a single node, because it should\n <mask>         # not be needed (except in the case of yield, where removing the parentheses\n <mask>         # produces a SyntaxError).\n <mask>         if (\n <mask>             len(node.children) == 3\n <mask>             and isinstance(node.children[0], Leaf)\n <mask>             and node.children[0].type == token.LPAR\n <mask>             and isinstance(node.children[2], Leaf)\n <mask>             and node.children[2].type == token.RPAR\n <mask>             and isinstance(node.children[1], Leaf)\n <mask>             and not (\n <mask>                 node.children[1].type == token.NAME\n <mask>                 and node.children[1].value == \"yield\"\n <mask>             )\n <mask>         ):\n <mask>             node.children[0].value = \"\"\n <mask>             node.children[2].value = \"\"\n <mask>         yield from super().visit_default(node)\n <mask> \n <mask>     def visit_factor(self, node: Node) -> Iterator[Line]:\n <mask>         \"\"\"Force parentheses between a unary op and a binary power:\n <mask> \n <mask>         -2 ** 8 -> -(2 ** 8)\n <mask>         \"\"\"\n </s> Back out #850 (#1079)\n\nFixes #1042 (and probably #1044 which looks like the same thing).\r\n\r\nThe issue with the \"obviously unnecessary\" parentheses that #850 removed is that sometimes they're necessary to help Black fit something in one line. I didn't see an obvious solution that still removes the parens #850 was intended to remove, so let's back out this change for now in the interest of unblocking a release.\r\n\r\nThis PR also adds a test adapted from the failing example in #1042, so that if we try to reapply the #850 change we don't break the same case again. </s> remove x = 3\n </s> add data = (\n    \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n).encode()\n\n\nasync def show_status():\n    while True:\n        try:\n            if report_host:\n                data = (\n                    f\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n                ).encode()\n        except Exception as e:\n            pass </s> remove print(1)\n </s> add  </s> add data = (\n    \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n).encode()\n\nasync def show_status():\n    while True:\n        try:\n            if report_host:\n                data = (\n                   f\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n               ).encode()\n        except Exception as e:\n            pass </s> remove -(SomeName)\n+SomeName\n </s> add  (SomeName) </s> remove SomeName\n </s> add (SomeName) </s> remove print((1))\n </s> add ", "html_url": "https://github.com/psf/black/commit/14b28c89c22659e1f935bc0ac22ee03d90bcc290", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> -{'2.7', '3.6', '3.7', '3.8', '3.9', '4.0' if gilectomy else '3.10'}\n <mask> +{\"2.7\": dead, \"3.7\": long_live or die_hard}\n <mask> +{\"2.7\", \"3.6\", \"3.7\", \"3.8\", \"3.9\", \"4.0\" if gilectomy else \"3.10\"}\n <mask>  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10 or A, 11 or B, 12 or C]\n <mask> -(SomeName)\n <mask> +SomeName\n <mask>  SomeName\n <mask>  (Good, Bad, Ugly)\n <mask>  (i for i in (1, 2, 3))\n <mask>  ((i ** 2) for i in (1, 2, 3))\n <mask> -((i ** 2) for i, _ in ((1, 'a'), (2, 'b'), (3, 'c')))\n </s> Back out #850 (#1079)\n\nFixes #1042 (and probably #1044 which looks like the same thing).\r\n\r\nThe issue with the \"obviously unnecessary\" parentheses that #850 removed is that sometimes they're necessary to help Black fit something in one line. I didn't see an obvious solution that still removes the parens #850 was intended to remove, so let's back out this change for now in the interest of unblocking a release.\r\n\r\nThis PR also adds a test adapted from the failing example in #1042, so that if we try to reapply the #850 change we don't break the same case again. </s> remove SomeName\n </s> add (SomeName) </s> remove     def visit_atom(self, node: Node) -> Iterator[Line]:\n        # Always make parentheses invisible around a single node, because it should\n        # not be needed (except in the case of yield, where removing the parentheses\n        # produces a SyntaxError).\n        if (\n            len(node.children) == 3\n            and isinstance(node.children[0], Leaf)\n            and node.children[0].type == token.LPAR\n            and isinstance(node.children[2], Leaf)\n            and node.children[2].type == token.RPAR\n            and isinstance(node.children[1], Leaf)\n            and not (\n                node.children[1].type == token.NAME\n                and node.children[1].value == \"yield\"\n            )\n        ):\n            node.children[0].value = \"\"\n            node.children[2].value = \"\"\n        yield from super().visit_default(node)\n\n </s> add  </s> add data = (\n    \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n).encode()\n\nasync def show_status():\n    while True:\n        try:\n            if report_host:\n                data = (\n                   f\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n               ).encode()\n        except Exception as e:\n            pass </s> remove x = 3\n </s> add data = (\n    \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n).encode()\n\n\nasync def show_status():\n    while True:\n        try:\n            if report_host:\n                data = (\n                    f\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n                ).encode()\n        except Exception as e:\n            pass </s> remove print(1)\n </s> add  </s> remove (x) = (3)\n </s> add ", "html_url": "https://github.com/psf/black/commit/14b28c89c22659e1f935bc0ac22ee03d90bcc290", "file_name": "tests/data/expression.diff"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> (str or None) if (sys.version_info[0] > (3,)) else (str or bytes or None)\n <mask> {\"2.7\": dead, \"3.7\": long_live or die_hard}\n <mask> {\"2.7\", \"3.6\", \"3.7\", \"3.8\", \"3.9\", \"4.0\" if gilectomy else \"3.10\"}\n <mask> [1, 2, 3, 4, 5, 6, 7, 8, 9, 10 or A, 11 or B, 12 or C]\n <mask> SomeName\n <mask> SomeName\n <mask> (Good, Bad, Ugly)\n <mask> (i for i in (1, 2, 3))\n <mask> ((i ** 2) for i in (1, 2, 3))\n <mask> ((i ** 2) for i, _ in ((1, \"a\"), (2, \"b\"), (3, \"c\")))\n </s> Back out #850 (#1079)\n\nFixes #1042 (and probably #1044 which looks like the same thing).\r\n\r\nThe issue with the \"obviously unnecessary\" parentheses that #850 removed is that sometimes they're necessary to help Black fit something in one line. I didn't see an obvious solution that still removes the parens #850 was intended to remove, so let's back out this change for now in the interest of unblocking a release.\r\n\r\nThis PR also adds a test adapted from the failing example in #1042, so that if we try to reapply the #850 change we don't break the same case again. </s> remove -(SomeName)\n+SomeName\n </s> add  (SomeName) </s> remove     def visit_atom(self, node: Node) -> Iterator[Line]:\n        # Always make parentheses invisible around a single node, because it should\n        # not be needed (except in the case of yield, where removing the parentheses\n        # produces a SyntaxError).\n        if (\n            len(node.children) == 3\n            and isinstance(node.children[0], Leaf)\n            and node.children[0].type == token.LPAR\n            and isinstance(node.children[2], Leaf)\n            and node.children[2].type == token.RPAR\n            and isinstance(node.children[1], Leaf)\n            and not (\n                node.children[1].type == token.NAME\n                and node.children[1].value == \"yield\"\n            )\n        ):\n            node.children[0].value = \"\"\n            node.children[2].value = \"\"\n        yield from super().visit_default(node)\n\n </s> add  </s> add data = (\n    \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n).encode()\n\nasync def show_status():\n    while True:\n        try:\n            if report_host:\n                data = (\n                   f\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n               ).encode()\n        except Exception as e:\n            pass </s> remove x = 3\n </s> add data = (\n    \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n).encode()\n\n\nasync def show_status():\n    while True:\n        try:\n            if report_host:\n                data = (\n                    f\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n                ).encode()\n        except Exception as e:\n            pass </s> remove print(1)\n </s> add  </s> remove (x) = (3)\n </s> add ", "html_url": "https://github.com/psf/black/commit/14b28c89c22659e1f935bc0ac22ee03d90bcc290", "file_name": "tests/data/expression.py"}
{"docstring_tokens": "replace keep keep replace keep keep keep keep keep", "code_tokens": " <mask> print((1))\n <mask> x = (1)\n <mask> x = (1.2)\n <mask> (x) = (3)\n <mask> \n <mask> \n <mask> def example():\n <mask>     return ((\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"))\n <mask> \n </s> Back out #850 (#1079)\n\nFixes #1042 (and probably #1044 which looks like the same thing).\r\n\r\nThe issue with the \"obviously unnecessary\" parentheses that #850 removed is that sometimes they're necessary to help Black fit something in one line. I didn't see an obvious solution that still removes the parens #850 was intended to remove, so let's back out this change for now in the interest of unblocking a release.\r\n\r\nThis PR also adds a test adapted from the failing example in #1042, so that if we try to reapply the #850 change we don't break the same case again. </s> add data = (\n    \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n).encode()\n\nasync def show_status():\n    while True:\n        try:\n            if report_host:\n                data = (\n                   f\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n               ).encode()\n        except Exception as e:\n            pass </s> remove x = 3\n </s> add data = (\n    \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n).encode()\n\n\nasync def show_status():\n    while True:\n        try:\n            if report_host:\n                data = (\n                    f\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n                ).encode()\n        except Exception as e:\n            pass </s> remove print(1)\n </s> add  </s> remove     def visit_atom(self, node: Node) -> Iterator[Line]:\n        # Always make parentheses invisible around a single node, because it should\n        # not be needed (except in the case of yield, where removing the parentheses\n        # produces a SyntaxError).\n        if (\n            len(node.children) == 3\n            and isinstance(node.children[0], Leaf)\n            and node.children[0].type == token.LPAR\n            and isinstance(node.children[2], Leaf)\n            and node.children[2].type == token.RPAR\n            and isinstance(node.children[1], Leaf)\n            and not (\n                node.children[1].type == token.NAME\n                and node.children[1].value == \"yield\"\n            )\n        ):\n            node.children[0].value = \"\"\n            node.children[2].value = \"\"\n        yield from super().visit_default(node)\n\n </s> add  </s> remove SomeName\n </s> add (SomeName)", "html_url": "https://github.com/psf/black/commit/14b28c89c22659e1f935bc0ac22ee03d90bcc290", "file_name": "tests/data/remove_parens.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> x = (1)\n <mask> x = (1.2)\n <mask> \n <mask> \n <mask> def example():\n <mask>     return ((\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"))\n <mask> \n <mask> \n </s> Back out #850 (#1079)\n\nFixes #1042 (and probably #1044 which looks like the same thing).\r\n\r\nThe issue with the \"obviously unnecessary\" parentheses that #850 removed is that sometimes they're necessary to help Black fit something in one line. I didn't see an obvious solution that still removes the parens #850 was intended to remove, so let's back out this change for now in the interest of unblocking a release.\r\n\r\nThis PR also adds a test adapted from the failing example in #1042, so that if we try to reapply the #850 change we don't break the same case again. </s> remove (x) = (3)\n </s> add  </s> remove print((1))\n </s> add  </s> remove x = 3\n </s> add data = (\n    \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n).encode()\n\n\nasync def show_status():\n    while True:\n        try:\n            if report_host:\n                data = (\n                    f\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n                ).encode()\n        except Exception as e:\n            pass </s> remove print(1)\n </s> add  </s> remove     def visit_atom(self, node: Node) -> Iterator[Line]:\n        # Always make parentheses invisible around a single node, because it should\n        # not be needed (except in the case of yield, where removing the parentheses\n        # produces a SyntaxError).\n        if (\n            len(node.children) == 3\n            and isinstance(node.children[0], Leaf)\n            and node.children[0].type == token.LPAR\n            and isinstance(node.children[2], Leaf)\n            and node.children[2].type == token.RPAR\n            and isinstance(node.children[1], Leaf)\n            and not (\n                node.children[1].type == token.NAME\n                and node.children[1].value == \"yield\"\n            )\n        ):\n            node.children[0].value = \"\"\n            node.children[2].value = \"\"\n        yield from super().visit_default(node)\n\n </s> add  </s> remove SomeName\n </s> add (SomeName)", "html_url": "https://github.com/psf/black/commit/14b28c89c22659e1f935bc0ac22ee03d90bcc290", "file_name": "tests/data/remove_parens.py"}
{"docstring_tokens": "keep replace keep keep replace keep keep keep", "code_tokens": " <mask> # output\n <mask> print(1)\n <mask> x = 1\n <mask> x = 1.2\n <mask> x = 3\n <mask> \n <mask> \n <mask> def example():\n </s> Back out #850 (#1079)\n\nFixes #1042 (and probably #1044 which looks like the same thing).\r\n\r\nThe issue with the \"obviously unnecessary\" parentheses that #850 removed is that sometimes they're necessary to help Black fit something in one line. I didn't see an obvious solution that still removes the parens #850 was intended to remove, so let's back out this change for now in the interest of unblocking a release.\r\n\r\nThis PR also adds a test adapted from the failing example in #1042, so that if we try to reapply the #850 change we don't break the same case again. </s> remove (x) = (3)\n </s> add  </s> add data = (\n    \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n).encode()\n\nasync def show_status():\n    while True:\n        try:\n            if report_host:\n                data = (\n                   f\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n               ).encode()\n        except Exception as e:\n            pass </s> remove print((1))\n </s> add  </s> remove     def visit_atom(self, node: Node) -> Iterator[Line]:\n        # Always make parentheses invisible around a single node, because it should\n        # not be needed (except in the case of yield, where removing the parentheses\n        # produces a SyntaxError).\n        if (\n            len(node.children) == 3\n            and isinstance(node.children[0], Leaf)\n            and node.children[0].type == token.LPAR\n            and isinstance(node.children[2], Leaf)\n            and node.children[2].type == token.RPAR\n            and isinstance(node.children[1], Leaf)\n            and not (\n                node.children[1].type == token.NAME\n                and node.children[1].value == \"yield\"\n            )\n        ):\n            node.children[0].value = \"\"\n            node.children[2].value = \"\"\n        yield from super().visit_default(node)\n\n </s> add  </s> remove SomeName\n </s> add (SomeName)", "html_url": "https://github.com/psf/black/commit/14b28c89c22659e1f935bc0ac22ee03d90bcc290", "file_name": "tests/data/remove_parens.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>     If `write_back` is True, write reformatted code back to stdout.\n <mask>     `line_length` and `fast` options are passed to :func:`format_file_contents`.\n <mask>     \"\"\"\n <mask> \n <mask>     with tokenize.open(src) as src_buffer:\n <mask>         src_contents = src_buffer.read()\n <mask>     try:\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove             src_contents, line_length=line_length, fast=fast\n </s> add             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> remove     src_contents: str, line_length: int, fast: bool\n </s> add     src_contents: str, *, line_length: int, fast: bool, is_pyi: bool = False </s> add     is_pyi: bool = False </s> remove def format_str(src_contents: str, line_length: int) -> FileContent:\n </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> add     is_pyi: bool = False </s> remove     dst_contents = format_str(src_contents, line_length=line_length)\n </s> add     dst_contents = format_str(src_contents, line_length=line_length, is_pyi=is_pyi)", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     with tokenize.open(src) as src_buffer:\n <mask>         src_contents = src_buffer.read()\n <mask>     try:\n <mask>         dst_contents = format_file_contents(\n <mask>             src_contents, line_length=line_length, fast=fast\n <mask>         )\n <mask>     except NothingChanged:\n <mask>         return False\n <mask> \n <mask>     if write_back == write_back.YES:\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> add     is_pyi = src.suffix == \".pyi\" </s> remove     dst_contents = format_str(src_contents, line_length=line_length)\n </s> add     dst_contents = format_str(src_contents, line_length=line_length, is_pyi=is_pyi) </s> remove         assert_stable(src_contents, dst_contents, line_length=line_length)\n </s> add         assert_stable(\n            src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n        ) </s> remove     if not name.endswith((\".py\", \".out\", \".diff\")):\n </s> add     if not name.endswith((\".py\", \".pyi\", \".out\", \".diff\")): </s> add     @property\n    def is_trivial_class(self) -> bool:\n        \"\"\"Is this line a class definition with a body consisting only of \"...\"?\"\"\"\n        return (\n            self.is_class\n            and self.leaves[-3:] == [Leaf(token.DOT, \".\") for _ in range(3)]\n        )\n </s> remove             newlines = 2\n            if current_line.depth:\n </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             sys.stdout.write(diff(src, dst, src_name, dst_name))\n <mask> \n <mask> \n <mask> def format_file_contents(\n <mask>     src_contents: str, line_length: int, fast: bool\n <mask> ) -> FileContent:\n <mask>     \"\"\"Reformat contents a file and return new contents.\n <mask> \n <mask>     If `fast` is False, additionally confirm that the reformatted code is\n <mask>     valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove def format_str(src_contents: str, line_length: int) -> FileContent:\n </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> remove         assert_stable(src_contents, dst_contents, line_length=line_length)\n </s> add         assert_stable(\n            src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n        ) </s> add     is_pyi = src.suffix == \".pyi\" </s> add     is_pyi: bool = False </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None:\n </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> remove     newdst = format_str(dst, line_length=line_length)\n </s> add     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi)", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     if src_contents.strip() == \"\":\n <mask>         raise NothingChanged\n <mask> \n <mask>     dst_contents = format_str(src_contents, line_length=line_length)\n <mask>     if src_contents == dst_contents:\n <mask>         raise NothingChanged\n <mask> \n <mask>     if not fast:\n <mask>         assert_equivalent(src_contents, dst_contents)\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove         assert_stable(src_contents, dst_contents, line_length=line_length)\n </s> add         assert_stable(\n            src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n        ) </s> remove             src_contents, line_length=line_length, fast=fast\n </s> add             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> add     is_pyi = src.suffix == \".pyi\" </s> remove             newlines = 2\n            if current_line.depth:\n </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines: </s> remove             max_allowed = 2\n </s> add             max_allowed = 1 if self.is_pyi else 2 </s> remove             before = 1 if depth else 2\n </s> add             if self.is_pyi:\n                before = 0 if depth else 1\n            else:\n                before = 1 if depth else 2", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask>     if not fast:\n <mask>         assert_equivalent(src_contents, dst_contents)\n <mask>         assert_stable(src_contents, dst_contents, line_length=line_length)\n <mask>     return dst_contents\n <mask> \n <mask> \n <mask> def format_str(src_contents: str, line_length: int) -> FileContent:\n <mask>     \"\"\"Reformat a string and return new contents.\n <mask> \n <mask>     `line_length` determines how many characters per line are allowed.\n <mask>     \"\"\"\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove     src_contents: str, line_length: int, fast: bool\n </s> add     src_contents: str, *, line_length: int, fast: bool, is_pyi: bool = False </s> remove     dst_contents = format_str(src_contents, line_length=line_length)\n </s> add     dst_contents = format_str(src_contents, line_length=line_length, is_pyi=is_pyi) </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None:\n </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> remove     newdst = format_str(dst, line_length=line_length)\n </s> add     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi) </s> add     @property\n    def is_trivial_class(self) -> bool:\n        \"\"\"Is this line a class definition with a body consisting only of \"...\"?\"\"\"\n        return (\n            self.is_class\n            and self.leaves[-3:] == [Leaf(token.DOT, \".\") for _ in range(3)]\n        )\n", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     dst_contents = \"\"\n <mask>     future_imports = get_future_imports(src_node)\n <mask>     py36 = is_python36(src_node)\n <mask>     lines = LineGenerator(\n <mask>         remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n <mask>     )\n <mask>     empty_line = Line()\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n    elt = EmptyLineTracker()\n </s> add     lines = LineGenerator(\n        remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n    ) </s> remove             src_contents, line_length=line_length, fast=fast\n </s> add             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> remove             before = 1 if depth else 2\n </s> add             if self.is_pyi:\n                before = 0 if depth else 1\n            else:\n                before = 1 if depth else 2 </s> add     is_pyi: bool = False </s> remove     if not name.endswith((\".py\", \".out\", \".diff\")):\n </s> add     if not name.endswith((\".py\", \".pyi\", \".out\", \".diff\")): </s> remove             newlines = 2\n            if current_line.depth:\n </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     src_node = lib2to3_parse(src_contents)\n <mask>     dst_contents = \"\"\n <mask>     future_imports = get_future_imports(src_node)\n <mask>     py36 = is_python36(src_node)\n <mask>     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n <mask>     elt = EmptyLineTracker()\n <mask>     empty_line = Line()\n <mask>     after = 0\n <mask>     for current_line in lines.visit(src_node):\n <mask>         for _ in range(after):\n <mask>             dst_contents += str(empty_line)\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> add     elt = EmptyLineTracker(is_pyi=is_pyi) </s> add     is_pyi: bool = False </s> remove             before = 1 if depth else 2\n </s> add             if self.is_pyi:\n                before = 0 if depth else 1\n            else:\n                before = 1 if depth else 2 </s> remove def format_str(src_contents: str, line_length: int) -> FileContent:\n </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> remove             newlines = 2\n            if current_line.depth:\n </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines: </s> remove     if not name.endswith((\".py\", \".out\", \".diff\")):\n </s> add     if not name.endswith((\".py\", \".pyi\", \".out\", \".diff\")):", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>             and self.leaves[0].value == \"class\"\n <mask>         )\n <mask> \n <mask>     @property\n <mask>     def is_def(self) -> bool:\n <mask>         \"\"\"Is this a function definition? (Also returns True for async defs.)\"\"\"\n <mask>         try:\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove             src_contents, line_length=line_length, fast=fast\n </s> add             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> remove def format_str(src_contents: str, line_length: int) -> FileContent:\n </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> add     is_pyi = src.suffix == \".pyi\" </s> remove         assert_stable(src_contents, dst_contents, line_length=line_length)\n </s> add         assert_stable(\n            src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n        ) </s> remove     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n    elt = EmptyLineTracker()\n </s> add     lines = LineGenerator(\n        remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n    ) </s> remove     src_contents: str, line_length: int, fast: bool\n </s> add     src_contents: str, *, line_length: int, fast: bool, is_pyi: bool = False", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     are consumed by `maybe_empty_lines()` and included in the computation.\n <mask>     \"\"\"\n <mask>     previous_line: Optional[Line] = None\n <mask>     previous_after: int = 0\n <mask>     previous_defs: List[int] = Factory(list)\n <mask> \n <mask>     def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> add     is_pyi: bool = False </s> remove             max_allowed = 2\n </s> add             max_allowed = 1 if self.is_pyi else 2 </s> remove def format_str(src_contents: str, line_length: int) -> FileContent:\n </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None:\n </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> remove     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n    elt = EmptyLineTracker()\n </s> add     lines = LineGenerator(\n        remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n    ) </s> remove             newlines = 2\n            if current_line.depth:\n </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:\n <mask>         max_allowed = 1\n <mask>         if current_line.depth == 0:\n <mask>             max_allowed = 2\n <mask>         if current_line.leaves:\n <mask>             # Consume the first leaf's extra newlines.\n <mask>             first_leaf = current_line.leaves[0]\n <mask>             before = first_leaf.prefix.count(\"\\n\")\n <mask>             before = min(before, max_allowed)\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove             before = 1 if depth else 2\n </s> add             if self.is_pyi:\n                before = 0 if depth else 1\n            else:\n                before = 1 if depth else 2 </s> remove             newlines = 2\n            if current_line.depth:\n </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines: </s> add     is_pyi: bool = False </s> add     is_pyi: bool = False </s> remove     newdst = format_str(dst, line_length=line_length)\n </s> add     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi) </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None:\n </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             before = 0\n <mask>         depth = current_line.depth\n <mask>         while self.previous_defs and self.previous_defs[-1] >= depth:\n <mask>             self.previous_defs.pop()\n <mask>             before = 1 if depth else 2\n <mask>         is_decorator = current_line.is_decorator\n <mask>         if is_decorator or current_line.is_def or current_line.is_class:\n <mask>             if not is_decorator:\n <mask>                 self.previous_defs.append(depth)\n <mask>             if self.previous_line is None:\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove             newlines = 2\n            if current_line.depth:\n </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines: </s> remove             max_allowed = 2\n </s> add             max_allowed = 1 if self.is_pyi else 2 </s> remove     dst_contents = format_str(src_contents, line_length=line_length)\n </s> add     dst_contents = format_str(src_contents, line_length=line_length, is_pyi=is_pyi) </s> remove     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n    elt = EmptyLineTracker()\n </s> add     lines = LineGenerator(\n        remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n    ) </s> remove     if not name.endswith((\".py\", \".out\", \".diff\")):\n </s> add     if not name.endswith((\".py\", \".pyi\", \".out\", \".diff\")): </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None:\n </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 and before == 0\n <mask>             ):\n <mask>                 return 0, 0\n <mask> \n <mask>             newlines = 2\n <mask>             if current_line.depth:\n <mask>                 newlines -= 1\n <mask>             return newlines, 0\n <mask> \n <mask>         if (\n <mask>             self.previous_line\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove             before = 1 if depth else 2\n </s> add             if self.is_pyi:\n                before = 0 if depth else 1\n            else:\n                before = 1 if depth else 2 </s> remove             max_allowed = 2\n </s> add             max_allowed = 1 if self.is_pyi else 2 </s> add     is_pyi: bool = False </s> remove     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n    elt = EmptyLineTracker()\n </s> add     lines = LineGenerator(\n        remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n    ) </s> remove             src_contents, line_length=line_length, fast=fast\n </s> add             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> remove             yield from self.line()\n </s> add             if (\n                not self.is_pyi\n                or not node.parent\n                or not self.is_trivial_suite(node.parent)\n            ):\n                yield from self.line()", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>     Note: destroys the tree it's visiting by mutating prefixes of its leaves\n <mask>     in ways that will no longer stringify to valid Python code on the tree.\n <mask>     \"\"\"\n <mask>     current_line: Line = Factory(Line)\n <mask>     remove_u_prefix: bool = False\n <mask> \n <mask>     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]:\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> add     is_pyi: bool = False </s> remove     src_contents: str, line_length: int, fast: bool\n </s> add     src_contents: str, *, line_length: int, fast: bool, is_pyi: bool = False </s> remove             max_allowed = 2\n </s> add             max_allowed = 1 if self.is_pyi else 2 </s> add     is_pyi = src.suffix == \".pyi\" </s> remove def format_str(src_contents: str, line_length: int) -> FileContent:\n </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None:\n </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     def visit_simple_stmt(self, node: Node) -> Iterator[Line]:\n <mask>         \"\"\"Visit a statement without nested statements.\"\"\"\n <mask>         is_suite_like = node.parent and node.parent.type in STATEMENT\n <mask>         if is_suite_like:\n <mask>             yield from self.line(+1)\n <mask>             yield from self.visit_default(node)\n <mask>             yield from self.line(-1)\n <mask> \n <mask>         else:\n <mask>             yield from self.line()\n <mask>             yield from self.visit_default(node)\n <mask> \n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove             yield from self.line()\n </s> add             if (\n                not self.is_pyi\n                or not node.parent\n                or not self.is_trivial_suite(node.parent)\n            ):\n                yield from self.line() </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None:\n </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> remove             newlines = 2\n            if current_line.depth:\n </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines: </s> add     is_pyi: bool = False </s> add     @property\n    def is_trivial_class(self) -> bool:\n        \"\"\"Is this line a class definition with a body consisting only of \"...\"?\"\"\"\n        return (\n            self.is_class\n            and self.leaves[-3:] == [Leaf(token.DOT, \".\") for _ in range(3)]\n        )\n </s> remove def format_str(src_contents: str, line_length: int) -> FileContent:\n </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             yield from self.visit_default(node)\n <mask>             yield from self.line(-1)\n <mask> \n <mask>         else:\n <mask>             yield from self.line()\n <mask>             yield from self.visit_default(node)\n <mask> \n <mask>     def visit_async_stmt(self, node: Node) -> Iterator[Line]:\n <mask>         \"\"\"Visit `async def`, `async for`, `async with`.\"\"\"\n <mask>         yield from self.line()\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove             yield from self.line(+1)\n            yield from self.visit_default(node)\n            yield from self.line(-1)\n </s> add             if self.is_pyi and self.is_trivial_body(node):\n                yield from self.visit_default(node)\n            else:\n                yield from self.line(+1)\n                yield from self.visit_default(node)\n                yield from self.line(-1) </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None:\n </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> add     is_pyi: bool = False </s> remove             newlines = 2\n            if current_line.depth:\n </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines: </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_stub(self) -> None:\n        source, expected = read_data(\"stub.pyi\")\n        actual = fs(source, is_pyi=True)\n        self.assertFormatEqual(expected, actual)\n        black.assert_stable(source, actual, line_length=ll, is_pyi=True)\n </s> remove def format_str(src_contents: str, line_length: int) -> FileContent:\n </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             break\n <mask>     return imports\n <mask> \n <mask> \n <mask> PYTHON_EXTENSIONS = {\".py\"}\n <mask> BLACKLISTED_DIRECTORIES = {\n <mask>     \"build\", \"buck-out\", \"dist\", \"_build\", \".git\", \".hg\", \".mypy_cache\", \".tox\", \".venv\"\n <mask> }\n <mask> \n <mask> \n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove             newlines = 2\n            if current_line.depth:\n </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines: </s> remove             src_contents, line_length=line_length, fast=fast\n </s> add             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> remove def format_str(src_contents: str, line_length: int) -> FileContent:\n </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> add     elt = EmptyLineTracker(is_pyi=is_pyi) </s> remove     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n    elt = EmptyLineTracker()\n </s> add     lines = LineGenerator(\n        remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n    ) </s> remove             max_allowed = 2\n </s> add             max_allowed = 1 if self.is_pyi else 2", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             f\"This diff might be helpful: {log}\"\n <mask>         ) from None\n <mask> \n <mask> \n <mask> def assert_stable(src: str, dst: str, line_length: int) -> None:\n <mask>     \"\"\"Raise AssertionError if `dst` reformats differently the second time.\"\"\"\n <mask>     newdst = format_str(dst, line_length=line_length)\n <mask>     if dst != newdst:\n <mask>         log = dump_to_file(\n <mask>             diff(src, dst, \"source\", \"first pass\"),\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove     newdst = format_str(dst, line_length=line_length)\n </s> add     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi) </s> remove def format_str(src_contents: str, line_length: int) -> FileContent:\n </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> remove         assert_stable(src_contents, dst_contents, line_length=line_length)\n </s> add         assert_stable(\n            src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n        ) </s> remove     src_contents: str, line_length: int, fast: bool\n </s> add     src_contents: str, *, line_length: int, fast: bool, is_pyi: bool = False </s> remove             yield from self.line(+1)\n            yield from self.visit_default(node)\n            yield from self.line(-1)\n </s> add             if self.is_pyi and self.is_trivial_body(node):\n                yield from self.visit_default(node)\n            else:\n                yield from self.line(+1)\n                yield from self.visit_default(node)\n                yield from self.line(-1) </s> add     is_pyi: bool = False", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def assert_stable(src: str, dst: str, line_length: int) -> None:\n <mask>     \"\"\"Raise AssertionError if `dst` reformats differently the second time.\"\"\"\n <mask>     newdst = format_str(dst, line_length=line_length)\n <mask>     if dst != newdst:\n <mask>         log = dump_to_file(\n <mask>             diff(src, dst, \"source\", \"first pass\"),\n <mask>             diff(dst, newdst, \"first pass\", \"second pass\"),\n <mask>         )\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None:\n </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> remove def format_str(src_contents: str, line_length: int) -> FileContent:\n </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> remove         assert_stable(src_contents, dst_contents, line_length=line_length)\n </s> add         assert_stable(\n            src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n        ) </s> remove     src_contents: str, line_length: int, fast: bool\n </s> add     src_contents: str, *, line_length: int, fast: bool, is_pyi: bool = False </s> remove             max_allowed = 2\n </s> add             max_allowed = 1 if self.is_pyi else 2 </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_stub(self) -> None:\n        source, expected = read_data(\"stub.pyi\")\n        actual = fs(source, is_pyi=True)\n        self.assertFormatEqual(expected, actual)\n        black.assert_stable(source, actual, line_length=ll, is_pyi=True)\n", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def read_data(name: str) -> Tuple[str, str]:\n <mask>     \"\"\"read_data('test_name') -> 'input', 'output'\"\"\"\n <mask>     if not name.endswith((\".py\", \".out\", \".diff\")):\n <mask>         name += \".py\"\n <mask>     _input: List[str] = []\n <mask>     _output: List[str] = []\n <mask>     with open(THIS_DIR / name, \"r\", encoding=\"utf8\") as test:\n <mask>         lines = test.readlines()\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n    elt = EmptyLineTracker()\n </s> add     lines = LineGenerator(\n        remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n    ) </s> remove             src_contents, line_length=line_length, fast=fast\n </s> add             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> remove             max_allowed = 2\n </s> add             max_allowed = 1 if self.is_pyi else 2 </s> add     is_pyi = src.suffix == \".pyi\" </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_stub(self) -> None:\n        source, expected = read_data(\"stub.pyi\")\n        actual = fs(source, is_pyi=True)\n        self.assertFormatEqual(expected, actual)\n        black.assert_stable(source, actual, line_length=ll, is_pyi=True)\n </s> add     elt = EmptyLineTracker(is_pyi=is_pyi)", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_stable(source, actual, line_length=ll)\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_fmtonoff(self) -> None:\n <mask>         source, expected = read_data(\"fmtonoff\")\n <mask>         actual = fs(source)\n </s> Add support for pyi files (#210)\n\nFixes #207 </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None:\n </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> remove     newdst = format_str(dst, line_length=line_length)\n </s> add     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi) </s> add     is_pyi: bool = False </s> remove             max_allowed = 2\n </s> add             max_allowed = 1 if self.is_pyi else 2 </s> remove             before = 1 if depth else 2\n </s> add             if self.is_pyi:\n                before = 0 if depth else 1\n            else:\n                before = 1 if depth else 2 </s> remove     if not name.endswith((\".py\", \".out\", \".diff\")):\n </s> add     if not name.endswith((\".py\", \".pyi\", \".out\", \".diff\")):", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             check_lpar = True\n <mask> \n <mask>         if check_lpar:\n <mask>             if child.type == syms.atom:\n <mask>                 if maybe_make_parens_invisible_in_atom(child, parent=node):\n <mask>                     wrap_in_parentheses(node, child, visible=False)\n <mask>             elif is_one_tuple(child):\n <mask>                 wrap_in_parentheses(node, child, visible=True)\n <mask>             elif node.type == syms.import_from:\n <mask>                 # \"import from\" nodes store parentheses directly as part of\n </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove         maybe_make_parens_invisible_in_atom(middle, parent=parent)\n </s> add         maybe_make_parens_invisible_in_atom(middle, parent=parent, preview=preview) </s> remove         or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY\n </s> add         or (max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY and for_stmt_check) </s> remove def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:\n </s> add def maybe_make_parens_invisible_in_atom(\n    node: LN,\n    parent: LN,\n    preview: bool = False,\n) -> bool: </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         check_lpar = isinstance(child, Leaf) and child.value in parens_after\n <mask> \n <mask> \n <mask> def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:\n <mask>     \"\"\"If it's safe, make the parens in the atom `node` invisible, recursively.\n <mask>     Additionally, remove repeated, adjacent invisible parens from the atom `node`\n <mask>     as they are redundant.\n <mask> \n <mask>     Returns whether the node should itself be wrapped in invisible parentheses.\n </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True </s> remove         maybe_make_parens_invisible_in_atom(middle, parent=parent)\n </s> add         maybe_make_parens_invisible_in_atom(middle, parent=parent, preview=preview) </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove     for (xxx_xxxx, _xxx_xxx, _xxx_xxxxx, xxx_xxxx) in xxxx:\n </s> add     for xxx_xxxx, _xxx_xxx, _xxx_xxxxx, xxx_xxxx in xxxx: </s> remove                 if maybe_make_parens_invisible_in_atom(child, parent=node):\n </s> add                 if maybe_make_parens_invisible_in_atom(\n                    child,\n                    parent=node,\n                    preview=preview,\n                ):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     Returns whether the node should itself be wrapped in invisible parentheses.\n <mask> \n <mask>     \"\"\"\n <mask> \n <mask>     if (\n <mask>         node.type != syms.atom\n <mask>         or is_empty_tuple(node)\n <mask>         or is_one_tuple(node)\n </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove         or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY\n </s> add         or (max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY and for_stmt_check) </s> remove def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:\n </s> add def maybe_make_parens_invisible_in_atom(\n    node: LN,\n    parent: LN,\n    preview: bool = False,\n) -> bool: </s> remove     for (xxx_xxxx, _xxx_xxx, _xxx_xxxxx, xxx_xxxx) in xxxx:\n </s> add     for xxx_xxxx, _xxx_xxx, _xxx_xxxxx, xxx_xxxx in xxxx: </s> remove         maybe_make_parens_invisible_in_atom(middle, parent=parent)\n </s> add         maybe_make_parens_invisible_in_atom(middle, parent=parent, preview=preview) </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove         for (idx, leaf) in enumerate(LL):\n </s> add         for idx, leaf in enumerate(LL):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         node.type != syms.atom\n <mask>         or is_empty_tuple(node)\n <mask>         or is_one_tuple(node)\n <mask>         or (is_yield(node) and parent.type != syms.expr_stmt)\n <mask>         or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY\n <mask>     ):\n <mask>         return False\n <mask> \n <mask>     if is_walrus_assignment(node):\n <mask>         if parent.type in [\n </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove         for (idx, leaf) in enumerate(LL):\n </s> add         for idx, leaf in enumerate(LL): </s> remove     for (xxx_xxxx, _xxx_xxx, _xxx_xxxxx, xxx_xxxx) in xxxx:\n </s> add     for xxx_xxxx, _xxx_xxx, _xxx_xxxxx, xxx_xxxx in xxxx: </s> remove                 if maybe_make_parens_invisible_in_atom(child, parent=node):\n </s> add                 if maybe_make_parens_invisible_in_atom(\n                    child,\n                    parent=node,\n                    preview=preview,\n                ): </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         middle = node.children[1]\n <mask>         # make parentheses invisible\n <mask>         first.value = \"\"\n <mask>         last.value = \"\"\n <mask>         maybe_make_parens_invisible_in_atom(middle, parent=parent)\n <mask> \n <mask>         if is_atom_with_invisible_parens(middle):\n <mask>             # Strip the invisible parens from `middle` by replacing\n <mask>             # it with the child in-between the invisible parens\n <mask>             middle.replace(middle.children[1])\n </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:\n </s> add def maybe_make_parens_invisible_in_atom(\n    node: LN,\n    parent: LN,\n    preview: bool = False,\n) -> bool: </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove                 if maybe_make_parens_invisible_in_atom(child, parent=node):\n </s> add                 if maybe_make_parens_invisible_in_atom(\n                    child,\n                    parent=node,\n                    preview=preview,\n                ): </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>     string_processing = auto()\n <mask>     one_element_subscript = auto()\n <mask> \n <mask> \n <mask> class Deprecated(UserWarning):\n </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove         maybe_make_parens_invisible_in_atom(middle, parent=parent)\n </s> add         maybe_make_parens_invisible_in_atom(middle, parent=parent, preview=preview) </s> add     \"remove_for_brackets\", </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL): </s> remove         for (idx, leaf) in enumerate(LL):\n </s> add         for idx, leaf in enumerate(LL): </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/mode.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         LL = line.leaves\n <mask> \n <mask>         is_valid_index = is_valid_index_factory(LL)\n <mask> \n <mask>         for (i, leaf) in enumerate(LL):\n <mask>             if (\n <mask>                 leaf.type == token.STRING\n <mask>                 and is_valid_index(i + 1)\n <mask>                 and LL[i + 1].type == token.STRING\n <mask>             ):\n </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove         for (idx, leaf) in enumerate(LL):\n </s> add         for idx, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             replace_child(atom_node, string_leaf)\n <mask> \n <mask>         # Build the final line ('new_line') that this method will later return.\n <mask>         new_line = line.clone()\n <mask>         for (i, leaf) in enumerate(LL):\n <mask>             if i == string_idx:\n <mask>                 new_line.append(string_leaf)\n <mask> \n <mask>             if string_idx <= i < string_idx + num_of_strings:\n <mask>                 for comment_leaf in line.comments_after(LL[i]):\n </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL): </s> remove         for (idx, leaf) in enumerate(LL):\n </s> add         for idx, leaf in enumerate(LL): </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         LL = line.leaves\n <mask> \n <mask>         is_valid_index = is_valid_index_factory(LL)\n <mask> \n <mask>         for (idx, leaf) in enumerate(LL):\n <mask>             # Should be a string...\n <mask>             if leaf.type != token.STRING:\n <mask>                 continue\n <mask> \n <mask>             # If this is a \"pointless\" string...\n </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL): </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # contains the \"assert\" keyword...\n <mask>         if parent_type(LL[0]) == syms.assert_stmt and LL[0].value == \"assert\":\n <mask>             is_valid_index = is_valid_index_factory(LL)\n <mask> \n <mask>             for (i, leaf) in enumerate(LL):\n <mask>                 # We MUST find a comma...\n <mask>                 if leaf.type == token.COMMA:\n <mask>                     idx = i + 2 if is_empty_par(LL[i + 1]) else i + 1\n <mask> \n <mask>                     # That comma MUST be followed by a string...\n </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove         for (idx, leaf) in enumerate(LL):\n </s> add         for idx, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL): </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             and LL[0].type == token.NAME\n <mask>         ):\n <mask>             is_valid_index = is_valid_index_factory(LL)\n <mask> \n <mask>             for (i, leaf) in enumerate(LL):\n <mask>                 # We MUST find either an '=' or '+=' symbol...\n <mask>                 if leaf.type in [token.EQUAL, token.PLUSEQUAL]:\n <mask>                     idx = i + 2 if is_empty_par(LL[i + 1]) else i + 1\n <mask> \n <mask>                     # That symbol MUST be followed by a string...\n </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL): </s> remove         for (idx, leaf) in enumerate(LL):\n </s> add         for idx, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL): </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # If this line is apart of a dictionary key assignment...\n <mask>         if syms.dictsetmaker in [parent_type(LL[0]), parent_type(LL[0].parent)]:\n <mask>             is_valid_index = is_valid_index_factory(LL)\n <mask> \n <mask>             for (i, leaf) in enumerate(LL):\n <mask>                 # We MUST find a colon...\n <mask>                 if leaf.type == token.COLON:\n <mask>                     idx = i + 2 if is_empty_par(LL[i + 1]) else i + 1\n <mask> \n <mask>                     # That colon MUST be followed by a string...\n </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove         for (idx, leaf) in enumerate(LL):\n </s> add         for idx, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL): </s> remove                 if maybe_make_parens_invisible_in_atom(child, parent=node):\n </s> add                 if maybe_make_parens_invisible_in_atom(\n                    child,\n                    parent=node,\n                    preview=preview,\n                ):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             )\n <mask> \n <mask> \n <mask> def foo(xxxx):\n <mask>     for (xxx_xxxx, _xxx_xxx, _xxx_xxxxx, xxx_xxxx) in xxxx:\n <mask>         for xxx in xxx_xxxx:\n <mask>             assert (\"x\" in xxx) or (xxx in xxx_xxx_xxxxx), (\n <mask>                 \"{0} xxxxxxx xx {1}, xxx {1} xx xxx xx xxxx xx xxx xxxx: xxx xxxx {2}\"\n <mask>                 .format(xxx_xxxx, xxx, xxxxxx.xxxxxxx(xxx_xxx_xxxxx))\n <mask>             )\n </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:\n </s> add def maybe_make_parens_invisible_in_atom(\n    node: LN,\n    parent: LN,\n    preview: bool = False,\n) -> bool: </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL): </s> remove         or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY\n </s> add         or (max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY and for_stmt_check) </s> remove             for (i, leaf) in enumerate(LL):\n </s> add             for i, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "tests/data/long_strings__regression.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     \"long_strings__regression\",\n <mask>     \"percent_precedence\",\n <mask>     \"one_element_subscript\",\n <mask> ]\n <mask> \n <mask> SOURCES: List[str] = [\n </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove         or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY\n </s> add         or (max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY and for_stmt_check) </s> add     remove_redundant_parens = auto() </s> remove         maybe_make_parens_invisible_in_atom(middle, parent=parent)\n </s> add         maybe_make_parens_invisible_in_atom(middle, parent=parent, preview=preview) </s> remove         for (i, leaf) in enumerate(LL):\n </s> add         for i, leaf in enumerate(LL): </s> remove         for (idx, leaf) in enumerate(LL):\n </s> add         for idx, leaf in enumerate(LL): </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import asyncio\n <mask> import logging\n <mask> from concurrent.futures import ThreadPoolExecutor\n <mask> from contextlib import contextmanager\n <mask> from functools import partial, wraps\n <mask> from io import BytesIO, TextIOWrapper\n <mask> import os\n <mask> from pathlib import Path\n <mask> import re\n <mask> import sys\n </s> Fix async blackd tests which won't fail currently (#966) </s> remove from typing import (\n    Any,\n    BinaryIO,\n    Callable,\n    Coroutine,\n    Generator,\n    List,\n    Tuple,\n    Iterator,\n    TypeVar,\n)\n </s> add from typing import Any, BinaryIO, Generator, List, Tuple, Iterator, TypeVar </s> remove     from aiohttp.test_utils import TestClient, TestServer\n </s> add     from aiohttp.test_utils import AioHTTPTestCase, unittest_run_loop\n    from aiohttp import web </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove     old_loop = policy.get_event_loop()\n </s> add  </s> remove         policy.set_event_loop(old_loop)\n </s> add  </s> remove def async_test(f: Callable[..., Coroutine[Any, None, R]]) -> Callable[..., None]:\n    @event_loop(close=True)\n    @wraps(f)\n    def wrapper(*args: Any, **kwargs: Any) -> None:\n        asyncio.get_event_loop().run_until_complete(f(*args, **kwargs))\n\n    return wrapper\n\n\n </s> add ", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> from pathlib import Path\n <mask> import re\n <mask> import sys\n <mask> from tempfile import TemporaryDirectory\n <mask> from typing import (\n <mask>     Any,\n <mask>     BinaryIO,\n <mask>     Callable,\n <mask>     Coroutine,\n <mask>     Generator,\n <mask>     List,\n <mask>     Tuple,\n <mask>     Iterator,\n <mask>     TypeVar,\n <mask> )\n <mask> import unittest\n <mask> from unittest.mock import patch, MagicMock\n <mask> \n <mask> from click import unstyle\n <mask> from click.testing import CliRunner\n </s> Fix async blackd tests which won't fail currently (#966) </s> remove from functools import partial, wraps\n </s> add from functools import partial </s> remove     from aiohttp.test_utils import TestClient, TestServer\n </s> add     from aiohttp.test_utils import AioHTTPTestCase, unittest_run_loop\n    from aiohttp import web </s> add         else:\n            raise exc </s> remove def async_test(f: Callable[..., Coroutine[Any, None, R]]) -> Callable[..., None]:\n    @event_loop(close=True)\n    @wraps(f)\n    def wrapper(*args: Any, **kwargs: Any) -> None:\n        asyncio.get_event_loop().run_until_complete(f(*args, **kwargs))\n\n    return wrapper\n\n\n </s> add  </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b\"what even ( is\")\n            self.assertEqual(response.status, 400)\n            content = await response.text()\n            self.assertTrue(\n                content.startswith(\"Cannot parse\"),\n                msg=f\"Expected error to start with 'Cannot parse', got {repr(content)}\",\n            )\n </s> add         response = await self.client.post(\"/\", data=b\"what even ( is\")\n        self.assertEqual(response.status, 400)\n        content = await response.text()\n        self.assertTrue(\n            content.startswith(\"Cannot parse\"),\n            msg=f\"Expected error to start with 'Cannot parse', got {repr(content)}\",\n        ) </s> remove         app = blackd.make_app()\n </s> add ", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from black import Feature, TargetVersion\n <mask> \n <mask> try:\n <mask>     import blackd\n <mask>     from aiohttp.test_utils import TestClient, TestServer\n <mask> except ImportError:\n <mask>     has_blackd_deps = False\n <mask> else:\n <mask>     has_blackd_deps = True\n <mask> \n </s> Fix async blackd tests which won't fail currently (#966) </s> remove from functools import partial, wraps\n </s> add from functools import partial </s> remove from typing import (\n    Any,\n    BinaryIO,\n    Callable,\n    Coroutine,\n    Generator,\n    List,\n    Tuple,\n    Iterator,\n    TypeVar,\n)\n </s> add from typing import Any, BinaryIO, Generator, List, Tuple, Iterator, TypeVar </s> add         else:\n            raise exc </s> remove     old_loop = policy.get_event_loop()\n </s> add  </s> remove def async_test(f: Callable[..., Coroutine[Any, None, R]]) -> Callable[..., None]:\n    @event_loop(close=True)\n    @wraps(f)\n    def wrapper(*args: Any, **kwargs: Any) -> None:\n        asyncio.get_event_loop().run_until_complete(f(*args, **kwargs))\n\n    return wrapper\n\n\n </s> add  </s> remove         policy.set_event_loop(old_loop)\n </s> add ", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> @contextmanager\n <mask> def event_loop(close: bool) -> Iterator[None]:\n <mask>     policy = asyncio.get_event_loop_policy()\n <mask>     old_loop = policy.get_event_loop()\n <mask>     loop = policy.new_event_loop()\n <mask>     asyncio.set_event_loop(loop)\n <mask>     try:\n <mask>         yield\n <mask> \n </s> Fix async blackd tests which won't fail currently (#966) </s> remove def async_test(f: Callable[..., Coroutine[Any, None, R]]) -> Callable[..., None]:\n    @event_loop(close=True)\n    @wraps(f)\n    def wrapper(*args: Any, **kwargs: Any) -> None:\n        asyncio.get_event_loop().run_until_complete(f(*args, **kwargs))\n\n    return wrapper\n\n\n </s> add  </s> remove         policy.set_event_loop(old_loop)\n </s> add  </s> remove     from aiohttp.test_utils import TestClient, TestServer\n </s> add     from aiohttp.test_utils import AioHTTPTestCase, unittest_run_loop\n    from aiohttp import web </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            source, expected = read_data(\"stub.pyi\")\n            response = await client.post(\n                \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n            )\n            self.assertEqual(response.status, 200)\n            self.assertEqual(await response.text(), expected)\n </s> add         source, expected = read_data(\"stub.pyi\")\n        response = await self.client.post(\n            \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n        )\n        self.assertEqual(response.status, 200)\n        self.assertEqual(await response.text(), expected)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace replace replace replace replace replace replace replace replace", "code_tokens": " <mask> \n <mask>     finally:\n <mask>         policy.set_event_loop(old_loop)\n <mask>         if close:\n <mask>             loop.close()\n <mask> \n <mask> \n <mask> def async_test(f: Callable[..., Coroutine[Any, None, R]]) -> Callable[..., None]:\n <mask>     @event_loop(close=True)\n <mask>     @wraps(f)\n <mask>     def wrapper(*args: Any, **kwargs: Any) -> None:\n <mask>         asyncio.get_event_loop().run_until_complete(f(*args, **kwargs))\n <mask> \n <mask>     return wrapper\n <mask> \n <mask> \n </s> Fix async blackd tests which won't fail currently (#966) </s> add     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n    def test_blackd_main(self) -> None:\n        with patch(\"blackd.web.run_app\"):\n            result = CliRunner().invoke(blackd.main, [])\n            if result.exception is not None:\n                raise result.exception\n            self.assertEqual(result.exit_code, 0)\n\n\nclass BlackDTestCase(AioHTTPTestCase):\n    async def get_application(self) -> web.Application:\n        return blackd.make_app()\n </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\",\n                data=b'print(\"hello\")\\n',\n                headers={blackd.LINE_LENGTH_HEADER: \"NaN\"},\n            )\n            self.assertEqual(response.status, 400)\n\n    @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n    def test_blackd_main(self) -> None:\n        with patch(\"blackd.web.run_app\"):\n            result = CliRunner().invoke(blackd.main, [])\n            if result.exception is not None:\n                raise result.exception\n            self.assertEqual(result.exit_code, 0)\n </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"NaN\"}\n        )\n        self.assertEqual(response.status, 400) </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n\n            async def check(header_value: str, expected_status: int = 400) -> None:\n                response = await client.post(\n                    \"/\",\n                    data=b\"what\",\n                    headers={blackd.PYTHON_VARIANT_HEADER: header_value},\n                )\n                self.assertEqual(response.status, expected_status)\n\n            await check(\"lol\")\n            await check(\"ruby3.5\")\n            await check(\"pyi3.6\")\n            await check(\"py1.5\")\n            await check(\"2.8\")\n            await check(\"py2.8\")\n            await check(\"3.0\")\n            await check(\"pypy3.0\")\n            await check(\"jython3.4\")\n </s> add         async def check(header_value: str, expected_status: int = 400) -> None:\n            response = await self.client.post(\n                \"/\", data=b\"what\", headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n            )\n            self.assertEqual(response.status, expected_status)\n\n        await check(\"lol\")\n        await check(\"ruby3.5\")\n        await check(\"pyi3.6\")\n        await check(\"py1.5\")\n        await check(\"2.8\")\n        await check(\"py2.8\")\n        await check(\"3.0\")\n        await check(\"pypy3.0\")\n        await check(\"jython3.4\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b'print(\"hello world\")\\n')\n            self.assertEqual(response.status, 204)\n            self.assertEqual(await response.read(), b\"\")\n </s> add         response = await self.client.post(\"/\", data=b'print(\"hello world\")\\n')\n        self.assertEqual(response.status, 204)\n        self.assertEqual(await response.read(), b\"\")", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     except Exception as exc:\n <mask>         if exc.__class__.__name__ == e:\n <mask>             unittest.skip(f\"Encountered expected exception {exc}, skipping\")\n <mask> \n <mask> \n <mask> class BlackRunner(CliRunner):\n <mask>     \"\"\"Modify CliRunner so that stderr is not merged with stdout.\n <mask> \n </s> Fix async blackd tests which won't fail currently (#966) </s> remove def async_test(f: Callable[..., Coroutine[Any, None, R]]) -> Callable[..., None]:\n    @event_loop(close=True)\n    @wraps(f)\n    def wrapper(*args: Any, **kwargs: Any) -> None:\n        asyncio.get_event_loop().run_until_complete(f(*args, **kwargs))\n\n    return wrapper\n\n\n </s> add  </s> add     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n    def test_blackd_main(self) -> None:\n        with patch(\"blackd.web.run_app\"):\n            result = CliRunner().invoke(blackd.main, [])\n            if result.exception is not None:\n                raise result.exception\n            self.assertEqual(result.exit_code, 0)\n\n\nclass BlackDTestCase(AioHTTPTestCase):\n    async def get_application(self) -> web.Application:\n        return blackd.make_app()\n </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\",\n                data=b'print(\"hello\")\\n',\n                headers={blackd.LINE_LENGTH_HEADER: \"NaN\"},\n            )\n            self.assertEqual(response.status, 400)\n\n    @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n    def test_blackd_main(self) -> None:\n        with patch(\"blackd.web.run_app\"):\n            result = CliRunner().invoke(blackd.main, [])\n            if result.exception is not None:\n                raise result.exception\n            self.assertEqual(result.exit_code, 0)\n </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"NaN\"}\n        )\n        self.assertEqual(response.status, 400) </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            source, expected = read_data(\"stub.pyi\")\n            response = await client.post(\n                \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n            )\n            self.assertEqual(response.status, 200)\n            self.assertEqual(await response.text(), expected)\n </s> add         source, expected = read_data(\"stub.pyi\")\n        response = await self.client.post(\n            \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n        )\n        self.assertEqual(response.status, 200)\n        self.assertEqual(await response.text(), expected) </s> remove     @async_test\n </s> add     @unittest_run_loop", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>             ff(THIS_FILE)\n <mask> \n <mask>     # TODO: remove these decorators once the below is released\n <mask>     # https://github.com/aio-libs/aiohttp/pull/3727\n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @unittest_run_loop\n </s> Fix async blackd tests which won't fail currently (#966) </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\",\n                data=b'print(\"hello\")\\n',\n                headers={blackd.LINE_LENGTH_HEADER: \"NaN\"},\n            )\n            self.assertEqual(response.status, 400)\n\n    @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n    def test_blackd_main(self) -> None:\n        with patch(\"blackd.web.run_app\"):\n            result = CliRunner().invoke(blackd.main, [])\n            if result.exception is not None:\n                raise result.exception\n            self.assertEqual(result.exit_code, 0)\n </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"NaN\"}\n        )\n        self.assertEqual(response.status, 400) </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b'print(\"hello world\")\\n')\n            self.assertEqual(response.status, 204)\n            self.assertEqual(await response.read(), b\"\")\n </s> add         response = await self.client.post(\"/\", data=b'print(\"hello world\")\\n')\n        self.assertEqual(response.status, 204)\n        self.assertEqual(await response.read(), b\"\")", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep replace keep replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>     # https://github.com/aio-libs/aiohttp/pull/3727\n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_request_needs_formatting(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             response = await client.post(\"/\", data=b\"print('hello world')\")\n <mask>             self.assertEqual(response.status, 200)\n <mask>             self.assertEqual(response.charset, \"utf8\")\n <mask>             self.assertEqual(await response.read(), b'print(\"hello world\")\\n')\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n </s> Fix async blackd tests which won't fail currently (#966) </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b'print(\"hello world\")\\n')\n            self.assertEqual(response.status, 204)\n            self.assertEqual(await response.read(), b\"\")\n </s> add         response = await self.client.post(\"/\", data=b'print(\"hello world\")\\n')\n        self.assertEqual(response.status, 204)\n        self.assertEqual(await response.read(), b\"\") </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n        )\n        self.assertEqual(response.status, 200)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace keep replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_request_no_change(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             response = await client.post(\"/\", data=b'print(\"hello world\")\\n')\n <mask>             self.assertEqual(response.status, 204)\n <mask>             self.assertEqual(await response.read(), b\"\")\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n </s> Fix async blackd tests which won't fail currently (#966) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b\"print('hello world')\")\n            self.assertEqual(response.status, 200)\n            self.assertEqual(response.charset, \"utf8\")\n            self.assertEqual(await response.read(), b'print(\"hello world\")\\n')\n </s> add         response = await self.client.post(\"/\", data=b\"print('hello world')\")\n        self.assertEqual(response.status, 200)\n        self.assertEqual(response.charset, \"utf8\")\n        self.assertEqual(await response.read(), b'print(\"hello world\")\\n') </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n        )\n        self.assertEqual(response.status, 501) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n        )\n        self.assertEqual(response.status, 200)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace replace replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask>             self.assertEqual(await response.read(), b\"\")\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_request_syntax_error(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             response = await client.post(\"/\", data=b\"what even ( is\")\n <mask>             self.assertEqual(response.status, 400)\n <mask>             content = await response.text()\n <mask>             self.assertTrue(\n <mask>                 content.startswith(\"Cannot parse\"),\n <mask>                 msg=f\"Expected error to start with 'Cannot parse', got {repr(content)}\",\n <mask>             )\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n </s> Fix async blackd tests which won't fail currently (#966) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b'print(\"hello world\")\\n')\n            self.assertEqual(response.status, 204)\n            self.assertEqual(await response.read(), b\"\")\n </s> add         response = await self.client.post(\"/\", data=b'print(\"hello world\")\\n')\n        self.assertEqual(response.status, 204)\n        self.assertEqual(await response.read(), b\"\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b\"print('hello world')\")\n            self.assertEqual(response.status, 200)\n            self.assertEqual(response.charset, \"utf8\")\n            self.assertEqual(await response.read(), b'print(\"hello world\")\\n')\n </s> add         response = await self.client.post(\"/\", data=b\"print('hello world')\")\n        self.assertEqual(response.status, 200)\n        self.assertEqual(response.charset, \"utf8\")\n        self.assertEqual(await response.read(), b'print(\"hello world\")\\n') </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n        )\n        self.assertEqual(response.status, 501) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep replace keep replace replace replace replace replace replace keep keep", "code_tokens": " <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_unsupported_version(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             response = await client.post(\n <mask>                 \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n <mask>             )\n <mask>             self.assertEqual(response.status, 501)\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n </s> Fix async blackd tests which won't fail currently (#966) </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            source, expected = read_data(\"stub.pyi\")\n            response = await client.post(\n                \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n            )\n            self.assertEqual(response.status, 200)\n            self.assertEqual(await response.text(), expected)\n </s> add         source, expected = read_data(\"stub.pyi\")\n        response = await self.client.post(\n            \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n        )\n        self.assertEqual(response.status, 200)\n        self.assertEqual(await response.text(), expected)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace keep replace replace replace replace replace replace", "code_tokens": " <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_supported_version(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             response = await client.post(\n <mask>                 \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n <mask>             )\n <mask>             self.assertEqual(response.status, 200)\n </s> Fix async blackd tests which won't fail currently (#966) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n        )\n        self.assertEqual(response.status, 501) </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            source, expected = read_data(\"stub.pyi\")\n            response = await client.post(\n                \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n            )\n            self.assertEqual(response.status, 200)\n            self.assertEqual(await response.text(), expected)\n </s> add         source, expected = read_data(\"stub.pyi\")\n        response = await self.client.post(\n            \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n        )\n        self.assertEqual(response.status, 200)\n        self.assertEqual(await response.text(), expected)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_invalid_python_variant(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask> \n <mask>             async def check(header_value: str, expected_status: int = 400) -> None:\n <mask>                 response = await client.post(\n <mask>                     \"/\",\n <mask>                     data=b\"what\",\n <mask>                     headers={blackd.PYTHON_VARIANT_HEADER: header_value},\n <mask>                 )\n <mask>                 self.assertEqual(response.status, expected_status)\n <mask> \n <mask>             await check(\"lol\")\n <mask>             await check(\"ruby3.5\")\n <mask>             await check(\"pyi3.6\")\n <mask>             await check(\"py1.5\")\n <mask>             await check(\"2.8\")\n <mask>             await check(\"py2.8\")\n <mask>             await check(\"3.0\")\n <mask>             await check(\"pypy3.0\")\n <mask>             await check(\"jython3.4\")\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n </s> Fix async blackd tests which won't fail currently (#966) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n        )\n        self.assertEqual(response.status, 501) </s> remove             async def check(header_value: str, expected_status: int) -> None:\n                response = await client.post(\n                    \"/\", data=code, headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n                )\n                self.assertEqual(response.status, expected_status)\n </s> add         async def check(header_value: str, expected_status: int) -> None:\n            response = await self.client.post(\n                \"/\", data=code, headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n            )\n            self.assertEqual(response.status, expected_status) </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask>             await check(\"jython3.4\")\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_pyi(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             source, expected = read_data(\"stub.pyi\")\n <mask>             response = await client.post(\n <mask>                 \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n <mask>             )\n <mask>             self.assertEqual(response.status, 200)\n <mask>             self.assertEqual(await response.text(), expected)\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n </s> Fix async blackd tests which won't fail currently (#966) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n\n            async def check(header_value: str, expected_status: int = 400) -> None:\n                response = await client.post(\n                    \"/\",\n                    data=b\"what\",\n                    headers={blackd.PYTHON_VARIANT_HEADER: header_value},\n                )\n                self.assertEqual(response.status, expected_status)\n\n            await check(\"lol\")\n            await check(\"ruby3.5\")\n            await check(\"pyi3.6\")\n            await check(\"py1.5\")\n            await check(\"2.8\")\n            await check(\"py2.8\")\n            await check(\"3.0\")\n            await check(\"pypy3.0\")\n            await check(\"jython3.4\")\n </s> add         async def check(header_value: str, expected_status: int = 400) -> None:\n            response = await self.client.post(\n                \"/\", data=b\"what\", headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n            )\n            self.assertEqual(response.status, expected_status)\n\n        await check(\"lol\")\n        await check(\"ruby3.5\")\n        await check(\"pyi3.6\")\n        await check(\"py1.5\")\n        await check(\"2.8\")\n        await check(\"py2.8\")\n        await check(\"3.0\")\n        await check(\"pypy3.0\")\n        await check(\"jython3.4\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b'print(\"hello world\")\\n')\n            self.assertEqual(response.status, 204)\n            self.assertEqual(await response.read(), b\"\")\n </s> add         response = await self.client.post(\"/\", data=b'print(\"hello world\")\\n')\n        self.assertEqual(response.status, 204)\n        self.assertEqual(await response.read(), b\"\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b\"print('hello world')\")\n            self.assertEqual(response.status, 200)\n            self.assertEqual(response.charset, \"utf8\")\n            self.assertEqual(await response.read(), b'print(\"hello world\")\\n')\n </s> add         response = await self.client.post(\"/\", data=b\"print('hello world')\")\n        self.assertEqual(response.status, 200)\n        self.assertEqual(response.charset, \"utf8\")\n        self.assertEqual(await response.read(), b'print(\"hello world\")\\n')", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace keep replace keep", "code_tokens": " <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_python_variant(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         code = (\n </s> Fix async blackd tests which won't fail currently (#966) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            source, expected = read_data(\"stub.pyi\")\n            response = await client.post(\n                \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n            )\n            self.assertEqual(response.status, 200)\n            self.assertEqual(await response.text(), expected)\n </s> add         source, expected = read_data(\"stub.pyi\")\n        response = await self.client.post(\n            \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n        )\n        self.assertEqual(response.status, 200)\n        self.assertEqual(await response.text(), expected) </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b'print(\"hello world\")\\n')\n            self.assertEqual(response.status, 204)\n            self.assertEqual(await response.read(), b\"\")\n </s> add         response = await self.client.post(\"/\", data=b'print(\"hello world\")\\n')\n        self.assertEqual(response.status, 204)\n        self.assertEqual(await response.read(), b\"\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n        )\n        self.assertEqual(response.status, 501)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace keep replace replace replace replace replace keep", "code_tokens": " <mask>             \"    pass\\n\"\n <mask>         )\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask> \n <mask>             async def check(header_value: str, expected_status: int) -> None:\n <mask>                 response = await client.post(\n <mask>                     \"/\", data=code, headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n <mask>                 )\n <mask>                 self.assertEqual(response.status, expected_status)\n <mask> \n </s> Fix async blackd tests which won't fail currently (#966) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n\n            async def check(header_value: str, expected_status: int = 400) -> None:\n                response = await client.post(\n                    \"/\",\n                    data=b\"what\",\n                    headers={blackd.PYTHON_VARIANT_HEADER: header_value},\n                )\n                self.assertEqual(response.status, expected_status)\n\n            await check(\"lol\")\n            await check(\"ruby3.5\")\n            await check(\"pyi3.6\")\n            await check(\"py1.5\")\n            await check(\"2.8\")\n            await check(\"py2.8\")\n            await check(\"3.0\")\n            await check(\"pypy3.0\")\n            await check(\"jython3.4\")\n </s> add         async def check(header_value: str, expected_status: int = 400) -> None:\n            response = await self.client.post(\n                \"/\", data=b\"what\", headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n            )\n            self.assertEqual(response.status, expected_status)\n\n        await check(\"lol\")\n        await check(\"ruby3.5\")\n        await check(\"pyi3.6\")\n        await check(\"py1.5\")\n        await check(\"2.8\")\n        await check(\"py2.8\")\n        await check(\"3.0\")\n        await check(\"pypy3.0\")\n        await check(\"jython3.4\") </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            source, expected = read_data(\"stub.pyi\")\n            response = await client.post(\n                \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n            )\n            self.assertEqual(response.status, 200)\n            self.assertEqual(await response.text(), expected)\n </s> add         source, expected = read_data(\"stub.pyi\")\n        response = await self.client.post(\n            \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n        )\n        self.assertEqual(response.status, 200)\n        self.assertEqual(await response.text(), expected) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n        )\n        self.assertEqual(response.status, 501) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep replace replace replace replace replace keep", "code_tokens": " <mask>                     \"/\", data=code, headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n <mask>                 )\n <mask>                 self.assertEqual(response.status, expected_status)\n <mask> \n <mask>             await check(\"3.6\", 200)\n <mask>             await check(\"py3.6\", 200)\n <mask>             await check(\"3.6,3.7\", 200)\n <mask>             await check(\"3.6,py3.7\", 200)\n <mask> \n <mask>             await check(\"2\", 204)\n <mask>             await check(\"2.7\", 204)\n <mask>             await check(\"py2.7\", 204)\n <mask>             await check(\"3.4\", 204)\n <mask>             await check(\"py3.4\", 204)\n <mask> \n </s> Fix async blackd tests which won't fail currently (#966) </s> remove             async def check(header_value: str, expected_status: int) -> None:\n                response = await client.post(\n                    \"/\", data=code, headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n                )\n                self.assertEqual(response.status, expected_status)\n </s> add         async def check(header_value: str, expected_status: int) -> None:\n            response = await self.client.post(\n                \"/\", data=code, headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n            )\n            self.assertEqual(response.status, expected_status) </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b'print(\"hello world\")\\n')\n            self.assertEqual(response.status, 204)\n            self.assertEqual(await response.read(), b\"\")\n </s> add         response = await self.client.post(\"/\", data=b'print(\"hello world\")\\n')\n        self.assertEqual(response.status, 204)\n        self.assertEqual(await response.read(), b\"\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n\n            async def check(header_value: str, expected_status: int = 400) -> None:\n                response = await client.post(\n                    \"/\",\n                    data=b\"what\",\n                    headers={blackd.PYTHON_VARIANT_HEADER: header_value},\n                )\n                self.assertEqual(response.status, expected_status)\n\n            await check(\"lol\")\n            await check(\"ruby3.5\")\n            await check(\"pyi3.6\")\n            await check(\"py1.5\")\n            await check(\"2.8\")\n            await check(\"py2.8\")\n            await check(\"3.0\")\n            await check(\"pypy3.0\")\n            await check(\"jython3.4\")\n </s> add         async def check(header_value: str, expected_status: int = 400) -> None:\n            response = await self.client.post(\n                \"/\", data=b\"what\", headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n            )\n            self.assertEqual(response.status, expected_status)\n\n        await check(\"lol\")\n        await check(\"ruby3.5\")\n        await check(\"pyi3.6\")\n        await check(\"py1.5\")\n        await check(\"2.8\")\n        await check(\"py2.8\")\n        await check(\"3.0\")\n        await check(\"pypy3.0\")\n        await check(\"jython3.4\") </s> remove     @async_test\n </s> add     @unittest_run_loop", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>             await check(\"py3.4\", 204)\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_line_length(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             response = await client.post(\n <mask>                 \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n <mask>             )\n <mask>             self.assertEqual(response.status, 200)\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n </s> Fix async blackd tests which won't fail currently (#966) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\",\n                data=b'print(\"hello\")\\n',\n                headers={blackd.LINE_LENGTH_HEADER: \"NaN\"},\n            )\n            self.assertEqual(response.status, 400)\n\n    @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n    def test_blackd_main(self) -> None:\n        with patch(\"blackd.web.run_app\"):\n            result = CliRunner().invoke(blackd.main, [])\n            if result.exception is not None:\n                raise result.exception\n            self.assertEqual(result.exit_code, 0)\n </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"NaN\"}\n        )\n        self.assertEqual(response.status, 400) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b'print(\"hello world\")\\n')\n            self.assertEqual(response.status, 204)\n            self.assertEqual(await response.read(), b\"\")\n </s> add         response = await self.client.post(\"/\", data=b'print(\"hello world\")\\n')\n        self.assertEqual(response.status, 204)\n        self.assertEqual(await response.read(), b\"\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n        )\n        self.assertEqual(response.status, 501) </s> remove     @async_test\n </s> add     @unittest_run_loop", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep replace keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep", "code_tokens": " <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_invalid_line_length(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             response = await client.post(\n <mask>                 \"/\",\n <mask>                 data=b'print(\"hello\")\\n',\n <mask>                 headers={blackd.LINE_LENGTH_HEADER: \"NaN\"},\n <mask>             )\n <mask>             self.assertEqual(response.status, 400)\n <mask> \n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     def test_blackd_main(self) -> None:\n <mask>         with patch(\"blackd.web.run_app\"):\n <mask>             result = CliRunner().invoke(blackd.main, [])\n <mask>             if result.exception is not None:\n <mask>                 raise result.exception\n <mask>             self.assertEqual(result.exit_code, 0)\n <mask> \n <mask> \n </s> Fix async blackd tests which won't fail currently (#966) </s> add     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n    def test_blackd_main(self) -> None:\n        with patch(\"blackd.web.run_app\"):\n            result = CliRunner().invoke(blackd.main, [])\n            if result.exception is not None:\n                raise result.exception\n            self.assertEqual(result.exit_code, 0)\n\n\nclass BlackDTestCase(AioHTTPTestCase):\n    async def get_application(self) -> web.Application:\n        return blackd.make_app()\n </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove     @async_test\n </s> add     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501)\n </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n        )\n        self.assertEqual(response.status, 501)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>             syms.assert_stmt,\n <mask>             syms.return_stmt,\n <mask>             # these ones aren't useful to end users, but they do please fuzzers\n <mask>             syms.for_stmt,\n <mask>             syms.del_stmt,\n <mask>         ]:\n </s> Check stability for both preview and non-preview styles (#3423)\n\nAnd fix parens-related test failures this found.\r\n\r\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove     _assert_format_equal(expected, actual)\n </s> add     if expected is not None:\n        _assert_format_equal(expected, actual) </s> add class FormatFailure(Exception):\n    \"\"\"Used to wrap failures when assert_format() runs in an extra mode.\"\"\"\n\n </s> remove     if not fast and source != expected:\n </s> add     if not fast and source != actual: </s> add from dataclasses import replace </s> remove         normal=x, perhaps=[list, {an: d, dict: 1.0}] as y, otherwise=something, q=t as u\n </s> add         normal=x, perhaps=[list, {\"x\": d, \"y\": 1.0}] as y, otherwise=something, q=t as u", "html_url": "https://github.com/psf/black/commit/159984a7351bfc4789bc0fc85b5f408112efca85", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep", "code_tokens": " <mask> \n <mask> \n <mask> match bar1:\n <mask>     case Foo(\n <mask>         normal=x, perhaps=[list, {an: d, dict: 1.0}] as y, otherwise=something, q=t as u\n <mask>     ):\n <mask>         pass\n </s> Check stability for both preview and non-preview styles (#3423)\n\nAnd fix parens-related test failures this found.\r\n\r\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove     if not fast and source != expected:\n </s> add     if not fast and source != actual: </s> remove     _assert_format_equal(expected, actual)\n </s> add     if expected is not None:\n        _assert_format_equal(expected, actual) </s> add class FormatFailure(Exception):\n    \"\"\"Used to wrap failures when assert_format() runs in an extra mode.\"\"\"\n\n </s> add from dataclasses import replace </s> add             syms.except_clause,\n            syms.funcdef,", "html_url": "https://github.com/psf/black/commit/159984a7351bfc4789bc0fc85b5f408112efca85", "file_name": "tests/data/py_310/pattern_matching_extras.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> import sys\n <mask> import unittest\n <mask> from contextlib import contextmanager\n <mask> from functools import partial\n <mask> from pathlib import Path\n <mask> from typing import Any, Iterator, List, Optional, Tuple\n <mask> \n </s> Check stability for both preview and non-preview styles (#3423)\n\nAnd fix parens-related test failures this found.\r\n\r\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove     _assert_format_equal(expected, actual)\n </s> add     if expected is not None:\n        _assert_format_equal(expected, actual) </s> remove     if not fast and source != expected:\n </s> add     if not fast and source != actual: </s> add class FormatFailure(Exception):\n    \"\"\"Used to wrap failures when assert_format() runs in an extra mode.\"\"\"\n\n </s> remove         normal=x, perhaps=[list, {an: d, dict: 1.0}] as y, otherwise=something, q=t as u\n </s> add         normal=x, perhaps=[list, {\"x\": d, \"y\": 1.0}] as y, otherwise=something, q=t as u </s> add             syms.except_clause,\n            syms.funcdef,", "html_url": "https://github.com/psf/black/commit/159984a7351bfc4789bc0fc85b5f408112efca85", "file_name": "tests/util.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def assert_format(\n <mask>     source: str,\n <mask>     expected: str,\n <mask>     mode: black.Mode = DEFAULT_MODE,\n </s> Check stability for both preview and non-preview styles (#3423)\n\nAnd fix parens-related test failures this found.\r\n\r\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove     _assert_format_equal(expected, actual)\n </s> add     if expected is not None:\n        _assert_format_equal(expected, actual) </s> remove     if not fast and source != expected:\n </s> add     if not fast and source != actual: </s> add from dataclasses import replace </s> remove         normal=x, perhaps=[list, {an: d, dict: 1.0}] as y, otherwise=something, q=t as u\n </s> add         normal=x, perhaps=[list, {\"x\": d, \"y\": 1.0}] as y, otherwise=something, q=t as u </s> add             syms.except_clause,\n            syms.funcdef,", "html_url": "https://github.com/psf/black/commit/159984a7351bfc4789bc0fc85b5f408112efca85", "file_name": "tests/util.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace keep keep", "code_tokens": " <mask>     separate from TargetVerson Mode configuration.\n <mask>     \"\"\"\n <mask>     actual = black.format_str(source, mode=mode)\n <mask>     _assert_format_equal(expected, actual)\n <mask>     # It's not useful to run safety checks if we're expecting no changes anyway. The\n <mask>     # assertion right above will raise if reality does actually make changes. This just\n <mask>     # avoids wasted CPU cycles.\n <mask>     if not fast and source != expected:\n <mask>         # Unfortunately the AST equivalence check relies on the built-in ast module\n <mask>         # being able to parse the code being formatted. This doesn't always work out\n </s> Check stability for both preview and non-preview styles (#3423)\n\nAnd fix parens-related test failures this found.\r\n\r\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> add class FormatFailure(Exception):\n    \"\"\"Used to wrap failures when assert_format() runs in an extra mode.\"\"\"\n\n </s> add from dataclasses import replace </s> add             syms.except_clause,\n            syms.funcdef, </s> remove         normal=x, perhaps=[list, {an: d, dict: 1.0}] as y, otherwise=something, q=t as u\n </s> add         normal=x, perhaps=[list, {\"x\": d, \"y\": 1.0}] as y, otherwise=something, q=t as u", "html_url": "https://github.com/psf/black/commit/159984a7351bfc4789bc0fc85b5f408112efca85", "file_name": "tests/util.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep replace keep keep keep keep", "code_tokens": " <mask>         ctx.exit(0)\n <mask>         return\n <mask> \n <mask>     elif len(sources) == 1:\n <mask>         return_code = run_single_file_mode(\n <mask>             line_length, check, fast, quiet, write_back, sources[0]\n <mask>         )\n <mask>     else:\n <mask>         return_code = run_multi_file_mode(line_length, fast, quiet, write_back, sources)\n <mask>     ctx.exit(return_code)\n <mask> \n <mask> \n <mask> def run_single_file_mode(\n </s> Simplify single-file vs. multi-file modes </s> remove def run_multi_file_mode(\n    line_length: int,\n    fast: bool,\n    quiet: bool,\n    write_back: WriteBack,\n    sources: List[Path],\n) -> int:\n    loop = asyncio.get_event_loop()\n    executor = ProcessPoolExecutor(max_workers=os.cpu_count())\n    return_code = 1\n    try:\n        return_code = loop.run_until_complete(\n            schedule_formatting(\n                sources, line_length, write_back, fast, quiet, loop, executor\n            )\n        )\n    finally:\n        shutdown(loop)\n        return return_code\n\n\n </s> add  </s> remove def run_single_file_mode(\n    line_length: int,\n    check: bool,\n    fast: bool,\n    quiet: bool,\n    write_back: WriteBack,\n    src: Path,\n </s> add def reformat_one(\n    src: Path, line_length: int, fast: bool, quiet: bool, write_back: WriteBack </s> remove     report = Report(check=check, quiet=quiet)\n </s> add     \"\"\"Reformat a single file under `src` without spawning child processes.\n\n    If `quiet` is True, non-error messages are not output. `line_length`,\n    `write_back`, and `fast` options are passed to :func:`format_file_in_place`.\n    \"\"\"\n    report = Report(check=write_back is WriteBack.NO, quiet=quiet)", "html_url": "https://github.com/psf/black/commit/15d5e36ea38988084584639b02aafcaaa2744dcf", "file_name": "black.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace keep replace keep keep keep", "code_tokens": " <mask> \n <mask> def run_single_file_mode(\n <mask>     line_length: int,\n <mask>     check: bool,\n <mask>     fast: bool,\n <mask>     quiet: bool,\n <mask>     write_back: WriteBack,\n <mask>     src: Path,\n <mask> ) -> int:\n <mask>     report = Report(check=check, quiet=quiet)\n <mask>     try:\n <mask>         changed = Changed.NO\n <mask>         if not src.is_file() and str(src) == \"-\":\n </s> Simplify single-file vs. multi-file modes </s> remove def run_multi_file_mode(\n    line_length: int,\n    fast: bool,\n    quiet: bool,\n    write_back: WriteBack,\n    sources: List[Path],\n) -> int:\n    loop = asyncio.get_event_loop()\n    executor = ProcessPoolExecutor(max_workers=os.cpu_count())\n    return_code = 1\n    try:\n        return_code = loop.run_until_complete(\n            schedule_formatting(\n                sources, line_length, write_back, fast, quiet, loop, executor\n            )\n        )\n    finally:\n        shutdown(loop)\n        return return_code\n\n\n </s> add  </s> remove         return_code = run_multi_file_mode(line_length, fast, quiet, write_back, sources)\n </s> add         loop = asyncio.get_event_loop()\n        executor = ProcessPoolExecutor(max_workers=os.cpu_count())\n        return_code = 1\n        try:\n            return_code = loop.run_until_complete(\n                schedule_formatting(\n                    sources, line_length, write_back, fast, quiet, loop, executor\n                )\n            )\n        finally:\n            shutdown(loop) </s> remove         return_code = run_single_file_mode(\n            line_length, check, fast, quiet, write_back, sources[0]\n        )\n </s> add         return_code = reformat_one(sources[0], line_length, fast, quiet, write_back)", "html_url": "https://github.com/psf/black/commit/15d5e36ea38988084584639b02aafcaaa2744dcf", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         report.failed(src, str(exc))\n <mask>     return report.return_code\n <mask> \n <mask> \n <mask> def run_multi_file_mode(\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     quiet: bool,\n <mask>     write_back: WriteBack,\n <mask>     sources: List[Path],\n <mask> ) -> int:\n <mask>     loop = asyncio.get_event_loop()\n <mask>     executor = ProcessPoolExecutor(max_workers=os.cpu_count())\n <mask>     return_code = 1\n <mask>     try:\n <mask>         return_code = loop.run_until_complete(\n <mask>             schedule_formatting(\n <mask>                 sources, line_length, write_back, fast, quiet, loop, executor\n <mask>             )\n <mask>         )\n <mask>     finally:\n <mask>         shutdown(loop)\n <mask>         return return_code\n <mask> \n <mask> \n <mask> async def schedule_formatting(\n <mask>     sources: List[Path],\n <mask>     line_length: int,\n <mask>     write_back: WriteBack,\n <mask>     fast: bool,\n </s> Simplify single-file vs. multi-file modes </s> remove         return_code = run_multi_file_mode(line_length, fast, quiet, write_back, sources)\n </s> add         loop = asyncio.get_event_loop()\n        executor = ProcessPoolExecutor(max_workers=os.cpu_count())\n        return_code = 1\n        try:\n            return_code = loop.run_until_complete(\n                schedule_formatting(\n                    sources, line_length, write_back, fast, quiet, loop, executor\n                )\n            )\n        finally:\n            shutdown(loop) </s> remove def run_single_file_mode(\n    line_length: int,\n    check: bool,\n    fast: bool,\n    quiet: bool,\n    write_back: WriteBack,\n    src: Path,\n </s> add def reformat_one(\n    src: Path, line_length: int, fast: bool, quiet: bool, write_back: WriteBack </s> remove         return_code = run_single_file_mode(\n            line_length, check, fast, quiet, write_back, sources[0]\n        )\n </s> add         return_code = reformat_one(sources[0], line_length, fast, quiet, write_back) </s> remove     report = Report(check=check, quiet=quiet)\n </s> add     \"\"\"Reformat a single file under `src` without spawning child processes.\n\n    If `quiet` is True, non-error messages are not output. `line_length`,\n    `write_back`, and `fast` options are passed to :func:`format_file_in_place`.\n    \"\"\"\n    report = Report(check=write_back is WriteBack.NO, quiet=quiet)", "html_url": "https://github.com/psf/black/commit/15d5e36ea38988084584639b02aafcaaa2744dcf", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         if leaves:\n <mask>             # Since body is a new indent level, remove spurious leading whitespace.\n <mask>             normalize_prefix(leaves[0], inside_brackets=True)\n <mask>             # Ensure a trailing comma when expected.\n <mask>             if original.is_import and len(leaves) == 1:\n <mask>                 leaves.append(Leaf(token.COMMA, \",\"))\n <mask>     # Populate the line\n <mask>     for leaf in leaves:\n <mask>         result.append(leaf, preformatted=True)\n <mask>         for comment_after in original.comments_after(leaf):\n <mask>             result.append(comment_after, preformatted=True)\n </s> Add trailing comma for single `as` imports, too </s> add from com.my_lovely_company.my_lovely_team.my_lovely_project.my_lovely_component import (\n    MyLovelyCompanyTeamProjectComponent,  # NOT DRY\n)\nfrom com.my_lovely_company.my_lovely_team.my_lovely_project.my_lovely_component import (\n    MyLovelyCompanyTeamProjectComponent as component,  # DRY\n)\n </s> add .. autofunction:: black.bracket_split_build_line\n", "html_url": "https://github.com/psf/black/commit/1610fd6bc5d594c4f27698825913d2f791d3ea02", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> Split functions\n <mask> ---------------\n <mask> \n <mask> .. autofunction:: black.bracket_split_succeeded_or_raise\n <mask> \n <mask> .. autofunction:: black.delimiter_split\n <mask> \n </s> Add trailing comma for single `as` imports, too </s> add from com.my_lovely_company.my_lovely_team.my_lovely_project.my_lovely_component import (\n    MyLovelyCompanyTeamProjectComponent,  # NOT DRY\n)\nfrom com.my_lovely_company.my_lovely_team.my_lovely_project.my_lovely_component import (\n    MyLovelyCompanyTeamProjectComponent as component,  # DRY\n)\n </s> remove             if original.is_import and len(leaves) == 1:\n                leaves.append(Leaf(token.COMMA, \",\"))\n </s> add             if original.is_import:\n                if leaves[-1].type != token.COMMA:\n                    leaves.append(Leaf(token.COMMA, \",\"))", "html_url": "https://github.com/psf/black/commit/1610fd6bc5d594c4f27698825913d2f791d3ea02", "file_name": "docs/reference/reference_functions.rst"}
